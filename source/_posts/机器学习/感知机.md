---
title: 感知机
date: 2022-09-07 17:46:19
tags: 
- 机器学习
categories: 
- 机器学习
---

<center>
引言：感知机是神经网络与支持向量机的基础
</center>

<!--more-->

# 感知机

## 感知机

> **感知机 perceptron** 是二类分类的线性模型，在输入特征向量后，可以输出类别，取+1与-1二值

感知机是一个**判别模型**，目的是求出可以将训练数据线性划分的分离**超平面**

感知机的数据必须满足**线性可分性**，即存在一个超平面可以将正实例点和负实例点完全分开

对于只有两个输入属性的数据，此时的超平面就是一条线

我们知道方法=模型+策略+算法，本文的感知机=`sign(ω·x+b)`+损失函数+梯度下降算法

## 模型

### 定义

感知机是一个判别模型，这意味着我们不需要求概率分布P(x,y)就可以得到决策函数：

```
f(x) = sign(ω·x+b)
```

参数注意：

- `ω`表示**权值向量**，其与向量`x`的点积`ω·x`为一个标量
- `b`表示**偏置 bias**
- `sign(x)`是符号函数，`x>=0`值为+1，`x<0`值为-1

因为感知机是一个线性分类模型，因此我们的**假设空间**就是全体线性方程集合`{f|f(x)=ω·x+b}`

我们要做的就是从假设空间中找出一个合适的模型

### 几何解释

假设特征空间为二维平面，如图所示：

![感知机模型](http://img.yesmylord.cn//image-20220908172849997.png)

- `ω`此时就是法向量
- `b`为截距
- 坐标原点到直线的距离为`-b/||ω||`

在我们规定`ω`的方向后，如图，线上及线的右上方就为+1，左下方为-1

## 策略

为了从假设空间找出合适的模型，我们需要确定一个学习策略，就是定义一个损失函数并将其最小化

对于感知机来说，有正确的分类就有**误分类**，如果统计误分类的个数，这个数将是离散的，不是对于`ω`和`b`的连续可导函数

因此我们可以选择求**误分类点到超平面的总距离**

### 损失函数

假设实例`(xi, yi)`被误分类，代入xi应该得到1，但是误分类的结果为-1

因此就有此不等式成立：`-yi(ω·x+b)>0`

我们还知道点到直线距离为：`|ω·x+b|/||ω||`

设误分类点集合为M，忽略`-1/||ω||`，就得到了如图所示的损失函数，我们要做的就是将此损失函数求得最小

![损失函数](http://img.yesmylord.cn//image-20220908183530529.png)

## 算法

求损失函数的最小的最优化问题，此处使用**随机梯度下降**

> 随机梯度下降：任意选一个初始值`ω`、`b`，通常为0，然后每次随机选择一个实例，如果其分类错误，就更新`ω`与`b`，直到每一个实例都分类正确为止

### 原始形式

![损失函数](http://img.yesmylord.cn//image-20220908183530529.png)

损失函数分别对ω与b求偏导，就可以得到**梯度**，然后去更新ω与b，如此反复

![原始形式步骤](http://img.yesmylord.cn//image-20220908204137767.png)

### 对偶形式

相比原始形式，对偶形式其实最大的变化就是需要**提前计算样本点的内积**，也就说可以用一个矩阵提前存储样本点的内积，这样可以大大加快效率

![对偶形式](http://img.yesmylord.cn//image-20220908204219147.png)

## 参考链接

- 《统计学习方法》

- [刘建平大佬的博客](https://www.cnblogs.com/pinard/p/6042320.html)：学完了这章才看到大佬的博客！！十个赞，这章结束之后不会更新统计学习的博客了，可能会有一些汇总，但是知识体系这边完全可以看这个博客





