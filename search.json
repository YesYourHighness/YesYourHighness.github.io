[{"title":"Git认识与简单使用","url":"/2019/07/29/Git/Git%E8%AE%A4%E8%AF%86%E4%B8%8E%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","content":"\n引言：\n\ngit是什么？为什么要学git？\ngit上半部分\n\n\n\n\n\nGit简介Git是什么？\n世界上最先进的分布式版本控制系统。\n什么是版本控制系统？记录每次文件的改动，还可以让朋友协作编辑它。\n省去自己整理文件的麻烦了\nGit诞生Linus创建了Linux之后。对于全世界的热心程序员发来的linux代码他和他的团队根本照顾不来。\n于是Linus选择了一个商业的版本控制系统BitKeeper，BitKeeper的东家BitMover公司出于人道主义精神，授权Linux社区免费使用这个版本控制系统。\n但是，牛人们想破解BitKeeper的协议，被BitMover公司发现了（监控工作做得不错！），于是BitMover公司怒了，要收回Linux社区的免费使用权。\nLinus花了两周时间自己用C写了一个分布式版本控制系统，这就是Git！\n一个月之内，Linux系统的源码已经由Git管理了！\n2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub。\n集中式vs分布式\n 集中式\n\n版本库存放在中央服务器，干活用自己的电脑。需要联网才能工作\n好比是一个图书馆，自己借书阅读，填上笔记之后再还回去（当然现实中不能给书加笔记）\n\n分布式\n\n版本库在自己的电脑上，工作的时候不需要联网，互相间推送一下，就可以修改啦\n创建使用版本库创建创建一个文件夹\n进入这个文件夹\n输入命令，把这个文件夹变成仓库\ngit initInitialized empty Git repository in D:/newTemp/.git/\n此时文件夹下多了一个.git文件，又来跟踪管理版本库（这个文件是一个隐藏文件）\n把文件添加到版本库注意：\n所有的版本控制系统，只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等\n版本控制系统可以告诉你每次的改动，\n比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。\n而图片、视频这些二进制文件，没法跟踪文件的变化，\n只能把二进制文件每次改动串起来，只知道图片从100KB改成了120KB，其他无法了解\n还有就是不要使用记事本编辑文件，否则可能会出现莫名其妙的Bug\n\n把一个文件放到仓库只需要两步\n假设我们有一个nihao.txt的文件\n他的内容是hello world\n\n把文件放在仓库文件下，输入git add nihao.txt\n输入git commit -m &quot;wrote a nihao file&quot;\n\n$ git commit -m &quot;第一次使用git添加了一个文件&quot;[master (root-commit) 51eb79a] 第一次使用git添加了一个文件 1 file changed, 1 insertion(+) create mode 100644 nihao.txt\n\n-m后面输入的是本次提交的说明，可以输入本次提交项目的信息\n提示 1 file changed,1 insertion（一个文件被改动，插入了一行内容）那么就成功了\n可以多次add之后一次性commit\n查看仓库状态我们成功的添加并且提交了一个nihao.txt文件\n现在我们更改一下文件的内容\n添加一行内容bye world\n运行git status查看仓库的当前状态\n$ git statusOn branch masterChanges not staged for commit:  (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)  (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory)        modified:   nihao.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)\n输出信息告诉我们\nnihao.txt已经被修改过了，但是还没有提交修改\n使用git diff查看修改的内容\n$ git diffdiff --git a/nihao.txt b/nihao.txtindex 95d09f2..0bf3550 100644--- a/nihao.txt+++ b/nihao.txt@@ -1 +1,2 @@-hello world\\ No newline at end of file+hello world+bye world\\ No newline at end of file\n通过信息告诉我们，我们添加了一行内容bye world\n我们再次输入git add命令更新文件\n然后再次输入git status\n$ git statusOn branch masterChanges to be committed:  (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)        modified:   nihao.txt\n告诉我们将要提交的修改包括nihao.txt\n我们可以继续下一步git commit了\n$ git commit -m &quot;修改了文件内容&quot;[master 8ced12a] 修改了文件内容 1 file changed, 2 insertions(+), 1 deletion(-)\n这时候告诉我，一个文件被修改，有两行内容，一个删除（为什么会出现一个删除？？）\n我们再再输入一次git status\n$ git statusOn branch masternothing to commit, working tree clean\nGit告诉我们当前没有需要提交的修改，而且，工作目录是干净（working tree clean）的\n查看历史记录使用命令git log查看历史记录\n$ git logcommit 8ced12a07d31eeb810eea3170d337eeab547259e (HEAD -&gt; master)Author: YesYourHighness &lt;1046467756@qq.com&gt;Date:   Sun Jul 28 16:38:14 2019 +0800    修改了文件内容commit 51eb79a431991cdc8dc1a78f9bab6f3153808a3bAuthor: YesYourHighness &lt;1046467756@qq.com&gt;Date:   Sun Jul 28 16:24:44 2019 +0800    第一次使用git添加了一个文件\n我们一共修改了两次文件，显示顺序是从最近到最远\n如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数：\n$ git log --pretty=oneline8ced12a07d31eeb810eea3170d337eeab547259e (HEAD -&gt; master) 修改了文件内容51eb79a431991cdc8dc1a78f9bab6f3153808a3b 第一次使用git添加了一个文件\n简单粗暴的显示了一大堆数字字母组合数，它其实是一个十六进制的非常大的数，是有SHA1计算出来的，为了避免大家都用1,2,3…作为版本号导致冲突，所以进行了这样的编排\n回退版本首先，git必须知道当前版本是哪一个版本\nGit中，当前版本用HEAD表示，例如上次输入log命令查询得到的第一条信息，其后有(HEAD -&gt; master) \n上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。\n输入git reset命令\n$ git reset --hard HEAD^HEAD is now at 51eb79a 第一次使用git添加了一个文件\n--hard后面再讲，放心使用\n打开文件发现回到了第一个版本的状态，只有一行hello world\n输入git log我们再看一次当前的版本库的状态\n$ git logcommit 51eb79a431991cdc8dc1a78f9bab6f3153808a3b (HEAD -&gt; master)Author: YesYourHighness &lt;1046467756@qq.com&gt;Date:   Sun Jul 28 16:24:44 2019 +0800    第一次使用git添加了一个文件\n只剩下了第一代的版本\n可是….\n我又后悔了，怎么办\n只要你的命令行窗口还没有关掉，往上查找，找到上一个版本的commit id\n输入git reset --hard 8ced12\n版本号写前几位即可，git会自动查找\n我们惊喜的发现，没错，文件又回来了\nGit的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是移动了一下指针而已\n可是，我把命令行窗口关掉了怎么办！！\n输入git reflog来查找那次的id，git能然你来回穿梭\n工作区和暂存区\n工作区\n\n电脑里能看到的目录，比如说你的仓库的文件夹就是一个目录\n但是不包括那个.git文件，这是Git的版本库\n\n暂存区\n\ngit的版本库内有很多东西\n最重要的就是stage(或者叫index)的暂存区，\n还有git为我们自动创建的第一个分支master，\n以及指向master的一个指针HEAD\n现在我们新建一个文件，放在仓库的目录下\n再修改一下nihao.txt文件\n输入git status\n$ git statusOn branch masterChanges not staged for commit:  (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)  (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory)        modified:   nihao.txtUntracked files:  (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed)        dierge.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)\n清晰的告诉我们，nihao.txt被修改了,而dierge.txt还没被添加，所以他的状态是untracked\n使用git add添加这两个文件，再用git status查看内容\n$ git statusOn branch masterChanges to be committed:  (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)        new file:   dierge.txt        modified:   nihao.txt\n现在，暂存区的状态就变成了这个样子\n所以git add命令就相当于把所有修改放在了暂存区，\n然后，\ngit commit把暂存区所有的修改提交到分支\n再一次运行git commit把改动提交到分支\n管理修改现在，我们还是给nihao.txt添加一段文字“一次添加”\ngit add再加上git status\n$ git statusOn branch masterChanges to be committed:  (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)        modified:   nihao.txt\n然后再加上一段文字“二次添加”\n然后提交git commit\n$ git commit -m &#x27;二次添加会显示吗&#x27;[master 0e6b9f4] 二次添加会显示吗 1 file changed, 2 insertions(+), 1 deletion(-)\n提交后再查看状态git status,发现第二次的修改没有被提交\n用git diff HEAD -- nihao.txt命令可以查看工作区和版本库里面最新版本的区别\n$ git diff HEAD -- nihao.txtdiff --git a/nihao.txt b/nihao.txtindex c514222..e4ab4ba 100644--- a/nihao.txt+++ b/nihao.txt@@ -1,4 +1,5 @@ hello world bye world change again-一次添加\\ No newline at end of file+一次添加+二次添加\\ No newline at end of file\n发现确实没有提交上去\n过程：第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git commit\n当我们git add时，工作区的第一次修改放入了暂存区，准备提交，但是第二次修改没有进去，所以只是提交了第一次的修改\n我们再git add和git commit提交第二次\n撤销修改我们难免犯错误，搞错了一行\n我们在nihao.txt这个文件加一行 “stupid boss”\n工作区发现如果我们发现的及时，在工作区就发现了这个错误\n立刻输入git checkout -- nihao.txt\n输入git status发现一切clean\n暂存区发现暂存区发现了错误，不要慌张\n输入git reset HEAD nihao.txt，这个命令可以回退版本，也可以把暂存区的修改撤销\n这样就回到了工作区\n再次输入git reset HEAD nihao.txt\n版本库发现如果还没有推到远程版本库，那么赶快版本回退吧\n远程版本库发现两个解决办法\n\n跑路\n等死\n\n删除文件现在我们不想要dierge.txt这个文件了，怎么删除\n本地删除文件rm dierge.txt\n这时候git已经检测到，你把它删掉了，\n输入git status检查状态\n$ git statusOn branch masterChanges not staged for commit:  (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed)  (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory)        deleted:    dierge.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)\n提示我们删掉了一个文件\n现在有两个选择\n\n删除文件\n恢复文件\n\n\n当我们铁了心就是想删除时\n\n输入git rm dierge.txt删除文件，并且git commit推送\n$ git commit -m &#x27;删除了dierge.txt&#x27;[master fdd980b] 删除了dierge.txt 1 file changed, 1 deletion(-) delete mode 100644 dierge.txt\n\n\n当我们删错了的时候\n\n输入 git checkout -- dierge.txt\n这个命令其实是用版本库里的版本替换工作区的版本，无论是修改还是删除，都可以还原\n如果你删掉的文件没有被添加到版本库就被删除，那就真的没有了\n","categories":["Git"],"tags":["Git"]},{"title":"XML","url":"/2019/09/03/Html/XML/","content":"\n引言：\n\nXML\n\n\n\n\n\n\nXMLXML也是一门标记语言\n了解\n概念Extensible Markup Language 可扩展标记语言\n\n可扩展：标签都是自定义的\n\nXML的发展历程\n\nw3c(万维网联盟)创建了这两个语言，最早出现了HTML，由于浏览器之间的竞争，HTML发展的缓慢，w3c一度想要放弃HTML，想要用XML来替代HTML，当时XML比HTML语法严谨外没有功能拓展，也不受青睐\n最后XML走了另一条路，成为了配置文件的内容\n例如properties如此存数据\nname = zhangsanage =23gender = nan\n但是XML更加清晰\n&lt;user&gt;    &lt;name&gt;zhangsan&lt;/name&gt;    &lt;age&gt;age&lt;/age&gt;&lt;/user&gt;\n\nXML与HTML的区别\n\n\nXML标签自定义，HTML标签预定义\nXML语法严格，HTML松散\nXML存储数据，HTML展示数据\n\n\n功能\n\n\n配置文件\n在网络中传输\n\n语法基本语法\n文档后缀名 .xml\n文档声明必须写且必须顶第一行写\n必须有根标签\n属性必须使用引号引起，单双都可以\n标签随意定义，但必须闭合\n标签区分大小写\n\n快速入门&lt;?xml version=&#x27;1.0&#x27;?&gt;&lt;users&gt;\t&lt;user id=&#x27;1&#x27;&gt;\t\t&lt;name&gt;zhangsan&lt;/name&gt;\t\t&lt;age&gt;23&lt;/age&gt;\t\t&lt;gender&gt;male&lt;/gender&gt;\t&lt;/user&gt;\t&lt;user id=&#x27;1&#x27;&gt;\t\t&lt;name&gt;lisi&lt;/name&gt;\t\t&lt;age&gt;20&lt;/age&gt;\t\t&lt;gender&gt;female&lt;/gender&gt;\t&lt;/user&gt;&lt;/users&gt;\n\n\n组成部分\n文档声明\n格式&lt;?xml 属性列表 ?&gt;\n属性列表\nversion 版本号,必须的属性，写1.0即可\nencoding 编码方式，告知解析引擎当前文档使用的字符集，默认ISO-8859-1\nstandalone 是否依赖其他文件,取值有yes和no\n\n\n\n\n指令(了解) &lt;?xml-stylesheet type=&quot;text/css&quot; href=&quot;a.css&quot;?&gt;\n name&#123;color: red;&#125;\n标签\n\n命名规则    1. 名称不能以数字或符号开头    2. 名称不能以xml开始    3. 名称不能有空格\n\n属性\n 属性必须有引号    \n id属性值唯一\n\n文本内容\n 代码内容使用CDATA区，该区的代码原样展示\n  &lt;![CDATA[    代码写在这里]]&gt;\n约束\n\n约定XML文档的书写规则，用来给框架程序解析，也用来给程序员约定书写规范\n作为框架的使用者的我们\n只需要\n\n简单的读懂\n会引用\n\n分类：\n\nDTD：一种简单的约束技术\nSchema：复杂的约束技术\n\nDTD引入DTD文档到XML文档中\n分两种\n\n内部dtd ：将约束规则定义在xml文档中\n外部dtd ：将约束的规则定义在外部的dtd文件中\n本地：&lt;!DOCTYPE 根标签名 SYSTEM &quot;dtd文件的位置&quot;&gt;\n网络：&lt;!DOCTYPE 根标签名 PUBLIC &quot;dtd文件名字&quot; &quot;dtd文件的位置URL&quot;&gt;\n\n\n\ndtd文档\n&lt;!--dtd文档--&gt;&lt;!ELEMENT students (student*) &gt;&lt;!--正则表达式，* 表示写0次或多次--&gt;&lt;!ELEMENT student (name,age,sex)&gt;&lt;!ELEMENT name (#PCDATA)&gt;&lt;!ELEMENT age (#PCDATA)&gt;&lt;!ELEMENT sex (#PCDATA)&gt;&lt;!--xml必须要按照这个顺序写，否则会报错--&gt;&lt;!ATTLIST student number ID #REQUIRED&gt;&lt;!--#REQUIRED表示这个number是必须含有的--&gt;\nxml文档\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE students SYSTEM &quot;student.dtd&quot;&gt;&lt;students&gt;\t&lt;student number=&quot;s1&quot;&gt;\t\t&lt;name&gt;tom&lt;/name&gt;\t\t&lt;age&gt;18&lt;/age&gt;\t\t&lt;sex&gt;male&lt;/sex&gt;\t&lt;/student&gt;\t&lt;student number=&quot;s2&quot;&gt;\t\t&lt;name&gt;tom&lt;/name&gt;\t\t&lt;age&gt;18&lt;/age&gt;\t\t&lt;sex&gt;male&lt;/sex&gt;\t&lt;/student&gt;&lt;/students&gt;\n\nSchemadtd虽然简单，但是有着诸多问题，比如它并不能规定文本的内容\nSchema解决了这个问题\n后缀名 .xsd\nxsd文档读懂注释处即可\n&lt;?xml version=&quot;1.0&quot;?&gt;&lt;xsd:schema xmlns=&quot;http://www.itcast.cn/xml&quot;        xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot;        &lt;!--这里是定义了一个别名xsd来代表后面的一串地址--&gt;        &lt;!--如果xmlns后面是空的话则代表没有前缀别名--&gt;        targetNamespace=&quot;http://www.itcast.cn/xml&quot; elementFormDefault=&quot;qualified&quot;&gt;    &lt;xsd:element name=&quot;students&quot; type=&quot;studentsType&quot;/&gt;    &lt;xsd:complexType name=&quot;studentsType&quot;&gt;        &lt;xsd:sequence&gt;            &lt;xsd:element name=&quot;student&quot; type=&quot;studentType&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&gt;        &lt;/xsd:sequence&gt;    &lt;/xsd:complexType&gt;    &lt;xsd:complexType name=&quot;studentType&quot;&gt;        &lt;xsd:sequence&gt;            &lt;xsd:element name=&quot;name&quot; type=&quot;xsd:string&quot;/&gt;            &lt;xsd:element name=&quot;age&quot; type=&quot;ageType&quot; /&gt;            &lt;xsd:element name=&quot;sex&quot; type=&quot;sexType&quot; /&gt;            &lt;!--规定了书写的顺序--&gt;        &lt;/xsd:sequence&gt;        &lt;xsd:attribute name=&quot;number&quot; type=&quot;numberType&quot; use=&quot;required&quot;/&gt;    &lt;/xsd:complexType&gt;    &lt;xsd:simpleType name=&quot;sexType&quot;&gt;        &lt;xsd:restriction base=&quot;xsd:string&quot;&gt;            &lt;!--规定了sex的类型--&gt;            &lt;xsd:enumeration value=&quot;male&quot;/&gt;            &lt;xsd:enumeration value=&quot;female&quot;/&gt;            &lt;!--规定了sex的种类，只能有两种--&gt;        &lt;/xsd:restriction&gt;    &lt;/xsd:simpleType&gt;    &lt;xsd:simpleType name=&quot;ageType&quot;&gt;        &lt;xsd:restriction base=&quot;xsd:integer&quot;&gt;            &lt;!--规定了age的类型--&gt;            &lt;xsd:minInclusive value=&quot;0&quot;/&gt;            &lt;xsd:maxInclusive value=&quot;256&quot;/&gt;            &lt;!--规定了age的最大最小值--&gt;        &lt;/xsd:restriction&gt;    &lt;/xsd:simpleType&gt;    &lt;xsd:simpleType name=&quot;numberType&quot;&gt;        &lt;xsd:restriction base=&quot;xsd:string&quot;&gt;            &lt;xsd:pattern value=&quot;heima_\\d&#123;4&#125;&quot;/&gt;            &lt;!--规定必须是heima_开头后跟四位数字--&gt;        &lt;/xsd:restriction&gt;    &lt;/xsd:simpleType&gt;&lt;/xsd:schema&gt; \nxml文档\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!-- \t1.填写xml文档的根元素\t2.引入xsi前缀.  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\t3.引入xsd文件命名空间.  xsi:schemaLocation=&quot;http://www.itcast.cn/xml  student.xsd&quot;\t4.为每一个xsd约束声明一个前缀,作为标识  xmlns=&quot;http://www.itcast.cn/xml&quot; --&gt;&lt;students xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;          xmlns=&quot;http://www.itcast.cn/xml&quot;          xsi:schemaLocation=&quot;http://www.itcast.cn/xml  student.xsd&quot;&gt;    &lt;student number=&quot;heima_0001&quot;&gt;        &lt;name&gt;tom&lt;/name&gt;        &lt;age&gt;18&lt;/age&gt;        &lt;sex&gt;male&lt;/sex&gt;    &lt;/student&gt;&lt;/students&gt;\n\n解析操作xml文档，将文档的数据读取到内存中\n操作XML文档\n\n解析（读取）：将文档中的数据读取到内存中\n写入：将内存中的数据保存到XML中，持久化的存储\n\n\n\n解析XML的方式\n\n\nDOM：将标记语言一次性载入内存中，在内存中形成一个DMO树\n\n优点：操作方便，可以对文档进行CRUD的所有操作\n缺点：消耗内存\n服务器端\n\n\nSAX：逐行读取，基于事件驱动\n\n优点：占内存十分小\n缺点：只能读取，不能增删改\n移动端使用\n\n\n\n\nXML常见的解析器\nJAXP：sun公司提供的解析器，支持DOM和SAX两种思想，性能差，了解\nDOM4J：一款优秀的解析器\nJsoup：可以使用类似于JQuery的方式来解析\nPull：Android操作系统内置的解析器，sax方式\n\n\n\nJsoup快速入门快速入门：\n步骤\n\n导入jar包\n获取Document对象\n获取对应的标签\n\n//2. 获取Document对象，根据xml文档来获取//2.1 获取xml的路径String path = JsoupDemo1.class.getClassLoader().getResource(&quot;xml/student.xml&quot;).getPath();//2.2 解析xml文档，加载文档进内存，获取DOM树Document document = Jsoup.parse(new File(path), &quot;utf-8&quot;);//返回一个Elements的集合（ArrayList）Elements elements = document.getElementsByTag(&quot;elements&quot;);System.out.println(elements.size());//3.1 获取第一个elements的element对象Element element = elements.get(0);String text = element.text();System.out.println(text);\n\n\nJsoup是一个工具类，可以解析html文档或者xml文档，返回Document对象\nparse方法：解析html或xml文档，返回Document\nparse(File in,Stirng charsetName):解析xml或html文件\nparse(String html)解析html字符串\nparse(URL url,int timeoutMillis)通过网络来获取html文件\n\n\n\n\n\n\n\nDocument：文档对象，代表内存中的Dom树\n获取Element对象\ngetElementsByTag(String tagName):根据标签名称获取元素对象集合\ngetElementsByAttribute(String key)根据属性名称获取元素对象集合\ngetElementsByAttributeValue(String key,String value)根据对应的属性名和属性值获取元素对象的集合\ngetElementsById(String id)通过id属性值获取唯一的element对象\n\n\n\n\n\n\n\nElements，元素Elements对象的集合，可以当做ArrayList集合来使用\n\n\n\nElement元素对象  - 也可以获取Element对象\n   - `getElementsByTag(String tagName)`:根据标签名称获取元素对象集合\n  - `getElementsByAttribute(String key)`根据属性名称获取元素对象集合\n  - `getElementsByAttributeValue(String key,String value)`根据对应的属性名和属性值获取元素对象的集合\n  - `getElementsById(String id)`通过id属性值获取唯一的element对象\n\n\n获取属性值\nString attr(String key)根据属性名称获取属性值\n\n\n获取文本内容\nString text()获取所有标签的纯文本内容\nString html()获取标签体的所有内容（包括子标签的标签和文本内容）\n\n\n\n\n\n\n\nNode节点对象\n是Document和Element元素的父类\n\n\n\nJsoup选择器查询快捷查询方式：\n\nselector：选择器的方式\n\n使用的方法：Elements select(String sccQuery)\n语法是css的选择器语法，参考文档中selector类\n\n\nXPath : XML路径语言，确定XML文档中某部分位置的\n\n语法：参考\n需要额外导入一个jar包\npublic static void main(String[] args) throws IOException, XpathSyntaxErrorException &#123;    URL url = new URL(&quot;http://baidu.com/&quot;);    Document document = Jsoup.parse(url, 10000);    //创建xpath的document    JXDocument jxDocument = new JXDocument(document);    //结合语法来查询    List&lt;JXNode&gt; jxNodes = jxDocument.selN(&quot;//span/div/span&quot;);    //返回一个JSNode    for (JXNode jxNode : jxNodes) &#123;        System.out.println(jxNode);    &#125;&#125;","categories":["后台","XML"],"tags":["XML"]},{"title":"JQuery-01基础","url":"/2019/10/27/JQuery/JQuery-01%E5%9F%BA%E7%A1%80/","content":"\n引言：\n\nJQuery的入门基础篇\n\n\n\n\n\nJQuery\nJQuery 是javascript的框架，简化js的开发\n\n快速入门\n下载JQueryJQuery版本1.x 兼容IE678，使用最为广泛2.x 不兼容IE6783.x 不兼容IE678但支持最新的浏览器 \n导入JQuery.js文件\n使用&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Jquery快速入门&lt;/title&gt;    &lt;script src=&quot;jquery-3.3.1.min.js&quot;&gt;&lt;/script&gt;    &lt;!--导入JQuery包--&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;div1&quot;&gt;div1&lt;/div&gt;    &lt;div id=&quot;div2&quot;&gt;div2&lt;/div&gt;&lt;script&gt;    var $div = $(&quot;div&quot;);    alert($div);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n使用\n获取ID对象\n//Js源码var oDiv1 = document.getElementById(&quot;div1&quot;);alert(oDiv1.innerHTML);//js源码使用innerHtml属性来获取//使用JQuery获取元素对象var div1 = $(&quot;#div1&quot;);alert(div1.html());//JQ使用html()这个方法来获取\n获取标签对象\n//Js源码var aDiv = document.getElementsByTagName(&quot;div&quot;);alert(aDiv);for (var i=0;i&lt;aDiv.length;i++)&#123;    aDiv[i].innerHTML = &quot;666&quot;;&#125;//使用JQuery获取元素对象var $div = $(&quot;div&quot;);alert($div);$div.html(&quot;777&quot;);//jq中不需要遍历就直接使用\njs对象与jq对象的转换\n//Js源码var aDiv = document.getElementsByTagName(&quot;div&quot;);var $div = $(&quot;div&quot;);//jq与js对象之间的转换//1. jq转js--使用方括号加索引[索引]，或者使用get()方法var div1 = $div.get(0);var div2 = $div[0];//2. js转jq--使用 $() 包裹js对象var $1 = $(aDiv[0]);\n选择器\n\n\n\n基本语法\n事件绑定     //js源码var oB1 = document.getElementById(&quot;b1&quot;);var oDiv1 = document.getElementById(&quot;div1&quot;);oB1.onclick=function () &#123;    oDiv1.innerText=&quot;点击事件绑定&quot;;&#125;    //jq实现var $b1 = $(&quot;#b1&quot;);var $div = $(&quot;div&quot;);$b1.click(function () &#123;    $div.get(0).innerHTML=&quot;点击事件绑定&quot;;&#125;)\n入口函数//js源码入口函数，防止DOM未被载入完成而出错window.onload =function () &#123;    alert(1);&#125;//jq入口函数$(function () &#123;    alert(1);&#125;)/*window.onload与$(function)的区别- 前者只能使用一次，- 但是后者可以使用多次*/\n样式控制//jswindow.onload =function () &#123;    var oDiv1 = document.getElementById(&quot;div1&quot;);    oDiv1.style.background =&quot;red&quot;;&#125;//jq$(function () &#123;    var $div2 = $(&quot;#div2&quot;);    $div2.css(&quot;background&quot;,&quot;blue&quot;);&#125;)\n\n\n选择器的使用\n基本选择器//1. 元素选择器(见上文)//2. id选择器(见上文)//3. class选择器//jswindow.onload =function () &#123;    var div1 = document.getElementsByClassName(&quot;div1&quot;)[0];    alert(div1);&#125;//jq$(function () &#123;     var $div1 = $(&quot;.div1&quot;);    alert($div1);&#125;)//4. 兄弟选择器//jswindow.onload = function () &#123;    var oDiv1 = document.querySelector(&quot;.div1&quot;);    oDiv1.nextElementSibling.style.background = &quot;red&quot;;&#125;//jq$(function () &#123;    var $div1 = $(&quot;.div1,.div2&quot;);    $div1.css(&quot;background&quot;,&quot;blue&quot;);&#125;)\n层级选择器//选择直接的后代，不会选择后代的后代var $div1 = $(&quot;.div1&gt;.div3&quot;);//选择所有的后代，会选择后代的后代var $div1 = $(&quot;.div1 .div3&quot;);\n属性选择器//1. 属性名称选择器$(&quot;div[name]&quot;).css(&quot;background&quot;,&quot;lightblue&quot;);//2. 属性选择器$(&quot;div[name=&#x27;third&#x27;]&quot;).css(&quot;background&quot;,&quot;green&quot;);//3. 复合属性选择器    //name不为third    $(&quot;div[name!=&#x27;third&#x27;]&quot;).css(&quot;background&quot;,&quot;blue&quot;)    //name以d结尾    $(&quot;div[name$=&#x27;d&#x27;]&quot;).css(&quot;background&quot;,&quot;red&quot;)    //name以th开头    $(&quot;div[name^=&#x27;th&#x27;]&quot;).css(&quot;background&quot;,&quot;orange&quot;)    //name含有d    $(&quot;div[name*=&#x27;d&#x27;]&quot;).css(&quot;background&quot;,&quot;yellow&quot;)    //选取有属性id且name含有e的    $(&quot;div[id][name*=&#x27;e&#x27;]&quot;).css(&quot;background&quot;,&quot;purple&quot;)\n过滤选择器//选择第一个元素$(&quot;div:first&quot;).css(&quot;background&quot;,&quot;red&quot;);//选择最后一个元素$(&quot;div:last&quot;).css(&quot;background&quot;,&quot;orange&quot;);//选择class不为div1的所有div元素$(&quot;div:not(.div1)&quot;).css(&quot;background&quot;,&quot;green&quot;);//选择索引为偶数的元素，从0开始计数$(&quot;div:even&quot;).css(&quot;background&quot;,&quot;blue&quot;);//选择索引为奇数的元素$(&quot;div:odd&quot;).css(&quot;background&quot;,&quot;pink&quot;);//选择索引大于3的元素,great than$(&quot;div:gt(3)&quot;).css(&quot;background&quot;,&quot;grey&quot;);//选择索引小于3的元素,less than$(&quot;div:lt(3)&quot;).css(&quot;background&quot;,&quot;black&quot;);//选择索引等于3的元素,equals$(&quot;div:eq(3)&quot;).css(&quot;background&quot;,&quot;white&quot;);//选择标题元素,header$(&quot;:header&quot;).css(&quot;background&quot;,&quot;green&quot;);\n表单过滤选择器//jQuery对象val()方法改变表单内可用input值,enabled表示可使用$(&quot;input[type=&#x27;text&#x27;]:enabled&quot;).val(&quot;改变值&quot;);//改变不可用元素$(&quot;input[type=&#x27;text&#x27;]:disabled&quot;).val(&quot;改变值&quot;);//复选框:checked 获取复选框选中的个数$(&quot;input[type=&#x27;checkbox&#x27;]:checked&quot;).length;//获取下拉框option选中的个数$(&quot;select&gt;option:checked&quot;).length;\n\n\nDOM操作\n内容操作\n\n\nhtml():获取/设置元素的标签体内容\ntext():获取/设置元素的标签体纯文本内容\nval():获取/设置元素的value属性值&lt;a href=&quot;&quot;&gt;&lt;span&gt;你好&lt;/span&gt;&lt;/a&gt;\n$(&quot;a&quot;).html();//&lt;span&gt;你好&lt;/span&gt;$(&quot;a&quot;).text();//你好$(&quot;input&quot;).val(&quot;你好&quot;);//所有input的value全为“你好”\n\n\n属性操作\n\n\n通用属性操作\nattr()//获取/设置元素的属性\nremoveAttr()//删除属性\nprop()//获取/设置元素的属性\nremoveProp()//删除属性//操作固有属性使用prop，操作自定义属性使用attr//获取console.log($(&quot;#bj&quot;).attr(&quot;name&quot;));//设置$(&quot;#bj&quot;).attr(&quot;name&quot;,&quot;更改值&quot;);$(&quot;#bj&quot;).attr(&quot;new&quot;,&quot;新增值&quot;);//删除属性$(&quot;#bj&quot;).removeAttr(&quot;name&quot;);\n\n\n对class属性操作\naddClass():添加class属性值\nremoveClass():移除class属性值\ntoggleClass():切换class属性值，有就删除，没有就添加$(&quot;#bj&quot;).addClass(&quot;first&quot;);$(&quot;#bj&quot;).removeClass(&quot;first&quot;);$(&quot;#tj&quot;).toggleClass(&quot;first&quot;);\n\n\nCRUD操作\nobj1.append(obj2):将obj2添加到obj1的内部，并且在末尾\nobj1.prepend(obj2)将obj2添加到obj1的内部，并且在开头\nobj1.appendTo(obj2)将obj1添加到obj2的内部\nobj1.pretendTo(obj2)将obj1添加到obj2的内部\nobj1.after(对象2)将obj2添加到obj1的后面，兄弟关系\nobj1.before(obj2)将obj2添加到obj1的前面，兄弟关系\nobj1.insertAfter(obj2)将obj2添加到obj1的前面，兄弟关系\nobj1.insertBefore(obj2)将obj2添加到obj1的前面，兄弟关系\nobj.remove()删除对象,自己删除自己10 obj.empty()清空元素所有的后代元素，但保留当前对象以及当前节点\n\n\n\n\n\n","categories":["前端","JQuery"],"tags":["JQuery"]},{"title":"JQuery-02动画与遍历","url":"/2019/10/27/JQuery/JQuery-02%E5%8A%A8%E7%94%BB%E4%B8%8E%E9%81%8D%E5%8E%86/","content":"\n引言：\n\nJQuery的动画与遍历，事件绑定，案例，插件\n\n\n\n\n\n动画JQuery中定义好了一些方法来实现比较简单的动画\n默认显示和隐藏方式折叠收缩\n\nshow()\nhide()\ntoggle()/*show有三个参数：1. speed：动画的速度，有三个预定义的值&quot;slow&quot;,&quot;normal&quot;,&quot;fast&quot;,或者直接给定毫秒值    //swing是先快后慢，linear是匀速的2. easing：用来指定切换效果，默认是swing，可用参数linear3. fn：一个在动画完成时执行的函数，每个元素执行只一次*///展示$(&quot;button:eq(0)&quot;).click(function () &#123;    $(&quot;.div1&quot;).show(&quot;slow&quot;,&quot;linear&quot;,function () &#123;        alert(&quot;展示了&quot;);    &#125;);&#125;)//隐藏$(&quot;button:eq(1)&quot;).click(function () &#123;    $(&quot;.div1&quot;).hide(&quot;slow&quot;,&quot;linear&quot;,function () &#123;        alert(&quot;隐藏了&quot;);    &#125;);&#125;)//自动切换$(&quot;button:eq(2)&quot;).click(function () &#123;$(&quot;.div1&quot;).toggle(&quot;slow&quot;,&quot;swing&quot;,function () &#123;    alert(&quot;切换了&quot;);&#125;);\n\n滑动显示和隐藏方式从下往上的滑动\n//展示$(&quot;button:eq(0)&quot;).click(function () &#123;    $(&quot;.div1&quot;).slideUp(&quot;slow&quot;);&#125;)//隐藏$(&quot;button:eq(1)&quot;).click(function () &#123;    $(&quot;.div1&quot;).slideDown(&quot;slow&quot;);&#125;)//自动切换$(&quot;button:eq(2)&quot;).click(function () &#123;    $(&quot;.div1&quot;).slideToggle(&quot;slow&quot;);&#125;);\n\n淡入淡出显示和隐藏方式淡入淡出\n//展示$(&quot;button:eq(0)&quot;).click(function () &#123;    $(&quot;.div1&quot;).fadeIn(&quot;slow&quot;);&#125;)//隐藏$(&quot;button:eq(1)&quot;).click(function () &#123;    $(&quot;.div1&quot;).fadeOut(&quot;slow&quot;);&#125;)//自动切换$(&quot;button:eq(2)&quot;).click(function () &#123;    $(&quot;.div1&quot;).fadeToggle(&quot;slow&quot;);&#125;);\n\n遍历js中需要使用for循环遍历对象\n但JQuery中的遍历更加简单\n\nobj.each(callback)方法 //obj.each(callback())$(&quot;ul li&quot;).each(function (index,element) &#123;    //这里可以直接使用this来获取，但是获取不到索引值    console.log(this.innerHTML);    //所以我们可以给回调函数设置两个参数，一个是索引，一个是每一个对象    console.log(index+&quot;：&quot;+element.innerHTML);    //返回false相当于break    //return false;    //返回true相当于continue    //return true;&#125;);\n$.each(obj,[callback])方法 $.each($(&quot;ul li&quot;),function () &#123;    console.log(this.innerHTML);&#125;)//这个方法同上\nfor..of方法,JQuery3.0版本之后提供的方法 for (li of $(&quot;ul li&quot;))&#123;    console.log(li.innerHTML);&#125;\n\n","categories":["前端","JQuery"],"tags":["JQuery"]},{"title":"JQuery-03事件绑定与插件","url":"/2019/10/27/JQuery/JQuery-03%E4%BA%8B%E4%BB%B6%E7%BB%91%E5%AE%9A%E4%B8%8E%E6%8F%92%E4%BB%B6/","content":"\n引言：\n\nJQuery的事件绑定与插件\n\n\n\n\n\n事件绑定\nJQuery标准的绑定方式\n\njqObj.事件方法(回调函数)\n //鼠标点击,进入,离开，可以链式编程$(&quot;button&quot;).click(function () &#123;    alert(1);&#125;).mouseover(function () &#123;    alert(&quot;鼠标来了&quot;);&#125;).mouseleave(function () &#123;    alert(&quot;鼠标离开&quot;);&#125;)$(&quot;#input1&quot;).focus();//让文本输入框获得焦点$(&quot;#form1&quot;).submit();//会让表单提交\n\non绑定事件/off解除绑定\n\njqObj.on(&quot;事件名称&quot;,回调函数)\njqObj.off(&quot;事件名称&quot;)\n$(&quot;button:eq(0)&quot;).on(&quot;click&quot;,function () &#123;    alert(&quot;我被点击了&quot;);    //点击后取消他的点击事件    $(&quot;button:eq(0)&quot;).off(&quot;click&quot;);    //不传递参数会将组件上的所有事件全部解绑&#125;)\n\n事件切换：toggle\n1.9版本后移除，可以使用插件migrate来恢复此功能\n\n\n\njqObj.toggle(fn1,fn2...)点击第一下执行fn1，第二下点fn2\n$(&quot;button&quot;).toggle(function () &#123;    alert(1);&#125;,function () &#123;    alert(2);&#125;)//重复点击会来回切换fn1和fn2\n插件增强JQuery功能，jQuery提供了两种插件的方式\n\n$.fn.extend(obj)对象级别插件\n 增强通过jQuery获取的对象的功能\n\n$.extend(obj)全局级别插件\n 增强jQuery对象自身的功能\n\n\n小案例使用插件实现全选的功能\n&lt;button class=&quot;button1&quot;&gt;全选&lt;/button&gt;&lt;button class=&quot;button2&quot;&gt;取消全选&lt;/button&gt;&lt;input type=&quot;checkbox&quot;&gt;一个&lt;input type=&quot;checkbox&quot;&gt;二个&lt;input type=&quot;checkbox&quot;&gt;三个\n\n$.fn.extend(&#123;    check:function () &#123;        //选中所有的复选框        this.prop(&quot;checked&quot;,true);    &#125;,    unCheck:function () &#123;        //取消全选        this.prop(&quot;checked&quot;,false);    &#125;&#125;);$(&quot;.button1&quot;).click(function () &#123;    $(&quot;input[type=&#x27;checkbox&#x27;]&quot;).check();&#125;);$(&quot;.button2&quot;).click(function () &#123;    $(&quot;input[type=&#x27;checkbox&#x27;]&quot;).unCheck();&#125;)\n\n","categories":["前端","JQuery"],"tags":["JQuery"]},{"title":"JDBC-2","url":"/2019/09/02/JDBC/JDBC-2/","content":"\n引言：\n\n数据库连接池\nJDBC Template\n\n\n\n\n\n数据库连接池为什么要使用数据库连接池？\n原本的逻辑是，用户访问数据库要先向操作系统请求连接，访问完数据库把连接删除\n这样的效率十分低下\n数据库连接池就可以解决这个问题，它把所有的连接放在一个容器当中，当用户访问完成时就会归还连接到这个容器中，效率更高\n概念一个存放数据库连接的容器\n当系统初始化好后，容器被创建，容器中会申请一些连接对象，\n当用户来访问数据库时，从容器中获取连接对象，\n用户访问完成后，会将连接对象归还给容器\n好处：\n\n节约资源\n高效\n\nDataSourceDataSource接口由驱动程序供应商实现。 \n包路径javax.sql\n方法\n获取连接getConnection()\n归还连接close()//如果连接对象是连接池提供的，那么close方法将不再关闭连接，而是归还连接\n\n两个数据库连接池C3P0(旧的技术)基本使用：\n\n导入两个jar包(JDBC的jar包也要导入)\nc3p0-0.9.5.2\nmchange-commons-java-0.2.12\n\n\n定义配置文件\n配置文件通常在应用程序类路径顶层的标准名称c3p0.properties或c3p0-config.xml下查找\n路径：直接将文件放在src目录下即可\n\n\n创建核心对象 数据库连接池对象 ComboPooleDataSource\n获取连接：getConnectionpublic static void main(String[] args) throws SQLException &#123;    //1. 创建数据库连接对象    DataSource ds= new ComboPooledDataSource();    //2. 获取连接对象    Connection conn = ds.getConnection();    //3. 打印    System.out.println(conn);&#125;\nc3p0-config.xml配置文件&lt;c3p0-config&gt;  &lt;!-- 使用默认的配置读取连接池对象 --&gt;  &lt;default-config&gt;  \t&lt;!--  连接参数 --&gt;    &lt;property name=&quot;driverClass&quot;&gt;com.mysql.cj.jdbc.Driver&lt;/property&gt;    &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/database?serverTimezone=UTC&lt;/property&gt;    &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt;    &lt;property name=&quot;password&quot;&gt;1046qwer.&lt;/property&gt;        &lt;!-- 连接池参数 --&gt;    &lt;property name=&quot;initialPoolSize&quot;&gt;5&lt;/property&gt;    &lt;property name=&quot;maxPoolSize&quot;&gt;10&lt;/property&gt;    &lt;property name=&quot;checkoutTimeout&quot;&gt;3000&lt;/property&gt;  &lt;/default-config&gt;  &lt;named-config name=&quot;otherc3p0&quot;&gt;     &lt;!--  连接参数 --&gt;    &lt;property name=&quot;driverClass&quot;&gt;com.mysql.cj.jdbc.Driver&lt;/property&gt;    &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/database?serverTimezone=UTC&lt;/property&gt;    &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt;    &lt;property name=&quot;password&quot;&gt;1046qwer.&lt;/property&gt;        &lt;!-- 连接池参数 --&gt;    &lt;property name=&quot;initialPoolSize&quot;&gt;5&lt;/property&gt;    &lt;property name=&quot;maxPoolSize&quot;&gt;8&lt;/property&gt;    &lt;property name=&quot;checkoutTimeout&quot;&gt;1000&lt;/property&gt;  &lt;/named-config&gt;&lt;/c3p0-config&gt;\n\nDruid(阿里巴巴提供)步骤：\n\n导入jar包\n定义配置文件\n是properties形式的\n可以称任意名称，可以放在任意目录下\n\n\n加载配置文件\n获取数据库连接池对象：通过一个工厂类来获取DruidDataSourceFactory\n获取连接getConnection示例代码public class druid &#123;    public static void main(String[] args) throws Exception &#123;        //1. 导入jar包        //2. 定义配置文件        //3. 加载配置文件        Properties pro = new Properties();        InputStream is = druid.class.getClassLoader().getResourceAsStream(&quot;druid.properties&quot;);        pro.load(is);        //4. 获取连接对象        DataSource ds = DruidDataSourceFactory.createDataSource(pro);        //5. 获取连接        Connection conn = ds.getConnection();        System.out.println(conn);    &#125;&#125;\n定义工具类准备一个JDBCUtils类\n\n内部要有\n\n静态代码块加载配置文件\n获取连接方法\n释放资源\n获取连接池的方法/** * @author BlackKnight * 工具类 */public class JdbcUtils &#123;    private static DataSource ds;    static &#123;        //1. 加载配置文件        try &#123;            Properties pro = new Properties();            pro.load(JdbcUtils.class.getClassLoader().getResourceAsStream(&quot;druid.properties&quot;));            ds = DruidDataSourceFactory.createDataSource(pro);        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    /**     * 获取连接     *     * @return     * @throws SQLException     */    public static Connection getConnection() throws SQLException &#123;        return ds.getConnection();    &#125;    /**     * 释放资源     * @param stmt     * @param conn     */    public static void close(Statement stmt, Connection conn) &#123;        if (stmt != null) &#123;            try &#123;                stmt.close();            &#125; catch (SQLException e) &#123;                e.printStackTrace();            &#125;        &#125;        if (conn != null) &#123;            try &#123;                conn.close();            &#125; catch (SQLException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;    public static void close(ResultSet rs, Statement stmt, Connection conn) &#123;        close(null,stmt,conn);        if (rs != null) &#123;            try &#123;                rs.close();            &#125; catch (SQLException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;    public static DataSource getDataSource()&#123;        return ds;    &#125;&#125;\n使用工具类public class druid &#123;    public static void main(String[] args) &#123;        Connection conn = null;        PreparedStatement preStat = null;        try &#123;            conn = JdbcUtils.getConnection();            String sql = &quot;insert into deliver values(1,?,?)&quot;;            preStat = conn.prepareStatement(sql);            preStat.setString(1,&quot;李白&quot;);            preStat.setString(2,&quot;3000&quot;);            int i = preStat.executeUpdate();            System.out.println(i);        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;finally &#123;            JdbcUtils.close(preStat,conn);        &#125;    &#125;&#125;\n\nSpring JDBCSpring框架提供的对JDBC简单封装\n提供了一个JDBCTemplate对象简化JDBC的开发\n步骤：\n\n导入jar包\n创建JDBCTemplate对象，依赖于数据源DataSource JdbcTemplate template = new JdbcTemplate(ds)\n使用JDBCTemplate方法完成CRUD操作\nupdate()执行DML语句\nqueryForMap()查询结果，将结果封装为Map集合\nqueryForList()查询结果将结果封装为List集合\nquery()查询结果，将结果封装为JavaBean对象\nqueryForObject查询结果，将结果封装为对象\n\n\n\n示例代码\npublic class JdbcTemplateDemo &#123;    public static void main(String[] args) &#123;        //1. 导入jar包        //2. 创建JDBCTemplate对象        JdbcTemplate template = new JdbcTemplate(JdbcUtils.getDataSource());        //3. 调用方法        String sql = &quot;update deliver set bank = 5000 where id = ?&quot;;        int count = template.update(sql, 3);        System.out.println(count);    &#125;&#125;","categories":["后台","JDBC"],"tags":["JDBC"]},{"title":"JSON","url":"/2019/10/31/JSON/JSON/","content":"\n引言：\n\nJSON：Js对象表示法\n\n\n\n\nJSON\nJavaScript Object Notation  ： Js对象表示法\n\n一种存储、交换信息的语法\n语法\n基本规则* 数据在名称/值对中：json数据是由键值对构成的    * 键用引号（单双引号都可以）勾起来，也可以不使用引号    * 值的取值类型        1. 数字（可以直接写）        2. 字符串（双引号中）        3. 布尔值        4. 数组（方括号中）        5. 对象（花括号中）        6. null* 数据由逗号分隔：多个键值对由逗号分隔* 花括号保存对象：使用&#123;&#125;定义json格式* 方括号保存数组：[]\n//1. 定义基本格式var person = &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;;//2. 嵌套格式//&#123;&#125;嵌套[]var persons = &#123;    &quot;persons&quot;: [        &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;,        &#123;&quot;name&quot;: &quot;李四&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;,        &#123;&quot;name&quot;: &quot;王五&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;    ]&#125;;//[]嵌套&#123;&#125;var ps = [    &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;,    &#123;&quot;name&quot;: &quot;李四&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;];\n获取数据\njson对象.键名键名不需要加引号\njson对象[&quot;键名&quot;]这时需要加引号\n数组对象[索引]\n\n\n遍历数据var person = &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;;for(var key in person)&#123;    // alert(key+&quot;:&quot;+person.key);    // key默认为一个字符串，不能用.来调用它    alert(key+&quot;:&quot;+person[key]);&#125;var ps = [&#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;,&#123;&quot;name&quot;: &quot;李四&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;];for(var i=0;i&lt;ps.length;i++)&#123;    for (var pKey in ps[i]) &#123;        alert(pKey+&quot;:&quot;+ps[i][pKey])    &#125;&#125;\n\nJSON数据与JAVA对象的相互转换JSON解析器：一些封装好的工具类直接可以帮我们解析\n\n常见的解析器：Jsonlib，Gson，fastjson，jackson\n\nJSON转为java对象了解，使用的并不多\n使用步骤：\n\n导入jackson相关jar包\n创建jackson核心对象，ObjectMapper\n调用ObejctMapper的相关方法进行转换\n\n\n转换相关方法：readValue(json,Obejct)第一个参数为json字符串，第二个参数为对象\n示例 String json = &quot;&#123;\\&quot;gender\\&quot;:\\&quot;男\\&quot;,\\&quot;name\\&quot;:\\&quot;张三\\&quot;,\\&quot;age\\&quot;:23&#125;&quot;;ObjectMapper mapper = new ObjectMapper();Person p = mapper.readValue(json, Person.class);p.setName(&quot;李四&quot;);System.out.println(p);//Person&#123;name=&#x27;李四&#x27;, age=23, gender=&#x27;男&#x27;&#125;\n\nJava对象转换JSON使用步骤：\n\n导入jackson相关jar包\n创建jackson核心对象，ObjectMapper\n调用ObejctMapper的相关方法进行转换\n\n\n转换相关方法：writeValue(参数1,obj对象);    参数1：        File：将obj对象转换为Json字符串，保存到指定的文件中        Writer：保存到字符输出流中        OutputStream：保存到字节输出流中writeValueAsString(obj):将对象专为json字符串\n\n//1.创建Person对象Person p = new Person();p.setName(&quot;张三&quot;);p.setAge(20);p.setGender(&quot;男&quot;);//2. 创建Jackson的核心对象 ObjectMapperObjectMapper mapper = new ObjectMapper();//3. 调用相关方法String json = mapper.writeValueAsString(p); System.out.println(json);//打印出&#123;&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;:20,&quot;gender&quot;:&quot;男&quot;&#125;\n\n注解：\n\n\n@JsonIgnore，排除属性\n@JsonFormat，属性值的格式化\n\n将注解加在JavaBean的成员变量上\n@JsonIgnore //忽略该属性private Date birthday;@JsonFormat(pattern = &quot;yyyy-MM-dd&quot;)//格式化该属性private Date birthday;\n\n\n复杂集合的转换\n\nList集合转换，会成为一个数组\nList&lt;Person&gt; ps = new ArrayList&lt;&gt;();ps.add(p);String s = mapper.writeValueAsString(ps);System.out.println(s);//[&#123;&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;:20,&quot;gender&quot;:&quot;男&quot;&#125;]\n\nMap集合转换，和对象转换一样\nMap&lt;String, Object&gt; map = new HashMap&lt;&gt;();map.put(&quot;name&quot;,&quot;张三&quot;);map.put(&quot;age&quot;,23);map.put(&quot;gender&quot;,&quot;男&quot;);String s = mapper.writeValueAsString(map);System.out.println(s);//&#123;&quot;gender&quot;:&quot;男&quot;,&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;:23&#125;\n\n注意服务器响应的数据，在客户端使用时，要想当做json的数据格式使用：\n以下方式二选一\n\n$.get(type)将最后一个参数设置为”json”\n服务端设置MIME类型response.setContentType(&quot;application/json;&quot;)\n\n","categories":["后台","JSON"],"tags":["JSON"]},{"title":"限流算法","url":"/2024/04/11/JUC/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/","content":"\n  引言：限流，对流量加以控制\n\n\n\n\n限流算法服务总有一个承载上限，如果不加以控制，很有可能导致服务过大，打爆服务。\n本节介绍四种经典的限流算法（图片来自于博客）\n固定窗口\n固定窗口限流：固定时间处理阈值以内的流量，如果超过该时间的请求就丢弃\n\n\n优缺点：\n\n优点：实现简单\n缺点：存在明显的临界问题，假设当前每秒限流10qps，第8s的最后100ms有8qps，第9s的前100ms有5qps，那么在这不到200ms的时间，流量有8+5=13qps，我们的限流失败了。\n\n具体实现：\npublic class FixedWindows implements RateLimiter &#123;    public AtomicInteger counter = new AtomicInteger(0);  //统计请求数    public long lastAcquireTime =  System.currentTimeMillis();    public final Long windowUnit = 1000L ; // 假设固定时间窗口是1000ms    public final Integer threshold = 10; // 窗口阀值是10    @Override    public synchronized boolean allowReq() &#123;        long currentTime = System.currentTimeMillis();  //获取系统当前时间        if (currentTime - lastAcquireTime &gt; windowUnit) &#123;            // 如果进入了新窗口期，清空计数器，并且开启新窗口            counter.set(0);            lastAcquireTime = currentTime;        &#125;        if (counter.get() &lt; threshold) &#123;            // 如果计数还在阈值，计数器+1            counter.incrementAndGet();            return true;        &#125;        return false;    &#125;&#125;\n\n滑动窗口为了解决固定窗口的临界问题，引入了滑动窗口：\n\n优缺点：\n\n优点：简单，解决了临界问题\n缺点：突发流量无法处理（意思是：达到阈值，后续请求都会被拒绝，而不是排队等待处理）\n\npublic class SlideWindows implements RateLimiter &#123;    // 单位时间划分的小周期（单位时间是1分钟，10s一个小格子窗口，一共6个格子）    private int SUB_CYCLE = 10;    // 每分钟限流请求数    private final int threshold = 10;    // 计数器, key为当前窗口的开始时间值秒，value为当前窗口的计数    private final Map&lt;Long, Integer&gt; counters = new TreeMap&lt;&gt;();    @Override    public synchronized boolean allowReq() &#123;        //获取当前时间在哪个小周期窗口        long epochSecond = LocalDateTime.now().toEpochSecond(ZoneOffset.UTC);        long currentWindowTime = epochSecond / SUB_CYCLE * SUB_CYCLE;        // 这里先除再乘的意思：比如 100、102、109都是属于100这个段的，/10去掉个位数        //当前窗口总请求数        int currentWindowNum = countCurrentWindow(currentWindowTime);        //超过阀值限流        if (currentWindowNum &gt;= threshold) &#123;            return false;        &#125;        counters.put(currentWindowTime, counters.getOrDefault(currentWindowTime, 0) + 1);        return true;    &#125;    // 统计当前窗口的请求数    private int countCurrentWindow(long currentWindowTime) &#123;        // 计算窗口开始位置        long startTime = currentWindowTime - SUB_CYCLE * (60 / SUB_CYCLE);        int count = 0;        // 遍历存储的计数器        Iterator&lt;Map.Entry&lt;Long, Integer&gt;&gt; iterator = counters.entrySet().iterator();        while (iterator.hasNext()) &#123;            Map.Entry&lt;Long, Integer&gt; entry = iterator.next();            // 删除无效过期的子窗口计数器            if (entry.getKey() &lt; startTime) &#123;                iterator.remove();            &#125; else &#123;                //累加当前窗口的所有计数器之和                count += entry.getValue();            &#125;        &#125;        return count;    &#125;&#125;\n\n注意此处的计算窗口的开始位置：\n// 计算窗口开始位置long startTime = currentWindowTime - SUB_CYCLE * (60 / SUB_CYCLE);\n\n(60 / SUB_CYCLE) 计算了一个分钟内有多少个小周期，我们设置的是10，因此一分钟有6个小周期\n假设当前时间为 15:23:35，我们要计算的是在当前时间之前的窗口的起始时间戳。那么 currentWindowTime 就是当前时间的整十秒：currentWindowTime = 15:23:30\nstartTime 计算为：\nstartTime = currentWindowTime - SUB_CYCLE * (60 / SUB_CYCLE)         = 15:23:30 - 10 * (60 / 10)         = 15:23:30 - 10 * 6         = 15:23:30 - 60         = 15:22:30\n\n漏桶算法所谓漏桶算法如图所示，有一定的处理量，而且有一定的储存量，但是如果超出储存，请求还是会被拒绝：\n\n优点：可以应对突增流量（输入可以是随机速率（就像是现实中的流量），输出是恒定速率（方便服务匀速处理请求））\n缺点：\n\n桶存储请求，增大服务器消耗\n桶的参数调整不能随时变化\n不能遇强则强：无论当前流量如何，都会按固定速率处理\n\npublic class LeakyBucket implements RateLimiter &#123;    private final int capacity = 10; // 桶的容量    private final long interval = 1000; // 漏水速率时间间隔（毫秒）    private int water; // 桶中的水量    private long lastLeakTime; // 上次漏水时间    @Override    public synchronized boolean allowReq() &#123;        long currentTime = System.currentTimeMillis();        // 计算当前时间和上次漏水时间之间的时间差，即桶中应该漏出的水量        int leakAmount = (int) ((currentTime - lastLeakTime) / interval);        lastLeakTime = currentTime;        // 桶中的水量减去漏出的水量        water = Math.max(0, water - leakAmount);                // 如果桶中的水量加上新请求的水量不超过容量，则允许请求通过        if (water &lt; capacity) &#123;            water++;            return true;        &#125;        // 否则拒绝请求        return false;    &#125;&#125;\n\n令牌桶算法该算法的模型是：\n现在有一个存放了很多令牌的桶（所谓令牌就是，拿到令牌的请求可以执行），每秒会向桶中存放令牌，一个请求消耗一个令牌。\n\n相较于漏桶算法，令牌桶算法主要的区别是：允许流量短时间内突增\n但是这个特点也带来的一个问题：短时间内可能用完令牌，导致一段时间内的其他请求都无法响应。\n\n因此如果我们的应用场景就是要求削峰填谷，那么使用漏桶反而是更好的选择。\n如果是为了应对短时间内的流量突增，那么可以考虑使用令牌桶。\n\npublic class TokenBucket implements RateLimiter &#123;    private final int capacity = 10; // 桶的容量    private final long interval = 100; // 令牌生成速率时间间隔（毫秒）    private final BlockingQueue&lt;Object&gt; tokenBucket = new ArrayBlockingQueue&lt;&gt;(capacity); // 令牌桶队列    public TokenBucket() &#123;        // 启动定时任务，定时向令牌桶中添加令牌        ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);        scheduler.scheduleAtFixedRate(() -&gt; &#123;            if (tokenBucket.size() &lt; capacity) &#123;                tokenBucket.offer(new Object());            &#125;        &#125;, 0, interval, TimeUnit.MILLISECONDS);    &#125;    @Override    public boolean allowReq() &#123;        // 从令牌桶中尝试获取令牌        return tokenBucket.poll() != null;    &#125;&#125;\n\n","categories":["限流算法"],"tags":["限流算法"]},{"title":"Java反射_Class","url":"/2020/02/29/Java%E5%8F%8D%E5%B0%84/Java%E5%8F%8D%E5%B0%84-Class/","content":"\n引言：反射机制\n\n\n\n反射反射是Java中比较高阶的技巧，理解了反射对理解JVM、使用Spring框架都有好处\n\n反射就是Reflection，Java的反射是指程序在运行期可以拿到一个对象的所有信息。\n\nClass类先来看一段官方API\n\nInstances of the class Class represent classes and interfaces in a running Java application.（Class实例代表正在运行的类和接口）An enum is a kind of class and an annotation is a kind of interface.（枚举是类、注解是接口）Every array also belongs to a class that is reflected as a Class object that is shared by all arrays with the same element type and number of dimensions.（每个数组也属于一个反映为Class对象的类，该类对象由具有相同元素类型和维数的所有数组共享）The primitive Java types (boolean, byte, char, short, int, long, float, and double), and the keyword void are also represented as Class objects.（Java的原始数据类型以及void关键字也表现为Class对象）\n\n巴比巴卜、屋里哇啦说了些什么呢？\n意思是全部的Java数据类型，只要一运行，都可以是Class的对象。\n请注意，一个Class对象实际上表示的是一个类型，而这个类型未必一定是一种类。\n例如， int 不是类，但 int.class 是一个 Class 类型的对象。 \n在JVM第一次读取到一个class时，会把它加载到内存，而且会为他创建一个Class类型的实例（注意是Class还是class，不要搞错了！！）\n创建\n官方API：Class has no public constructor. Instead Class objects are constructed automatically by the Java Virtual Machine as classes are loaded and by calls to the defineClass method in the class loader.\n\nClass没有公有的构造方法，因为它的创建是当class加载时，通过类加载器的defineClass方法，由JVM自动创建的。\n\n上文中提到：请注意，一个Class对象实际上表示的是一个类型，而这个类型未必一定是一种类。\n\nJVM持有的每个Class实例都指向一个（class或interface）：\n┌───────────────────────────┐│      Class Instance       │──────&gt; String├───────────────────────────┤│name = &quot;java.lang.String&quot;  │└───────────────────────────┘┌───────────────────────────┐│      Class Instance       │──────&gt; Random├───────────────────────────┤│name = &quot;java.util.Random&quot;  │└───────────────────────────┘┌───────────────────────────┐│      Class Instance       │──────&gt; Runnable├───────────────────────────┤│name = &quot;java.lang.Runnable&quot;│└───────────────────────────┘\n每个Class都详细的描述了这个class的信息\n┌───────────────────────────┐│      Class Instance       │──────&gt; String├───────────────────────────┤│name = &quot;java.lang.String&quot;  │├───────────────────────────┤│package = &quot;java.lang&quot;      │├───────────────────────────┤│super = &quot;java.lang.Object&quot; │├───────────────────────────┤│interface = CharSequence...│├───────────────────────────┤│field = value[],hash,...   │├───────────────────────────┤│method = indexOf()...      │└───────────────────────────┘\nJVM为每个加载的class创建了对应的Class实例，并在实例中保存了该class的所有信息，包括类名、包名、父类、实现的接口、所有方法、字段等，因此，如果获取了某个Class实例，我们就可以通过这个Class实例获取到该实例对应的class的所有信息。\n反射是什么呢？反射就是通过Class实例来获取class信息\n使用Class虽然我们没有创建Class的权利，但是我们可以调用它\n[法一]：通过类名\nClass cls = String.class;\n[法二]：通过实例\nString str = &quot;你好&quot;;Class cls = str.getClass();\n[法二]：通过调用forName()方法，这个方法需要知道包路径（但是这个方法的参数只能填类或者接口，否则会抛出异常）\nClass.forName(&quot;java.lang.String&quot;);\nJVM对于相同类型的类只会为它创建一个Class，所以上述三个方法会调取到同一个Class\nClass实例比较和instanceof区别Integer i = new Integer(1);System.out.println(i instanceof Integer);//trueSystem.out.println(i instanceof Number);//true\ninstanceof判定子类是父类的也是祖父类的实例\nSystem.out.println(i.getClass() == Integer.class);//trueSystem.out.println(i.getClass() == Number.class);//不可比较，编译报错\nClass实例只能使用==比较，并且比较的两个必须相同类型（在参考资料中，最后这一个比较会返回false，而不是报错，而我实测编译报错，版本为JDK1.8）\n获取信息反射的目的就是调用Class来获取class的信息\nClass中有大量的方法，我们写一个如下的函数\nstatic void printClassInfo(Class cls) &#123;    System.out.println(&quot;Class name: &quot; + cls.getName());    System.out.println(&quot;Simple name: &quot; + cls.getSimpleName());    if (cls.getPackage() != null) &#123;        System.out.println(&quot;Package name: &quot; + cls.getPackage().getName());    &#125;    System.out.println(&quot;is interface: &quot; + cls.isInterface());    System.out.println(&quot;is enum: &quot; + cls.isEnum());    System.out.println(&quot;is array: &quot; + cls.isArray());    System.out.println(&quot;is primitive: &quot; + cls.isPrimitive());&#125;\n当我们输入参数为String.class（一个类）\nClass name: java.lang.StringSimple name: StringPackage name: java.langis interface: falseis enum: falseis array: falseis primitive: false\n当我们输入参数为Runnable.class（一个接口）\nClass name: java.lang.RunnableSimple name: RunnablePackage name: java.langis interface: trueis enum: falseis array: falseis primitive: false\n当我们输入参数为java.time.Month.class（一个枚举类）\nClass name: java.time.MonthSimple name: MonthPackage name: java.timeis interface: falseis enum: trueis array: falseis primitive: false\n当我们输入参数为String[].class（一个数组）\nClass name: [Ljava.lang.String;Simple name: String[]is interface: falseis enum: falseis array: trueis primitive: false\n当我们输入参数为int[].class（一个数组）\nClass name: [ISimple name: int[]is interface: falseis enum: falseis array: trueis primitive: false\n当我们输入参数为int.class（一个基本类型）\nClass name: intSimple name: intis interface: falseis enum: falseis array: falseis primitive: true\n当我们输入参数为void.class（一个基本类型）\nClass name: voidSimple name: voidis interface: falseis enum: falseis array: falseis primitive: true\n\n上面的例子，基本上提到了所有可能出现的情况，类、接口、数组、枚举、基本类型（void）\nClass都可以将他们的信息打印出来\n（有意思的是：在打印void的primitive属性时，显示为true，对这个感兴趣可以自己搜一下哈，在《Java编程思想》这本圣经级别的书中，它把void也规定为了基本类型）\nClass也可以创建class实例Class cls = String.class;String s = (String) cls.newInstance();\n以上这个方法相当于new String()，通过newInstance()方法可以创建实例，但是有一定的局限：只能调用public的无参数构造方法，带参数的构造方法，或者非public的构造方法都无法通过Class.newInstance()被调用\n将 forName 与 newlnstance 配合起来使用， 可以根据存储在字符串中的类名创建一个对象 \nString s = &quot;java.util.Random&quot;;Object m = Class.forName(s).newlnstance();\n\n动态加载在JVM执行Java程序时，并不是一次性加载所有的类到内存，而是第一次要用到的时候才回去加载\n使用这个特性我们可以在运行期根据条件来控制加载class。\n\n参考资料廖雪峰官方网站官方API《Java核心技术卷一》\n\n","categories":["Java","反射"],"tags":["反射"]},{"title":"Java反射_检查类结构","url":"/2020/03/01/Java%E5%8F%8D%E5%B0%84/Java%E5%8F%8D%E5%B0%84-%E6%A3%80%E6%9F%A5%E7%B1%BB%E7%BB%93%E6%9E%84/","content":"\n引言：反射机制\n\n\n\n\n使用反射类我们使用反射类主要就就是为了检查类的结构\n一个类主要由三个部分组成\n\nField 字段域\nMethod 方法\nConstructor 构造器\n\nField主要有四个方法，以Filed为例\nField getField(name)Field getDeclaredField(name)Field[] getFields()Field[] getDeclaredFields()\n\nClass类中的 getFields、 getMethods 和 getConstructors方法将分别返回类提供的 public域、 方法和构造器数组， 其中包括超类的公有成员\nClass 类的 getDeclareFields、 getDeclareMethods 和 getDeclaredConstructors方法将分别返回类中声明的全部域、 方法和构造器， 其中包括私有和受保护成员，但不包括超类的成员\n区别就是：\n\ngetField()只能返回public的字段、包括继承自父类的字段\ngetDeclareField()返回全部字段，不会返回继承的字段\n\n例如：\nclass Student extends Person &#123;    public int score;    private int grade;    protected int edu;    int id;&#125;class Person &#123;    public String name;&#125;\npublic static void main(String[] args) throws Exception &#123;    Class cls = Student.class;    Field[] fields1 = cls.getFields();    System.out.println(Arrays.toString(fields1));    //[public int Student.score, public java.lang.String Person.name]    Field[] fields2 = cls.getDeclaredFields();    System.out.println(Arrays.toString(fields2));    //[public int Student.score, private int Student.grade, protected int Student.edu, int Student.id]&#125;\n\n\n\n\n获得到Field对象之后，这个字段的任意信息我们都可以查看了\npublic String getName()//返回字段名称public Class&lt;?&gt; getType()//返回字段类型，也是一个Class实例，例如，String.class；public int getModifiers()//返回字段的修饰符，它是一个int，不同的bit表示不同的含义，可以使用Modifier类的静态方法来解析\n我们尝试了解String类的value字段\npublic final class String &#123;    private final byte[] value;&#125;\nField f = String.class.getDeclaredField(&quot;value&quot;);f.getName(); // &quot;value&quot;f.getType(); // class [B 表示byte[]类型int m = f.getModifiers();Modifier.isFinal(m); // trueModifier.isPublic(m); // falseModifier.isProtected(m); // falseModifier.isPrivate(m); // trueModifier.isStatic(m); // false\n\n上述只是第一步，我们更多时候是想得到实例的字段值\n我们要读取的类\nclass Student extends Person &#123;    public int score;    private int grade;    public void setGrade(int grade) &#123;        this.grade = grade;    &#125;    public int getGrade() &#123;        return grade;    &#125;    public Student(String name) &#123;        super(name);    &#125;&#125;class Person &#123;    public String name;    public Person(String name) &#123;        this.name = name;    &#125;&#125;\n\nStudent stu1 = new Student(&quot;Jack&quot;);Student stu2 = new Student(&quot;Rose&quot;);//------------分隔----------Class cls = Student.class;Field name = cls.getField(&quot;name&quot;);Object o1 = name.get(stu1);Object o2 = name.get(stu2);System.out.println(o1);//JackSystem.out.println(o2);//Rose\n核心是调用Field实例的get()方法\n如果我们访问一个private字段呢？\nStudent stu1 = new Student(&quot;Jack&quot;);Student stu2 = new Student(&quot;Rose&quot;);stu1.setGrade(1);stu2.setGrade(2);//------------分隔----------Class cls = Student.class;Field grade = cls.getDeclaredField(&quot;grade&quot;);//获取要用getDeclaredField方法Object o = grade.get(stu1);System.out.println(o);   \n结果报错了\nException in thread &quot;main&quot; java.lang.IllegalAccessException:...\n这是因为正常情况下，private标记的字段是不能被其他类访问的\n修复错误我们可以调用setAccessible方法，设置后，我们就可以访问任意类型了\nField grade = cls.getDeclaredField(&quot;grade&quot;);grade.setAccessible(true);//加上这个Object o = grade.get(stu1);System.out.println(o);//1\n\nsetAccessible(true)可能会失败。如果JVM运行期存在SecurityManager，那么它会根据规则进行检查，有可能阻止setAccessible(true)。例如，某个SecurityManager可能不允许对java和javax开头的package的类调用setAccessible(true)，这样可以保证JVM核心库的安全。\n\n可以访问了，当然就可以赋值了\nField score = cls.getDeclaredField(&quot;score&quot;);score.set(stu1,99);\n核心是set(object,object)方法，第一个参数输入实例、第二个参数输入待修改的值（注意类型要匹配，否则会报错）同样如果要访问私有字段，依然要设置setAccessible(true)\nMethod获得Method\nMethod getMethod(name, Class...)//获取某个public的Method（包括父类）Method getDeclaredMethod(name, Class...)//获取当前类的某个Method（不包括父类）Method[] getMethods()//获取所有public的Method（包括父类）Method[] getDeclaredMethods()//获取当前类的所有Method（不包括父类）\n基本和Field相同，但在调用时要注意参数，例如：\nclass Student&#123;    private String name;    private int id;    public void nothing()&#123;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public int getId() &#123;        return id;    &#125;    public void setId(int id) &#123;        this.id = id;    &#125;&#125;\npublic static void main(String[] args) throws Exception &#123;    Student stu1 = new Student();    //调用有参方法    Method method1 = Student.class.getMethod(&quot;setName&quot;,String.class);    Method method2 = Student.class.getMethod(&quot;setId&quot;, int.class);    //调用无参方法    Method method3 = Student.class.getMethod(&quot;nothing&quot;);&#125;\n\n使用Method\n使用反射实现subString功能\nString name = &quot;hello world&quot;;Method method = String.class.getMethod(&quot;substring&quot;, int.class);//Method method = String.class.getMethod(&quot;substring&quot;, int.class,int.class);//改变参数即可选择是哪个重载函数System.out.println(method.invoke(name, 6));//world\n核心是invoke()方法\npublic Object invoke(Object obj,                     Object... args)              throws IllegalAccessException,                     IllegalArgumentException,                     InvocationTargetException/*第一个参数是这个方法所操作的对象，第二及以后的参数都是原方法的参数（待补充）*/\n\n访问非public方法，记得设置许可\nConstructor\n调用Class.newInstance()的局限是，它只能调用该类的public无参数构造方法。如果构造方法带有参数，或者不是public，就无法直接通过Class.newInstance()来调用。\n\n获取Constructor依然使用getConstructor或getDeclareConstructor()方法\n这种情况我们可以使用反射来解决\nConstructor&lt;Integer&gt; constructor = Integer.class.getConstructor(int.class);Integer integer = constructor.newInstance(5);\n核心在于newInstance()方法，参数传递构造方法需要传递的参数\n同样访问非public方法，记得设置许可\n\n参考资料廖雪峰官方网站官方API《Java核心技术卷一》\n\n","categories":["Java","反射"],"tags":["反射"]},{"title":"Java-API-1","url":"/2019/08/11/Java/Java-API-1/","content":"\n引言：\n\nAPI是什么？\n如何使用呢？\nScanner类\nRandom类\nArrayList类\n\n\n\n\n\nAPIAPI是什么Application Programming Interface\n应用程序编程接口，其实就是一堆前辈已经写好的，可以直接复用的常用组件\nAPI文档的使用第一看 包路径\n第二看 构造方法\n第三看 普通方法\n引用API的使用步骤\n导包\n import 包路径. 类名称\n 如果需要使用的目标类和当前类处于同一个包下，那么就不需要导包了\n 只有java.lang包下的内容不需要导包，其他都需要用到import语句\n\n创建 类名称 对象名 = new 类名称();\n\n使用 对象名.成员方法名()\n\n\n\n那么开始学习第一个API吧\n\nScanner一个可以使用正则表达式来解析基本类型和字符串的简单文本扫描器。\nScanner 使用分隔符模式将其输入分解为标记，默认情况下该分隔符模式与空白匹配。然后可以使用不同的 next 方法将得到的标记转换为不同类型的值。 \n包路径：java.util\n\n构造方法://有很多构造方法，包括从文件中读入的scanner构造//目前只需要了解以下即可public Scanner(InputStream source)// 从指定的输入流扫描，并通过默认字符集转换为字符\n常用方法：public boolean nectInt()    //输入int变量public double nectDouble()  //输入double变量public float nectFloat()    //输入float变量public String nect()        //输入String变量public byte nextByte()      //输入Byte变量public short nectShort()    //输入short类型public long nectInt()       //输入long类型public boolean nextBoolean()//输入boolean类型\n\n示例代码：Scanner sc = new Scanner(System.in);//构造一个系统输入的Scanner类//调用最常见的方法int x1 = sc.nextInt();String x2 =sc.next();long x3 = sc.nextLong();double x4 = sc.nextDouble();byte x5 = sc.nextByte();short x6 = sc.nextShort();boolean x7 = sc.nextBoolean();float x8 = sc.nextFloat();\n\nRandom使用了48位的种子，使用线性同余公式生成伪随机数流\n包路径：java.util\n\n构造方法：public Random()// 创建一个新的随机数生成器。// 此构造方法将随机数生成器的种子设置为某个值，// 该值与此构造方法的所有其他调用所用的值完全不同。 \n常用方法：public int nextInt()//返回下一个伪随机数，它是此随机数生成器的序列中均匀分布的 int 值public int nextInt(int n)//返回一个伪随机数，它是从[0,n)的一个随机的整型，左开右闭区间\n示例代码：Random r = new Random();// 构造Random类int num = r.nextInt(5);//返回一个[0,5)的随机数System.out.println(num);int num2 = r.nextInt(5)+1;//返回一个[0,5]的随机数,只需要加一个1即可\n\nArrayListList 接口的大小可变数组的实现。\n实现了所有可选列表操作，并允许包括 null 在内的所有元素。\n除了实现 List接口外，此类还提供一些方法来操作内部用来存储列表的数组的大小\n尖括号内的E叫做泛型，装在该集合当中的所有元素都必须是统一的类型\n泛型只能是引用类型，不能是基本类型\n包路径：java.util\n\n构造方法：public ArrayList(Collection&lt;? extends E&gt; c)//构造一个包含指定 collection 的元素的列表，//这些元素是按照该 collection的迭代器返回它们的顺序排列的。 \n常用方法public E set(int index,E element);  //输入索引值和相同的泛型内容替换原有的内容public E get(int index)             //返回索引值对应的内容public boolean add(E e)             //把指定元素添加到集合的尾部public void add(int index,E element)//添加指定的元素到索引值处，后面的内容索引值加一public E remove(int index)          //移除集合上指定位置上的元素public boolean remove(Object o)     //移除此列表中首次出现的指定元素（如果存在）。如果列表不包含此元素，则列表不做改动public void clear()                 //移除集合中的所有元素public boolean addAll(Collection&lt;? extends E&gt; c)//将另一个集合并入此集合public boolean addAll(int index,Collection&lt;? extends E&gt; c)//从指定位置并入另一个集合public void ensureCapacity(int minCapacity)//增加此ArrayList的容量,以确保至少能容纳参数所指定的元素数public boolean isEmpty()            //判断集合是否为空public boolean contains(Object o)   //判断集合是否含有指定的元素public int indexOf(Object o)//返回此列表中首次出现的指定元素的索引，或如果此列表不包含元素，则返回 -1。public int lastIndexOf(Object o)//返回此列表中最后一次出现的指定元素的索引，或如果此列表不包含索引，则返回 -1。\n\n示例代码：ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();// 创建了一个ArrayList的集合，// 泛型为String类型，代表这个集合内只能含有String类型的数据System.out.println(list);//返回[]//直接打印空集合，返回的并不是地址，而是一个空数组list.add(&quot;小明&quot;);//添加方法list.add(1,&quot;小白&quot;);//指定添加String str = list.get(0);//得值方法list.set(0, &quot;小红&quot;);//替换方法list.remove(0);//移除方法list.remove(&quot;小白&quot;);//移除第一个指定值list.ensureCapacity(9);//最小兼容方法list.isEmpty();//是否空方法list.contains(&quot;小白&quot;);//是否包含方法list.indexOf(&quot;小白&quot;);//求首次出现索引方法list.lastIndexOf(&quot;小白&quot;);//求末次出现索引方法ArrayList&lt;String&gt; list2 = new ArrayList&lt;&gt;();list2.addAll(list);//合并另一个ArrayListlist.size();//返回长度for (int i = 0; i &lt; list.size(); i++) &#123;    System.out.println(list.get(i));&#125;//输入list.fori+TAB快速得到遍历集合的循环\n\n泛型只能导入引用类型，那怎么存入基本类型呢？\n使用基本类型的对应的包装类\n从JDK1.5开始，支持自动装箱拆箱\nArrayList&lt;Integer&gt; list1 = new ArrayList&lt;&gt;();list1.add(100);//完成了自动装箱list1.add(new Integer(100));//手动装箱，同上","categories":["后台","Java"],"tags":["Java","JavaAPI"]},{"title":"Java-API-4","url":"/2019/08/13/Java/Java-API-4/","content":"\n引言：\n\nDate类\nDateFormat类\nCalendar类\n\n\n\n\n\nDate表示特定的瞬间，精确到毫秒，可以对日期和事件进行计算，计算完毕再讲毫秒转换为日期\n包路径java.util\n\n构造方法public Date()//分配 Date 对象并初始化此对象，以表示分配它的时间（精确到毫秒）。 public Date(long date)//分配 Date 对象并初始化此对象，以表示自从标准基准时间（称为“历元（epoch）”，即 1970 年 1 月 1 日 00:00:00 GMT）以来的指定毫秒数。\n\n常用方法public long getTime()//public long getTime()\n\n示例代码System.out.println(System.currentTimeMillis());//系统的方法Date d = new Date(); //构造一个日期类System.out.println(d.getTime());//日期类的常用方法\n\nDateFormat(SimpleDateFormat)对日期进行一个格式化，是一个抽象类\n可以用来进行 日期和文本 之间的转化\nDateFormat是一个抽象类，无法直接创建对象使用，可以使用DateFormat类的子类SimpleDateFormat来创建对象\n包路径java.text.DateFormatjava.text.SimpleDateFormat\n\n构造方法public SimpleDateFormat(String pattern)//参数：字符串类型的参数，要传递一个指定的模式//年(y)月(M)日(d)时(H)分(m)秒(s)//例如 &quot;yyyy-MM-dd HH:mm:ss&quot;\n注意：模式中的字母不能改变，连接的符号可以改变\n例如改为 “yyy年MM月dd日 HH:mm:ss”\n常用方法DateFormat的常用方法\npublic String format(Date date)//按照指定的模式，把日期转换为符合模式的字符串public Date parse(String source)//把符合模式的字符串转换为date日期\n\nSimpleDateFormat的常用方法\nformat(Date date, StringBuffer toAppendTo, FieldPosition pos) //将给定的 Date 格式化为日期/时间字符串，//并将结果添加到给定的 StringBuffer。parse(String text, ParsePosition pos)//解析字符串的文本，生成 Date。//声明了一个异常叫ParseException，//如果字符串和构造方法的模式不同，则会抛出此异常\n示例代码//这里要加一个throws抛出异常SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy年MM月dd日 HH时mm分ss秒&quot;);// 创建一个格式Date date = new Date();// 创建当前日期System.out.println(sdf.format(date));// 按照格式解析日期对象Date d = sdf.parse(&quot;2000年1月5日 00时00分00秒&quot;);// 解析文本,文本格式不正确的话会报出异常System.out.println(d);\n\nCalendar日历类，也是一个抽象类，无法直接创建对象\n它为特定瞬间与一组诸如 YEAR、MONTH、DAY_OF_MONTH、HOUR 等 日历字段之间的转换提供了一些方法，并为操作日历字段（例如获得下星期的日期）提供了一些方法。\n包路径java.util\n\n构造方法protected Calendar()\n常用方法public static Calendar getInstance()//使用默认时区和语言环境获得一个日历。返回的 Calendar 基于当前时间，使用了默认时区和默认语言环境。 public int get(int field)//返回给定日历字段的值public void set(int field,int value)//将给定的日历字段设置为给定值。public abstract void add(int field,int amount)//根据日历的规则，为给定的日历字段添加或减去指定的时间量public final Date getTime()//返回一个表示此 Calendar 时间值（从历元至现在的毫秒偏移量）的 Date 对象。 \n\n示例代码Calendar c = Calendar.getInstance();// getInstance方法System.out.println(c);//打印出一长串日历字段//参数 int field :是一个日历类的字段，可以使用Calendar类的静态成员变量获取int year = c.get(Calendar.YEAR);int month = c.get(Calendar.MONTH);// 西方月份0-11int date = c.get(Calendar.DATE);//get方法System.out.println(year +&quot; &quot;+ month +&quot; &quot;+ date);//2019 7 13//set方法c.set(Calendar.YEAR,9999);c.set(Calendar.MONTH,9);c.set(Calendar.DATE,9);c.set(8888,8,8);//同时设置System.out.println(c.get(Calendar.YEAR));// 8888c.add(Calendar.YEAR,2);//add方法,增加两年System.out.println(c.get(Calendar.YEAR));//8890Date d = c.getTime();// getTime返回一个日期类System.out.println(d);// Fri Sep 08 11:44:23 GMT+08:00 8890\n","categories":["后台","Java"],"tags":["Java","JavaAPI"]},{"title":"Java-API-2","url":"/2019/08/12/Java/Java-API-2/","content":"\n引言：\n\nString类\nArrays类\n\n\n\n\n\nStringString 类代表字符串。Java 程序中的所有字符串字面值（如 “abc” ）都作为此类的实例实现。 \n字符串是常量；它们的值在创建之后不能更改。字符串缓冲区支持可变的字符串。因为 String 对象是不可变的，所以可以共享。 \n包路径：java.lang\n\n构造方法：public String()//初始化一个新创建的 String 对象，使其表示一个空字符序列。//由于 String 是不可变的，所以无需使用此构造方法。 public String(char[] value) //表示字符数组参数中当前包含的字符序列public String(byte[] bytes)//通过使用平台的默认字符集解码指定的 byte 数组，构造一个新的 String。//还有一种直接创建的方式，使用类似于int关键字\n\n常用方法：比较方法\npublic boolean equals(Object anObject)//将此字符串与指定的对象比较。//当且仅当该参数不为null，并且是与此对象表示相同字符序列的 String 对象时，结果才为 true。 public boolean equalsIgnoreCase(String anotherString)//不考虑大小写比较。//如果两个字符串的长度相同，并且其中的相应字符都相等（忽略大小写），则认为这两个字符串是相等的。\n属性获取方法\npublic int length()//返回此字符串的长度public boolean isEmpty()//长度为0时返回 true。 public char charAt(int index)//返回指定索引处的 char 值。索引范围为从 0 到 length() - 1public int indexOf(String str)//返回指定子字符串在此字符串中第一次出现处的索引，没有返回-1\n裁剪方法\npublic String concat(String str)//将指定字符串连接到此字符串的结尾。 //如果参数字符串的长度为 0，则返回此 String 对象。否则，创建一个新的 String 对象public String substring(int index);//从参数位置一直到字符串末尾，返回新字符串public String(intbegin,intend);//从begin开始到end,左闭右开区间。\n转换方法\npublic char[] toCharArray();//将当前字符串拆分为字符数组作为返回值public byte[] getBytes();//获得当前字符串的底层的字节数组public String replace(CharSequence oldString,CharSequence newString);//将所有的老字符串换成新的字符串\n分割方法\npublic String[] split(String regex);//按参数的规则，将字符串且分为若干部分（参数是一个正则表达式,不能切割英文句点&quot;.&quot;，要写&quot;.&quot;要加转义符反斜杠&quot;\\\\.&quot;）\n\n示例代码：构造方法\nString str1 = &quot;hello&quot;;//直接构造System.out.println(str1);// helloString str2 = new String();//空参构造一个空字符串System.out.println(str2);// &#x27;&#x27;空char[] charArray = &#123;&#x27;a&#x27;,&#x27;w&#x27;,&#x27;c&#x27;&#125;;String str3 = new String(charArray);//用字符数组构造System.out.println(str3);//awcbyte[] byteArray = &#123;85,49,35&#125;;String str4 = new String(byteArray);//用ASCII码构造System.out.println(str4);//U1#\n常用方法:\n比较方法\nString str1 = &quot;hello&quot;;String str2 = &quot;hello&quot;;char[] arr = &#123;&#x27;h&#x27;,&#x27;e&#x27;,&#x27;l&#x27;,&#x27;l&#x27;,&#x27;o&#x27;&#125;;String str3 = new String(arr);String str4 = &quot;HellO&quot;;System.out.println(str1==str2);//true//直接使用等号比较，比较的是地址，又因为相同字符串的地址会归在一起，所以为trueSystem.out.println(str1==str3);//false 与str3此时地址就不一样了System.out.println(str1.equals(str2));//true 直接比较内容System.out.println(str1.equals(str3));//trueSystem.out.println(str1.equalsIgnoreCase(str4));//true\n属性获取方法\nSystem.out.println(str1.length());//5   长度获取方法System.out.println(str1.charAt(3));//l  获取元素方法System.out.println(str1.indexOf(&quot;h&quot;));//0  查找索引方法\n裁剪方法\nString str1 = &quot;hello&quot;;String str2 = &quot;hello&quot;;str1.concat(str2);//hellohello&quot;你好&quot;.concat(str1);//你好hellostr1.substring(2);//llo str1.substring(2,4); //ll\n\n转换方法\nString str1 = &quot;hello&quot;;char[] arr1 = str1.toCharArray(); //拆分当前字符串为数组byte[] arr2 = str1.getBytes();  // 获得当前字符串的底层数组String str2 = str1.replace(&#x27;l&#x27;,&#x27;w&#x27;);// hewwo 新字符代替旧字符\n\n分割方法\nString str1 = &quot;he,l,lo&quot;;String[] str2 = str1.split(&quot;,&quot;);// 用,对其进行分割for (int i = 0; i &lt; str2.length; i++) &#123;    System.out.println(str2[i]);// 分成he  l  lo&#125;\n\n字符串常量池在java虚拟机堆中，字符串有一个专门的常量池\n直接写上双引号的字符串，就在字符串常量池中\nnew创建的字符串不在常量池内\n对于引用类型来说，等于号是对地址进行的比较\n特点：\n\n字符串的内容不可以改变\n字符串内部是可以共享使用的，相同加了双引号的字符串，如果内容都相同，他的地址也是来自一块地址的\n字符串的底层原理是byte字节数组\n\nArrays用来操作数组（比如排序和搜索）的各种方法\n包路径java.util\n\n构造方法所有的数组都可以使用这个类的方法\n常用方法public static String toString(int[] a)//把数组转换为字符串，数组不限定类型，有多种重载函数public static void sort(int[] a)//排序：数字按从小到大排序，字母按字母升序\n\n示例代码int[] arr = &#123;3,8,2,1&#125;;String str = Arrays.toString(arr);// 转换为字符串System.out.println(str);// [3,8,2,1]Arrays.sort(arr);//从小到大排序，改变了原数组的顺序System.out.println(Arrays.toString(arr));//[1,2,3,8]","categories":["后台","Java"],"tags":["Java","JavaAPI"]},{"title":"Java-API-3","url":"/2019/08/12/Java/Java-API-3/","content":"\n引言：\n\nMath类\nObject类\nObjects类\n\n\n\n\n\nMathMath 类包含用于执行基本数学运算的方法，如初等指数、对数、平方根和三角函数。 \n包路径java.lang\n\n构造方法直接通过Math调用，没有构造函数\n常用方法public static double abs(double num)//获取绝对值public static double ceil(double num)//向上取整public static double floor(double num)//向下取整public static long round(double num)//四舍五入Math.PI\t//代表近似的圆周率常量\n\n示例代码int x = -8;double y = 2.6;System.out.println(Math.abs(x));    // 8  绝对值System.out.println(Math.ceil(y));   // 3.0 向上取整System.out.println(Math.floor(y));  // 2.0 向下取整System.out.println(Math.round(y));  // 3  四舍五入System.out.println(Math.PI);        // 3.1415926 圆周率\n\nObject类 Object 是类层次结构的根类。\n每个类都使用 Object 作为超类。所有对象（包括数组）都实现这个类的方法。 \n包路径java.lang\n\n构造方法public Object()\n\n常用方法public String toString() // 返回该对象的字符串表示//该字符串由类名（对象是该类的一个实例）、at 标记符“@”和此对象哈希码的无符号十六进制表示组成public boolean equals(Object obj)//\n\n示例代码toString\nfather f = new father();String str = f.toString();System.out.println(str);//cn.itcast.day04.demo01.father@1b6d3586System.out.println(f);//cn.itcast.day04.demo01.father@1b6d3586// 直接打印一个对象直接调用了toString方法\n但是直接打印一个对象的地址没有什么意义，我们重写它的String方法\npublic class father &#123;    public String name;    @Override    public String toString()&#123;        return &quot;Person:&quot;+name;    &#125;//这时候再打印就会返回我们重写之后的形式&#125;//看一个类是否重写了toString我们直接打印这个类的对象即可，//如果没有重写toString方法，打印的就是对象的地址值\n\nequals\n//源码：从源码可以看出，默认的比较是比较地址的位置public boolean equals(Object obj)&#123;return(this  ==  obj);&#125;//原本的比较father f1 = new father(&quot;A&quot;);father f2 = new father(&quot;A&quot;);System.out.println(f1.equals(f2));// false 比较地址，地址不同f1 = f2;System.out.println(f1.equals(f2));// true 地址相同\n但是我们比较他们的地址没有意义，所以我们重写一下equals方法\n@Overridepublic boolean equals(Object obj)&#123;    //因为obj是Object的子类，我们必须要向下转型,否则不能调用子类新增的成员    father f = (father)obj;    return this.name.equals(f.name);&#125;\n又考虑到传入空或者传入其他类型的对象，可能会报错，我们完善一下重写的方法\n使用ALT+insert即可\n@Overridepublic boolean equals(Object o) &#123;    if (this == o) return true;//地址相同直接返回true    if (o == null || getClass() != o.getClass()) return false;    // 如果是一个null返回false    //getClass()!= o.getClass()利用反射技术，判断o是否是原本的类型    // 等效于 o instanceof father 这句话    father father = (father) o;    return Objects.equals(name, father.name);    //object的方法容易抛出空指针异常，Objects解决了这个问题&#125;@Overridepublic int hashCode() &#123;    return Objects.hash(name);&#125;//对于集合的方法\n\nObjectsJDK7添加，提供了一些静态方法来操作对象，这些方法是空指针安全的\n包路径java.util\n\n构造函数无构造方法，直接调用Objects来使用\n常用方法//equals源码public static boolean equals(Object a,Object b) &#123;return  (a==b)  ||  (  a!=null &amp;&amp; a.equals(b)  );//先比较地址，再判断是不是空指针，然后再调用Object的&#125;requireNonNull()//查看是否为空对象//有两个参数，第一个是要判断的对象，第二个是放置想要报出的错误信息\n\n示例代码直接使用Obejct的equals会报空指针异常\nString s1 = null;s1.equals(&#x27;a&#x27;);//报错Exception in thread &quot;main&quot; java.lang.NullPointerException\n而Obejcts不会报错\nString s1 = null;Objects.equals(s1, &quot;a&quot;);\n\n查看是否为空对象\nString s1 = null;Objects.equals(s1, &quot;a&quot;);\n\n","categories":["后台","Java"],"tags":["Java","JavaAPI"]},{"title":"Java-API-5","url":"/2019/08/13/Java/Java-API-5/","content":"\n引言：\n\nSystem类\nStringBuilder类\n\n\n\n\n\nSystemSystem 类包含一些有用的类字段和方法。\n它不能被实例化。 \n在 System 类提供的设施中，有标准输入、标准输出和错误输出流；\n对外部定义的属性和环境变量的访问；加载文件和库的方法；还有快速复制数组的一部分的实用方法。 \n包路径java.lang\n\n构造方法不能实例化\n常用方法public static long currentTimeMillis()//返回以毫秒为单位的当前时间public static void arraycopy(Object src,int srcPos,Object dest,int destPos,int length)//从指定源数组中复制一个数组，复制从指定的位置开始，到目标数组的指定位置结束//五个参数:src(源数组),srcPos(源数组的起始位置),dest(目标数组),destPos(目标数组中的起始位置),length(要复制的数组元素的数量)\n\nStringBuilderString类是一个常量，他们的值在创建以后不能更改\n而字符串缓冲区支持可变的字符串——StringBuider类\n可以提高字符串的操作效率\nString类和StringBuilder类的区别\nString类\n  字符串是一个常量，他们的值在创建之后不能再更改，字符串的底层是一个被final修饰的数组，不能改变，是一个常量private final byte[] value\n  比如说进行一个字符串的加减String s = &quot;a&quot; + &quot;b&quot; + &quot;c&quot; = &quot;abc&quot;\n  在这个过程中，会出现五个字符串  “a” “b” “c” “ab” “abc”\n  这样大大的占用了空间\n\nStringBuilder类\n  是一个字符串的缓冲区，可以提高字符串的操作效率，可以看成一个长度可以变化的字符串，底层也是一个数组，但是没有被final修饰  byte[] value = new byte[16]\n  StringBuilder类在内存中始终是一个数组，占用空间少，效率高\n  如果超出了StringBuilder的容量，就会自动的扩容\n\n\n包路径java.lang\n\n构造函数public StringBuilder()//构造一个不带任何字符的字符串生成器，其初始容量为 16 个字符。 public StringBuilder(String str)//构造一个字符串生成器，并初始化为指定的字符串内容。该字符串生成器的初始容量为 16 加上字符串参数的长度。 \n\n常用方法public StringBuilder append(boolean b)//参数可以是任意类型，有多个重载函数//将 boolean 参数的字符串表示形式追加到序列,//参数将被转换成字符串,将所得字符串中的字符追加到此序列。 public String toString()//返回此序列中数据的字符串表示形式\n\n示例代码构造方法\nStringBuilder builder1 = new StringBuilder();//空参构造System.out.println(builder1);// 空StringBuilder builder2 = new StringBuilder(&quot;abc&quot;);//有参构造System.out.println(builder2);//abc\n\n常用方法\n//使用append方法象棋中添加数据,// append返回值是一个this,即返回调用方法的对象，// 所以我们使用append方法不需要接收返回值builder1.append(15);//int类型builder1.append(&quot;你好&quot;);//字符串System.out.println(builder1);//15你好//可以链式编程builder1.append(2019).append(true).append(&quot;链式编程&quot;);System.out.println(builder1);//15你好2019true链式编程\n//StringBuilder类可以和String相互转换//String-&gt;StringBuilder可以使用StringBuilder方法String str1 = builder1.toString();System.out.println(str1);//15你好2019true连式编程//StringBuilder-&gt;String使用StringBuilder方法String str2 = &quot;字符串&quot;;StringBuilder builder3 = new StringBuilder(str2).append(&quot;world&quot;);System.out.println(builder3);//字符串world\n","categories":["后台","Java"],"tags":["Java","JavaAPI"]},{"title":"Properties","url":"/2019/08/21/Java/Java-IO-Properties/","content":"\n引言：\nProperties配置文件   \n\n\n\n\n\nProperties\nProperties 属性映射：是一种存储键值对的数据结构，在java中用来存储配置信息\n\n特性：\n\n继承自Hashtable，每个键及其对应值都是一个字符串\n映射可以很容易的存入文件以及从文件中加载\n有一个二级表保存默认值\n该类也被许多Java类使用，比如获取系统属性时，System.getProperties方法就是返回一个Properties对象\n\nProperties集合是唯一一个与IO流相结合的集合\n包路径java.util\n\n常用方法\nProperties集合是一个双列集合，key和value默认都是字符串\nProperties集合有一些操作字符串的特有方法  public Object setProperty(String key,String value)//设置键值public String getProperty(String key)//通过key找到value值,用指定的键在此属性列表中搜索属性，相当于Map集合中的get方法public String getProperty(String key,String defaultValue)//当找不到key值时，会返回设置的默认值public Set&lt;String&gt; stringPropertyNames()//返回此属性列表中的键集，其中该键及其对应值是字符串，相当于Map集合中的keySet方法\n\nProperties prop = new Properties();prop.setProperty(&quot;赵丽颖&quot;,&quot;160&quot;);prop.setProperty(&quot;迪丽热巴&quot;,&quot;165&quot;);prop.setProperty(&quot;古力娜扎&quot;,&quot;160&quot;);//set只能输入字符串Set&lt;String&gt; set = prop.stringPropertyNames();//使用stringPropertyNames方法把集合中的键取出，存储到一个set集合中//遍历set集合，取出Properties集合的每一个键for (String s : set) &#123;    System.out.println(prop.getProperty(s));&#125;\n\nstore方法public void store(Writer writer,String comments)throws IOExceptionpublic void store(OutputStream out,String comments)throws IOException/*用来把集合中的临时数据持久化的写入到硬盘中参数一个是字节流，一个是字符流String comments是用来解释说明保存的文件是做什么用的，不能使用中文，会产生乱码，默认是Unicode编码，一般使用空字符串*/\n步骤：\n\n创建Properties集合对象\n使用setProperty()方法存入键值对\n创建字节/字符流对象\n使用Properties集合中的方法store，把集合中的临时数据持久化写入到硬盘中存储\n释放资源\n\n示例代码\nProperties prop = new Properties();prop.setProperty(&quot;username&quot;,&quot;Jack&quot;);prop.setProperty(&quot;password&quot;,&quot;123&quot;);FileWriter fw = new FileWriter(&quot;D:\\\\a.txt&quot;);prop.store(fw,&quot;Settings&quot;);fw.close();\n运行后的a.txt文件，会自动加一个时间\n#Settings#Fri Jan 17 11:27:04 GMT+08:00 2020password=123username=Jack\n\nload方法public void load(Reader reader)throws IOExceptionpublic void load(InputStream inStream)throws IOException/*参数 Inputstream inStream字节输入流，不能读取含有中文的键值对Reader reader：字符输入流，能读取含有中文的键值对*/\n步骤：\n\n创建Properties集合对象\n创建字符/字节输入流\n使用Properties集合对象中的方法load读取保存键值对的文件\n遍历Properties集合\n\nProperties prop = new Properties();prop.load(new FileReader(&quot;D:\\\\a.txt&quot;));Set&lt;String&gt; set = prop.stringPropertyNames();for (String s : set) &#123;    String value =prop.getProperty(s);    System.out.println(value);&#125;\n\n注意：\n\n存储键值对的文件中，键与值默认的连接符号可以使用 -，空格（其他符号）\n存储键值对的文件中，可以使用#进行注释，被注释的键值对不会再被读取\n存储键值对的文件中，键与值默认都是字符串，不用再加引号\n\nSystem中的Properties方法\nProperties getProperties()//获取所有的系统属性，应用必须有权获得属性，否则会抛出一个安全异常String getProperty(String key)//获取给定键名对应的系统属性\n\n例子\nProperties properties = System.getProperties();Set&lt;String&gt; strings = properties.stringPropertyNames();for (String string : strings) &#123;System.out.println(string+&quot;=&quot;+properties.getProperty(string));&#125;//会打印出所有的系统属性\n\n缺点\n 某些操作系统没有主目录的概念，所以很难找到一个统一的配置文件位置\n\n可以用System.out.println(System.getProperties().getProperty(&quot;user.home&quot;));来获取用户主目录\n\n关于配置文件的命名没有标准约定，用户安装多个java应用时，很容易发生命名冲突\n\n","categories":["后台","Java"],"tags":["Java","资源配置"]},{"title":"Java-IO-字符流","url":"/2019/08/21/Java/Java-IO-%E5%AD%97%E7%AC%A6%E6%B5%81/","content":"\n引言：\n\n字符流\n\n\n\n\n\n字符流为了解决读取中文可能会出现的显示不了完整的字符的问题，java提供了字符流类\nReader用于读取字符流的抽象类,是一个抽象类所以我们得使用子类\n子类很多，我们重点学习InputStreamReader类下的FileReader这个类\n包路径java.io\n\n常用方法public int read()throws IOException//读取单个字符public int read(char[] cbuf)throws IOException//将字符读入数组public abstract void close()throws IOException//关闭该流并释放与之关联的所有资源\nWriter同样有很多子类，我们主要关注FileWrite这个子类\n包路径java.io\n\n常用方法public void write(int c)throws IOException//写入单个字符public void write(char[] cbuf)throws IOException//写入字符数组。 public abstract void write(char[] cbuf,int off,int len)throws IOException//写入字符数组的某一部分。 \n\n\n\nFileReader用来读取字符文件的便捷类，\n包路径java.io\n\n构造方法public FileReader(File file)throws FileNotFoundException//在给定从中读取数据的 File 的情况下创建一个新 FileReader。            public FileReader(String fileName)throws FileNotFoundException//在给定从中读取数据的文件名的情况下创建一个新 FileReader。 \n构造方法的作用：\n\n创建一个FileReader对象\n会把FileReader对象指向要读的文件\n\n读取数据步骤：\n\n创建FileReader对象，构造方法中绑定要读取的数据源\n使用FileReader对象中的方法read读取文件\n释放资源\n\nFileReader fr = new FileReader(&quot;D:\\\\a.txt&quot;);int len = 0;while ((len=fr.read()) != -1)&#123;System.out.print((char)len);&#125;fr.close();\n数组也是可以的\nFileReader fr = new FileReader(&quot;D:\\\\a.txt&quot;);int len = 0;char[] cs = new char[1024];while ((len=fr.read(cs)) != -1)&#123;System.out.print(new String(cs,0,len));//选择转化多少为字符串&#125;fr.close();\n\nFileWrite把内存中的字符数据写入到文件中\n包路径java.io\n\n构造方法public FileWriter(File file)throws IOException//参数：写入数据的目的地public FileWriter(String fileName)throws IOException//根据给定的文件名构造一个 FileWriter 对象。\n步骤:\n\n创建FileWriter对象，构造方法中绑定要写入数据的目的地\n使用FileWriter中的方法write，把数据写入到内存缓冲区中（字符转换为字节的过程）\n使用FileWriter中的方法flush，把内存缓冲区中的数据刷新到文件中\n释放资源(会先把内存缓冲区中的数据刷新到文件中)\n\n注意：与其他输出方法不同，writer要走内存缓冲区\nFileWriter fw = new FileWriter(&quot;D:\\\\a.txt&quot;);fw.write(88);fw.flush();fw.close();\n\nclose与flush区别两个方法都可以把数据刷新到文件中\n\nflush : 刷新缓冲区，流对象可以继续使用\nclose : 先刷新缓冲区，然后通知系统释放资源，流对象不可以再被使用了\n\n写出其他数据可以写字符数组，写字符数组的一部分，写字符串，还有字符串的某一部分\nFileWriter fw = new FileWriter(&quot;D:\\\\a.txt&quot;);char[] cs = &#123;&#x27;a&#x27;,&#x27;w&#x27;,&#x27;w&#x27;&#125;;String s = &quot;你好啊&quot;;fw.write(cs);//写字符数组fw.write(cs,0,1);//从第一个开始写，写一个fw.write(s);//写一个字符串fw.write(s,0,1);//从第一个字符串开始写，写一个fw.close();\n续写与换行同字节流\nFileWriter fw = new FileWriter(&quot;D:\\\\a.txt&quot;,true);//续写fw.write(&quot;\\n\\r&quot;);//windows换行\\r\\n//Linux换行\\n//mac换行\\rfw.write(&quot;later equals never&quot;);fw.close();\n\n\nIO流异常抛出的处理一直我们都是throws丢给JVM来处理，但是我们可以使用try\\catch\\finally来处理异常\npublic static void main(String[] args) &#123;    FileWriter fw = null;    try &#123;        fw = new FileWriter(&quot;w:\\\\a.txt&quot;, true);        fw.write(&quot;\\n\\r&quot;);        fw.write(&quot;later equals never&quot;);    &#125; catch (IOException e) &#123;        System.out.println(&quot;出错啦&quot;);    &#125; finally &#123;        if (fw != null) &#123;            //判断fw是否为空            try &#123;                fw.close();            &#125; catch (IOException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n\nJDK7新特性\n  在try的后边可以增加一个()，在括号中可以定义流对象，那么这个流对象的作用域就在try有效，try中的代码执行完毕，会把流对象自动释放，不用写finally\n  格式：\n  try(定义流对象;定义流对象...)&#123;    //可能会产生异常代码&#125;catch(异常类变量 变量名)&#123;    //异常的处理逻辑&#125;\ntry (        FileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);        FileOutputStream fos = new FileOutputStream(&quot;D:\\\\a.txt&quot;);) &#123;    int len = 0;    while ((len = fis.read()) != -1) &#123;        fos.write(len);    &#125;    &#125; catch (IOException e) &#123;        e.printStackTrace();&#125;\nJDK9新特性\n  try的前面我们可以定义流对象，try后面的()中，可以直接引入流对象的名称(变量名)\n  在try代码执行完毕之后，流对象也可以释放掉，不用写finally\n  格式:\n  A a = new A();B b = new B();try(a,b)&#123;    //可能会产生异常代码&#125;catch(异常类变量 变量名)&#123;    //异常的处理逻辑&#125;\n\n","categories":["后台","Java"],"tags":["Java","JavaIO"]},{"title":"Java-IO-字节流","url":"/2019/08/21/Java/Java-IO-%E5%AD%97%E8%8A%82%E6%B5%81/","content":"\n引言: 字节流\n\n\n\n\n\nIO什么是IO流\ninput:输入——数据从硬盘到内存\noutput:输出——数据从内存到硬盘\n流：数据\n\nIO的分类根据数据流向可以分为输入流和输出流\n输入流：把数据从其他设备读取到内存中的流\n输出流：把数据从内存写出到输出设备上的流\n格局数据的类型分为:字节流和字符流\n一切皆为字节明确一个概念：\n一切文本、视频、图片、视频在存储时，都是以二进制数字的形式保存的\n字节输出流OutputStream此抽象类是表示输出字节流的所有类的超类。\n输出流接受输出字节并将这些字节发送到某个接收器\n常用方法public void close()throws IOException//关闭此输出流并释放与此流有关的所有系统资源public void flush() throws IOException//刷新此输出流并强制写出所有缓冲的输出字节public abstract void write(int b)throws IOException//一共有三个write，作用相同//将指定的字节写入此输出流\n\n子类ByteArrayOutputStream//向数组写数据FileOutputStream,//向文件写数据//重点介绍FilterOutputStream,//带过滤器的文件写入ObjectOutputStream, //向对象写数据OutputStream, //其他包内的流PipedOutputStream //管道流\n\nFileOutputStream包路径java.io\n\n构造方法FileOutputStream(File file) // 创建一个向指定 File 对象表示的文件中写入数据的文件输出流//参数是一个文件  FileOutputStream(String name) //创建一个向具有指定名称的文件中写入数据的输出文件流//参数是一个路径\n作用：\n\n创建一个FileOutputStream对象\n会根据构造方法中传递的文件/文件路径，创建一个空的文件\n会把FileOutputStream对象指向创建好的文件\n\n写数据到文件原理：内存-&gt;文件\nJava程序 –&gt; JVM –&gt; OS(操作系统) –&gt; OS调用写数据的方法 –&gt; 把数据写入到文件中\n步骤：\n\n创建一个FileOutputStream对象，构造方法中传递写入数据的目的地\n调用FileOutputStream对象中的方法write，把数据写入到文件中\n释放资源（流会占用一定的内存，使用完毕要把内存清空，提高程序的效率）\n\npublic static void main(String[] args) throws IOException &#123;    FileOutputStream fos = new FileOutputStream(&quot;D:\\\\a.txt&quot;);    fos.write(97);    fos.close();    //文件就自动创建并且写入了一个 a&#125;\n\n文件存储和记事本打开原理\n存储\n\n写入数据会把十进制的整数转化为二进制整数，\nfos.write(97);会把97变为1100001\n\n记事本\n\n任意的文本编辑器（记事本），\n在打开文件的时候都会查询编码表，\n把字节转换为字符表示，会把97变为a\n字节输出流写多个字节的方法FileOutputStream fos = new FileOutputStream(&quot;D:\\\\a.txt&quot;);byte[] bytes = &#123;-49,-99,-28,120&#125;;//如果第一个字节是正数(0-127),那么会查询ASCII码表显示//如果第一个字节是负数，会与第二个字节组成一个中文显示fos.write(bytes);fos.close();\n选定输入几个字节\nFileOutputStream fos = new FileOutputStream(&quot;D:\\\\a.txt&quot;);byte[] bytes = &#123;49,99,28,120&#125;;fos.write(bytes,1,2);//int off 开始的索引//int len 写几个字节fos.close();\n输入字符串\nFileOutputStream fos = new FileOutputStream(&quot;D:\\\\a.txt&quot;);//String有getBytes()的方法，可以把字符串转换为字节数组fos.write(&quot;你好啊&quot;.getBytes());fos.close();\n\n数据的追加续写这就用到了另外两个FileOutputStream的构造方法\nFileOutputStream(File file, boolean append) //创建一个向指定File对象表示的文件中写入数据的文件输出流          FileOutputStream(String name, boolean append) //创建一个向具有指定name的文件中写入数据的输出文件流。//第一个参数都是文件的位置，第二个参数是是否追加写的开关，true的话不会覆盖原文件，false则会覆盖原文件\n\nFileOutputStream fos = new FileOutputStream(&quot;D:\\\\a.txt&quot;,true);//String有getBytes()的方法，可以把字符串转换为字节数组fos.write(&quot;\\r\\n&quot;.getBytes());fos.write(&quot;你好啊&quot;.getBytes());//换行:// windows:\\r\\n// Linux:/n// mac: /rfos.close();\n\n字节输入流InputStream此抽象类是表示字节输入流的所有类的超类。 \n包路径java.io\n\n子类AudioInputStream//读取音频ByteArrayInputStream, //读取字节数FileInputStream, //读取文件//重点研究FilterInputStream, //带过滤器ObjectInputStream, //读取对象PipedInputStream, //读取管道SequenceInputStream, //读取队列StringBufferInputStream //读取字符串缓冲区\n\n常用方法public abstract int read()throws IOException//从输入流中读取数据的下一个字节,返回 0 到 255 范围内的 int 字节值public abstract int read() throws IOException//从输入流中读取一定数量的字节，并将其存储在缓冲区数组 b 中public void close() throws IOException//关闭此输入流并释放与该流关联的所有系统资源\n\nFileInputStream构造方法FileInputStream(File file) //通过打开一个到实际文件的连接来创建一个FileInputStream//该文件通过文件系统中的 File 对象 file 指定。FileInputStream(String name) //通过打开一个到实际文件的连接来创建一个 FileInputStream，//该文件通过文件系统中的路径名 name 指定\n\n作用：\n\n创建一个FileInputStream对象\n会把FileInputStream对象指定到构造方法的位置中去读取文件\n\n原理：\nJava程序 -&gt; JVM -&gt; OS -&gt; OS读取数据的方法 -&gt; 读取文件\n常用方法public int read()throws IOException//从此输入流中读取一个数据字节,读取完成后再次调用此方法，会读取下一个数据//返回-1表示读取完毕public int read(byte[] b)throws IOException//从此输入流中将最多 b.length 个字节的数据读入一个 byte 数组中public int read(byte[] b,int off,int len)throws IOException//从此输入流读取任意字节的数据\n\n步骤：\n\n创建FileInputStream对象，构造方法中绑定要读取的数据源\n使用FileInputStream中的read方法读取文件\n释放资源\n\nFileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);int len = fis.read();//读取第一个字符System.out.println(len);int len2 = fis.read();System.out.println(len2);//读取第二个字符fis.close();\n读取未知文件，使用while循环，固定写法\nFileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);int len = 0;//这个变量必须定义，否则读取的指针在判断时会改变//记录读取的字符while ((len = fis.read())!=-1)&#123;    System.out.print((char)len);&#125;fis.close();\n\n原理:\n创建构造函数之后，会创建一个指针指向文件的第一个字节，每当运行read()方法，指针就指向下一个\n当read()方法返回-1时，读取将会结束\n\n一次读取多个字节的方法\n使用第二个构造函数\n注意：\n\nbyte[]设定了一次读取的个数，起到缓冲作用，存储每次读取到的多个字节；数组的长度一般设定为1024或者1024的整数倍\nread方法的返回值int是每次读取的有效元素的长度FileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);byte[] bytes = new byte[2];int len = fis.read(bytes);//返回数组的长度System.out.println(len);System.out.println(Arrays.toString(bytes));fis.close();\n\n\n原理：\n一次读取多个字节，\n构造函数创建后，指针指向第一个字节\n在此后的read方法中，会一次读取数组长度的字节\n之后指向数组长度之后的那个字节\n\n读取固定写法\nFileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);byte[] bytes = new byte[1024];int len = 0;while ((len = fis.read(bytes))!=-1)&#123;System.out.println(new String(bytes,0,len));&#125;fis.close;\n\n\n文件复制原理：\n读入再输出即可\n//复制一个文件FileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);//读入FileOutputStream fos = new FileOutputStream(&quot;D:\\\\a\\\\a.txt&quot;);//输出int len = 0;while ((len=fis.read())!=-1) &#123;    fos.write(len);&#125;fos.close();//先关闭输出的fis.close();","categories":["后台","Java"],"tags":["Java","JavaIO"]},{"title":"Java-File","url":"/2019/08/20/Java/Java-File/","content":"\n引言：用Java进行对文件的操作使用File类\n\n\n\n\nFile类文件和目录路径名的抽象表示形式\n\nJava把电脑中的文件和文件夹封装为了一个File类，我们可以使用File类对文件和文件夹进行操作\n\n注意：\n\nFile类与操作系统无关，任何操作系统都可以使用这个类\n\n用于文件和目录的创建、查找和删除等操作\n\n\n分隔符的使用static String pathSeparator //与系统有关的路径分隔符，为了方便，它被表示为一个字符串。 static char pathSeparatorChar //与系统有关的路径分隔符。 static String separator //与系统有关的默认名称分隔符，为了方便，它被表示为一个字符串。 static char separatorChar //与系统有关的默认名称分隔符。 \n示例代码\nString pathSeparator = File.pathSeparator;System.out.println(pathSeparator);//路径分隔符是 windows是分号; Linux是冒号:String separator = File.separator;System.out.println(separator);//文件名称分隔符 windows反斜杠\\ Linux正斜杠///布置在服务器上，路径不能写死，因为服务器有可能是windows也有可能是Linux/** * C:\\a\\a.txt   windows * C:/a/a.txt   Linux * 我们要写成以下这个样子 * &quot;C:&quot;+File.separator+&quot;a&quot;+File.separator+&quot;a.txt&quot; */\n\n绝对路径与相对路径注意事项：\n\n路径不区分大小写\n路径中的文件名称分隔符，windows使用反斜杠要写两个表示一个反斜杠\n\n构造方法File(String pathname) //通过将给定路径名字符串转换为抽象路径名来创建一个新 File 实例。//参数可以是以文件结尾，也可以是以文件夹结尾//路径可以是相对路径也可以是绝对路径//路径可以是存在的也可以是不存在的//创建File对象只是把字符串路径封装为File对象不考虑路径的真假情况File(String parent, String child) //根据 parent 抽象路径名和 child 路径名字符串创建一个新 File 实例。 //好处:父路径和子路径可以单独书写，使用起来十分灵活，父路径和子路径都可以变化File(File parent, String child) //与第二个类似，但是第一个参数是File类//好处：父路径是File类型，可以使用File类的方法对路径进行一些操作，再使用路径创建对象\n第一个构造\nFile f1 = new File(&quot;D:\\\\百度&quot;);System.out.println(f1);//打印出D:\\百度，说明重写了toString方法\n第二个构造\npublic static void main(String[] args) &#123;    show2(&quot;D:\\\\&quot;,&quot;百度&quot;);&#125; private static void show2(String parent, String child) &#123;    File f2 = new File(parent,child);    System.out.println(f2);&#125;\n第三个构造方法\nFile parent = new File(&quot;C:\\\\&quot;);File file = new File(parent,&quot;hello.java&quot;);System.out.println(file);//打印出C:\\hello.java\n常用方法\n获取功能的方法\npublic String getAbsolutePath()//返回此抽象路径名的绝对路径名字符串。public File getAbsoluteFile()//返回此抽象路径名的绝对路径名形式public String getName()//返回由此抽象路径名表示的文件或目录的名称public long length()//返回由此抽象路径名表示的文件的大小,以字节为单位//如果此路径名表示一个文件夹，则返回值是不确定的//如果路径不存在则返回0\n示例代码\nFile f1 = new File(&quot;C:\\\\a.txt&quot;);File f2 = new File(&quot;a.txt&quot;);String str = f1.getAbsolutePath();String str2 = f2.getAbsolutePath();System.out.println(str);//打印出绝对路径C:\\a.txtSystem.out.println(str2);//打印出绝对路径D:\\basic-code\\a.txt//默认会打印出当前路径下的绝对路径System.out.println(f1.getPath());//打印出绝对路径C:\\a.txtSystem.out.println(f2.getPath());//打印出相对路径a.txtSystem.out.println(f1);//C:\\a.txtSystem.out.println(f1.toString());//C:\\a.txt,其实调用的就是toString方法System.out.println(f1.getName());//a.txtSystem.out.println(f2.getName());//a.txt，获取要么是文件要么是文件夹System.out.println(f1.length());//0，文件不存在返回0System.out.println(f2.length());//0\n判断功能的方法\npublic boolean exists()//测试此抽象路径名表示的文件或目录是否存在。 public boolean isDirectory()//测试此抽象路径名表示的文件是否是一个目录。 //路径不存在返回falsepublic boolean isFile()//测试此抽象路径名表示的文件是否是一个标准文件//路径不存在返回false\n示例代码\nFile f1 = new File(&quot;C:\\\\a.txt&quot;);File f2 = new File(&quot;a.txt&quot;);System.out.println(f1.exists());System.out.println(f2.exists());System.out.println(f1.isFile());System.out.println(f2.isFile());System.out.println(f1.isDirectory());System.out.println(f2.isDirectory());\n创建删除功能\npublic boolean createNewFile()throws IOException//当且仅当不存在具有此抽象路径名指定名称的文件时，不可分地创建一个新的空文件//只能创建文件，并且路径必须存在public boolean delete()//删除此抽象路径名表示的文件或目录。如果此路径名表示一个目录，则该目录必须为空才能删除。 //delete不走回收站，会直接删除public boolean mkdir()//创建此抽象路径名指定的目录,单级文件夹public boolean mkdirs()//创建此抽象路径名指定的目录，包括所有必需但不存在的父目录。//注意，此操作失败时也可能已经成功地创建了一部分必需的父目录。 \n示例代码\nFile f1 = new File(&quot;D:\\\\a.md&quot;);//在此声明你想要创建的文件,给文件起名f1.createNewFile();//文件存在返回falsef1.delete();File f2 = new File(&quot;D:\\\\a&quot;);f2.mkdir();//只能创建单级文件夹f2.delete();File f3 = new File(&quot;D:\\\\a\\\\b&quot;);f3.mkdirs();//创建多级文件夹f3.delete();\n遍历文件夹功能\n\n\npublic String[] list()//返回一个字符串数组，表示该目录中的所有子文件或目录public File[] listFiles()//返回一个File数组，表示该File目录中的所有子文件或目录//注意：//如果路径不存在或不是一个文件夹，会抛出空指针异常\n示例代码\nFile f1 =new File(&quot;C:\\\\&quot;);//路径不存在会报错和空指针异常String[] arr = f1.list();for (String s : arr) &#123;    System.out.println(s);&#125;//隐藏文件也会看到\n\n循环遍历多级目录public static void main(String[] args) &#123;    File file = new File(&quot;D:\\\\blog&quot;);    showAllFiles(file);&#125;private static void showAllFiles(File file) &#123;    System.out.println(file);    File[] f = file.listFiles();    for (File s : f) &#123;        if(s.isDirectory())&#123;            showAllFiles(s);        &#125;        else &#123;            System.out.println(s+&quot;:&quot;+s.length());        &#125;    &#125;&#125;\n\n搜索文件public static void main(String[] args) &#123;    File file = new File(&quot;D:\\\\BaiduNetdiskDownload&quot;);    showAllFiles(file);&#125;private static void showAllFiles(File file) &#123;    File[] f = file.listFiles();    for (File s : f) &#123;        if (s.isDirectory()) &#123;            showAllFiles(s);        &#125; else &#123;            if (s.getName().endsWith(&quot;.mp4&quot;))            //搜索所有以mp4为结尾的文件            &#123;                System.out.println(s.getName());            &#125;        &#125;    &#125;&#125;\n\n文件过滤器public File[] listFiles(FileFilter filter)//java.io.FileFilter是一个接口，用于抽象路径名的过滤//boolean accept(File pathname) 含有这个方法，可以用来过滤//参数是一个ListFiles方法遍历目录得到的每一个文件对象public File[] listFiles(FilenameFilter filter)//java.io.FilenameFilter实现此类实例可用于过滤器的文件名//boolean accept(File dir,String name)//其构造函数有两个参数，//第一个是构造方法中传递的被遍历的目录，//第二个是ListFiles遍历目录获取的每一个文件/文件夹的名称//注意：这两个接口都没有实现类//需要我们写实现类，重写过滤的方法accept，重写过滤的方法\nFileFilter实现类\npublic class FileFilterImpl implements FileFilter &#123;    @Override    public boolean accept(File pathname) &#123;        //定义过滤规则        //true将该文件返回到调用处，false将不会返回        if (pathname.isDirectory()) &#123;return true;&#125;        //如果是文件夹也返回        return pathname.getName().toLowerCase().endsWith(&quot;mp4&quot;);    &#125;&#125;\nmain函数实现代码\npublic static void main(String[] args) &#123;    File file = new File(&quot;D:\\\\BaiduNetdiskDownload&quot;);    showAllFiles(file);&#125;private static void showAllFiles(File file) &#123;    File[] f = file.listFiles(new FileFilterImpl());    //传递过滤器对象    for (File s : f) &#123;        if (s.isDirectory()) &#123;            showAllFiles(s);        &#125; else &#123;                System.out.println(s.getName());        &#125;    &#125;&#125;\n\nFilenameFilter内部类\npublic static void main(String[] args) &#123;    File file = new File(&quot;D:\\\\BaiduNetdiskDownload&quot;);    showAllFiles(file);&#125;private static void showAllFiles(File file) &#123;    File[] f = file.listFiles(new FilenameFilter() &#123;        @Override        public boolean accept(File dir,String name) &#123;            //过滤规则            return new File(dir,name).isDirectory()||name.endsWith(&quot;.mp4&quot;);        &#125;    &#125;);    //传递过滤器对象    for (File s : f) &#123;        if (s.isDirectory()) &#123;            showAllFiles(s);        &#125; else &#123;            System.out.println(s.getName());        &#125;    &#125;&#125;","categories":["Java"],"tags":["Java"]},{"title":"Java-IO-缓冲流","url":"/2019/08/23/Java/Java-IO-%E7%BC%93%E5%86%B2%E6%B5%81/","content":"\n引言：\n\n高效读写的缓冲流\n\n\n\n\n\n缓冲流高效读写，对四种基本流的增强\n流程：\n创建后 -&gt; JVM -&gt; OS -&gt; 数据的字节\n但是区别在于，每次将不再是一个一个返回，放在一个数组内部，一次性返回，增加了效率\n分类：\n\n字节缓冲流:BufferedInputStream,BufferedOutputStream\n字符缓冲流:BufferedReader,BufferedWriter\n\n字节缓冲流BufferedOutputStream继承了OutputStream,\n子类继承父类，可以使用父类的方法\n包路径java.io\n\n构造函数BufferedOutputStream(OutputStream out) //创建一个新的缓冲输出流，以将数据写入指定的底层输出流。 BufferedOutputStream(OutputStream out, int size) //创建一个新的缓冲输出流，以将具有指定缓冲区大小的数据写入指定的底层输出流。 //第一个参数：字节输出流//第二个参数：指定缓冲流内部缓冲区的大小，不能默认\n步骤：\n\n创建FileOutputStream对象，构造方法绑定目的地\n创建BufferedOutputStream对象，构造方法中传递FileOutputStream对象，提高FileOutputStream对象效率\n使用BufferedOutputStream对象中的方法write，把数据写入到内部缓冲区中\n使用BufferedOutputStream对象中的flush方法，把内部缓冲区的数据刷新到文件\n释放资源(会先调用flush方法刷新数据)\n\nFileOutputStream fos = new FileOutputStream(&quot;D:\\\\a.txt&quot;);BufferedOutputStream bos=  new BufferedOutputStream(fos);bos.write(&quot;写入数据到内部缓冲区&quot;.getBytes());bos.flush();bos.close();\n\nBufferedInputStream继承了InputStream,\n子类继承父类，可以使用父类的方法\n包路径java.io\n构造函数BufferedInputStream(InputStream in) //创建一个 BufferedInputStream 并保存其参数，即输入流 in，以便将来使用。 BufferedInputStream(InputStream in, int size) //创建具有指定缓冲区大小的 BufferedInputStream 并保存其参数，即输入流 in，以便将来使用。 //第一个参数：字节输入流//第二个参数：执行缓冲流内部缓冲区大小，不能默认\n步骤：\n\n创建FileInputStream对象，构造方法中绑定要读取的数据源\n创建BufferedInputStream对象，构造函数绑定FileInputStream对象\n使用BufferedInputStream对象中的方法read，读取文件\n释放资源FileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);BufferedInputStream bis = new BufferedInputStream(fis);//一个一个字节读取int len = 0;while ((len = bis.read()) != -1) &#123;    System.out.println(len);&#125;bis.close();//每次读取1kbbyte[] bytes = new byte[1024];int len1 = 0;while ((len1 = bis.read(bytes)) != -1) &#123;    System.out.println(new String(bytes, 0, len1));&#125;\n\n字节缓冲流复制文件复制文件速度十分快，远远快于普通的流的速度\n//字节缓冲流复制文件FileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);FileOutputStream fos = new FileOutputStream(&quot;D:\\\\b.txt&quot;);BufferedInputStream bis = new BufferedInputStream(fis);BufferedOutputStream bos = new BufferedOutputStream(fos);int len = 0;while ((len = bis.read())!=-1)&#123;    bos.write(len);&#125;bos.close();bis.close();\n\n字符缓冲流将文本写入字符输出流，缓冲各个字符，从而提供单个字符、数组和字符串的高效写入。 \nBufferedWriter字符缓冲输出流，继承父类的所有方法\n包路径java.io\n\n构造方法BufferedWriter(Writer out) //创建一个使用默认大小输出缓冲区的缓冲字符输出流BufferedWriter(Writer out, int sz) //创建一个使用给定大小输出缓冲区的新缓冲字符输出流 //参数：//第一个传递FileWriter，缓冲流给FileWriter增加一个缓冲区，提高FileWriter的写入效率//第二个设定缓冲区的大小，不写会有默认的大小\n\n常用方法void newLine() //throws IOException写入一个行分隔符void write(char[] cbuf,int off,int len)throws IOException//写入字符数组的某一部分void write(String s,int off,int len)throws IOException//写入字符串的某一部分。 public void flush()throws IOException//刷新该流的缓冲。 public void close()throws IOException//关闭此流，但要先刷新它。\n步骤：\n\n创建字符缓冲输出流对象，构造方法中传递字符输出流\n调用字符缓冲输出流中的方法write，把数据写入到内存缓冲区中\n调用字符缓冲输出流中的方法flush，把缓冲区数据刷新到文件\n释放资源\n\nBufferedWriter bw = new BufferedWriter(new FileWriter(&quot;D:\\\\a.txt&quot;));for(int i = 0;i&lt;10;i++)&#123;    bw.write(&quot;你好&quot;);    bw.newLine();&#125;bw.flush();bw.close();\n\nBufferedReader从字符输入流中读取文本，缓冲各个字符，从而实现字符、数组和行的高效读取。 \n包路径java.io\n\n构造方法BufferedReader(Reader in) //创建一个使用默认大小输入缓冲区的缓冲字符输入流。BufferedReader(Reader in, int sz) //创建一个使用指定大小输入缓冲区的缓冲字符输入流。 //参数：//第一个参数绑定一个FileReader类//第二个参数设定缓冲区大小\n\n常用方法public String readLine()throws IOException//读取一个文本行。//通过下列字符之一即可认为某行已终止：//换行 (&#x27;\\n&#x27;)、回车(&#x27;\\r&#x27;)或回车后直接跟着换行public int read()throws IOException//读取单个字符。 public int read(char[] cbuf,int off,int len)throws IOException//将字符读入数组的某一部分。public void close()throws IOException//关闭流并在关闭前刷新数据\n步骤：\n\n创建字符缓冲输入流对象，构造方法中传递字符输入流\n使用字符缓冲输入流对象的方法read/read line读取文本\n释放资源\n\n","categories":["后台","Java"],"tags":["Java","JavaIO"]},{"title":"Java-IO-转换流","url":"/2019/08/23/Java/Java-IO-%E8%BD%AC%E6%8D%A2%E6%B5%81/","content":"\n引言：\n\n转换流\n\n\n\n\n\n字符编码与字符集\n字符编码：\n\n计算机只能识别二进制，\n电脑上的任何软件都是以二进制的1和0存储的，将字符存储到计算机中，称为编码，\n将二进制解析显示出来称为解码。\n字符编码就是两者之间对应的转换规则\n\n字符集是一个系统所有字符的集合，包含各国文字等等\n\n常见的字符集有：\nASCII编码--&gt;ASCII字符集GBK编码--&gt;GBK字符集UTF-8编码--&gt;Unicode字符集UTF-16编码--&gt;Unicode字符集UTF-32编码--&gt;Unicode字符集\n\n编码引出的问题在IDEA中，使用UTF-8,日常使用没有问题，FileReader默认也是读取UTF-8\n但是windows中有GBK编码，这样使用FileReader读取GBK的文件，就会产生乱码\n转换流InputStreamReader字节流通向字符流的桥梁：\n它使用指定的charset读取字节并将其解码为字符。\n它使用的字符集可以由名称指定或显式给定，或者可以接受平台默认的字符集\n构造方法InputStreamReader(InputStream in) //创建一个使用默认字符集的 InputStreamReader。 InputStreamReader(InputStream in, String charsetName) //创建使用指定字符集的 InputStreamReader。//第二个参数写入指定的编码表名称，默认使用UTF-8，不区分大小写\n常用方法public String getEncoding()//返回此流使用的字符编码的名称。 //其他方法同FileReader\n步骤：\n\n创建一个InputStreamReader对象，构造方法中传递字节输入流和指定的编码表名称\n使用InputStreamReader对象中的方法read读取文件\n释放资源\n\n示例代码\nInputStreamReader osr = new InputStreamReader(new FileInputStream(&quot;D:\\\\a.txt&quot;),&quot;UTF-8&quot;);int len = 0;System.out.println(osr.getEncoding());//打印出UTF8while ((len = osr.read())!=-1)&#123;    System.out.println((char)len);&#125;osr.close();\n\nOutputStreamReader字符流通向字节流的桥梁：可使用指定的 charset 将要写入流中的字符编码成字节。\n它使用的字符集可以由名称指定或显式给定，否则将接受平台默认的字符集。 \n构造方法OutputStreamWriter(OutputStream out) //创建使用默认字符编码的 OutputStreamWriter。 OutputStreamWriter(OutputStream out, String charsetName) //创建使用指定字符集的 OutputStreamWriter。//第二个参数写入指定的编码表名称，默认使用UTF-8，不区分大小写\n\n步骤：\n\n创建OutputStreamWriter对象，构造方法中传递字节输出流和指定的编码表名称\n使用OutputStreamWrirer对象中的write方法，把字符转换为字节存储缓冲区中\n使用OutputStreamWriter的方法flush，把内存缓冲区中的字节刷新到文件中\n释放资源示例代码\n\nOutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream(&quot;D:\\\\a.txt&quot;),&quot;UTF-8&quot;);//构造函数中指定所要的编码表osw.write(&quot;你好&quot;);osw.flush();osw.close();\n","categories":["后台","Java"],"tags":["Java","JavaIO"]},{"title":"Java-异常","url":"/2019/08/17/Java/Java-%E5%BC%82%E5%B8%B8/","content":"\n引言：\n\n异常是什么？\n怎么处理异常？\n\n\n\n\n\n异常在程序执行的过程中，出现的非正常的情况，导致JVM非正常停止\n异常本身是一个类，产生异常就是创建异常对象并抛出了一个异常对象，java处理的方式是中断处理。\n异常不是语法错误！！\n异常体系：\n异常的最顶层的父类java.lang.Throwable\n子类：java.lang.Error与java.lang.Exception\ngraph LRError--&gt;ThrowableException--&gt;ThrowableRuntimeException--&gt;Exception\n处理第一种：抛出，交给虚拟机处理\n虚拟机的处理方式：中断处理，把异常打印在控制台上\npublic static void main(String[] args) throws ParseException &#123;    SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);    Date date = sdf.parse(&quot;1999-09-09&quot;);&#125;\n第二种：try/catch优点：程序抛出错误后，还可以继续运行。\nError的问题必须修改代码\n异常产生的过程第一步：\n在遇到不正常的情况时，jvm会做两件事情\n\n根据异常产生的原因创建一个异常对象，这个对象包含了一场产生的内容，原因，位置\n在出现异常的方法中，没有异常的处理逻辑（没有try/catch），那么jvm就会把异常调出给方法的调用者，main方法来处理这个异常\n\n第二步：\n如果main无法处理这个异常，则会把异常抛出给main方法的调用者——jvm；\n第三步：\nJVM接受到这个异常，继续做两件事情\n\n打印异常\nJVM中止当前的java程序——中断处理\n\n异常的处理五个关键字：\ntry catch finally throw\tthrows\n\nthrow可以抛出指定的异常throw new xxException(&quot;异常产生原因&quot;)注意：\n\nthrow关键字必须写在方法的内部\nthrow关键字后边new的对象必须是Exception或者是Exception的子类对象\nthrow关键字抛出指定的异常对象，我们就必须处理这个异常对象\nthrow关键字后边创建的如果是RuntimeException或者是RuntimeException的子类对象，我们可以不处理，默认交给jvm处理（打印异常对象，中断程序）\nthrow关键字后边创建的如果是编译异常，我们必须处理这个异常，要么throws要么try/catch\n\n\n空指针异常NullPointexception是一个运行期异常，我们不必处理\nArrayIndexOutOfBoundsException也是一个运行期异常\n\n注意：\n工作中我们要对传递过来的参数进行合法性校验，\n如果参数不合适，那么我们就必须使用异常给定方式，告知方法的调用者，传递的参数有问题。\nprivate static void get(int[]arr,int index)&#123;    if(arr==null)        throw new NullPointerException(&quot;传递的数组的值是空&quot;);    if(index&lt;0||index&gt;arr.length-1)        throw new ArrayIndexOutOfBoundsException(&quot;超出范围&quot;);    System.out.println(arr[index]);&#125;\nthrows异常处理的第一种方式：交给别人处理\n作用：\n当方法内部抛出异常对象的时候，我们就必须处理这个异常对象，\n可以使用throws关键字处理异常对象，会把异常对象声明抛出给方法的调用者处理（自己不处理，给别人处理），最终交给JVM处理——中断处理。\n//方法声明时使用修饰符  返回值类型  方法名（参数）throws&#123;throw new xxxException(&quot;产生原因&quot;);...&#125;\n注意：\n\n必须写在方法的声明处\n声明的异常必须是Exception或者他的子类\n方法内部如果抛出了多个异常对象，那么throws后边也必须声明多个异常\n如果抛出的异常对象有子父类关系，则只声明父类异常即可\n调用了一个声明抛出异常的方法，我们就必须的处理声明的异常，要么继续使用throws声明抛出，交给方法的调用者处理，最终交给JVM，要么try/catch自己处理异常\nFileNotFoundException是编译异常，抛出了编译异常就必须处理这个异常\nIOException也是一个编译异常，必须处理\n中断交给异常处理之后不会再执行之后的代码\n\npublic static void main(String[] args) throws IOException &#123;    readFile(&quot;d:\\\\a.txt&quot;);&#125;public static void readFile(String filename) throws IOException&#123;    if(!filename.endsWith(&quot;.txt&quot;))&#123;        throw new IOException(&quot;文件名后缀不正确&quot;);    &#125;&#125;\ntry/catch第二种处理方式：自己处理异常\ntry&#123;//可能产生异常的代码&#125;catch（//这里定义一个异常的变量，用来接收try中抛出的异常对象）&#123;//异常的处理逻辑，产生异常对象之后，怎么处理异常对象//一般在工作中会把异常的信息记录到一个日志中&#125;...catch可以有多个\n注意：\n\ntry中可能会抛出多个异常对象，那么就可以使用多个catch来处理这些异常对象\n如果try中产生了异常，那么就会执行catch中的异常处理逻辑，执行完毕之后，继续向下执行\n如果try中没有产生异常，则catch中的代码不会执行，将继续执行之后的代码\ncatch里面定义的异常变量，如果有子父类关系，那么子类的异常变量必须在上\n\npublic static void main(String[] args)  &#123;    try&#123;        //try中放有异常的代码        readFile(&quot;d:\\\\a.tx&quot;);    &#125;catch(IOException e)&#123;        //try中抛出什么异常对象，catch就定义什么异常变量用来接收这个异常对象        //这里放异常的处理逻辑        System.out.println(&quot;传递的文件的后缀不是txt&quot;);    &#125;    System.out.println(&quot;后续会继续执行&quot;);&#125;public static void readFile(String filename) throws IOException&#123;    if(!filename.endsWith(&quot;.txt&quot;))&#123;        throw new IOException(&quot;文件名后缀不正确&quot;);    &#125;&#125;\nfinallyfinally代码块：无论是否出现异常，都要执行\n注意事项：\n\n不能单独使用\nfinally一般用于资源释放（资源回收），无论程序是否出现异常，最后都要资源释放 try&#123;    readFile(&quot;d:\\\\a.tx&quot;);&#125;catch(IOException e)&#123;    System.out.println(&quot;传递的文件的后缀不是txt&quot;);&#125;finally &#123;    System.out.println(&quot;后续会继续执行&quot;);&#125;\n\nThrowableThrowable 类是 Java 语言中所有错误或异常的超类\n包路径java.lang\n\n常用方法public String getMessage()//返回此 throwable 的详细消息字符串。public String toString()//返回此 throwable的简短描述。结果是以下字符串的串联： //此对象的类的 name &quot;: &quot;（冒号和一个空格） 调用此对象 getLocalizedMessage() 方法的结果 //如果 getLocalizedMessage 返回 null，则只返回类名称。public void printStackTrace()//将此 throwable 及其追踪输出至标准错误流。\n示例代码：\npublic static void main(String[] args) &#123;    try &#123;        readFile(&quot;d:\\\\a.tx&quot;);    &#125; catch (IOException e) &#123;        System.out.println(&quot;传递的文件的后缀不是txt&quot;);        System.out.println(e.getMessage());//文件名后缀不正确        System.out.println(e.toString());//java.io.IOException: 文件名后缀不正确        e.printStackTrace();        //java.io.IOException: 文件名后缀不正确        //\tat cn.itcast.day04.demo01.demo.readFile(demo.java:22)        //\tat cn.itcast.day04.demo01.demo.main(demo.java:11)    &#125;&#125;public static void readFile(String filename) throws IOException &#123;    if (!filename.endsWith(&quot;.txt&quot;)) &#123;        throw new IOException(&quot;文件名后缀不正确&quot;);    &#125;&#125;\n自定义异常Java自带的异常类不够我们使用，我们需要自定义一些异常类\npublic class xxxException extends Exception|RuntimeException&#123;    //添加一个空参构造    //添加一个带异常信息的构造方法&#125;\n注意：\n\n自定义异常类一般都是以Exception结尾，说明该类是一个异常类\n自定义异常类，必须得继承Exception或者RuntimeException\nException:那么自定义的异常类就是一个编译期异常，如果方法内部抛出了异常，就必须处理这个异常，要么throws要么try/catch\nRuntimeException：那么自定义的异常类就是一个运行期异常，无需处理，交给虚拟机\n\n\n\npublic class RegisterException extends Exception&#123;    public RegisterException()&#123;&#125;    //空参构造    public RegisterException(String msg)&#123;        super(msg);    &#125;    //一个带异常信息的构造方法&#125;\n所有的异常类都会有一个带异常信息的构造方法，\n方法内部会调用父类带异常信息的构造方法，让父类来处理这个异常信息\n父类错误，子类也会跟着报错，不论子类是否错误\n","categories":["后台","Java"],"tags":["Java","Java异常"]},{"title":"Java-线程-1","url":"/2019/08/18/Java/Java-%E7%BA%BF%E7%A8%8B-1/","content":"\n引言：\n\n多线程是什么？\nThread类\n\n\n\n\n\n多线程并发和并行\n并发：指两个或多个事件在同一个时间段内发生\n\n并行：指两个或多个时间在同一时刻发生（同时发生，更快一些）\n\n\n进程一个内存中运行的应用程序，每个进程都有一个独立的内存空间，一个应用程序可以同时运行多个进程；\n进程也是程序的一次执行过程，是系统运行的基本单位\n系统运行一个程序就是一个进程从创建到消亡的过程\n线程程序到cpu的一个执行路径\n进程的一个执行单元，\n负责当前进程中程序的执行，\n一个进程中至少有一个线程，\n一个进程中是可以有多个线程的，这个应用程序也可以称之为多线程程序。\n线程调度\n分时调度\n\n所有线程轮流使用cpu的使用权，平均分配每个线程占用cpu的时间\n\n抢占式调度\n\n优先让优先级高的线程使用cpu，如果优先级相同，那么会随机选择一个（线程随机性），java使用的为抢占式调度。\n多线程原理\nJVM虚拟机执行main方法的时候，会开辟一条通往cpu的路径。（这个路径叫main线程，主线程）\ncpu可以通过这个路径执行main方法。\n当创建Thread类的子类对象的时候，会开辟另一台通往cpu的路径。\n两条路径，cpu进行选择，我们无法控制\n\n每调用一次Thread类的子类的start方法都会开辟一个新的栈空间用来执行run方法\n\n多线程的好处：\n  多个线程之间互不影响（在不同的栈空间）\n\n\nThread线程是程序中的执行线程。\nJava虚拟机允许应用程序并发地运行多个执行线程。 \n每个线程都有一个优先级，高优先级线程的执行优先于低优先级线程。\n包路径java.lang\n\n常用方法\n获取线程的名称：\n\n\n使用Thread类中的方法getName()public final String getName()//返回该线程的名称。 \n先获取到当前正在执行的线程，使用线程中的方法getName()获取线程的名称public static Thread currentThread()//返回对当前正在执行的线程对象的引用。 \n第一种获取线程名字方法：public class thread extends Thread &#123;    @Override    //重写Thread类中的run方法，设置线程任务    public void run() &#123;        System.out.println(getName());    &#125;&#125;\n主函数调用start()方法public class demo &#123;    public static void main(String[] args) &#123;        thread my = new thread();        my.start();//Thread-0        new thread().start();//Thread-1        new thread().start();//Thread-2        new thread().start();//Thread-3    &#125;&#125;\n第二种获取线程名字的方法：public class thread extends Thread &#123;    @Override    public void run()&#123;        Thread t = Thread.currentThread();        System.out.println(t);//Thread[Thread-0,5,main]        System.out.println(t.getName());//Thread-0    &#125;&#125;\npublic class demo &#123;    public static void main(String[] args) &#123;        thread my = new thread();        my.start();    &#125;&#125;\n\n\n设置线程的名字\n\n\n使用Thread的setName()名称\n创建一个带参数的构造方法，参数传递线程名称，调用父类的带参构造方法，让父类给子线程起一个名字\n\n法一：\nthread my = new thread();my.setName(&quot;线程1&quot;);my.start();\n法二：\npublic class thread extends Thread &#123;    public thread()&#123;&#125;    public thread(String name)&#123;        super(name);    &#125;    @Override    public void run()&#123;        System.out.println(getName());    &#125;&#125;\nthread my = new thread(&quot;线程1&quot;);my.start();\n\n\n指定秒数停止程序public static void main(String[] args) &#123;    for (int i = 0; i &lt;= 60 ; i++) &#123;        System.out.println(i);        try &#123;            Thread.sleep(1000);//休眠1秒        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n","categories":["后台","Java"],"tags":["Java","Java线程"]},{"title":"Java-线程-2","url":"/2019/08/18/Java/Java-%E7%BA%BF%E7%A8%8B-2/","content":"\n引言：\n\n创建线程的另一种方法：\nRunnable接口\n线程安全\n\n\n\n\n\nRunnable创建线程的另一种方法：使用Runnable接口\n开启线程的两个构造\nThread(Runnable target)//分配新的Thread对象Thread(Runnable target,String name)//分配新的Thread对象\n\n示例代码:\n实现类\n//创建Runnable接口的实现类public class runnable implements Runnable &#123;    @Override    public void run() &#123;        for (int i = 0; i &lt; 3; i++) &#123;            System.out.println(&quot;另一种方法&quot;+i);        &#125;    &#125;&#125;\nmain函数\npublic class demo &#123;    public static void main(String[] args) &#123;        runnable r = new runnable();        //实现类实例化对象        new Thread(r).start();        //通过Thread类对象来开启新线程        for (int i = 0; i &lt; 3; i++) &#123;            System.out.println(&quot;main&quot;+i);        &#125;    &#125;&#125;\n\n两种方法的区别区别：\n实现Runnable接口创建多线程的好处：\n\n避免了单继承的局限性（ 以接很多个）\n增强了程序的扩展性，降低了程序的耦合性（解耦）\n实现Runnable接口的方式，把设置线程任务和开启新线程进行了分离\n实现类重写run方法实现设置线程任务\n创建Thread对象，调用start方法，来开启新的线程\n\n\n\n\n\n多线程安全在多线程访问共享数据时，容易发生错误\n解决安全问题：同步技术——有三个\n同步代码块锁对象：任意的对象，但是必须保证多个线程使用的锁对象是同一个\n作用：把同步代码块锁住，只让一个线程在同步代码块中执行\nsynchronized (&quot;同步锁&quot;)&#123;    //需要同步的代码&#125;\n示例\npublic class runnable implements Runnable &#123;    private int ticket = 10;    Object obj = new Object();    @Override    public void run() &#123;        while (true) &#123;            synchronized (obj)&#123;                if (ticket &gt; 0) &#123;                    System.out.println(Thread.currentThread().getName()+&quot;   &quot;+ticket);                    ticket--;                &#125;                else return;            &#125;        &#125;    &#125;&#125;\n\n\n同步方法\n把访问了共享数据的代码放到方法中\n\n加synchronized关键字\n\n锁对象是this\npublic synchronized void method()&#123;    &#125;\n示例\npublic class runnable implements Runnable &#123;    private int ticket = 10;    Object obj = new Object();    @Override    public void run() &#123;        while (true) &#123;            method();        &#125;    &#125;    public synchronized void method()&#123;        if (ticket &gt; 0) &#123;            System.out.println(Thread.currentThread().getName()+&quot;   &quot;+ticket);            ticket--;        &#125;        else return;    &#125;&#125;\n静态同步方法\n\n静态没有this\n\n锁对象：本类的class属性—class文件对象（反射）\npublic class runnable implements Runnable &#123;    private static int ticket = 10;    Object obj = new Object();    @Override    public void run() &#123;        while (true) &#123;            method();        &#125;    &#125;    public static synchronized void method()&#123;        if (ticket &gt; 0) &#123;            System.out.println(Thread.currentThread().getName()+&quot;   &quot;+ticket);            ticket--;        &#125;        else return;    &#125;&#125;\n\nLock锁接口包路径\njava.util\n方法：\nlock()//获取锁unlock()//解锁\n步骤：\n\n在成员位置创建一个Reentrantlock对象\n在可能会出现安全问题的代码调用lock()方法\n在可能会出现安全代码问题之后调用unclock()方法public class runnable implements Runnable &#123;    private int ticket = 10;    Lock l = new ReentrantLock();    @Override    public void run() &#123;        while (true) &#123;            l.lock();            if (ticket &gt; 0) &#123;                System.out.println(Thread.currentThread().getName()+&quot;   &quot;+ticket);                ticket--;            &#125;            l.unlock();        &#125;    &#125;&#125;\n同步技术的原理：\n\n使用了一个锁对象，这个锁对象叫同步锁，也叫对象锁，也叫对象监视器\n当发生多线程分享共有资源时，抢到cpu运行权的时候，\n运行到synchronize时，检查是否有锁对象，有，就会获取到锁对象并进入到同步过程中，运行完归还锁对象。\n没有，就会等待直到锁对象被归还。\n","categories":["后台","Java"],"tags":["Java","Java线程"]},{"title":"Java-线程-3","url":"/2019/08/18/Java/Java-%E7%BA%BF%E7%A8%8B-3/","content":"\n引言：\n\n线程的状态\n线程池\n\n\n\n\n\n线程的状态状态\n\n\n状态\n意义\n\n\n\nnew\n新建状态\n\n\nRunnable\n运行状态\n\n\nBlocked\n阻塞状态\n\n\nTerminated\n死亡状态\n\n\nTimed_waiting\n休眠状态\n\n\nWaiting\n无线等待状态\n\n\n线程图\nwait/notifyObject的两个方法：\n进入到TimeWating(计时等待)有两种方式：\n\n使用sleep(long m)方法，在毫秒值结束之后，线程睡醒进入到Runnable/Blocked状态\n使用wait(long m )方法，wait方法如果在毫秒值结束之后，还没被notify唤醒，就会自动醒来public class demo &#123;    public static void main(String[] args) &#123;        //创建一个锁对象        Object obj = new Object();        //创建一个顾客线程        new Thread() &#123;            @Override            public void run() &#123;                //保证只有一个执行                synchronized (obj) &#123;                    System.out.println(&quot;顾客：我要一个包子&quot;);                    try &#123;                        obj.wait(5000);                        //Thread.sleep(5000);同样可以                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                    System.out.println(&quot;老板：包子做好了&quot;);                    System.out.println(&quot;顾客：吃包子&quot;);                &#125;            &#125;        &#125;.start();        new Thread() &#123;            @Override            public void run() &#123;                System.out.println(&quot;老板：做包子5s&quot;);                synchronized (obj) &#123;                &#125;            &#125;        &#125;.start();    &#125;&#125;\n唤醒的方法也有两个：\nnotify()方法：随机唤醒一个\nnotifyAll()方法：唤醒所有的等待\n\n注意事项：\n\nwait方法与notify方法必须同一个锁对象调用！！\nwait和notify方法是属于Object类的方法的\nwait和notify必须要在同步代码块或者是同步函数中使用\n\n线程池我们使用线程的时候就去创建一个线程，这样实现起来非常简便，但就会有一个问题：\n如果并发的线程数很多，并且每一个线程都是执行一个时间很短的任务就结束了，\n这样频繁的创建线程就会大大降低系统的效率，因为频繁的创建和销毁线程需要时间\n线程池就可以用来执行完一个任务而不被立刻销毁，而是可以继续完成其他任务\n线程池：\n容纳多个线程的容器——集合:\nJDK1.5之后,JDK内置了线程池，我们可以直接使用\n好处：\n\n减少了资源消耗，减少了线程创建和销毁的次数\n提高响应速度：任务不需要等待线程创建即可执行\n提高可管理性：根据系统的承受能力，调整线程池中工作线程的数目（每个线程大约要用1MB的内存）\n\nExecutors包路径java.util\n构造public static ExecutorService newFixedThreadPool(int nThreads)//创建一个可重用固定线程数的线程池，//以共享的无界队列方式来运行这些线程//返回值是一个ExecutorService接口，返回的是ExecutorService接口的实现类对象\nExecutorService线程池的接口，用来从线程池中获取线程，调用start方法执行线程任务\nExecutorService常用方法Future&lt;?&gt; submit(Runnable task)//提交一个 Runnable 任务用于执行，//并返回一个表示该任务的 Future。//该 Future 的 get 方法在成功 完成时将会返回 nullvoid shutdown()//启动一次顺序关闭，执行以前提交的任务，但不接受新任务。如果已经关闭，则调用没有其他作用。\n步骤步骤：\n\n使用工厂类Executors的静态方法newFixedThread生产一个指定线程数量的线程池\n创建一个类，实现Runnable接口，重写run方法，设置线程任务\n调用ExecutorService方法submit，传递线程任务（实现类），开启线程，执行run方法\n调用ExecutorService方法shutdown销毁线程池（不建议执行）\n\nimport java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class demo &#123;    public static void main(String[] args) &#123;        //1.使用工厂类Executors的静态方法newFixedThread生产一个指定线程数量的线程池        ExecutorService es = Executors.newFixedThreadPool(2);        //3.调用ExecutorService方法submit，传递线程任务（实现类），开启线程，执行run方法        es.submit(new demoImpl());        //线程池会一直开启，使用完了线程，会自动把线程归还给线程池，线程可以继续使用        es.submit(new demoImpl());        es.submit(new demoImpl());        //4.调用ExecutorService方法shutdown销毁线程池（不建议执行）        es.shutdown();    &#125;&#125;\n//2.创建一个类，实现Runnable接口，重写run方法，设置线程任务public class demoImpl implements Runnable&#123;    @Override    public void run() &#123;        System.out.println(Thread.currentThread().getName()+&quot;创建了一个新的线程执行&quot;);    &#125;&#125;\n\n","categories":["后台","Java"],"tags":["Java","Java线程"]},{"title":"Java-线程-4","url":"/2019/08/18/Java/Java-%E7%BA%BF%E7%A8%8B-4/","content":"\n引言：\n\n函数式编程思想\nLambda表达式\n\n\n\n\n\n思想\n面向对象的思想:\n\n做一件事情，找一个能解决这个事情的对象，调用对象的方法，完成事情\n\n函数式编程思想\n\n能得到结果，怎么做的不重要\n冗余的Runnable代码我们学会了使用Runnable来创建多线程\n正式方法类\npublic class RunnableImpl implements Runnable&#123;    @Override    public void run() &#123;        System.out.println(Thread.currentThread().getName()+&quot;新的线程创建了&quot;);    &#125;&#125;\n主函数\n//创建接口的实现类RunnableImpl run = new RunnableImpl();//创建Thread类对象，构造方法中传递Runnable接口的实现类Thread t = new Thread(run);//调用start方法开启线程t.start();\n\n匿名内部类//使用匿名内部类实现多线程Runnable r = new Runnable() &#123;    @Override    public void run() &#123;        System.out.println(Thread.currentThread().getName() + &quot;新的线程创建了&quot;);    &#125;&#125;;new Thread(r).start();\n甚至更简单\n//甚至更简单new Thread(new Runnable() &#123;    @Override    public void run() &#123;        System.out.println(Thread.currentThread().getName() + &quot;新的线程创建了&quot;);    &#125;&#125;).start();\n\nLambda表达式JDK1.8 引入了更加简便的方式\nnew Thread(()-&gt;&#123;    System.out.println(Thread.currentThread().getName() + &quot;新的线程创建了&quot;);&#125;).start();\n由于只有一句话，所以可以省去括号和分号\nnew Thread(()-&gt;    System.out.println(Thread.currentThread().getName() + &quot;新的线程创建了&quot;)).start();\n\nLambda表达式标准格式三部分组成:\n\n参数:多参数逗号分隔，无参数空下\n箭头\n一段代码(参数) -&gt; &#123;    //代码&#125;\n可以省略的内容\n参数列表：括号中的参数的数据类型可以不写\n参数列表：括号中的参数如果只有一个，那么类型和括号都可以省略\n一段代码：如果只有一行，无论是否有返回值，都可以省略{}，还可以省略return还有分号\n\n注意：省略必须一起省略\n使用前提：\n\nLambda表达式必须有接口，且要求接口中有且只有一个抽象方法，无论是JDK内置的Runnable还是自定义接口，只有当接口中的抽象方法唯一时，才可以使用Lambda表达式\n使用Lambda必须要有上下文判断，也就是方法的参数或局部变量类型必须为Lambda对应的接口类型，才能使用Lambda作为接口的实例\n\n","categories":["后台","Java"],"tags":["Java","Java线程"]},{"title":"Java-网络基础-2","url":"/2019/08/24/Java/Java-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80-2/","content":"\n引言：\n\n网络基础入门\n文件上传\nB\\S通信\n\n\n\n\n\n文件上传明确：\n\n数据源\n目的地\n\n客服端FileInputStream fis = new FileInputStream(&quot;D:\\\\a.txt&quot;);//1. 读取本地文件，创建本地字节输入流 FileInputStream 对象，构造函数绑定数据源Socket socket = new Socket(&quot;127.0.0.1&quot;,8888);//2. 创建客户端 Socket 对象，构造方法中绑定服务器的IP地址和端口号OutputStream os = socket.getOutputStream();//3. 使用`Socket`中的方法 getOutputStream ，获取网络字节输出流 OutputStream 对象int len = 0;byte[] bytes = new byte[1024];while ((len = fis.read(bytes))!=-1)&#123;//4. 使用本地字节输入流`FileInputStream`对象中的方法`read`，获取本地文件    os.write(bytes,0,len);    //5. 使用网络字节输出流`OutputStream`对象的write方法，把读取到的文件上传到服务器&#125;//socket.shutdownOutput();//此项加上，终止程序死循环InputStream is = socket.getInputStream();//6. 使用`Socket`中的方法`getInputStream`获取网络字节输入流while ((len = is.read(bytes))!=-1)&#123;//7. 使用网络字节输入流`InputStream`对象中的方法`read`读取服务器回写的数据       System.out.println(new String(bytes,0,len));    //8. 释放资源（`FileInputStream`,`Socket`）&#125;fis.close();socket.close();\n\n服务器端明确：\n\n数据源：客户上传的文件\n目的地：服务器的硬盘的某一个位置\n\nServerSocket server = new ServerSocket(8888);//1. 创建一个服务器ServerSocket对象，和系统要指定的端口Socket socket = server.accept();//2. 使用ServerSocket对象中的方法accept，获取到请求的客户端Socket对象InputStream is = socket.getInputStream();//3. 使用Socket对象的getInputStream获取网络字节输入流InputStream对象File file = new File(&quot;D:\\\\upload&quot;);if (!file.exists()) &#123;    file.mkdirs();&#125;//4. 判断目的地文件夹是否存在FileOutputStream fos = new FileOutputStream(file + &quot;a.txt&quot;);//5. 创建一个本地的字节输出流FileOutputStream对象，构造方法绑定输出目的地int len = 0;byte[] bytes = new byte[1024];while ((len = is.read(bytes)) != -1) &#123;//6. 使用网络字节输入流InputStream的read方法读取上传的文件    fos.write(bytes, 0, len);    //7. 使用本地字节输出流FileOutputStream对象中的方法write，把读取的文件保存着服务器硬盘上&#125;socket.getOutputStream().write(&quot;上传成功&quot;.getBytes());//8. 使用Socket对象中的方法getOutputStream，获取网络字节输出流OutputStream对象//9. 使用网络字节输出流OutputStream对象中的write方法给客户端回写数据“上传成功”fos.close();socket.close();server.close();//10. 释放资源（FileOutputStream,Socket,ServerSocket）\n\n\n运行服务器端和客户端，发现服务器端与客户端并没有停止下来，但是文件已经上传了\n其实是因为FileInputStream中的read方法，当其没有可输入时，此方法会阻塞\nread方法永远也读取不到文件的结束标记\n因为我们没有写结束标记，读取不到就会进入阻塞状态，进入死循环\n解决方法：\n上传完文件，给服务器写一个结束标记，void shutdownOutput()，禁用此套接字的输出流,任何以前写的数据都会被发送并且文件会正常结束\n文件上传优化ServerSocket server = new ServerSocket(8888);//让服务器一直处于监听状态（死循环accept方法）//有一个客户端上传文件，让服务器保存一个文件while (true) &#123;    Socket socket = server.accept();    //使用多线程技术，提高程序效率    //有一个客户端上传文件就开启一个线程，完成文件的上传    new Thread(new Runnable() &#123;        //开启线程完成上传        @Override        public void run() &#123;            try&#123;                InputStream is = socket.getInputStream();                File file = new File(&quot;D:\\\\upload&quot;);                if (!file.exists()) &#123;                    file.mkdirs();                &#125;                //文件名称优化                //自定义一个文件的命名规则：防止同名的文件被覆盖                //规则：域名+毫秒值+随机数                String fileName = &quot;域名&quot; + System.currentTimeMillis() + new Random().nextInt(9999) + &quot;.txt&quot;;                FileOutputStream fos = new FileOutputStream(file + &quot;\\\\&quot; + fileName);                int len = 0;                byte[] bytes = new byte[1024];                while ((len = is.read(bytes)) != -1) &#123;                    fos.write(bytes, 0, len);                &#125;                socket.getOutputStream().write(&quot;上传成功&quot;.getBytes());                fos.close();                socket.close();            &#125;            catch (IOException e)&#123;                System.out.println(e);            &#125;        &#125;    &#125;).start();&#125;//server.close();//服务器不需要关闭\n\n模拟B\\S服务器客户端不再是Java程序，而是一个web页面\n服务器端\n//创建一个服务器ServerSocket server = new ServerSocket(8080);//获取到请求的浏览器Socket socket = server.accept();InputStream is = socket.getInputStream();byte[] bytes = new byte[1024];int len = 0;while ((len = is.read(bytes))!=-1)&#123;    System.out.println(new String(bytes,0,len));&#125;\n网页地址输入\nhttp://127.0.0.1:8080/项目名目录地址/index.html\n服务端打印\nGET /day04-code/src/index.html HTTP/1.1Host: 127.0.0.1:8080Connection: keep-aliveCache-Control: max-age=0Upgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36Sec-Fetch-Mode: navigateSec-Fetch-User: ?1Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3Sec-Fetch-Site: noneAccept-Encoding: gzip, deflate, brAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\n服务器端要响应用户的信息，回应一个html页面，我们需要读取index文件必须知道这个文件的地址，二者地址就是请求信息的第一行\nGET /day04-code/src/index.html HTTP/1.1\n我们可以使用BufferedReader的readLine读取该一行，用String类的split(&quot; &quot;)切割字符串，得到\n/day04-code/src/index.html\n再使用String类的subString(1)获取html文件的路径\nday04-code/src/index.html\n这样就得到了路径\n服务器创建一个本地的字节输入流，根据获取到的文件路径，获取html文件,并写入固定三行代码\n//写入HTTP协议请求响应头os.write(&quot;HTTP/1.1 200 OK\\r\\n&quot;.getBytes());os.write(&quot;Content-Type:text/html\\r\\n&quot;.getBytes());//必须要写入空行，否则浏览器不解析os.write(&quot;\\r\\n&quot;.getBytes());\n服务器端使用网络字节输出流把读取到的文件写到客户端\n实现代码：\n//创建一个服务器ServerSocket server = new ServerSocket(8080);while (true) &#123;    Socket socket = server.accept();    new Thread(new Runnable() &#123;        @Override        public void run() &#123;            try &#123;                //获取到请求的浏览器                InputStream is = socket.getInputStream();                BufferedReader br = new BufferedReader(new InputStreamReader(is));                //只读取一行                String line = br.readLine();                //处理地址                String[] arr = line.split(&quot; &quot;);                String htmlPath = arr[1].substring(1);                //创建一个本地的字节输入流                FileInputStream fis = new FileInputStream(htmlPath);                OutputStream os = socket.getOutputStream();                //写入HTTP协议请求响应头                os.write(&quot;HTTP/1.1 200 OK\\r\\n&quot;.getBytes());                os.write(&quot;Content-Type:text/html\\r\\n&quot;.getBytes());                //必须要写入空行，否则浏览器不解析                os.write(&quot;\\r\\n&quot;.getBytes());                //一读一写复制文件                int len = 0;                byte[] bytes = new byte[1024];                while ((len = fis.read(bytes)) != -1) &#123;                    os.write(bytes, 0, len);                &#125;                fis.close();                socket.close();            &#125; catch (IOException e) &#123;                System.out.println(e);            &#125;        &#125;    &#125;).start();&#125;","categories":["后台","Java"],"tags":["Java","Java网络基础"]},{"title":"Java-网络基础-3","url":"/2020/01/31/Java/Java-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80-3/","content":"\n引言：\n\nURL和URI\n\n\n\n\n\nURI\nURI：统一资源标识符(Uniform Resource Identifier)，URI只是一个纯粹的语法结构，唯一的功能就是解析。URL是URI的一个特例\n\nURI的组成部分URI包含用来指定Web资源的字符串的各种组成成分主要由三大部分构成\n[scheme:]schemeSpecificPart[#fragment][方案/协议:]方案具体部分[#片段]&lt;!-- [...]中为可选 --&gt;\n包含scheme:的URI称为绝对URI，否则称为相对URI\nschemeSpecificPart不以/开头称不透明的的\n所有的绝对的透明URI（第一个）和所有相对URI（第二个）都是分层的\nhttp://horstmann.com/index.html../../java/net/Socket.html#Socket()\n一个分层的URI的schemeSpecificPart包含以下结构\n[//authority][path][?query][//权威][路径][?查询]\n而基于服务器的URI，authority又有以下形式\n[user-info@]host[:port]\nport必须是一个整数\n所以URI我们可以用以下的方法来读取他们\ngetScheme()getSchemeSpecificPart()getAuthority()getUserInfo()getHost()getPort()getPath()getQuery()getFragment()\nURI uriAbs = new URI(&quot;http://docs.mycompany.com/api/java/net/ServerSocker.html&quot;);URI uriRel = new URI(&quot;../../java/net/Socket.html#Socket()&quot;);uriAbs.isAbsolute();// trueuriRel.isAbsolute();// falseuriAbs.getScheme();// httpuriAbs.getSchemeSpecificPart();// 结果是//docs.mycompany.com/api/java/net/ServerSocker.html    &#123;//以下属于SchemeSpecificPart的组成        uriAbs.getAuthority();//docs.mycompany.com            &#123;//以下属于Authority的组成                uriAbs.getUserInfo();//null                uriAbs.getHost();//docs.mycompany.com                uriAbs.getPort();//-1 (端口是未定义的返回-1)            &#125;        uriAbs.getPath();///api/java/net/ServerSocker.html        uriAbs.getQuery();//null    &#125;uriAbs.getFragment();//nulluriRel.getFragment();//Socket()\nURI类的作用\n处理绝对标识符和相对标识符（是否包含[scheme:]）\n\n例如：如果存在以下的一个绝对URI，和相对URI，我们可以组合出一个绝对URI\n绝对URI: http://docs.mycompany.com/api/java/net/ServerSocker.html相对URI：../../java/net/Socket.html#Socket()组合后的绝对URI：http://docs.mycompany.com/api/java/net/ServerSocker.html#Socket()\n这个过程叫做解析相对URI，与此过程相反的过程叫相对化\n基本URI：http://docs.mycompany.com/api另一个URI：http://docs.mycompany.com/api/java/lang/String.html相对化后的URI：java/lang/String.html\nURI uriAbs = new URI(&quot;http://docs.mycompany.com/api/java/net/ServerSocker.html&quot;);URI uriRel = new URI(&quot;../../java/net/Socket.html#Socket()&quot;);/*    解析相对URI：    http://docs.mycompany.com/api/java/net/Socket.html#Socket()*/URI uriBase = new URI(&quot;http://docs.mycompany.com/api&quot;);URI uriOther = new URI(&quot;http://docs.mycompany.com/api/java/lang/String.html&quot;);uriBase.relativize(uriOther);/*    相对化：    java/lang/String.html*/\n\nURL\nURL：统一资源定位符 (Uniform Resource Locator)，URL可以打开一个到达资源的流，URL类只能作用于那些Java类库知道如何处理的类库，如http:、https:、ftp:、本地文件系统file:、JAR文件jar:\n\n包路径java.net\n构造方法URL(String urlString)\n\n常用方法public InputStream openStream()//获取一个InputStream对象，进而获取URL资源内容\nURLConnectionURLConnection类比URL类有更多的控制\n包路径java.net\n\n常用方法void setDoInput(boolean doInput)boolean getDoInput()//若doInput为true，那么用户可以接收来自该URLConnection的输入void setDoOutput(boolean doOutput)boolean getDoOutput()//若doOutput的值为true，用户可以将输出发送到URLConnectionvoid setIfModifiedSince(long time)long getIfModifiedSince()/*属性IfModifiedSince用于配置该URLConnection对象，使它只获得那些从某个给定时间以来被修改的数据传入的参数time:是从格林尼治时间开始计算的秒数*/void setUseCaches(boolean useCaches)boolean getUseCaches()//如果useCaches为true，那么数据可以从本地缓存中得到，缓存由浏览器之外的外部程序提供void setAllowUserInteraction(boolean allowUserInteraction)boolean getAllowUserInteraction()//如果allowUserInteraction为true，那么可以查询用户的口令，口令由浏览器之外的程序提供void setConnectTimeout(int timeout)int getConnectTimeout()//设置或得到连接超时时限void setReadTimeout(int timeout)int getReadTimeout()//设置读取数据的超时时限void setRequestProperty(String key,String value)//设置请求头的一个字段Map&lt;String,List&lt;String&gt;&gt; getRequestProperties()//返回请求头属性的一个映射表，相同的键对应的所有值被放置在同一个列表中void connect()//连接远程资源并获取响应头信息Map&lt;String,List&lt;String&gt;&gt; getHeaderFields()//返回响应的一个映射表，相同的键对应的所有值被放置在同一个列表中String getHeaderFieldKey(int n)//得到响应头的第n个字段的 键。如果n&gt;=0或者大于响应头字段的总数，返回nullString getHeaderField(int n)//得到响应头的第n个字段的 值。如果n&gt;=0或者大于响应头字段的总数，返回nullint getContentLength()//内容长度可以获得返回内容长度，不可获得返回-1String getContentEncoding()//获取内容的编码机制long getDate()long getExpiration()long getLastModified()//获取创建日期，过期日，以及最后一次被修改的日期，这些时间通通都是从格林尼治时间返回的秒数InputStream getInputStream()OutputStream getOutputStream()//返回从资源读取信息或向资源写入信息的流Object getContent()//选择适当的内容处理器，以便读取资源数据并将资源数据转换成对象。对text/plain或image/gif之类的标准内容类型没有用处，除非自己安装内容处理器\n\n\n\n操作步骤//1. 获取URLConnection对象URLConnection urlConnection = url.openConnection();//2. 使用各种相关方法来设置任意的请求属性","categories":["后台","Java"],"tags":["Java","Java网络基础"]},{"title":"Java基础扩展","url":"/2019/08/26/Java/Java%E5%9F%BA%E7%A1%80%E6%89%A9%E5%B1%95/","content":"\n引言：\n\n衔接SE基础部分，加强基础\nJunit\n反射\n注解\n\n\n\n\n\nJunit 测试的一些分类：\n\n黑盒测试\n 看不到代码什么样子，只需要给盒子输入一些参数，看看代码能不能输出预期的结果\n 基本上很多测试人员都是黑盒测试的\n\n白盒测试\n 白盒要关注进行的具体流程，需要关注代码\n\n\nJunit的使用步骤：\n\n定义一个测试类（测试用例）\n类名：被测试的类名+Test\n包名：xxx.xxx.xx.test\n\n\n定义测试方法：可以独立运行\n方法名：test测试的方法名 (testAdd)\n返回值：建议使用void，无返回值\n参数列表：空参\n\n\n给方法加注解@Test\n导入Junit依赖环境(ALT+Enter导入包)\n\n判定结果：\n红色代表失败\n绿色代表成功\n@Testpublic void testAdd()&#123;    //此处创建对象，调用测试方法    Calculator c = new Calculator();    int result = c.add(1, 2);    //System.out.println(result);    //一般不会直接打印它的结果，而是做一个断言的操作    //断言：我断言这个结果是3    assert result==3?true:false;&#125;\n\n\n\n@Before和@After\n@Before\n  修饰的方法会在测试方法之前被自动执行\n\n@After\n  修饰的方法会在测试方法之后被自动执行\n\n\n\n注意：Junit已经过时了解即可\n反射框架设计的灵魂\n框架：半成品软件，简化编码\nJava代码经历的三个阶段\n第一阶段：Source源代码阶段\n  Person.java –&gt; javac编译 –&gt; Person.class\n  Person.class分为三层，成员变量，构造方法，成员方法\n  代码还在硬盘上\n\n第二阶段：Class类对象阶段\n  类加载器，ClassLoader\n  Class类对象，用来描述所有的源代码而文件的行为\n  把第一阶段的三层分为三个对象 \n成员变量--&gt;Field对象数组构造函数--&gt;Constructor对象数组成员方法--&gt;Method对象数组\n\n\n第三阶段：Runtime运行时阶段\n  创建Person对象  new Person\n\n\n反射的好处\n反射： 将类的各个组成部分封装为其他对象，这就是反射机制\n\n好处：\n\n可以在程序运行时，操作这些对象\n可以解耦（降低程序的耦合性），提高程序的可扩展性\n\n反射获取字节码Class对象的三种方式\n获取成员变量Field[] getFields()//获取所有public修饰的成员变量Field getField(String name)//获取指定名称public修饰的成员变量 Field[] getDeclaredFields()//获取所有成员变量Field getDeclaredFields(String name)Field类1的方法：//获取值public Object get(Object obj)//设置值public void set(Object obj,Object value)\n\n示例代码\nClass personClass = Person.class;//0.获取Person的Class对象Field[] fields = personClass.getFields();for (Field field : fields) &#123;    System.out.println(field);&#125;Field a = personClass.getField(&quot;a&quot;);//获取成员变量a的值Person p = new Person();a.set(p, &quot;张三&quot;);//Field的set方法Object o = a.get(p);//Field的get方法System.out.println(o);//打印出  张三Field[] declaredFields = personClass.getDeclaredFields();//获取所有的成员变量，不考虑修饰符for (Field declaredField : declaredFields) &#123;    System.out.println(declaredField);&#125;Field d = personClass.getDeclaredField(&quot;d&quot;);d.setAccessible(true);//暴力反射,忽略访问权限修饰符的安全检查d.set(p,&quot;李四&quot;);Object o1 = d.get(p);System.out.println(o1);//出现异常IllegalAccessException,访问不是public项，需要忽略访问权限修饰符的安全检查\n\n\n获取构造方法\nConstructor&lt;?&gt;[] getConstructors()Constructor&lt;T&gt; getConstructor(类&lt;?&gt;... parameterTypes)Constructor&lt;?&gt;[] getDeclaredConstructors()Constructor类的方法：//用来创建对象public T newInstance(Object... initargs)//如果是空参创建对象，可以使用Class的newInstance的方法\n示例代码\nClass personClass = Person.class;Constructor constructor = personClass.getConstructor(String.class, int.class);//构造方法也要添加参数的ClassSystem.out.println(constructor);Object person = constructor.newInstance(&quot;张三&quot;, 26);System.out.println(person);\n获取成员方法\nMethod[] getMethods()Method getMethod(String name,类&lt;?&gt;... parameterTypes)Method类的方法：public Object invoke(Object obj,Object... args)//调用方法\n示例代码：\nClass personClass = Person.class;Method eat = personClass.getMethod(&quot;eat&quot;);//第一个参数是方法名，之后的参数是方法的参数System.out.println(eat);Person p = new Person();eat.invoke(p);//调用方法Method[] declaredMethods = personClass.getDeclaredMethods();for (Method declaredMethod : declaredMethods) &#123;    System.out.println(declaredMethod);    //会打印出自己的方法和Object类的方法    System.out.println(declaredMethod.getName());    //打印出方法名称&#125;\n\n\n获取类名String getName()\n\n示例代码\nClass personClass = Person.class;System.out.println(personClass.getName());\n\n\n注解注释：描述程序的文字，给程序员看\n注解：1.5版本之后的新特性，说明程序，给计算机看的\n作用分类：\n\n编译检查：例如@Override\n编写文档 /*** @author BlackKnight * @version 1.0* @since 1.5*/\n  /** *  * @param a 整数 * @param b 整数 * @return 两数的和 */public int add(int a,int b )&#123;    return a+b;&#125;\n 在cmd命令行运行javadoc 程序名抽取文件注解\n代码分析（使用反射）\n\nJDK预定义的注解\n@Override\n  用来检测被该注解标注的方法是否是继承自父类（接口）的\n  @Overridepublic String toString() &#123;    return &quot;Person&#123;&quot; +            &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; +            &quot;, age=&quot; + age +        &#x27;&#125;&#x27;;&#125;\n@Deprecated\n  将该注解标注的内容标记已过时\n  @Deprecatedpublic void eat()&#123;    //不建议使用这个方法    //但是还可以使用    System.out.println(&quot;吃饭&quot;);&#125;\n@SuppressWarnings\n  压制警告\n  @SuppressWarnings(&quot;all&quot;)//需要传参，一般传all，压制所有的警告\n\n自定义注解\n格式：\n  元注解public @interface 注解名称&#123;&#125;\n  cmd使用javap 注释类反编译得到注释的本质\n\n本质：\n  注解本质上就是一个接口，该接口默认继承Annotation接口\npublic interface MyAnno extends java.lang.annotation.Annotation &#123;&#125;\n属性：\n  接口中的抽象方法\n\n\n属性的要求：\n\n属性的返回值类型\n\n基本数据类型\nString\n枚举\n注解\n以上类型的数组int show1();//属性可以是普通方法String[] show2();//可以是数组Enum per();//可以是枚举类型//可以是另一个注解//类不可以放入//void不可以放入\n\n\n定义了属性，在使用时，需要给属性赋值\n@MyAnno(show1 = 1)public class Person &#123;    //.....&#125;\n可以添加默认值，不用赋值\npublic @interface MyAnno &#123;    int show1() default 3;&#125;\n如果只有一个属性并且属性名称是value，赋值可以直接写值\n@MyAnno(1)public class Person &#123;    //.....&#125;\n\n元注解用于描述注解的注解\n\n@Target\n  描述注解能够作用的位置\n  ElemenType取值:\n\nTYPE: 可以作用在类上\nMETHOD：可以作用于方法上\nFIELD：可以作用在成员变量上\n\n\n@Retention\n  描述注解被保留的一个阶段\n\n@Documented\n  描述注解是否被抽取到api文档中\n\n@Inherited\n  描述注解是否被子类继承\n\n\n@Target(&#123;ElementType.TYPE,ElementType.FIELD,ElementType.METHOD&#125;)//表示MyAnno注解只能作用在类上@Retention(RetentionPolicy.RUNTIME)//当前被描述的注解，会保留到class字节码文件中，并被JVM读取到（如果是CLASS不会被JVM读取到）@Documented@Inheritedpublic @interface MyAnno &#123;&#125;\n\n程序中使用注解在程序运行中调用程序的注解，用于配置文件\n\n获取注解定义的位置的对象{Class,Method,Field}\n获取指定的注解\n调用抽象方法中配置的属性值\n\n小结\n大多数是使用注解而不是自定义注解\n注解给谁用？\n编译器\n给解析程序用\n\n\n注解不是程序的一部分，注解就是一个标签\n\n","categories":["后台","Java"],"tags":["Java"]},{"title":"Java生态体系","url":"/2019/08/11/Java/Java%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB/","content":"\n引言：\n\n安装java环境\n认识java整个生态体系\n\n\n\n\n\nJavaJava的名字是一个咖啡的名字，没错，牛人就是这么随意，同样的Python也是起源于一部美剧。\nSun公司创造了Java，后来Oracle公司收购了Java，我们现在所使用的基本都是Oracle公司的java\nJava环境变量的配置去Oracle官网寻找java1.8版本下载\n下载完成后安装\n\n安装完java后要配置环境变量\n在电脑属性中打开高级系统设置\n再打开环境变量配置\n\n在环境变量中的系统变量内输入\nJAVA_HOME       C:\\xxxxxxjava安装路径\n\n再修改一下PATH的内容\n%JAVA_HOME%\\bin;\n添加上述即可，注意不要忘记分号\nJava技术体系\nJava设计语言\n各种平台上的Java虚拟机（JVM）\nJava API类库\n一系列的辅助工具，如javac\n1+2+3+4=JDK(Java开发最小环境)\n2+3=JRE(Java运行最小环境)\nJDK &gt; JRE &gt; JVM\n\nJava技术体系所划分的三大平台\nJavaSE：标准版的SE，用来开发一些电脑上的桌面软件等等\nJavaEE：企业版的Java，也是我们要一直学习的\nJavaME：微型Java，用来进行嵌入式开发\n\nJVM/JRE/JDKJVM，JRE，JDK傻傻分不清楚，他们到底都是什么东西\nJVM全名：Java Virtual Machine\n翻译就是java虚拟机的意思\n运行所有JAVA程序的虚拟计算机，不同的电脑装入不同的虚拟机，\n而JAVA程序就可以实现运行在JVM上面，从而实现跨平台的使用这个程序，\n但是要注意，虚拟机本身不是跨平台\nJRE全名：Java Runtime Environment\nJava运行时环境\nJava运行时所处于的环境，包含JVM和运行时所需要的核心类库\nJDK全名：Java Development Kit\nJava开发工具包\n开发Java程序所必要的环境\nJavaEE学习JavaEE我们都需要学习什么呢\n框架Spring： 一个开源的应用程序框架，提供了一个简易的开发方式，说的更通俗一点就是由框架来帮你管理这些对象，包括它的创建，销毁\n Spring就像是整个项目中装配bean（javabean是指java中可重复利用的组件）的大工厂，\n 在配置文件中可以指定使用特定的参数去调用实体类的构造方法来实例化对象。\nSSHSpring+Struct+Hibernate(过时，不学)\nSSMSSM指：Spring+SpringMVC+Mybatis\n\nSpringMVC  它原生支持的Spring特性，让开发变得非常简单规范。  Spring MVC 分离了控制器、模型对象、分派器以及处理程序对象的角色，这种分离让它们更容易进行定制。\n\n\nMybatis\n  可以这么理解，MyBatis是一个用来帮你管理数据增删改查的框架。。\n\n\nSpringBoot实现自动配置，降低项目搭建的复杂度\n初期的Spring通过代码加配置的形式为项目提供了良好的灵活性和扩展性，\n但随着Spring越来越庞大，其配置文件也越来越繁琐，太多复杂的xml文件也一直是Spring被人诟病的地方，\n大家渐渐觉得Spring那一套太过繁琐，\n此时，Spring社区推出了Spring Boot，它的目的在于实现自动配置，降低项目搭建的复杂度\nSpringCloud一系列框架的有序集合。\n它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发\n各种中间件\nMQ消息队列\nRPC通信框架\n搜索引擎elasticsearch\n\n数据库\nSQL：MySQL/ Postgre SQL\nNoSQL：Redis Memcacher mongodb elasticserach\n\n架构\n分布式/微服务架构\nspring cloud\ndubbo\nrpc通信框架\n\n虚拟化/容器化技术\nDocker 容器化\nK8S \n\n\n源码/性能（难度最高）\nJDK源码以及部分设计思想\nSpring源码\nJVM细节与排错\n高并发/高可用\n\n","categories":["后台","Java"],"tags":["Java"]},{"title":"Java进阶","url":"/2021/08/04/Java/Java%E8%BF%9B%E9%98%B6/","content":"\n引言:Java进阶，从问题来复习基础\n\n\n\nJava基础Java是解释执行吗？答：不完全是\n\n老版Java解释执行我们写的java代码，在Javac编译后，被JVM解释执行\nHotspot虚拟机实现JIT，对于热点代码，它会在运行时将其编译为机器码，直接跑在机器上\nJDK9 又有了一种新型的编译方式AOT（Ahead of  Time Compilation），直接将字节码转化为机器码\n\nException与Error\n都是Throwable类的子类，只有继承了Throwable才能被抛出或者捕获\n\nError指正常情况下难以预料的异常，交由父类或JVM来帮我们处理\n\nException指可以预见的异常，应该我们自己处理。\n\nException分为检查型异常和非检查型异常（或者说编译时异常、运行时异常）\n\n检查型异常必须显式的捕获处理（编译时异常）\n非检查型异常就是运行时异常，通常是编码可以避免的逻辑错误（运行时异常）\n\n\n常见的错误：\n\nError：OOM、SOF、NoClassDefFoundError、ExceptionInInitializerError（静态变量初始化的过程中出现了异常）\nException：\n检查型异常：IOException、ConcurrentModificationException \n运行时异常（非检查型异常）：NullPointException、ClassCastException\n\n\n\n\nNoClassDefFoundError与NoClassFoundExeption：区别\n\nNoClassDefFoundError：运行时JVM加载不到类或者找不到类\nNoClassFoundExeption：编译时JVM加载不到类或者找不到类导致的\n\n\n捕获异常要注意\n\n不要捕获大的异常比如Exception\n不要生吞异常（连记录都不记录）\n\n\n\nfinal、finall、finalize搞不懂为什么要将这三个进行分析。。。\n强、软、弱、虚引用​        虚引用补充：比如替代finalize方法的Cleaner，就用到了虚引用，就是用来通知此类，如果这个类被回收了，我能收到消息\n-XX:+PrintReferenceGC可以查看引用信息\nString\nintern：是一种显式的排重机制（因为intern会将字符串放进池，这样不会导致有重复的String）\nString变量\n\nJDK动态代理与cglib\nJDK动态代理，只能代理实现了接口的类\ncglib代理的类可以不实现接口\n\n包装类\nInteger：-128 到 127；缓存范围可以调整-XX:AutoBoxCacheMax=N\n\nBoolean缓存两个实例 True和False\n\nbooleanJVM当做int类型处理，占4个字节，但是如果是一个boolean数组，每个就只占1字节的大小，JVM会对其进行调节\n\n装箱：Integer.valueOf；拆箱：Integer.intValue\n\n自动装箱拆箱发生在什么阶段？\n\n\nVector、ArrayList、LinkedList\nVector扩容时扩容1倍\nArrayList扩容扩1.5倍\n集合类下有：list、queue、set（注意：map不是集合包下的）\nLinkedList用双向链表实现\n\nJava IO\n传统IO：FIle、Reader/Writer、Output/InputStream、BufferedOutputStream\n1.4 引入 NIO：Buffer、Channel、Selector（实现多路复用的基础）、Charset\nNIO同步非阻塞IO\n\n\n","categories":["后台","Java"],"tags":["Java"]},{"title":"Java异常传播","url":"/2022/02/27/Java%E5%BC%82%E5%B8%B8/Java%E5%BC%82%E5%B8%B8%E4%BC%A0%E6%92%AD/","content":"\n    引言：Java异常的传播机制。如何善用try、catch、finally？\n\n\n\n\n\nJava异常的传播机制本文不再讲解异常的基本知识点，进入更深层的异常学习，有关基础可以看博客\n怎么看打印的异常信息我们通常知道使用e.printStackTrace()来打印错误信息，但是怎么看呢？\n示例:\npublic class TempTest &#123;    public static void main(String[] args) &#123;        try &#123;            process1();        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    static void process1() &#123;        process2();    &#125;    static void process2() &#123;        Integer.parseInt(null); // 会抛出NumberFormatException    &#125;&#125;\n运行后报出\njava.lang.NumberFormatException: null\tat java.lang.Integer.parseInt(Integer.java:542)\tat java.lang.Integer.parseInt(Integer.java:615)\tat TempTest.process2(TempTest.java:20)\tat TempTest.process1(TempTest.java:16)\tat TempTest.main(TempTest.java:9)//IDEA中可以点击括号内容对应找到原码\n我们可以看出来，方法的运行顺序是\n\nmain调用了process1\nprocess1调用了process2\nprocess2调用了Integer.parseInt(String s)\nInteger.parseInt(String s调用了public static int parseInt(String s, int radix)\n\n打印结果如上，说明打印的结果是从最底层向最上层，层层打印出来的\n点击第一行括号内容，就可以找到抛出异常的原码位置\npublic static int parseInt(String s, int radix) throws NumberFormatException &#123;    if (s == null) &#123;        throw new NumberFormatException(&quot;null&quot;);    &#125;    ...&#125;\n异常转换观察以下代码\npublic class TempTest &#123;    public static void main(String[] args) &#123;        try &#123;            process1();        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    static void process1() &#123;        try &#123;            process2();        &#125; catch (NullPointerException e) &#123;            throw new IllegalArgumentException();        &#125;    &#125;    static void process2() &#123;        throw new NullPointerException();    &#125;&#125;\n分析一下：\n\nmain调用process1\nprocess1调用process2\nprocess2抛出NullPointerException\ncatch捕获异常NullPointerException\nprocess1抛出IllegalArgumentException\n\n运行后的异常栈类似下面：\njava.lang.IllegalArgumentException\tat TempTest.process1(TempTest.java:19)\tat TempTest.main(TempTest.java:9)\n发现：打印结果中只有IllegalArgumentException，看不到NullPointerException，异常丢失了原始的异常信息\n如果开发中出现这种问题，我们将无法定位原始的异常位置，该怎么办呢？\npublic class TempTest &#123;    public static void main(String[] args) &#123;        try &#123;            process1();        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    static void process1() &#123;        try &#123;            process2();        &#125; catch (NullPointerException e) &#123;            throw new IllegalArgumentException(e);            //改动在这里，将e作为了实例穿了进去        &#125;    &#125;    static void process2() &#123;        throw new NullPointerException();    &#125;&#125;\n再看打印信息\njava.lang.IllegalArgumentException: java.lang.NullPointerException\tat TempTest.process1(TempTest.java:19)\tat TempTest.main(TempTest.java:9)Caused by: java.lang.NullPointerException\tat TempTest.process2(TempTest.java:24)\tat TempTest.process1(TempTest.java:17)\t... 1 more\n注意到Caused by: Xxx，说明捕获的IllegalArgumentException并不是造成问题的根源，根源在于NullPointerException，是在TempTest.process2()方法抛出的。\n在Catch抛出异常如果我们在try或者catch语句块中抛出异常，finally语句是否会执行？例如：\npublic class Main &#123;    public static void main(String[] args) &#123;        try &#123;            Integer.parseInt(&quot;abc&quot;);        &#125; catch (Exception e) &#123;            System.out.println(&quot;catched&quot;);            throw new RuntimeException(e);        &#125; finally &#123;            System.out.println(&quot;finally&quot;);        &#125;    &#125;&#125;\n\n结果如下：\ncatchedfinallyException in thread &quot;main&quot; java.lang.RuntimeException: java.lang.NumberFormatException: For input string: &quot;abc&quot;    at Main.main(Main.java:8)Caused by: java.lang.NumberFormatException: For input string: &quot;abc&quot;    at ...\n发现执行顺序如下;\n\n先执行catch\n再执行finally\n最后抛出catch中的异常\n\n因此，在catch中抛出异常，不会影响finally的执行。JVM会先执行finally，然后抛出异常。\n在finally抛出异常：异常屏蔽如果在执行finally语句时抛出异常，那么，catch语句的异常还能否继续抛出？例如\npublic class Main &#123;    public static void main(String[] args) &#123;        try &#123;            Integer.parseInt(&quot;abc&quot;);        &#125; catch (Exception e) &#123;            System.out.println(&quot;catched&quot;);            throw new RuntimeException(e);        &#125; finally &#123;            System.out.println(&quot;finally&quot;);            throw new IllegalArgumentException();        &#125;    &#125;&#125;\n结果如下：\ncatchedfinallyException in thread &quot;main&quot; java.lang.IllegalArgumentException    at Main.main(Main.java:11)\n发现执行顺序如下;\n\n先执行catch\n再执行finally\n最后抛出finally中的异常\n\ncatch中抛出的异常去哪儿了？？\n这个异常被屏蔽了（Suppressed Exception）：为了让他显示出来，我们可以使用一个实例将异常存起来，最后调用addSuppressed()方法\npublic class Main &#123;    public static void main(String[] args) throws Exception &#123;        Exception origin = null;        try &#123;            System.out.println(Integer.parseInt(&quot;abc&quot;));        &#125; catch (Exception e) &#123;            origin = e;            throw e;        &#125; finally &#123;            Exception e = new IllegalArgumentException();            if (origin != null) &#123;                e.addSuppressed(origin);                // 如果origin异常存在，那么就带上这个异常            &#125;            throw e;        &#125;    &#125;&#125;\n结果\nException in thread &quot;main&quot; java.lang.IllegalArgumentException    at Main.main(Main.java:11)Suppressed: java.lang.NumberFormatException: For input string: &quot;abc&quot;    at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)    at java.base/java.lang.Integer.parseInt(Integer.java:652)    at java.base/java.lang.Integer.parseInt(Integer.java:770)    at Main.main(Main.java:6)\n发现Suppressed:后面包含了被屏蔽的异常\n绝大多数情况下，在finally中不要抛出异常。因此，我们通常不需要关心Suppressed Exception。\n总结本节我们可以总结的规则如下：\n\nprintStackTrace()方法可以打印异常栈信息，打印的顺序是从内到外的（因为方法的调用是入栈）\n如果catch代码块抛出了新的异常，尽量把旧的异常作为参数传入新的异常，这样可以避免异常转换，导致追踪不到原始的报错位置\n如果catch代码块出现异常，依然会先执行finally代码块\n如果finally中抛出异常，那么catch抛出的异常将不再理会，因此如果finally要抛出异常，最好使用addSuppressed()\n\n\n参考资料：廖雪峰官方网站\n\n","categories":["Java"],"tags":["Java异常"]},{"title":"Linux_C文件操作","url":"/2020/07/13/Linux/Linux%20C%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","content":"\n引言：Linux c 文件操作；文件描述符\n\n\n\n\nLinux C文件操作\nLinux系统I/O：open() read() write() lseek close\n\n文件描述符文件描述符是一个数组的下标值。\n​        files是一个文件指针数组，一般来说，一个进程会从files[0]读取输入，将输出写入files[1]，将错误信息写入files[2]\n每个进程被创建时，files的前三位被填入默认值，分别指向标准输入流、标准输出流、标准错误流。我们常说的「文件描述符」就是指这个文件指针数组的索引，所以程序的文件描述符默认情况下 0 是输入，1 是输出，2 是错误，3及以上就是打开的文件\n\n（图片取自知乎）\nopen()函数头文件：\n#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;\n\n原型：\nint open(const char *pathname, int flags);int open(const char *pathname, int flags, mode_t mode);\n\n参数：\n\npathname ：返回要打开的文件路径名称\n\nflags ：\n\nO_RDONLY：只读方式打开\nO_WRONLY：只写方式打开\nO_RDWR：可读可写\nO_CREAT：文件不存在则创建\nO_TRUNC：文件已存在则删除文件原有数据\nO_APPEND：追加\n\n（其中1、2、3互相排斥，其余可以使用|组合使用）\n\nmode ：如果文件被新建，指定其权限为mode（八进制表示）\n\n\n返回值：\n\n成功： 大于等于0 的整数（即文件描述符fd）\n失败：-1,并且errno会被设置\n\n\n示例\n#include &quot;stdio.h&quot;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int main()&#123;        int fd1 = open(&quot;./new.txt&quot;,O_RDONLY);                     printf(&quot;%d&quot;,fd1);        getchar();//为了查看程序的状态，在这里卡一下程序        return 0;&#125;\n\n编译执行程序，打开另一个终端\n[root@localhost local]# ps -aux | grep a.out root      3225  0.0  0.0   4220   352 tty1     S+   07:08   0:00 ./a.outroot      3227  0.0  0.0 112808   980 pts/0    S+   07:10   0:00 grep --color=auto a.out[root@localhost local]# ll /proc/3225/fdfd/     fdinfo/ [root@localhost local]# ll /proc/3225/fdtotal 0lrwx------. 1 root root 64 Jul 13 07:10 0 -&gt; /dev/tty1lrwx------. 1 root root 64 Jul 13 07:10 1 -&gt; /dev/tty1lrwx------. 1 root root 64 Jul 13 07:10 2 -&gt; /dev/tty1lr-x------. 1 root root 64 Jul 13 07:10 3 -&gt; /usr/local/new.txt\n\n为什么要查看/proc/3225/fd下的内容呢？\n每个进程被创建后，在/proc/[PID]/fd文件下，会有对应文件标识符，此例的文件标识符\n[root@localhost local]# ls /proc/3225/fd0  1  2  3# 其中0、1、2对应着标准输入、标准输出、标准错误，而3就是本文件\n\n我们可以看到lr-x------. 1 root root 64 Jul 13 07:10 3 -&gt; /usr/local/new.txt，文件的权限是r-x可读可执行，这就是O_RDONLY，如果改为O_WRONLY那这里就是-wx\n如果我们在文件中open打开多个文件，那他们的fd就是3,4,5,6…依次往下排序\nclose()函数头文件：\n#include &lt;unistd.h&gt;\n\n原型：\nint close(int fd);\n\n参数：\n\nfd：要关闭的文件描述符\n\n备注：重复关闭一个文件或是未打开的文件是安全的\n\n示例：\n如果一个文件被打开后，又关闭，然后又打开一个文件，那么这个文件的fd是3还是4？\n#include &quot;stdio.h&quot;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int main()&#123;        int fd1 = open(&quot;./new.txt&quot;,O_RDONLY);        printf(&quot;%d\\n&quot;,fd1);        close(fd1);        int fd2 = open(&quot;./new.txt&quot;,O_RDONLY);        printf(&quot;%d\\n&quot;,fd2);        return 0;&#125;\n\n结果是3\n[root@localhost local]# ./a.out 33\n\n说明当我们关闭一个文件后，对应的files[3]会被删除，新打开一个文件后，这个文件又被打开。\n即使我们打开了三个文件，分别是 3 4 5 ，我们关闭了 3，然后再打开一个文件，这个文件的fd依然是3 \nread()函数头文件：\n#include &lt;unistd.h&gt;\n\n原型：\nssize_t read(int fd, void *buf, size_t count);\n\n参数：\n\nfd：文件描述符\nbuf：指向存放读到的数据的缓冲区，（就是放数据的内存首地址）\ncount：想要从文件 fd 中读取的字节数\n\n返回值：\n\n成功：实际读到的字节数\n失败：-1\n\n补充： ssize_t ：是类型重定义，为了跨平台兼容。比如说long在32位系统可能是4字节，64位系统可能是8字节，嵌入式开发有的只有16位，那么int只有2个字节。\nwrite()函数头文件：\n#include &lt;unistd.h&gt;\n\n原型：\nssize_t write(int fd, const void *buf, size_t count);\n\n参数：\n\nfd:将数据写入到文件的fd中\nbuf:要写入的数据\ncount:要写入的字节数\n\n备注：实际写入的字节数小于等于count\n\n实现从a.txt文件中读取数据，写入到b.txt中\n#include &quot;stdio.h&quot;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int main()&#123;        int fd1 = open(&quot;./a.txt&quot;,O_RDONLY);        int fd2 = open(&quot;./a.txt&quot;,O_WRONLY);        int buf = [100];        read(fd1,buf,10);        write(fd2,buf,10);        return 0;&#125;\n\nlseek()待补充\nmmap()待补充\n","categories":["Linux"],"tags":["Linux"]},{"title":"Java-网络基础-1","url":"/2019/08/24/Java/Java-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80-1/","content":"\n引言：网络编程入门\n\n\n\nTCP通信程序TCP能实现两台计算机之间的数据交互，严格区分客户端与服务端\n两端通信时步骤：\n\n服务端程序，需要事先启动\n等待客户端的连接\n客户端主动连接服务器端，连接成功才能通信，服务端不能主动连接客户端\n这个连接中包含一个对象，这个对象就是IO对象，客户端可以使用IO对象进行通信\n通信的数据不仅仅是字符，所以IO对象是字节流对象\n\n服务器必须明确两件事情:\n\n多个客户端同时和服务器进行交互，服务器必须明确是哪一个用户\n 在服务器端有一个方法，叫做accept客服端获取到请求的客户端对象\n\n多个客户端同时和服务器交互，就需要使用到多个IO流对象\n 服务器是没有IO流的，服务器可以获取到请求的客服端对象Socket使用每个客服端Socket中提供的Socket流\n 服务器使用端的字节输入流读取客户端发送的数据，服务器使用客户端的字节输出流给客户端写数据\n 即：服务器使用客户端的流与客户交流\n\n\njava中提供了两个类来实现TCP通信:\n\n客户端：java.net.Socket实现客户端的套接字，套接字是两台机器之间通信的端点，包含了IP地址和端口号的网络单位\n服务器端：java.net.ServerSocket\n\n操作步骤客户端\n创建一个客户端对象Socket，构造方法绑定服务器的IP地址和端口号\n使用Socket对象中的方法getOutputStream()获取OutputSteam对象\n使用OutputStream对象中的方法write给服务器发送数据\n使用Socket对象中的方法getInputStream()获取InputStream对象\n使用InputStream对象中的方法read读取服务器回写的数据\n释放资源Socket\n\n服务器端\n创建服务器ServerSocket对象和系统要指定的端口号\n使用ServerSocket对象中的方法accept，获取到请求的客户端对象Socket\n使用Socket对象中的方法getInputStream()获取InputSteam对象\n使用InputStream对象中的方法read读取客户端发送的数据\n使用Socket对象中的方法getOutputStream()获取OutputStream对象\n使用OutputStream对象中的方法write，给客户端回写数据\n释放资源Socket,ServeSocket\n\nSocket包路径java.net\n\n构造方法public Socker()//创建一个还没有被连接的套接字public Socket(String host, int port)/*    host 是服务器主机的名称/服务器的IP地址    port 服务器的端口号*/\n成员方法public InputStream getInputStream() throws IOException//返回此套接字的输入流。 public OutputStream getOutputStream() throws IOException//返回此套接字的输出流。 public void close() throws IOException//关闭此套接字public void setSoTimeOut(int timeOutMilliseconds)//设置该套接字的一个等待时间public void connect(SocketAddress address)//将该套接字连接到指定地址public void connect(SocketAddress address,int timeOutInMilliseconds)//将该套接字连接到指定地址，若在给定的事件没有响应则抛出一个InterruptedIOExeptionpublic boolean isConnected()//如果该套接字已经被连接，返回truepublic boolean isClosed()//如果套接字已经被关闭，返回true\n\n\n注意：\n\n客户端和服务器交互，必须使用Socket，Socket中提供的网络流不能使用自己创建的流对象\n\n当我们创建客户端对象Socket的时候，就会去请求服务器和服务器经过 三次握手 建立连接通路\n 这时如果服务器没有启动就会抛出异常\n 如果服务器已经启动则可以进行交互\n半关闭\n\n\n半关闭(half-close)：套接字连接的一端可以终止其输出，同时仍可以接收来自另一端的数据\n\n/*    Socket的方法*/public void shutdownOutput()//将输出流设为流结束public void shutdownInput()//将输入流设为流结束public boolean isOutputShutdown()//如果输出流已被关闭，则返回truepublic boolean isInputShutdown()//如果输入流已被关闭，则返回true\n\n\nInetAddress在主机名和因特网地址之间进行转换\n包路径java.net\n构造方法static InetAddress getByName(String host)//静态方法，返回一个InetAddress对象，该对象封装了一个4字节的序列static InetAddress[] getAllByName(String host)/*    一些较大的主机名会对应多个因特网地址，可以使用这个方法来获得所有的主机*/\n常用方法static InetAddress getLocalHost()/*    有时我们需要本地地址的地址，如果只是要求得到localhost的地址，那总会得到本地回环地址127.0.0.1，但是其他程序无法用这个地址来连接到这台主机，所以我们可以使用getLocalHost方法来得到本地主机的地址*/byte[] getAddress()//返回一个包含数字地址的字节数组，是byte型数组，超过-128~127这个范围的数字都会以负数表示String getHostAddress()//返回一个由十进制数组成的字符串，如“129.15.2.53”String getHostName()//返回主机名称\n示例代码public class InetAddressTest &#123;    public static void main(String[] args) throws UnknownHostException &#123;        String host = &quot;baidu.com&quot;;        InetAddress[] allByName = InetAddress.getAllByName(host);        for (InetAddress inetAddress : allByName) &#123;            System.out.println(inetAddress);            /*                baidu.com/39.156.69.79                baidu.com/220.181.38.148                主机名/地址            */        &#125;        InetAddress localHost = InetAddress.getLocalHost();        byte[] address = localHost.getAddress();        for (byte b : address) &#123;            System.out.println(b);        &#125;    &#125;&#125;\n\n\nServerSocket此类实现服务器套接字。服务器套接字等待请求通过网络传入。\n它基于该请求执行某些操作，然后可能向请求者返回结果\n包路径java.net\n构造方法public ServerSocket(int port) throws IOException//创建一个监听端口的服务器套接字。端口 0 在所有空闲端口上创建套接字\n常用方法public Socket accept()throws IOException//侦听并接受到此套接字的连接。此方法在连接传入之前一直阻塞,当有客户端连接到该端口上，则返回一个Socket对象\n\n实现服务器和客户端的交流要先运行服务器，再运行客户端\n服务器\nimport java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;/** * @author BlackKnight */public class TcpServerSocket &#123;    public static void main(String[] args) throws IOException &#123;        ServerSocket serverSocket = new ServerSocket(2020);        /*            建立一个负责监听2020端口的服务器         */        Socket accept = serverSocket.accept();        /*            等待客户端接入服务器         */        OutputStream outputStream = accept.getOutputStream();        InputStream inputStream = accept.getInputStream();        outputStream.write(&quot;你好客户端，这里是服务器&quot;.getBytes());        byte[] bytes = new byte[1024];        int len = inputStream.read(bytes);        String content = new String(bytes, 0, len, &quot;UTF-8&quot;);        System.out.println(content);        accept.close();        serverSocket.close();    &#125;&#125;\n\n客户端\nimport java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.InetSocketAddress;import java.net.Socket;/** * @author BlackKnight */public class TcpSocket &#123;    public static void main(String[] args) throws IOException &#123;        //Socket socket = new Socket(&quot;127.0.0.1&quot;,2020);        Socket socket = new Socket();        socket.connect(new InetSocketAddress(&quot;127.0.0.1&quot;,2020),10000);        /*            第一种创建方式会一直阻塞等待下去，直到和host:port建立了连接为止            第二种创建方式可以解决这个问题，先创建一个Socket类，然后连接的同时设置一个响应超时时间        */        OutputStream outputStream = socket.getOutputStream();        outputStream.write(&quot;你好啊服务器，我是客户端&quot;.getBytes());        //创建输出流，向服务器发送数据        InputStream inputStream = socket.getInputStream();        byte[] bytes = new byte[1024];        int len = inputStream.read(bytes);        String content = new String(bytes,0,len,&quot;UTF-8&quot;);        /*            通过指定的编码来将byte型数组解析为字符串            bytes - 要解码为字符的字节            offset - 要解码的第一个字节的索引            length - 要解码的字节数            charsetName - 解码方式         */        System.out.println(content);        socket.close();    &#125;&#125;\n\n实现多线程服务器\nimport java.io.IOException;import java.net.ServerSocket;import java.net.Socket;/** * @author BlackKnight */public class TcpServerSocketMultithreading &#123;    public static void main(String[] args) throws IOException &#123;        ServerSocket serverSocket = new ServerSocket(2020);        while (true)&#123;            Socket socket = serverSocket.accept();            Runnable r = new TcpServerSocketMultithreadingImpl(socket);            Thread t = new Thread(r);            t.start();        &#125;    &#125;&#125;\n实现类\nimport java.io.IOException;import java.net.Socket;/** * @author BlackKnight */public class TcpServerSocketMultithreadingImpl implements Runnable &#123;    private Socket socket;    TcpServerSocketMultithreadingImpl(Socket socket) throws IOException &#123;        this.socket = socket;    &#125;    @Override    public void run()&#123;        String s = &quot;hello &quot;+ socket.getInetAddress();        try &#123;            socket.getOutputStream().write(s.getBytes());        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n","categories":["后台","Java"],"tags":["Java","Java网络基础","Socket"]},{"title":"Linux有趣的命令","url":"/2019/11/14/Linux/Linux%E6%9C%89%E8%B6%A3%E7%9A%84%E5%91%BD%E4%BB%A4/","content":"\n引言：\n\nLinux有趣的小命令\n\n\n\n\n整天对着代码是不是很枯燥，\n我找了一晚上这些小玩意儿，把不错的分享一下\n闲的发慌就来试试这几个命令吧！！\nLinux有趣的命令Ubuntu亲试！CentOs把apt-get换为yum试试，可能不是所有版本通用，\n安装前更新一下你的apt-get或者yum吧\nsudo apt-get update\n\n1.oneko\n一只小猫，追着鼠标跑啊跑，跑啊跑\n\n安装\nsudo apt-get install oneko\n运行\noneko //出现一只小猫咪oneko -dog //出现一只小狗oneko -sakura //出现一只小樱oneko -tora //出现一只白条纹老虎，和猫咪很像\n\n2.sl\n一个火车，注意是sl不是ls\n\n安装\nsudo apt-get install sl\n运行\nsl //一列火车开过来sl-h // 没有空格，是一辆长长的火车，CTRL+C退出\n\n3.fortune\n命运，推荐给你一条名言或者是其他的，最有趣的是竟然有中文版，会推荐给你诗歌、论语、毛主席语录\n\n安装\nsudo apt-get install fortune //英文版sudo apt-get install fortune-zh //中文版\n运行\nfortune  //即可\n\n4.cowsay\n牛说，出现一头牛说你让他说的话\n\n安装\nsudo apt-get install cowsay\n运行\ncowsay I love Linux  //cowsay后面随便加你想让他说的话就好了fortune|cowsay  //最有意思的是，它能和fortune联动，奶牛就会说出fortune的话// | 是管道命令符，可以将上一个命令的输出作为下一个命令的输入！学到了！\n\n5.cmatrix\n黑客帝国，敲上这行命令，就可以装作黑客的样子了！\n\n安装\nsudo apt-get install cmatrix\n运行\ncmatrix\n\n6.aafire\n一把火烧啊烧啊，一个动态图在你的终端一直烧啊烧啊烧\n\n安装\nsudo apt-get install libaa-bin\n运行\naafire\n","categories":["后台"],"tags":["Linux"]},{"title":"Crontab命令及Crontab语法","url":"/2022/02/14/Linux/Linux%E7%9A%84Crontab/","content":"\n引言：Linux Crontab命令及Crontab语法\n\n\n\n\nLinux命令crontab语法\ncrontab用来执行定时任务，或者说是制定日程的\n\ncrontab 的参数：\n\n-u user ：设定指定user的时程表\n-l ：列出目前的所有时程表\n-r：删除目前的的时程表\n\ncron表达式（即日程时间格式）：从左到右分别为：分钟（0-59）、小时（0-23）、天（1-31）、月（1-12）、星期（0-6）\nf1   f2   f3   f4   f5*    *    *    *    *-    -    -    -    -|    |    |    |    ||    |    |    |    +----- 星期中星期几 (0 - 6) (星期天 为0)|    |    |    +---------- 月份 (1 - 12) |    |    +--------------- 一个月中的第几天 (1 - 31)|    +-------------------- 小时 (0 - 23)+------------------------- 分钟 (0 - 59)\n\n各种符号表示的意思：\n\n*：表示每的意思；例如f1为*就表示每分钟，f2为*就表示每小时\n-：表示从多少到多少均执行；例如f2为0-10就表示凌晨0点到10点都要执行\n/：表示每隔多久执行一次；例如f2为*/2每隔2个小时执行一次\n,：表示准确的时间执行；例如f2为2,3,4表示2点、3点、4点分别执行一次\n\n例子Demo注意：命令crontab执行的是一个文件\n1、每天晚上24点关机\n0 0 * * * shutdown now\n\n2、在 12 月内, 每天的早上 6 点到 12 点，每隔 3 个小时 0 分钟执行一次/usr/bin/backup\n0 6-12/3 * 12 * /usr/bin/backup\n\n3、每月每天的午夜 0 点 20 分, 2 点 20 分, 4 点 20 分….执行 echo &quot;haha&quot;\n20 0-23/2 * * * echo &quot;haha&quot; \n\n参考资料\n菜鸟教程\n\n","categories":["Linux"],"tags":["Linux"]},{"title":"段哥的Linux私房菜","url":"/2020/07/12/Linux/%E6%AE%B5%E5%93%A5%E7%9A%84Linux%E7%A7%81%E6%88%BF%E8%8F%9C/","content":"\n引言：\n\n段哥的Linux私房菜：分区与挂载、网络操作、日志查看\n\n\n\n\n段哥的Linux私房菜分区与挂载操作使用VirtualBox创建一个磁盘，并且添加到虚拟机上\n创建分区fdisk（磁盘管理：创建分区、删除分区、查看分区）\n# 管理磁盘fdisk /dev/sdb# m 可以获取帮助# n 创建一个新的分区  -&gt; p创建主分区 e创建扩展分区# p 打印当前创建的分区# w 保存并退出# q 不保存退出\n\n创建完成后，生成了sdb1，我们就分好了一个区\n格式化格式化就是给当前分区头部添加一段数据，这段数据标明这个分区所使用的文件格式等信息。\nmkfs.ext4# 有多种文件系统可以选择 例如 ext4 xfs cramfs 等等# 这里选择了经典的ext4\n\n挂载在格式化完成后，就可以挂载目录了，接下来我们给/dev/sdb1分区挂载一个目录\n首先建立一个目录\nmkdir /data\n\n使用mount命令挂载\nmount /dev/sdb1 /data\n\n然后使用df -h查看挂载情况，我们就挂载好了\n卸载在卸载之前，我们可以向这个分区建立一个文件，例如\ncd /data# 进入到挂载点touch 1.txt# 创建一个新文件\n\n卸载了它\numount /dev/sdb1# 注意，如果报错buzy，意思是你不能在挂载点进行卸载操作，你可以换一个地方\n\n再使用df -h查看，我们就卸载了这个挂载点\n如果我们再装载上它，会发现，数据都还是在的，挂载只是将从根延伸出来的一个目录安装到一个分区上，（由于磁盘大小的限制，我们不可能将所有的根下的目录都挂载在同一个地方），从根延伸出来的这个目录，和根目录存储的分区不同（例如这个例子，我们的/挂载在/dev/sdb1，而我们将/data挂载在/dev/sdb2上）\n网络操作局域网内，通过mac地址就可以找到\n广域网需要通过网关，不配置网关不能访问外网\nDNS服务器：域名转换为IP，当我们输入一个域名，DNS会自动将这个域名换为IP地址\nGFW(Great FireWall)：墙，通过污染DNS，影响网站返回的真实IP地址，这就是墙\n实体机和虚拟机连接：能互相访问即可\nwindows方面：\nipconfig# 查看ip\n\nlinux方面：\nip addr# 查询ip地址\n\n\n可以看到有两张网卡：\n\nlo（Loopback Address）：回环地址，不属于任何一个有类别地址类。代表设备的本地虚拟接口，所以默认被看作是永远不会宕掉的接口\n\nenp：以太网\n# 默认关闭,查看配置文件cat /etc/sysconfig/network-scripts/ifcfg-enp0s\n\n\n注意到ONBOOT=no默认开机不会启动，而且BOOTPROTO=dhcp，dhcp是一个自动获取ip地址的协议，我们需要让他启动\n\nDHCP（动态主机配置协议）是一个局域网的网络协议。指的是由服务器控制一段IP地址范围，客户机登录服务器时就可以自动获得服务器分配的IP地址和子网掩码。默认情况下，DHCP作为Windows Server的一个服务组件不会被系统自动安装，还需要管理员手动安装并进行必要的配置。（百度百科）\n\ndhclient# 启动dhcp\n\n连接方式：\n\n桥接：直接与电脑使用同一台路由器（与电脑的网卡获取相同的路由器IP来源，共用同一个IP，同一个带宽）\nNAT：与主机共用同一个IP，但是在内部模拟了一个虚拟的IP，主机和虚拟机不是一个IP\nHost-only：与宿主机形成一个内部的小网络，主机和虚拟机可以互相访问，但是不能访问外网\n\n在启动dhc服务之后，虚拟机根据不同的连接方式，发送给网卡不同的请求。\n（在本机实验时，使用NAT方式，发现虚拟机可以ping通主机，但是主机ping不通虚拟机。所以改用了Host-only方式，但是发现在Virtual Box环境下，报错\nFailed to open/create the internal network &#x27;HostInterfaceNetworking-VirtualBox Host-Only Ethernet Adapter&#x27; (VERR_INTNET_FLT_IF_NOT_FOUND).Failed to attach the network LUN (VERR_INTNET_FLT_IF_NOT_FOUND).\n\n后来在网络与共享中心中更改适配器设置，将Host-only那张网卡禁用，再重新启动，即可解决）\n在主机ping通虚拟机后，就可以使用（Xshell、Termius）SSH服务远程操纵虚拟机了\n操作技巧重定向&gt;  # 重定向，将输出的文件输出到另一个位置# &gt; 覆盖  &gt;&gt; 追加\n\n例如，一个简单的C程序，hello.c\n#include &quot;stdio.h&quot;int main()&#123;        printf(&quot;hello world\\n&quot;);        return 0;&#125;\n\n编译一下（装一下gcc）\ngcc hello.c\n\n编译没有报错，就生成一个.out文件，运行一下\n[root@localhost local]# ./a.out hello world\n\n有时候我们并不希望这个数据输出到终端，所以我们可以使用重定向，将它写入到文件内（即使没有这个文件，他也会自动创建）\n./a.out &gt; b.txt\n\n这样，我们就可以在b.txt内看到执行结果\n管道|\n\n将上一个输出，转换为下一个的输入\n例如\n[root@localhost local]# ./a.out | cat | cat | cat |cathello world\n\n俄罗斯套娃\n日志查看tail xxx [-n20]# 查看文件的末尾数据，默认查看后10行# -n 参数，指定显示几行# -F 监听文件，文件一有变化，就立刻显示出\n\n示例\ntail -F b.txt# 回车后，会显示末尾10行并且进入等待# 使用另一个终端更改文件数据，保存后，会在这个终端立刻显示\n\n后台运行Ctrl + z # 切换到前台，程序后台运行nohup java -jar xxx.jar &amp; &gt; a.log# 后台运行xxx.jar，并且将日志输出到a.log","categories":["Linux"],"tags":["Linux"]},{"title":"Maven","url":"/2020/01/12/Maven/Maven/","content":"\n引言： Maven：项目管理工具\n\n\n\n\n\nMavenMavenMaven是什么？\n\nMaven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。\n\n为什么要学习Maven？\n\n帮我们处理jar包之间的冲突\n帮我们进行编译\n帮我们进行单元测试\n整合项目\n\n\n依赖管理：Maven工程将开发所用的jar包放置在jar包仓库中，通过在 pom.xml 文件中添加所需 jar 包的坐标，而传统模式下会把所有的jar包都放在项目里\n\n\n一键构建：Maven只需要一行命令就可以实现从编译、测试、运行、打包、安装、部署的一系列过程\n\n安装\n去Maven的官网，进行下载\n\n下载完成后，解压到某个位置\n\n配置系统变量和Path路径\n\n配置完成后打开cmd，输入mvn -v，显示版本信息，说明安装成功\n\n\nMaven仓库\n如图，Maven三个仓库\n\n本地仓库：无需网络，访问本地的jar包仓库，默认位置在 $&#123;user.dir&#125;/.m2/repository但我们都会自己配置这个地址\n远程仓库：局域网连接，公司内部使用的一个仓库\n中央仓库：需要互联网，这里几乎有所有的jar包，远程仓库地址 https://mvnrepository.com/ \n\n全局setting与用户setting\n全局配置：在 maven 安装目录下的有 conf/setting.xml 文件，此 setting.xml 文件用于 maven 的所有 project 项目，它作为 maven 的全局配置。 \n\n局部配置：如需要个性配置则需要在用户配置中设置，用户配置的 setting.xml 文件默认的位置在：$&#123;user.dir&#125; /.m2/settings.xml 目录中,${user.dir} 指windows 中的用户目录。\n\n\nMaven会先找用户配置，如果找到则以用户配置为准，否则使用全局配置\nMaven标准目录结构一个开发完成的项目，分为几部分：\n\n核心代码部分\n配置文件部分——这一部分可能会需要频繁的修改，所以不需要打为jar包\n测试代码\n测试配置文件\n\n传统的目录结构：项目名    -src    -config    -xxxx\n没有统一的规定，基本上所有的文件堆放在src目录下，混乱复杂，打包容易把所有的文件都打包\nMaven的目录结构\n\nsrc/main/java      //放置核心代码src/main/resources //放置配置文件src/main/webapp    //放置页面资源js，css,img资源//注意：如果是普通的 java 项目，那么就没有webapp 目录src/test/java      //放置测试代码src/test/resources //放置测试配置文件target —— 项目输出位置，编译后的class 文件会输出到此目录 pom.xml——maven 项目核心配置文件 \n\nMaven常用的命令\n编译命令\nmvn compile\nmaven 工程的编译命令，作用是将 src/main/java 下的文件编译为 class 文件输出到 target 目录下。\n\n测试命令\nmvn test\ntest 是 maven 工程的测试命令mvn test，会执行src/test/java下的单元测试类。 \n\n 清除命令\nmvn clean\nclean 是 maven 工程的清理命令，执行 clean 会删除 target 目录及内容。 \n\n打包命令\nmvn package\npackage是maven工程的打包命令，对于 java 工程执行 package 打成jar包，对于web 工程打成war包\n\n安装命令\nmvn install\n执行 install 将 maven 打成jar包或war包发布到本地仓库。 \n\n\n当后面的命令执行时，前面的操作过程也都会自动执行\n\n运行Maven工程\n\n进入 maven 工程目录（当前目录有 pom.xml 文件），运行\ntomcat:run\n\nMaven的生命周期maven 对项目构建过程分为三套相互独立的生命周期，请注意这里说的是“三套”，而且“相互独立”， 这三套生命周期分别是：  \n\nClean Lifecycle 在进行真正的构建之前进行一些清理工作。  \nDefault Lifecycle 构建的核心部分，编译，测试，打包，安装，部署等等。\nSite Lifecycle 生成项目报告，站点，发布站点\n\n\nMaven 概念模型\nPOM\n项目对象模型(Project Object Model)\n\n每个Maven工程都有一个pom.xml文件，配置了项目的坐标、项目依赖、插件信息等 例如：JDK，Tomcat等\nDMS\n依赖管理系统(Dependency Management System)\n\n通过 maven 的依赖管理对项目所依赖的 jar 包进行统一管理。 \n例如：项目依赖 junit4.9，通过在 pom.xml 中定义 junit4.9 的依赖即使用 junit4.9，如下所示是 junit4.9 的依赖定义： \n&lt;!-- 依赖关系 --&gt;  &lt;dependencies&gt;    &lt;!-- 此项目运行使用 junit，所以此项目依赖 junit --&gt;     &lt;dependency&gt;            &lt;!-- junit 的项目名称 --&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;!-- junit 的模块名称 --&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;!-- junit 版本 --&gt;            &lt;version&gt;4.9&lt;/version&gt;            &lt;!-- 依赖范围：单元测试时使用 junit --&gt;        &lt;scope&gt;test&lt;/scope&gt;       &lt;/dependency&gt; &lt;/dependencies&gt;\n","categories":["Maven"],"tags":["Maven"]},{"title":"Maven依赖冲突","url":"/2023/07/23/Maven/Maven%E4%BE%9D%E8%B5%96%E5%86%B2%E7%AA%81/","content":"\n引言： Maven解决依赖冲突的两种方式。\n\n\n\n\nMaven依赖冲突Maven产生依赖冲突的原因产生的原因：当使用Maven引入包时，包也会引入其他包，因此我们导入的包之间，可能其间接依赖的包之间版本不同，在启动后，可能会出现以下“找不到”的异常：\n\njava.lang.NoSuchMethodError\njava.lang.ClassNotFoundException\njava.lang.NoClassDefFoundError\n\nMaven的选择原则Maven有两个选择原则：\n\n路径最短原则：假设A-&gt;C1，B-&gt;D-&gt;C2，Maven会选择依赖路径短的一个，即C1\n优先声明原则：假设A-&gt;C1，B-&gt;C2，Maven会选择优先声明的一个，即C1\n\nMaven依赖冲突的解决方式IDEA安装插件Maven Helper，使用插件进行分析，我们自己手动排除exclusion那些需要的包。\n打开pom.xml文件，点击左下角Dependency Analyzer\n此时就可以进行选择了，对不需要的包我们可以直接Exclude\n在Pom文件中我们可以在dependency中使用标签exclusion\n&lt;dependency&gt;    &lt;groupId&gt;xxx&lt;/groupId&gt;    &lt;artifactId&gt;xxx&lt;/artifactId&gt;    &lt;version&gt;1.0&lt;/version&gt;    &lt;exclusions&gt;        &lt;exclusion&gt;            &lt;groupId&gt;xxx&lt;/groupId&gt;            &lt;artifactId&gt;xxx&lt;/artifactId&gt;        &lt;/exclusion&gt;    &lt;/exclusions&gt;&lt;/dependency&gt;","categories":["Maven"],"tags":["Maven"]},{"title":"HashMap源码探究","url":"/2021/06/13/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/HashMap%E6%BA%90%E7%A0%81%E6%8E%A2%E7%A9%B6/","content":"\n    引言：HashMap源码探究\n\n\n\nHashMap源码探究\n写在前面：\n​        HashMap是一个重要的内容，无论是日常使用还是面试，都会用到；\n​        个人水平不足以完成这个源码探究，但是找到了很多大佬的博客，深有感触，所以决定洗稿开始，加上自己的感受，如果有错误纯属正常操作，请指出。\n\n参考来源\n猿人谷：大佬，这篇blog直接路转粉\n敖丙：并发下的HashMap如何出现问题\n\nHashMap要点\nHashMap的底层实现：Jdk1.7中使用数组+链表；Jdk1.8使用数组+链表+红黑树\n\n红黑树化条件：（两个缺一不可）\n\n数组的长度大于64（如果不大于64，使用扩容策略）\n链表的长度大于8\n\n\n红黑树节点在6以下会恢复为链表\n\nHashMap的初始化方法仅仅是设置扩容临界值、负载因子、初始容量，真正的初始化Node在resize方法中\n\nresize方法负责两个工作：\n\n初始化node数组table\n\n扩容\n\n\n\nHashMap是线程不安全的，如果在多线程中，请使用ConcurrentHashMap\n\n负载因子默认值0.75：\n\n负载因子大：提高内存利用率，但是碰撞几率变大\n负载因子小：提高查询速度，浪费内存空间\n\n\n扩容一定是2的幂次，成倍的进行扩容\n\nJDK1.7是表头插入法，每次扩容改变存储顺序，易造成列表环\n\nJDK1.8是尾部插入法，扩容不改变存储顺序\n\n\nHashMap底层实现基本field/**     * 初始化容量大小16     * &lt;&lt; 表示左移位，每移动一位相当于*2     */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16/**     * 最大容量：2^30     */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/**     * 负载因子：0.75     */static final float DEFAULT_LOAD_FACTOR = 0.75f;/**     * 使用树而不是列表的临界点（threshold）！     * hash表中出现哈希碰撞后，当链表长度达到8的时候，才会考虑转换为红黑树（注意是才会考虑！）     */static final int TREEIFY_THRESHOLD = 8;/**     * 非树化的临界值     * 如果红黑树的数量小于6，那么转换回链表     */static final int UNTREEIFY_THRESHOLD = 6;/**     * 转换为红黑树的另一个条件：数组的长度为64以上     */static final int MIN_TREEIFY_CAPACITY = 64;\n\n由此我们可以看出，JDk1.8由链表转换红黑树的条件有两个且必须同时满足：\n\n数组的长度至少为64\n链表的长度至少大于8\n\n由红黑树转换回链表的条件：\n\n红黑树的节点数小于6\n\n内部类——Node在JDK1.7中称为Entry，在JDK1.8中叫Node\nHashMap本质就是一个Node数组，而Node又有next，可以看做链表\n// 是一个静态类，方便HashMap调用（不需要借助引用）static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;    // hash值，也不可更改    final int hash;    // key 与 value：key是不可以更改的    final K key;    V value;    // 连接到下一个节点    Node&lt;K,V&gt; next;    // 构造方法    Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;...&#125;    // get set toString 相关方法，都有final关键字，说明不可以重写    public final K getKey()   &#123;...&#125;    public final V getValue()      &#123;...&#125;    public final String toString()  &#123;...&#125;    public final V setValue(V newValue) &#123;...&#125;    /**         * hash值计算方法：将key与value的hash值进行位运算：异或运算（相异为1，相同为0）         * Obejcts类的hashcode方法为：         * return o != null ? o.hashCode() : 0;         * 可见，除null是0外，其他都调用Obejct类的hashcode方法（即简单对内存地址进行一下处理）         * @return         */    public final int hashCode() &#123;        return Objects.hashCode(key) ^ Objects.hashCode(value);    &#125;    // equals方法    public final boolean equals(Object o) &#123;        if (o == this)            return true;        if (o instanceof Map.Entry) &#123;            // Map的节点都叫Entry，JDK1.8HashMap将自己的Entry改名为Node            Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;            // objets的equals方法：return (a == b) || (a != null &amp;&amp; a.equals(b));            if (Objects.equals(key, e.getKey()) &amp;&amp;                Objects.equals(value, e.getValue()))                return true;        &#125;        return false;    &#125;&#125;\n\n构造方法前置变量：\n// transient 表名这个变量不需要被序列化;// HashMap是一个Node数组transient Node&lt;K,V&gt;[] table;// HashMap中元素的数量transient int size;\n\n共有四个重载的构造方法:\n\n两个参数：初始容量和负载因子\n\npublic HashMap(int initialCapacity, float loadFactor) &#123;        // 参数：初始容量、负载因子        if (initialCapacity &lt; 0)            throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; +                                               initialCapacity);        if (initialCapacity &gt; MAXIMUM_CAPACITY)            initialCapacity = MAXIMUM_CAPACITY;        if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))            throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +                                               loadFactor);        this.loadFactor = loadFactor;        // tableSizeFor 返回一个大于输入参数且是2的整数次幂的数        // 比如：输入10，返回2的三次方为8、2的四次方为16，大于10，那么输出16        // tableSizeFor 的代码经过优化调优，使用移位与位异或实现        //threshold用来判断什么时候进行扩容        this.threshold = tableSizeFor(initialCapacity);&#125;\n\n\n一个参数\n\npublic HashMap(int initialCapacity) &#123;        this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;\n\n\n无参构造\n\npublic HashMap() &#123;        this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;\n\n\n将一个Map转为一个HashMap（不讨论此构造）\n\npublic HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;        this.loadFactor = DEFAULT_LOAD_FACTOR;        putMapEntries(m, false);&#125;\n\n核心方法put方法：\nstatic final int TREEIFY_THRESHOLD = 8; public V put(K key, V value) &#123;        return putVal(hash(key), key, value, false, true); &#125;    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,               boolean evict) &#123;    // 参数说明：hash是key的哈希值、onlyIfAbsent如果是真代表无需改变现有的值、evict如果是假，则表（Node数组）在初始化阶段    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;    // 如果当前map无数据，那么执行resize方法    if ((tab = table) == null || (n = tab.length) == 0)        n = (tab = resize()).length;    // 如果要插入的键值对要存放的这个位置刚好没有元素，那么把他封装成Node对象，放在这个位置上即可    if ((p = tab[i = (n - 1) &amp; hash]) == null)        tab[i] = newNode(hash, key, value, null);    // 否则有元素    else &#123;        Node&lt;K,V&gt; e; K k;        // a.如果这个元素的key与要插入的一样，那么就替换一下。        if (p.hash == hash &amp;&amp;            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            e = p;        // b.如果这个node是TreeNode，那么就调用Tree的put方法（代表这个结构现在是红黑树）        else if (p instanceof TreeNode) &#123;            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);        &#125;        // c.此时这个值是完完全全的新值，而且仍然属于链表结构        else &#123;            // 遍历这个链表，把值放在合适的位置上            for (int binCount = 0; ; ++binCount) &#123;                if ((e = p.next) == null) &#123;                    p.next = newNode(hash, key, value, null);                    // 下面就是将链表转换为红黑树的判断                    // 当链表的长度大于TREEIFY_THRESHOLD时，调用treeifyBin方法                    // （但不一定会树化，另一个条件在这个方法内，当数组长度小于64时，会进行扩容，而不是树化）                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st                        treeifyBin(tab, hash);                    break;                &#125;                if (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    break;                p = e;            &#125;        &#125;        if (e != null) &#123; // existing mapping for key            V oldValue = e.value;            if (!onlyIfAbsent || oldValue == null)                e.value = value;            afterNodeAccess(e);            return oldValue;        &#125;    &#125;    ++modCount;    // 判断threshold，决定是否扩容    if (++size &gt; threshold)        resize();    afterNodeInsertion(evict);    return null;&#125;\n\ntreeifyBin方法：（树化）\nfinal void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123;     int n, index; Node&lt;K,V&gt; e;     //树形化还有一个要求就是数组长度必须大于等于64，否则继续采用扩容策略     if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY)         resize();     else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123;         ... 树化具体过程    &#125;&#125;\n\nHashMap原理为什么JDK1.8要进行树化？原因1：并发操作（不要并发使用hashmap）易死循环\n​        JDK1.7的情况下，并发扩容时容易形成链表环，此情况在1.8时就好太多太多了。因为在1.8中当链表长度大于阈值（默认长度为8）时，链表会被改成树形（红黑树）结构。\n​    JDK1.7采用表头插入法。扩容是改变链表原本的顺序，并发易导致链表形成环。\n​    JDK1.8采用尾部插入法。扩容时保持原有顺序，不会出现链表环问题。\n原因2：安全问题\n​        因为在元素放置过程中，如果一个对象哈希冲突，都被放置到同一个桶里，则会形成一个链表，我们知道链表查询是线性的，会严重影响存取的性能。\n​        而在现实世界，构造哈希冲突的数据并不是非常复杂的事情，恶意代码就可以利用这些数据大量与服务器端交互，导致服务器端CPU大量占用，这就构成了哈希碰撞拒绝服务攻击，国内一线互联网公司就发生过类似攻击事件。\n\n用哈希碰撞发起拒绝服务攻击(DOS，Denial-Of-Service attack)，常见的场景是攻击者可以事先构造大量相同哈希值的数据，然后以JSON数据的形式发送给服务器，服务器端在将其构建成为Java对象过程中，通常以Hashtable或HashMap等形式存储，哈希碰撞将导致哈希表发生严重退化，算法复杂度可能上升一个数据级，进而耗费大量CPU资源。\n\n为什么链表转换红黑树的临界值为8？链表长度符合泊松分布，各个长度的命中概率依次递减，当长度为 8 的时候，是最理想的值。也是出于时间与空间的一种平衡。\n\n如果太大：链表的查询速度为O(n)会大大降低查询速度\n\n如果太小：TreeNode占用的资源远大于Node\n\n\n负载因子的作用“负载极限”是一个0～1的数值，“负载极限”决定了hash表的最大填满程度。\n​    当hash表中的负载因子达到指定的“负载极限”时，hash表会自动成倍地增加容量（桶的数量），并将原有的对象重新分配，放入新的桶内，这称为rehashing。\n“负载极限”的默认值（0.75）是时间和空间成本上的一种折中：\n\n较高的“负载极限”可以降低hash表所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的操作（HashMap的get()与put()方法都要用到查询）\n较低的“负载极限”会提高查询数据的性能，但会增加hash表所占用的内存开销\n\n线程不安全为什么HashMap线程不安全：\nHashMap使用时，内部无可避免会进行resize与rehash。\n\nrehash极有可能形成链表环，导致死循环\n\nresize期间，由于会新建一个新的空数组，并且用旧的项填充到这个新的数组中去。所以，在这个填充的过程中，如果有线程获取值，很可能会取到 null 值，而不是我们所希望的、原来添加的值。\n\n\nJDK1.7、1.8计算索引的区别JDK1.7计算索引使用indexFor方法：\nstatic int indexFor(int h, int length) &#123;     // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;;     return h &amp; (length-1); &#125;\n\nhash方法是这样的：\nfinal int hash(Object k) &#123;     int h = hashSeed;     if (0 != h &amp;&amp; k instanceof String) &#123;         return sun.misc.Hashing.stringHash32((String) k);     &#125;      h ^= k.hashCode();      // This function ensures that hashCodes that differ only by     // constant multiples at each bit position have a bounded     // number of collisions (approximately 8 at default load factor).     h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);     return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125;\n\n\nJDK1.8具体键值对在哈希表中的位置（数组index）取决于下面的位运算（去除了indexFor方法）：\ni = (n - 1) &amp; hash// n是数组的长度；hash是要存储Key的hash值\n\n仔细观察哈希值的源头，会发现它并不是key本身的hashCode，而是来自于HashMap内部的另一个hash方法。\n//（这里的hash值方法来源于）static final int hash(Object key) &#123;    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);    //&gt;&gt;&gt;代表无符号右移，高位统统补0；&gt;&gt;则表示带符号右移，高位补符号位；&#125;\n\n为什么这里需要将高位数据移位到低位进行异或运算呢？\n​        这是因为有些数据计算出的哈希值差异主要在高位，而HashMap里的哈希寻址是忽略容量以上的高位的，那么这种处理就可以有效避免哈希碰撞。\n为什么要重写equals方法？​        equals默认是继承自Object的方法，它本身是比较内存地址的；假如有一个HashMap，内部有一个由于哈希碰撞拉出的链表，如果我们不重写equals方法，不比较内容的话，就只能找到链表为止，找不到我们要的node了\n​        而重写hashcode方法，是为了让相同内容的对象返回相同的哈希值\nHashMap、HashTable、TreeMap区别\n可以存储NULL？\nHashMap可以存储key为null，value为null的值，但是只能有一个key为null的元素\nHashTable、TreeMap都不能为null\n\n\n\n\n为什么hashTable的key不能为null，但是Hashmap却可以？\n\n​        因为HashTable对于null的key是直接抛异常的，但是HashMap内部的hash方法进行判断，如果是null，返回0\n\n如果深究的话，就是因为安全失败机制(fail safe)，这种机制会使你此次读到的数据不一定是最新的数据。\n\n如果你使用null值，就会使得其无法判断对应的key是不存在还是为空，因为你无法再调用一次contain(key)来对key是否存在进行判断ConcurrentHashMap同理。\n\n初始容量：\nhashmap为16\nHashTable为11（负载因子都是0.75）\n扩容机制：\nHashmap翻倍\nHashTable翻倍+1\n\n\n是否有序？\nHashMap、HashTable无序\nTreeMap能够对保存的记录根据键进行排序\n\n\n时间复杂度\nHashTable、HashMap具有O(1)级别时间复杂度\nTreeMap因为有序，所以为O(logn)\n\n\n线程安全问题：\nHashMap线程不安全\nHashTable线程安全\n\n\n底层实现：\nHashMap：数组+链表+红黑树\nTreeMap：数组+红黑树\nHashTable：数组+链表\n\n\n选择：\n首选HashMap\n需要排序则选TreeMap\n\n\n\n","categories":["Java源码","HashMap"],"tags":["Java源码","HashMap"]},{"title":"JavaBean","url":"/2020/02/25/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/JavaBean/","content":"\n引言：JavaBean\n\n\n\n\nJavaBean来看一个小猫类\npublic class Cat &#123;    private int age;    private String name;    private boolean health;    public Cat() &#123;    &#125;    public boolean isHealth() &#123;        return health;    &#125;    public void setHealth(boolean health) &#123;        this.health = health;    &#125;    public int getAge() &#123;        return age;    &#125;    public void setAge(int age) &#123;        this.age = age;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;&#125;\n在编程过程中，我们发现很多类都和这个类有着很多共同点\n\n实例字段用private修饰\n实例方法用public修饰并且方法名是getXxx()setXxx()这种类我们都叫JavaBean\n\n属性\n我们通常把一组对应的读方法（getter）和写方法（setter）称为属性（property）\n\n\n属性只需要定义getter和setter方法，不一定需要对应的字段\n\npublic class Cat &#123;    private int age;    private String name;    private boolean health;        //没有字段但是也是属性    public boolean isChild() &#123;        return age &lt;= 6;    &#125;        ...    &#125;\nJavaBean的作用JavaBean主要用来传递数据，即把一组数据组合成一个JavaBean便于传输。\n此外，JavaBean可以方便地被IDE工具分析，生成读写属性的代码，主要用在图形界面的可视化设计中。\n遍历JavaBean属性要枚举一个JavaBean的所有属性，可以直接使用Java核心库提供的Introspector：\n\nIntrospector:\nThe Introspector class provides a standard way for tools to learn about the properties, events, and methods supported by a target Java Bean.\n\n\nBeanInfo\nUse the BeanInfo interface to create a BeanInfo class and provide explicit information about the methods, properties, events, and other features of your beans.\n\n\n\n示例：打印小猫类的属性\nBeanInfo info = Introspector.getBeanInfo(Cat.class);for(PropertyDescriptor pd : info.getPropertyDescriptors())&#123;    System.out.println(pd.getName());    System.out.println(pd.getReadMethod());    System.out.println(pd.getWriteMethod());&#125;\n打印结果\nagepublic int Cat.getAge()public void Cat.setAge(int)child/*代码没有定义字段，但是却有这个字段，这个字段是被isChild方法带来的*/public boolean Cat.isChild()nullclass/*class类是继承自Object类的属性getClass方法带来的*/public final native java.lang.Class java.lang.Object.getClass()nullhealthpublic boolean Cat.isHealth()public void Cat.setHealth(boolean)namepublic java.lang.String Cat.getName()public void Cat.setName(java.lang.String)\n\n\n\n\n\n\n知识来源：廖雪峰博客及 官方api文档\n\n","categories":["Java核心类","JavaBean"],"tags":["Java核心类","JavaBean"]},{"title":"Linux用户权限与文件系统","url":"/2020/07/09/Linux/Linux%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","content":"\n引言：\n\nLinux用户权限与文件系统\n\n\n\n\nLinux文件系统用户与用户组\nlinux中每一个文件都有三个权限身份User、Group、Others \n\nUser就是指用户，每一名用户对文件的操作权限都不同\nGroup就是用户组，对一个文件，用户组内对其操作权限相同\nOthers，对于一个用户来说，其他用户对其就是Others，其他人\nroot对于linux来说是神，拥有最高权限\n\n在Linux中，所有用户的账号与root用户信息都是在/etc/passwd，用户组信息存放在/etc/group，个人的密码存放在/etc/shadow\n\n\nLinux文件属性使用ls -al来查询文件的类别\n[root@localhost usr] ls -aldrwxr-xr-x.  17 root root   221 Jul  4 19:33 .dr-xr-xr-x.  17 root root   224 Jul  5 18:17 ..dr-xr-xr-x.   2 root root 49152 Jul  4 19:35 bindrwxr-xr-x.   3 root root    79 Jul  4 19:16 cmakedrwxr-xr-x.   2 root root     6 Apr 10  2018 etclrwxrwxrwx.   1 root root    10 Jul  4 01:47 tmp -&gt; ../var/tmp\n\n总共分为七个部分：\n\n第一个部分dr-xr-xr-x：\n第一个字符有多种不同的文件类型\n[d]：目录\n[-]：文件\n[l]：链接，并且在文件名会显示出链接到哪里\n[b]：可供存储的接口设备\n[c]：串行端口设备（例如鼠标键盘）\n\n\n后九个字符，每三个一组，分别代表User、Group、Others对该文件的操作权限\n[r]：read，可读\n[w]：write\n[x]：execute\n\n\n\n\n第二个部分17，这个数字代表连接数，有多少文件名连接到此节点\n第三个部分代表文件的所有者User账号\n第四个部分代表文件的所属用户组Group\n第五个部分代表文件的大小，单位是B字节\n第六个部分代表文件的创建时间或者文件的最近更新时间\n第七个部分代表文件名，文件名前有.，代表这个文件为隐藏文件\n\n改变文件的操作权限该笔那文件的操作权限，有以下三个命令\nchgrp # 改变用户组chown # 改变用户chmod # 改变文件的权限\n\n改变用户组的操作权限chgrp -R [用户组名] [文件名]\n-R参数代表的意思递归的持续更改，连同文件下的子目录\n[root@localhost usr]# ls -l text.txt -rw-r--r--. 1 root root 0 Jul  8 19:08 text.txt[root@localhost usr]# chgrp usr text.txt [root@localhost usr]# ls -l text.txt -rw-r--r--. 1 root usr 0 Jul  8 19:08 text.txt\n\n此处的用户组名是usr，用户组名必须是/etc/group目录下的文件，如果在/etc/group目录下不存在用户组会报错\n[root@localhost usr]# chgrp xxx text.txt chgrp: invalid group: ‘xxx’\n\n改变用户的操作权限chown -R [账号名] [文件名]\n[root@localhost usr]# ls -l text.txt -rw-r--r--. 1 root usr 0 Jul  8 19:08 text.txt[root@localhost usr]# chown usr text.txt[root@localhost usr]# ls -l text.txt -rw-r--r--. 1 usr usr 0 Jul  8 19:08 text.txt\n\n同样，此处的usr必须是/etc/passwd文件下有的，否则也会报错\n改变文件的操作权限（重点）Linux中共有三个身份，每个身份对应三个权限，分别是rwx，现在分别给各个权限一个数字\nr → 4w → 2x → 1- → 0\n\n那么假设有这样一个操作权限组-rw-r--r--，那么他的操作权限数字就是622（4+2+0,2+0+0,2+0+0）\n那么最高权限就是777了\n[root@localhost usr]# ls -l text.txt -rw-r--r--. 1 usr usr 0 Jul  8 19:08 text.txt[root@localhost usr]# chmod 777 text.txt [root@localhost usr]# ls -l text.txt -rwxrwxrwx. 1 usr usr 0 Jul  8 19:08 text.txt\n\n\n除了给数字，我们还可以通过字符给文件设置可读可写\nchmod  u/g/o/a +/-/= r/w/x [文件名]# 给user/group/other 增添/减去/设置 读/写/执行\n\n例如：\n[root@localhost usr]# ls -l text.txt -rwxrwxrwx. 1 usr usr 0 Jul  8 19:08 text.txt[root@localhost usr]# chmod u=rw,go-wx text.txt [root@localhost usr]# ls -l text.txt -rw-r--r--. 1 usr usr 0 Jul  8 19:08 text.txt\n\n对于文件和目录，rwx分别对应着什么对于文件r\t代表用户可以读文件的内容w\t代表用户可以更改增添文件的内容x\t代表用户可以执行这个文件\n\n注意：\n\n对文件给予w权限，不代表用户可以删除这个文件\n在Linux系统中判断文件是否可以执行，不同于windows中的.exe文件\n\n对于目录r\t代表用户使用ls查询这个目录下的内容w\t代表用户可以更改这个目录下的文件结构，可以删除，可以创建x\t代表用户可以cd到这个目录下\n\n注意：\n\nw的权限不能轻易给\n\nLinux中的文件种类与扩展名文件种类：\n普通文件（regular file），属性用[-]表示\n纯文本文件（ASCII），可以使用cat直接读取数据\n二进制文件（binary），可执行程序就是二进制文件\n数据格式文件（data），程序在运行过程中需要读取特定格式的文件，例如登录数据/var/log/wtmp只能使用last读取，使用cat读取会乱码\n目录（directory），属性使用[d]表示\n连接文件（link），类似windows中的快捷方式\n设备与设备文件（device），与外设或存储有关的文件，集中在/dev目录下，分为两种\n块（block）设备文件：提供一些存储数据的接口设备，属性用[b]表示\n字符（character）设备文件：串行端口的接口设备，属性为[c]\n\n\n套接字（Socket），数据接口文件，网络上的数据连接，属性为[S]\n管道（FIFO，pipe），解决多个程序同时访问到一个文件时所造成的错误，属性为[P]\n\n文件扩展名在linux中文件扩展名没有作用，这也是和windows重要的区别之一，在linux中的操作权限由rwx来决定，与.exe .bat等等是没有任何关系的，在Linux中后缀名的唯一作用就是告诉你一些关于这个文件的信息\n\n.sh：脚本或批处理文件（scripts）\n.tar .xz .zi .tar.gz等：压缩文件\n.html .php网页先关文件\n\n文件名长度的限制linux使用默认的Ext2/Ext3文件系统：\n\n文件或目录最大容许文件名最大容许255个字符\n包含完整路径及目录(/)的完整文件名为4096个字符\n避免使用特殊字符* ? &lt; &gt; ; % ^ &amp; * ( ) &#123;  &#125;\n\n文件目录配置\n\n\n目录\n应放置的文件内容\n\n\n\n/bin\n放置执行文件。在bin下的命令可以被root或是一般用户使用\n\n\n/boot\n放置开机会用到的文件。包括内核的引导文件、引导程序（grub）\n\n\n/dev\n放置设备和接口设备的文件。\n\n\n/etc\n放置系统的配置文件。重要的文件有：1. /etc/init.d：放置所有服务的默认脚本2. /etc/X11：放置与 X Window 有关的各种文件配置3. /etc/xinetd.d：super daemon（总管进程）管理的各项服务的配置文件目录\n\n\n/var\n单独来谈\n\n\n/home\n一般用户的用户主目录。有两种表示方法：1. ~ 2. ~[用户名]\n\n\n/usr\n重要目录，专门来谈\n\n\n/lib\n放置开机、运行/bin或是/sbin目录下命令的函数库。尤其是/lib/modules下，放置着linux内核相关的模块\n\n\n/media\n放置着可删除设备，例如光盘、软盘\n\n\n/opt\n放置第三方程序。不过还是习惯放置在/usr/local目录下\n\n\n/root\nroot的主文件夹，如果在root下cd ~，会进入到这个文件夹下\n\n\n/sbin\n放置开机所需要的重要命令。服务器软件程序产生的命令放置在/usr/sbin，系统自行安装的软件的命令放置在/usr/local/sbin下\n\n\n/srv\n一些网络服务启动后，这些服务所需要取用的数据目录，例如WWW，FTP服务\n\n\n/tmp\n一般用户或者是正在执行的程序暂时存放文件的地方\n\n\n/proc\n虚拟文件系统，放置的数据都在内存当中，不占硬盘空间\n\n\n/sys\n类似于/proc\n\n\n其中，开机主要和根目录有关，其他分区是在开机完成后才会持续进行挂载的行为，所以有五个目录不能分区到其他硬盘\n\n/etc配置文件\n/bin可执行文件\n/dev所需要的设备文件\n/lib执行文件所需要的函数库与内核所需要的模块\n/sbin重要的系统执行文件\n\n\n文件目录配置标准（FHS）\n四种交互形态：\n\n可分享与不可分享\n可分享：可以分享给其他系统使用的目录\n不可分享：与本机有关，不可分享的\n\n\n可变动的与不可变动\n可变动的：经常改变的数据\n不变的：有些数据不会跟着distribution的变动而变动，例如函数库等\n\n\n\n\n\n/usr目录\n由FHS，可以知道/usr是可分享不可变动的。\nusr不是user的缩写，是Unix Software Resource（Unix操作系统软件资源）的缩写\n\n\n\n\n目录\n应放置文件内容\n\n\n\n/usr/X11R6\n为X Window系统重要数据所放置的目录\n\n\n/usr/bin\n绝大多数用户的命令都可以放在这里，与/bin的区别是，没有与开关机相关的命令\n\n\n/usr/include\nC/C++语言的头文件\n\n\n/usr/lib\n包含各应用的函数库、目标文件、不被一般用户使用的命令\n\n\n/usr/local\n用户在本机自行安装下载的软件\n\n\n/usr/sbin\n非系统正常运行所需要的命令（网络服务器软件的服务命令）\n\n\n/usr/share\n可以分享的与平台无关的文件\n\n\n/usr/src\n放置源码，linux内核的源码就在/usr/src中\n\n\n/var目录\n\n\n目录\n应放置文件内容\n\n\n\n/var/cache\n放置应用程序中产生的一些暂存文件\n\n\n/var/lib\n放置应用程序运行中需要使用到的数据放置的目录\n\n\n/var/lock\n某些文件一次只能被一个程序所使用，因此就得给这种文件上锁\n\n\n/var/log\n存放登录文件\n\n\n/var/mail\n存放个人邮件\n\n\n/var/run\n某些程序或是服务启动后，PID会存放在这个目录下\n\n\n/var/spool\n队列数据（排队等待其他应用使用的数据）\n\n\n\n其他\n.与..\n\n.代表当前目录，也可以使用./表示\n..代表上一层目录，也可以使用../来表示\n\n","categories":["Linux"],"tags":["Linux"]},{"title":"包装类型","url":"/2020/02/24/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/%E5%8C%85%E8%A3%85%E7%B1%BB%E5%9E%8B/","content":"\n引言：包装类型\n\n\n\n\n包装类型java的数据类型分为两类：一类是基本类型：int byte short long float double boolean char一类是引用类型：类、接口、数组\nJava是一个面向对象的语言，有时在对于基本类型操作很不方便，所以引入了包装类型，给基本类型加上了方法和类型\n为什么要叫包装类型？我是这么理解的：基本类型就像是芝麻粒，为了吃它或者是榨油，我们只有将它装起来才能更好的利用它。\n\n以下都用int型来举例\n创建一个包装类型对象总共有三种方法来创建一个包装类型\nInteger i1 = new Integer(1);Integer i2 = Integer.valueOf(2);Integer i3 = Integer.valueOf(&quot;3&quot;);\n第一个是Integer类的构造方法\n第二个和第三个方法是Integer类的静态方法\n自动装箱、自动拆箱我们经常见到的\nInteger n = 100;//编译器自动使用Integer.valueOf(int)int x = n; // 编译器自动使用Integer.intValue()\n其实是编译器帮我们完成了这项工作，在我们编译的时候，编译器仍然会把这个句子翻译成valueOf()的方法，从基本类型到包装类型这个过程叫自动装箱(Auto Boxing)，同理从包装类型到基本类型有自动拆箱\n底层发现很有意思的一件事\nInteger i1 = new Integer(1);Integer i2 = new Integer(1);Integer i3 = 1;Integer i4 = 1;Integer i5 = 128;Integer i6 = 128;System.out.println(i1==i2);//falseSystem.out.println(i1==i3);//falseSystem.out.println(i3==i4);//trueSystem.out.println(i5==i6);//false\n前两个很好理解，new方法创建的实例会放在堆中，是不一样的实例\n但是后两个一个true一个false\n这是为什么呢？\n不变类观察Integer底层代码，会发现其实Integer对象是不可以改变的\npublic final class Integer &#123;    private final int value;&#125;\n但是为了节省内存，Java将-128 ~ 127的所有数都返回相同的实例，这就是i3和i4相同但是i5和i6不同的原因\n**所以我们在创建Integer类的时候，最好使用Integer.valueOf();（或者直接自动装箱）**这个构造方法，因为new方法构建的实例对象是一个“新”的实例，而这个方法直接从IntegerCache中获取\n包装类比较包装类是一个类，我们不能把它再看做一个基本类型了，所以我们需要使用equals方法，使用==就算对了，也只是碰巧使用的数字恰好在-128~127之间而已\n所以我们进行比较依然要使用equals()方法\n其他常见方法进制转换包装类可以轻松的进制转换\nInteger i1 = new Integer(59);System.out.println(Integer.toBinaryString(i1));//111011System.out.println(Integer.toHexString(i1));//3b\n\n获取常量// boolean只有两个值true/false，其包装类型只需要引用Boolean提供的静态字段:Boolean t = Boolean.TRUE;Boolean f = Boolean.FALSE;// int可表示的最大/最小值:int max = Integer.MAX_VALUE; // 2147483647int min = Integer.MIN_VALUE; // -2147483648// long类型占用的bit和byte数量:int sizeOfLong = Long.SIZE; // 64 (bits)int bytesOfLong = Long.BYTES; // 8 (bytes)\n转换各类所有的整数和浮点数的包装类型都继承自Number，因此，可以非常方便地直接通过包装类型获取各种基本类型：\n// 向上转型为Number:Number num = new Integer(999);// 获取byte, int, long, float, double:byte b = num.byteValue();int n = num.intValue();long ln = num.longValue();float f = num.floatValue();double d = num.doubleValue();\n\n处理无符号整型Java中都是有符号的，没有无符号的整型\n而c中对此非常认真，有符号也有无符号\n无符号整型和有符号整型的转换在Java中就需要借助包装类型的静态方法完成。\npublic class Main &#123;    public static void main(String[] args) &#123;        byte x = -1;        byte y = 127;        System.out.println(Byte.toUnsignedInt(x)); // 255        System.out.println(Byte.toUnsignedInt(y)); // 127    &#125;&#125;\n因为byte的-1的二进制表示是1111 1111，以无符号整型转换后的int就是255。\n类似的，可以把一个short按unsigned转换为int，把一个int按unsigned转换为long。\n\n参考资料：简书：@我没有三颗心脏以及廖雪峰官方网站\n\n","categories":["Java核心类","包装类型"],"tags":["Java核心类","包装类型"]},{"title":"StringBuilder","url":"/2020/02/24/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/StringBuilder/","content":"\n\n引言: StringBuilder\n\n\n\n\nStringBuilder为什么要有StringBuilder我们先不学习StringBuilder，先来思考一个问题：为什么Java要引入这么一个类呢？\n看以下代码\nString str = 1 + &quot;2&quot; + 3;\n这一行代码，会产生 &quot;12&quot;、&quot;123&quot;两个字符串对象，但是我们&quot;12&quot;其实并不是我们需要的，他是Java创建的临时对象，浪费内存，还会浪费GC(Java垃圾清理)效率\n为了高效的提高直接拼接字符串的效率，所以java提供了StringBuilder这个类\n如果我们使用StringBuilder这个类，在运行上面代码时，不会创建新的临时对象了\njdk api 官方说明：\n\nThis class is designed for use as a drop-in replacement for StringBuffer in places where the string buffer was being used by a single thread (as is generally the case). Where possible, it is recommended that this class be used in preference to StringBuffer as it will be faster under most implementations.\n\n构造方法StringBuilder()//无参构造StringBuilder(CharSequence seq)//CharSequence是一个接口，String、StringBuilder、StringBuffer实现了这个接口，其实代表的就是一个字符串StringBuilder(int capacity)//capacity参数是缓存大小StringBuilder(String str)//通过一个字符串构造\n\n\n常见方法StringBuilder的常用方法主要有两个，他们都有多个重载方法，匹配了各种各样的数据类型\n\napped\ninsertappedStringBuilder append(String str)//添加一个字符串到调用字符串的末尾\n例如StringBuilder sb = new StringBuilder(&quot;你好&quot;);System.out.println(sb.append(&quot;晚安&quot;));//你好晚安\nappend方法可以链式调用StringBuilder sb = new StringBuilder(&quot;你好&quot;);sb.append(&quot;晚安&quot;)        .append(&quot;去哪儿&quot;)        .append(1);System.out.println(sb);//你好晚安去哪儿1\n\n补充：链式调用实现链式调用的秘诀在于返回自身，我们也可以实现一个可以链式调用的方法\npublic class Chain &#123;    private int sum =0;    public Chain add(int x)&#123;        sum+=x;        return this;    &#125;    public int getSum() &#123;        return sum;    &#125;&#125;public static void main(String[] args)&#123;    Chain c = new Chain();    c.add(5).add(6).add(8);    System.out.println(c.getSum());&#125;\n\n\n\ninsertStringBuilder insert(int offset, String x)//offset 第几个开始插入,从1开始//x 插入的内容\n例子：\nStringBuilder sb = new StringBuilder(&quot;你好&quot;);sb.insert(1,&quot;晚安&quot;);System.out.println(sb);//你晚安好\ninsert同样可以链式编程\n值得注意的是，sb.append(x)和sb.insert(str.length(), x)其实作用是相同的\nStringBuilder sb1 = new StringBuilder(&quot;你好&quot;);StringBuilder sb2 = new StringBuilder(&quot;你好&quot;);sb1.insert(&quot;你好&quot;.length(),&quot;晚安&quot;);sb2.append(&quot;晚安&quot;);System.out.printf(&quot;%s , %s&quot;,sb1,sb2);//你好晚安 , 你好晚安\n\n其他方法StringBuilder delete(int start, int end)//删除方法，从0开始，比如我想删除第一个字符，delete(0,1);  删除所有的delete(0,str.length())int\tcapacity()//返回当前StringBuilder的缓存容量\n\n\n\n知识来源：廖雪峰博客及 官方api文档\n\n","categories":["Java核心类","StringBuilder"],"tags":["Java核心类","StringBuilder"]},{"title":"Preferences","url":"/2020/01/18/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/Preferences/","content":"\n引言：\n\nPreferences配置文件  \n\n\n\n\nPreferences\nPreferences首选项API：存储资源配置，为解决Properties的一些缺点（某些操作系统没有用户主目录的概念，而且大量的java文件有可能会有冲突）而出现的稳定的存储类\n\nPreferences通过类似于包名节点路径的配置/com/company/app的存储\n特点：\n\nPreferences可以有多棵并行的树，常见有两棵树：\n用户树：用来配置个性化的设置\n系统树：设置应用程序的设置数据等等\n\n\n每个节点都有一个preferences的对象，也是用键值对来存储数值、字符串、字节数组，但是不能储存可序列化(串行化)的对象（官方认为串行化的格式过于脆弱）\n\n获得树根、操作节点Preferences的每一个结点都是一个Preferences对象，所以我们需要先获得结点\npublic static Preferences userRoot()//获取用户树的树根节点public static Preferences systemRoot()//获取系统树的树根节点```javapublic abstract Preferences node(String pathname)/*node方法：可以传入节点的相对路径或者绝对路径名:    绝对路径名：以 / 开头的路径    相对路径名：不以 / 开头的路径*/\n\n示例代码\nPreferences root = Preferences.userRoot();//获得用户根节点Preferences preferences1 = root.node(&quot;/demo03/PreferencesTest&quot;);System.out.println(preferences1);//打印结果：User Preference Node: /demo03/PreferencesTest\n\n常用方法获得树根节点后，可以通过如下方法来操作数据\n存取数据abstract void put(String key,String value)abstract void putInt(String key, int value)//类似的有putDouble等方法/*    key：都是String类型    value：各有不同*/abstract String get(String key, String def)abstract int getInt(String key, int def)//同理，有类似的getDouble等方法/*    key：都是String类型    def：默认值。没有不带默认值的方法，必须传入一个默认值，为了确保在首选项不可以使用时依旧不会影响程序的运行，提高程序的鲁棒性（健壮性）*/String[] keys()//返回当前节点的所有键\n示例代码\npreferences1.put(&quot;username&quot;,&quot;李白&quot;);String s = preferences1.get(&quot;username&quot;, &quot;默认值&quot;);System.out.println(s);String[] keys = preferences1.keys();for (String key : keys) &#123;    System.out.println(key+&quot;,&quot;+preferences1.get(key,&quot;默认值&quot;));&#125;\n\n刷新数据Preferences中，使用异步的方式写入数据，可以使用flush方法刷新数据\nabstract void flush()\n\n删除数据abstract void remove(String key)//删除指定键对应的值abstract void removeNode()//删除当前节点\n示例代码\npreferences1.remove(&quot;username&quot;);s = preferences1.get(&quot;username&quot;, &quot;默认值&quot;);System.out.println(s);//打印结果：默认值preferences1.removeNode();preferences1.put(&quot;username&quot;,&quot;李白&quot;);//打印报错：Node has been removed.\n\n导出/导入数据数据的载体XML文件\nstatic void importPreferences(InputStream is)//导入一个XML文件的所有数据，注意：导入数据是一个静态方法，可以直接使用类名调用abstract void exportNode(OutputStream os)//导出当前节点存储的数据，但是不会导出当前节点的子节点中的数据abstract void exportSubtree(OutputStream os)//导出当前节点及子节点的数据\n导出数据到xml文件\nPreferences root = Preferences.userRoot();Preferences preferences1 = root.node(&quot;/demo03/PreferencesTest&quot;);preferences1.exportNode(new FileOutputStream(&quot;preferences.xml&quot;));\n导出的xml文件的格式\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;!DOCTYPE preferences SYSTEM &quot;http://java.sun.com/dtd/preferences.dtd&quot;&gt;&lt;preferences EXTERNAL_XML_VERSION=&quot;1.0&quot;&gt;  &lt;root type=&quot;user&quot;&gt;    &lt;map/&gt;    &lt;node name=&quot;demo03&quot;&gt;      &lt;map/&gt;      &lt;node name=&quot;PreferencesTest&quot;&gt;        &lt;map&gt;          &lt;entry key=&quot;username&quot; value=&quot;李白&quot;/&gt;        &lt;/map&gt;      &lt;/node&gt;    &lt;/node&gt;  &lt;/root&gt;&lt;/preferences&gt;\n导入这个文件\nPreferences.importPreferences(new FileInputStream(&quot;preferences.xml&quot;));\n\n实现一个判断是否第一次登录的小demo第一次登录会输出 欢迎你好，第二次登录会输出 你好，您的上次登录时间是\npublic class PreferencesTest &#123;    public static void main(String[] args) throws BackingStoreException, IOException, InvalidPreferencesFormatException &#123;        Preferences node = Preferences.userRoot().node(&quot;/demo03/PreferencesTest&quot;);        boolean isFirstLogin = node.getBoolean(&quot;isFirstLogin&quot;, true);        if(isFirstLogin)&#123;            System.out.println(&quot;欢迎光临&quot;);            node.putBoolean(&quot;isFirstLogin&quot;,false);        &#125;else &#123;            System.out.println(&quot;您好,您的上次登录时间是&quot;+node.get(&quot;LoginTime&quot;,&quot;Error&quot;));        &#125;        node.put(&quot;LoginTime&quot;, String.valueOf(LocalTime.now()));    &#125;&#125;\n\n","categories":["后台","Java","Preferences"],"tags":["Java","资源配置","Preferences"]},{"title":"乐理知识1","url":"/2020/09/01/Music/%E4%B9%90%E7%90%86%E7%9F%A5%E8%AF%86/","content":"\n前言：\n\n没错没错，一个好的程序员怎么能不懂一点音乐呢！\n\n\n\n乐理知识节奏\n拍：拍子，一拍一拍\n速度：每分钟有多少拍。bpm(beats per minutes)\n小节：基本为4拍\n节拍：基本为4/4拍  -&gt; 分母：以四分音符为一拍，分子：每小节有四拍\n音符时值：几分音符\n\n四分音符为例：\n\n\n\n\n此图的A5，就是一个四分音符，位于第二小节的第二拍\n\n\n钢琴键盘\n一共88个键，越靠左音越低，越靠左音越高\n\n相邻琴键差半音，不管是相邻白键还是白黑相邻\n\n两个半音加起来就是一个全音\n\n\n这两个键，相差一个全音：\n\n\n这两个也是差一个全音：\n\n\n\n\n排列模式：(2+3)个黑键 + 7个白键，在钢琴上不断重复这个模式 \n\n\n音名：从左到右依次为——C D E F G A B\n\n\n但是也有几个特殊的地方：\n\n小字五组 ，钢琴键上的最高音\n\n\n\n\n最低音为大字二组的A\n\n\n\n中央C——小字一组的C\n\n黑键由左右的白键来确定，例如C右边的黑键就是c#“升C”，也可以叫D b（这个b是降号），所以一个黑键由两个名字\n\n\n\n\n\n\n  \n\n调C大调\n\nD大调，升号调\n\n升号调和降号调\n\nF大调，降号调\n\n稳定的音最稳定的是主音，比如C大调，C就是主音\n\n\n倾向性：\n\n\nqqbqqqb","categories":["music"],"tags":["乐理知识","music"]},{"title":"大数值","url":"/2020/02/27/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/%E5%A4%A7%E6%95%B0%E5%80%BC/","content":"\n引言： 大数值\n\n\n\n\n大数值先来看一个例子吧：\nSystem.out.println(Long.MAX_VALUE);//9223372036854775807System.out.println(Long.MAX_VALUE+5);//-9223372036854775804 已经崩溃了\n\nlong是最大的整型了，但是我们遇到比再大一点的数怎么办？\n这时候就引入了大数值两个类BigInteger和BigDecimal\n这两个类并非是一个数，是模拟出来的数，在类的内部使用了数组（BigInteger使用了int[]）来模拟任意大小的数，前者是整数，后者是浮点数\nBigIntegerBigInteger可以表示任意大小的整数\nSystem.out.println(Long.MAX_VALUE);//9223372036854775807System.out.println(Long.MAX_VALUE+5);//-9223372036854775804 已经崩溃了BigInteger big = new BigInteger(String.valueOf(Long.MAX_VALUE));System.out.println(big.add(new BigInteger(&quot;5&quot;)));//9223372036854775812 依然ok\n但是BigInteger的加减乘除只可以使用方法来运算,而且运算对象只能是相同的类型\nBigInteger big1 = new BigInteger(String.valueOf(Long.MAX_VALUE));BigInteger big2 = new BigInteger(String.valueOf(Long.MIN_VALUE));System.out.println(big1.add(big2));//-1\n\n转换转换成基本类型，例如转换为long型\npublic long longValue()public long longValueExact()/*两个方法都可以将大数值转换为 long 型    不同的是     如果大数值的数值大小超过long的范围，    第一个方法不会报错，但是转化后的数据不正确。    第二个方法会报出异常*/\n如下\nBigInteger big1 = new BigInteger(String.valueOf(Long.MAX_VALUE));BigInteger big2 = new BigInteger(String.valueOf(Long.MAX_VALUE));long l1 = big1.add(big2).longValue();//值是 -2long l2 = big1.add(big2).longValueExact();//ArithmeticException: BigInteger out of long range\n\n同样转换 int float double short byte都有对应的方法\n如果BigInteger的值甚至超过了float的最大范围（3.4x10^38），那么返回的float是什么呢\nBigInteger n = new BigInteger(&quot;999999&quot;).pow(99);float f = n.floatValue();System.out.println(f);//Infinity\n\n\nBigDecimal如果查看BigDecimal的源码，可以发现，实际上一个BigDecimal是通过一个BigInteger和一个scale来表示的，即BigInteger表示一个完整的整数，而scale表示小数位数：\npublic class BigDecimal extends Number implements Comparable&lt;BigDecimal&gt; &#123;    private final BigInteger intVal;    private final int scale;&#125;\n\n基本方法public int scale()//返回小数点后数字个数，如果是一个整数则会返回负数，例如：-2，代表数字末尾有2个0 例如 3400public BigDecimal setScale(int newScale,                           int roundingMode)//按设置的newScale个数，对应的roundingMode方法来截断大数值//常见的截断方法：RoundingMode.HALF_UP 四舍五入、RoundingMode.DOWN 直接截断public BigDecimal stripTrailingZeros()//去除末尾多余的 0 ，例如3.1400 -&gt; 3.14\n\n除此之外还有加减乘除方法，其中除法要注意,有可能出现除不尽的状况，要注意添加截断方法\nBigDecimal d1 = new BigDecimal(&quot;123.456&quot;);BigDecimal d2 = new BigDecimal(&quot;23.456789&quot;);BigDecimal d3 = d1.divide(d2, 10, RoundingMode.HALF_UP); // 保留10位小数并四舍五入BigDecimal d4 = d1.divide(d2); // 报错：ArithmeticException，因为除不尽\nBigDecimal可以做除法同时求余数divideAndRemainder()\nBigDecimal n = new BigDecimal(&quot;12.345&quot;);BigDecimal m = new BigDecimal(&quot;0.12&quot;);BigDecimal[] dr = n.divideAndRemainder(m);/*    数组的共两个：第一个是商第二个是余数*/System.out.println(dr[0]); // 102System.out.println(dr[1]); // 0.105\n\n比较equals()/* equals方法比较时，会比较scale()的值所以 3.14和3.1400使用equals方法比较时，大小是不同的*/compareTo()//这个方法根据两个值的大小返回正数负数0，表示大于小于和等于\n所以比较两个BigDecimal的时候，使用compareTo比较\n\n廖雪峰官方网站官方API\n\n","categories":["Java核心类","大数值"],"tags":["Java核心类","大数值"]},{"title":"MySQL-1","url":"/2019/08/26/MySQL/MySQL-1/","content":"\n引言：\n\n终于步入了正式的Web后端开发\n数据库\nMySQL的安装与基本配置\nSQL\n\n\n\n\n\n数据库(DataBase)什么是数据库？用于存储和管理数据的仓库\n数据库的特点\n持久化存储数据：其实数据库就是一个文件系统\n方便的管理数据：\n使用了统一的方式来操作数据库\n\n常见的数据库软件\nMySQL：开源免费的数据库，Oracle收购\nOracle：收费的大型数据库，Oracle公司的产品\nDB2：IBM公司的数据库产品，收费的，常用在银行系统\nSQLServer：微软公司的中型数据库\nDB2：IBM公司\n\nMySQL安装安装指南\n但我依然配置了图形界面，并且在环境变量里的系统变量配置了MySQL的实际bin路径\n卸载假如没有安装成功，那么需要先卸载再重新安装\n\n 卸载MySQL\n 删除C:\\ProgramData\\MySQL此文件\n\n配置\nMySQL服务启动\ncmd中输入Services.msc，打开图形界面启动关闭MySQL服务\n以管理员运行cmd，输入net stop mysql80来停止，net start mysql80来运行\n\n\n\n登录与退出本地MySQL的登录\n登录mysql -uroot -p\n\n-u后是用户名，用户名都是root\n-p后是密码，可以此处直接输入也可以下一步再输入\n\n退出exit//quit也可以\n\n连接他人的MySQLmysql -h127.0.0.1 -uroot -p//mysql --host=127.0.0.1 --user=root --password也可以\n-h后面填IP地址\n-p后是目标的密码\nMySQL的目录结构安装目录\nbin：二进制可执行文件\ninclude：c语言头信息\nlib：所需库文件\nshare：错误信息\n\n数据目录\n数据库：文件夹\n表：文件\n数据：文件的内容\n\nSQL什么是SQL？Structured Query Language：结构化查询语言\n定义了操作所有关系型数据库的通用规则\n每一种数据库操作的方式存在不一样的地方，称为方言\nSQL通用语法\nSQL语句以分号结尾，可以单行或者多行书写\nMySQL数据库的SQL语句不区分大小写，但是建议使用大写\n注释\n单行注释：-- 注释内容MySQL独有#注释内容\n多行注释1：/注释/show databases; -- 你好//注意空格show databases; #你好//MySQL独有方法不需要空格\n\n\n\n分类按功能分为四类\n\nDDL(Data Definition Language)\n 数据定义语言，用来定义数据库对象：数据库、表、列等。\n 关键字create drop alter\n\nDML(Data Manipulation Language)\n 数据操作语言，用来对数据库中表的数据进行增删改\n 关键字insert delete update\n\nDQL(Data Query Language)\n 数据查询语言，用来查询数据库表的数据\n 关键字select where\n\nDCL(Data Control Language)(了解即可)\n 数据控制语言，用来定义数据库的访问权限和安全级别及创建用户\n 关键字GRANT REVOKE\nDDL：操作数据库、表\n\n操作数据库的CRUD\nCreate增\n\ncreate database 库名称;增加一个数据库\ncreate database if not exists 库名称;先判断是否存在改库再创建库\ncreate database 库名称 character set utf8;创建时指定字符集，MySQL8.0之后默认字符集是utf8mb4，是utf8的一个超集\n\n\nDelete删\n\ndrop database 库名称;删除一个数据库\n\n\nUpdate改\n\nalter database 库名称 character set utf8;更改数据库的字符集\n\n\nRetrieve查\n\nshow databases;查询所有的数据库\nshow create database 库名称;查询某一个数据库的创建语句，可以看到字符集\n\n\n使用数据库\n\nselect database();查询当前正在使用的数据库名称\nuse 库名称;使用某库\n\n\n\n操作表的CRUD\nCreate增\ncreate table 表名(列名1 数据类型1,列名2 数据类型2...列名n 数据类型n);创建一个表，注意最后一列不要加逗号\n常用数据类型：\nint：整数类型\ndouble：小数类型\n列表名 double(小数有几位,小数点后保留几位) \n\n\ndate：日期类型，yyyy-MM-dd\ndatetime:日期类型：yyyy-MM-dd HH:mm:ss\ntimestamp:时间戳类型，yyyy-MM-dd\n如果不给这个字段赋值或赋值为null，则默认使用当前系统时间来默认赋值\n\n\nvarchar：字符串类型\n列名 varchar(20)最大二十个字符\n\n\n\n\ncreate table 新表 like 旧表复制表\n\n\n\n\nDelete删\n\ndrop table 表名称;删除表名称\ndrop table if exists 表名;判断删除\n\n\nUpdata改\n\nalter table 表名 rename to 新的表名修改表名\nshow create table 表名;查看表的字符集\nalter table 表名 character set 字符集名称;修改表的字符集\nalter table 表名 add 列名 数据类型;添加列\nalter table 表名 change 旧表名 新表名 数据类型修改列名及类型\nalter table 表名 modify 列名 类型;只改类型\nalter table 表名 drop 列名删除列\n\n\nRetrieve查\n\nshow tables;查询当前库内所有的表\ndesc 表名称查询表结构\n\n\n\nNavicat使用命令行来处理数据是非常麻烦的，\n所以以后我们使用Navicat来对数据进行操作\nDML：增删改表中的数据\n添加数据：\n\ninsert into 表名(列名1，列名2，...，列名n) values(值1，值2，...，值n);\n注意要一一对应\n不定义列名会给所有值添加此值\n除数字外都得加引号\n\n\n\n\n删除数据：\n\ndelete from 表名 where 条件\n不加条件会删除所有\n如果要删除所有记录不要用此方法\n\n\ntruncate table stu;删除表再创建一个一模一样的空表\n\n\n修改数据\n\nupdate 表名 set 列名1=值1,列名2=值2,... where 条件\n不加条件会修改所有\n\n\n\n\n\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"StringJoiner","url":"/2020/02/24/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/StringJoiner/","content":"\n    引言：StringJoiner\n\n\n\nStringJoiner为了更更更进一步高效的拼接字符串，Java1.8出现了StringJoiner类\n\n现在有一个字符串数组，里面有几个人名，我们现在要实现你好：小明，小红，小王！这样的效果\nString[] str = &#123;&quot;小明&quot;,&quot;小红&quot;,&quot;小王&quot;&#125;;StringBuilder sb = new StringBuilder(&quot;你好：&quot;);//逐个加上符号for (String s : str) &#123;    sb.append(s+&quot;,&quot;);&#125;//删除最后一个多余的，sb.delete(sb.length()-1,sb.length());sb.append(&quot;!&quot;);System.out.println(sb);//你好：小明,小红,小王!\n感觉很繁琐，很琐碎，但是使用StringJoiner不一样了\nStringJoiner sj = new StringJoiner(&quot;,&quot;,&quot;你好：&quot;,&quot;!&quot;);String[] str = &#123;&quot;小明&quot;,&quot;小红&quot;,&quot;小王&quot;&#125;;for (String s:str) &#123;    sj.add(s);&#125;System.out.println(sj);//你好：小明,小红,小王!\n简单方便，已经处理好了，不需要处理细节\n构造方法一共有\nStringJoiner(CharSequence delimiter)//以分隔符构造一个实例StringJoiner(CharSequence delimiter, CharSequence prefix, CharSequence suffix)/*三个参数分别是：1. 分隔符2. 字首3. 字尾*/\n常用方法StringJoiner底层其实也是用StringBuilder类实现的\npublic StringJoiner setEmptyValue(CharSequence emptyValue)/*设置确定此StringJoiner的字符串表示形式并且尚未添加任何元素（即，当它为空时）时要使用的字符序列。为此，复制了emptyValue参数。请注意，一旦调用了add方法，即使添加的元素对应于空字符串，StringJoiner也不再被认为是空的。*/public StringJoiner add(CharSequence newElement)//添加一个字符串\nString.join()String还提供了一个静态方法join()，这个方法在内部使用了StringJoiner来拼接字符串，在不需要指定“开头”和“结尾”的时候，用String.join()更方便\nString[] str = &#123;&quot;小明&quot;,&quot;小红&quot;,&quot;小王&quot;&#125;;String s = String.join(&quot;,&quot;,str);System.out.println(s);//小明,小红,小王\n\n\n\n\n\n知识来源：廖雪峰博客及 官方api文档\n\n","categories":["Java核心类","StringJoiner"],"tags":["Java核心类","StringJoiner"]},{"title":"MySQL-2","url":"/2019/08/31/MySQL/MySQL-2/","content":"\n    引言：\n\n\nSQL的继续学习\nDQL\n四种约束\n\n\n\n\n\nSQLDQL基础查询查询表中的记录\nselect 字段列表 from 表名列表 where 条件列表 group by 分组字段 having 分组之后的条件order by 排序limit 分页\n\n\n多字段查询\n SELECT age , `name` FROM stu;\n 标准格式，还需要加上注释\n  SELECT age , -- 年龄`name`  -- 姓名 FROM stu;  -- 学生表\n\n去除重复（如果结果有多个NULL值，并不会合并为一个）\n SELECT DISTINCT sex FROM stu;# 加一个DISTINCT关键字即可# 没能去除可能是因为多了一个空格或者回车SELECT DISTINCT sex , &#x27;name&#x27; FROM stu;# 多表查询时只有被查询项都相同才会去重\n计算列\n SELECT sex,id + age FROM stu;# 如果有NULL数据就要使用IFNULL来吧NULL变为0\n\n起别名\n SELECT sex,id + age AS 总和 FROM stu;# 别名可以起名为中文，但是不推荐# AS 可以不写， 用空格来替代\n\n条件查询SQL的运算符：\n\n&gt; &lt; &lt;= &gt;= =  &lt;&gt;或!=(不等于)\n\nBETWEEN ... AND\n\nIN \n\nLIKE模糊查询\n\nIS NULL\n\nand 或 &amp;&amp; or 或 || not 或 |\n\n\n语法\nWHERE 条件\n示例\nSELECT * FROM stu WHERE age &gt;50; # 大于SELECT * FROM stu WHERE age &lt;&gt; 99; # 不等于SELECT * FROM stu WHERE age != 99; # 不等于SELECT * FROM stu WHERE age BETWEEN 10 AND 50; # 区间SELECT * FROM stu WHERE age = 18 OR age = 22 OR age = 20; # 或者SELECT * FROM stu WHERE age IN (18,22,20); # 简便的或者SELECT * FROM stu WHERE age  =  NULL; # NULL是不可以这样判断的SELECT * FROM stu WHERE age IS NULL; # 正确方法SELECT * FROM stu WHERE age IS NOT NULL; # 正确方法\n\n模糊查询LIKE关键字\n占位符\n%  多个任意字符_  单个任意字符\n示例\n# 查询姓马的人SELECT * FROM stu WHERE `name` LIKE &#x27;马%&#x27;;# 查询第二个字是化的人SELECT * FROM stu WHERE `name` LIKE &#x27;马%&#x27;;# 查询名字是三个的人SELECT * FROM stu WHERE `name` LIKE &#x27;___&#x27;;# 查询含有马字的人SELECT * FROM stu WHERE `name` LIKE &#x27;%马%&#x27;;\n\n排序查询语法\norder by 子句order by 排序字段1 排序方式1，排序字段2 排序方式二第二排序条件只有当第一排序条件一致时才会发挥作用\n默认为从小到大排序\n排序方式共两种\nASC //升序DESC //降序\n示例\nSELECT * FROM `stu` ORDER BY age ASC,qq asc\n\n聚合函数将一列数据作为一个整体，进行纵向的计算\n\ncount 计算个数\n一般选择非空的列，主键\nCOUNT(*)也可以，但不推荐\n\n\nmax 计算最大值\nmin 计算最小值\nsum 计算和\navg 计算平均值\n\n注意：排除NULL值\n示例\nSELECT COUNT(NAME) FROM stu;SELECT SUM(qq) FROM stu;SELECT COUNT(IFNULL(qq,0)) FROM stu;#如果qq是null，那就换成0\n\n分组查询语法：\ngroup by 分组字段\n注意：\n\n分组之后查询的字段必须是该分组字段或者聚合函数 SELECT sex,SUM(qq) FROM `stu` GROUP BY sexSELECT sex,MIN(qq) FROM `stu` WHERE qq &gt; 5000 GROUP BY sex# 可以在分组之前加条件SELECT sex,MIN(qq) FROM `stu` WHERE qq &gt; 5000 GROUP BY sex HAVING sex = &#x27;男&#x27;;# 分组之后还可以继续添加条件\nHAVING和WHERE语句的区别\nWHERE作用在分组前，WHERE后不可以跟聚合函数\nHAVING作用在分组之后,HAVING可以使用聚合函数\n\n\n\n分页查询语法：\nlimit 开始的索引,每页查询的条数;\n分页操作在Oracle,MySQL内是不一样的\n示例代码\nSELECT * FROM stu LIMIT 0,2; -- 第一页SELECT * FROM stu LIMIT 1,2 ;-- 第二页# 公式：开始的索引 = （当前页码 -1）* 每页的条数\n\n约束对表中的数据进行限定，保证数据的正确性，有效性和完整性\n分类：\n1. 主键约束 primary key2. 非空约束 not null3. 唯一约束 unique4. 外键约束 foreign key\n\n非空约束值不能为空\nnot null语法：\n\n创建表时添加约束\nCREATE TABLE student(\tid INT,\tNAME VARCHAR(20) NOT NULL)# 此后添加数据NAME则为必填项\n普通添加约束\nALTER TABLE student MODIFY NAME VARCHAR(20) NOT NULL;# 覆盖掉原有\n删除非空约束\nALTER TABLE student MODIFY NAME VARCHAR(20);# 覆盖掉原有的not null\n\n唯一约束值不能重复\nunique语法\n\n创建表时添加约束\nCREATE TABLE stu(\tid INT,\tnumber VARCHAR(20) UNIQUE; # 添加唯一约束)# 此后number是不可以重复的值# 唯一约束的限定值可以有多个null\n普通添加约束\nALTER TABLE stu MODIFY number VARCHAR(20) UNIQUE;\n删除约束\nALTER TABLE stu DROP INDEX number;\n\n主键约束注意：\n\n非空且唯一\n一张表只能有一个字段为主键\n主键就是表中记录的唯一标识\n\n语法：\n\n创建表时添加约束\nCREATE TABLE student (\tid INT PRIMARY KEY,\tNAME VARCHAR(20))\n普通添加约束\nALTER TABLE stu MODIFY id INT PRIMARY KEY;\n删除主键\nALTER TABLE stu DROP PRIMARY KEY\n主键约束的自动增长\n\n\n如果某一列是数值类型的，使用关键字auto_increment可以完成值的自动增长\nCREATE TABLE x (\tid INT PRIMARY KEY AUTO_INCREMENT,\tNAME VARCHAR(20))\n\n删除自动增长ALTER TABLE stu MODIFY id INT;\n添加自动增长ALTER TABLE stu MODIFY id INT AUTO_INCREMENT;\n\n外键约束保证表中数据的一些逻辑完整性，让表与表产生一些关系\n外键值可以为null，但是不可以为不存在的值\n\n创建表时添加外键\nCREATE TABLE 表名(    ...    外键列    CONSTRAINT 外键名称 FOREIGN KEY 外键列名称 REFERENCES 主表名称(主列表名称));\n普通添加外键\nALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGIN KEY (外键字段) REFERENCES 主表名称(主表列名称)\n删除外键\nALTER TABLE 表名 DROP FOREIGIN KEY 外键名\n代码示例\n# 创建部门表CREATE TABLE department (\tid INT PRIMARY KEY AUTO_INCREMENT,\tdep_name VARCHAR(20),\tdep_locationion VARCHAR(20));# 导入数据INSERT INTO department(id,dep_name,dep_locationion) VALUES(NULL,&#x27;销售部&#x27;,&#x27;深圳&#x27;);INSERT INTO department(id,dep_name,dep_locationion) VALUES(NULL,&#x27;研发部&#x27;,&#x27;广州&#x27;);# 创建员工表并创建外键CREATE TABLE emp (\tid INT PRIMARY KEY AUTO_INCREMENT,\tNAME VARCHAR(30),\tage INT,\tdep_id INT,\tCONSTRAINT emp_dept_fk FOREIGN KEY (dep_id) REFERENCES department(id));# 导入数据INSERT INTO emp(NAME,age,dep_id) VALUES(&#x27;张三&#x27;,20,1);INSERT INTO emp(NAME,age,dep_id) VALUES(&#x27;李四&#x27;,20,2);INSERT INTO emp(NAME,age,dep_id) VALUES(&#x27;王五&#x27;,20,3);\n级联操作\n\n\n\n添加级联\n# 创建表之后ALTER TABLE 表名 ADD CONSTRAINT 外键名称FOREIGIN KEY (外键字段名) REFERENCES 主表名称 ON UPDATE CASCADE ON DELETE CASCADE# 最后三个单词根据操作来更改\n分类\n\n级联更新 : ON UPDATE CASCADE\n级联删除 : ON DELETE CASCADE\n\n\n好处：方便\n\n缺点：会把有联系的数据全部删除，十分危险\n\n\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"MySQL-3","url":"/2019/08/31/MySQL/MySQL-3/","content":"\n引言：\n\nMySQL的设计\n多表操作\n三大范式\n\n\n\n\n\n数据库的设计数据库的设计就是在设计表，一个好的数据库设计可以大大简化代码的完成\n多表之间的关系\n一对一：一个人和一个身份证\n一对多：员工和部门\n多对多：学生和课程\n\n一对一例如：人和身份证\n可以在任意的一方添加外键指向另一方的主键，且得让外键唯一\n一般情况下一对一可以合成为一张表\ngraph LR人--&gt;身份证\n或者\ngraph LR身份证--&gt;人\n\n一对多例如：员工和部门\n员工（多）添加一列外键指向部门（一）的主键\n实现方式：\n多的一方的外键指向少的一方的主键\ngraph LR员工A--&gt;部门A员工B--&gt;部门A员工C--&gt;部门A员工D--&gt;部门A\n\n多对多例如：学生和课程\n中间表：最少得有两个字段\n\n学生的主键\n课程的主键\n\n多对多要借助一个中间表\ngraph LR学生A--&gt;中间表数学--&gt;中间表中间表--&gt;学生A中间表--&gt;数学\n\n\n数据库设计的范式范式：设计数据库时，需要遵循的一些规范\n百度百科：\n设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，\n这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小\n要遵循更高层的范式必须遵循低层的全部范式\n目前关系数据库有六种范式：\n第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）\n第一范式数据库表的每一列都是不可分割的原子数据项\n缺点：\n\n数据冗余严重\n数据添加存在问题，添加新内容时不合法\n数据删除也存在问题\n\n第二范式在1NF的基础上，非码属性必须完全依赖于码（在1NF基础上消除非主属性对主码的部分函数依赖）\n解决了数据冗余的问题\n基本概念\n函数依赖\n  A–&gt;B，通过A属性的值，可以确定唯一B属性的值，则称B依赖于A（A是B的充分条件）\n  例如：学号–&gt;姓名，（学号，课程名）–&gt;分数\n\n完全函数依赖\n  A–&gt;B，A是B的唯一充分条件\n\n部分函数依赖\n\n传递函数依赖\n  A–&gt;B,B–&gt;A，通过A可以确定唯一的C\n\n码\n  如果一张表中一个属性或属性组，被其他所有属性完全依赖，则称这个属性为这个表的码\n\n\n第三范式在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）\n解决了所有的问题\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"MySQL事务","url":"/2019/08/31/MySQL/Mysql%E4%BA%8B%E5%8A%A1/","content":"\n引言：\n更新：将本篇改为纯介绍事务的一篇blog，将其他内容移出\n\n\n\n\n\nMysql事务\n概念：如果一个包含多个步骤的业务操作，被事务管理，那么这些操作要么同时成功，要么同时失败\n\n操作：\n\n开启事务： start transaction;\n回滚：ROLLBACK\n提交：COMMIT\n\n\n\n例如：王给张转500元钱\n\n判断王有没有500\n王-500\n张+500\n转账完成，中间出现差错会从头回滚START TRANSACTION;# 开启事务# 王给张转500# 判断是否大于五百元# 王账户减去五百UPDATE deliver SET bank = bank -500 WHERE `NAME` = &#x27;王&#x27; &amp;&amp; bank&gt;500;# 张账户加五百#这里出错UPDATE deliver SET bank = bank  +500 WHERE `NAME` = &#x27;张&#x27;;#这里出错 ROLLBACK; 出错就添加ROllBACK 回到开启事务的地方COMMIT;# 成功就会完成这项事务\nMySQL数据库中事务默认自动提交（Oracle默认是手动提交的）\n手动打开事务才是自动提交\n修改事务的默认提交方式 # 查看默认提交方式SELECT @@autocommit# 1代表自动提交，0代表手动提交SET @@autocommit = 0;# 更改为手动提交，只有COMMIT才会\n\n事务ACID原则\n原子性A：同时成功，要么同时失败\n一致性C：在事务开始之前和事务结束以后，数据库的完整性没有被破坏\n隔离性I：多个事务之间，相互独立\n持久性D：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失\n\n隐式提交mysql中事务提交后，才会改变数据的值，但是如果在事务执行时执行了如下的操作，mysql就会隐式的替我们提交：\n\n执行了DDL语句（create、drop、alter）\n开启了一个新的事务\n使用了锁\n使用了加载语句操作\n\n事务引发的问题多个事务操作同一批数据，存在问题：\n脏读：一个事务读取到另一个事务中没有提交的数据\n比如A、B、C三个人，A有500元，B有100、C有1000\nA向B转100元——正常流程：A = 500B = 100A = A - 100 = 400B = B + 100 = 200但C同时也向B转100元，导致这种情况发生C = 1000B = 100 （B现在已经是200元，但是事务还未提交，所以读到了100）B = 100 + 100 = 200 （此时Commit后，B仍是200，少了100元）\n\n不可重复读：在同一个事务中两次读取到的数据不一样（不一定是错误，但是某些场合不对）\n比如总支出计算，第一次读出开支100元，准备生成报表，结果读出为200元（在那一瞬间别的事务又花了100）\n幻读：一个事务(同一个read view)在前后两次查询同一范围的时候，后一次查询看到了前一次查询没有看到的行（一般指数据行记录变多了或者少了）\n比如给员工都涨薪，update set salary= salary + 100，但是此时又来一个新人，最后发现，命名给所有人涨薪100的操作，缺疏忽了一个人\n事务的隔离级别多个事务之间是隔离的，相互独立的。\n但是如果多个事务操作同一批数据，则会引发一些问题，设置不同的隔离级别就可以解决这些问题\n隔离级别：\n\nread uncommited读未提交：所有事务都可以看到没有提交事务的数据\n 产生的问题：脏读、不可重复度、幻读\n\nread commited读已提交(Oracle默认)：事务成功提交后才可以被查询到\n 产生的问题：不可重复度、幻读\n\nrepeatable read可重复读(MySQL默认)：同一个事务内多次查询却返回了不同的数据值\n 产生的问题：幻读\n\nserializable串行化：写加写锁，读加读锁可以解决所有的问题\n\n\n注意：隔离级别从小到大安全性越来越大，但是效率越来越低\n查询隔离级别\nselect @@tx_isolation # 老版MySQLSELECT @@transaction_isolation # 新版MySQL\n设置隔离级别\nset global transaction isolation level 级别字符串;# 老版set session transaction isolation level 级别字符串;\n\n区别脏读与不可重复读的区别：\n\n脏读：读了另一事务未提交的数据\n不可重复读：读了另一事务提交的数据\n\n","categories":["MySQL"],"tags":["MySQL","事务"]},{"title":"MySQL-4","url":"/2019/08/31/MySQL/MySQL-4/","content":"\n引言: 多表查询\n\n\n\n\n\n\n\n多表查询查询语法\nSELECT    列表名称    FROM    表单名称WHERE    条件\n\n示例：\nSELECT * FROM emp,department;# 会从两个表中组合所有情况显示为一张表（笛卡尔积）# 例如A表有两种情况，B表有三种情况，结果就有2*3六种情况\n这并不是我们想要的情况，我们需要淘汰那些有毛病的数据\n多表查询的分类内连接查询- 隐式内连接：使用`WHERE`来消除无用的数据- 显式内连接：`SELECT 字段列表 FROM 表名1 INNER JOIN 表名2 ON 条件`\n\n隐式\nSELECT\tt1.NAME, # 员工姓名\tt1.age, # 员工年龄 \tt2.dep_name # 部门名称FROM\temp t1,\tdepartment t2WHERE\tt1.dep_id = t2.id\n显示\nSELECT * FROM emp JOIN department ON emp.dep_id = department.id# INNER 可以省略\n\n外连接查询\n左外连接：左表所有数据及其交集\n右外连接：右表所有数据及其连接\n\n语法\nSELECT 字段列表 FROM 表1 LEFT OUTER JOIN 表2 ON 条件# OUTER可以省略\n示例代码\nSELECT t1.*,t2.dep_name FROM emp t1 LEFT JOIN department t2 ON t1.dep_id=t2.id# LEFT和RIGHT可以选择# 可以主要显示一个表，副显示另一个表，不管另一个表的对应值是否存在\n\n\n子查询查询中嵌套查询\nSELECT MAX(salary) FROM emp;# 从员工表中查询最高工资,假设为9000SELECT * FROM emp WHERE emp.salary = 9000;# 查询工资为9000的人\n一条查询即可完成\nSELECT * FROM emp WHERE emp.salary = (SELECT MAX(salary) FROM emp);\n\n子查询的不同情况\n子查询结果是单行单列的\n子查询可以作为条件，可以使用运算符计算&gt; &lt; &lt;= &gt;= =\n\n\n子查询的结果是多行单列的\n子查询可以作为条件，可以使用运算符计算IN\n\n\n子查询的结果是多行多列的\n放入FROM中\n\n\n\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"Mysql实战","url":"/2021/09/05/MySQL/Mysql%E5%AE%9E%E6%88%98/","content":"\n引言：Mysql实战；实操环节~\n\n\n\nMysql实战Mysql中数据类型括号中数字表示的含义字节与字符字节与字符是什么就不说了，这里主要说一下Mysql中的字符与字节\n\nUTF-8编码：一个英文字符等于一个字节，一个中文（含繁体）字符等于三个字节\n\nUnicode编码：一个英文等于两个字节，一个中文（含繁体）字符等于两个字节\n符号：英文标点占一个字节，中文标点占两个字节\n举例：英文句号.占1个字节的大小，中文句号。占2个字节的大小。\n\nUTF-16编码：一个英文字母字符或一个汉字字符存储都需要2个字节（Unicode扩展区的一些汉字存储需要4个字节）\n\nUTF-32编码：世界上任何字符的存储都需要4个字节。\n\n\n\nutf-8与utf-8mb4的区别\n\n如果要存互联网emoji表情，例如昵称，聊天，就需要utf8mb4，而不是utf-8\nMySQL数据库的 “utf8”并不是真正概念里的 UTF-8。\nMySQL中的“utf8”编码只支持最大3字节每字符。\n真正的大家正在使用的UTF-8编码是应该能支持4字节每个字符。\nMySQL中的 “utf8mb4” 才是 真正意义上的“UTF-8”。\nchar与varchar\nchar(8)与varchar(8)表示什么意思？\n\n\nchar的长度可选范围在0-255字符之间（注意单位是字符）\n\nvarchar的长度是可变的，mysql5.0.3之后varchar的长度范围为0-65535个字节（注意这里是字节）\n\n\n所以：\n\nchar(8)就表示char的长度为8，可存储8个字符，如果你存储的少于8个字符，它会自动在右方填充空格补齐\nvarchar(8)可变大小，最大为8；它的长度为其实际长度+1，多出来的1是因为varchar需要存储长度这个信息\n\nvarchar(m)里面表示的是长度，例如：varchar（5）表示最大可存储5个中文或5个英文字母。 \nint系列\n\n\n类型\n大小\n范围（有符号）\n范围（无符号）\n用途\n\n\n\nTINYINT\n1B\n（-128，127）\n（0，255）\n小整数值\n\n\nSMALLINT\n2B\n（-32 768,32 767）\n（0，65535）\n大整数值\n\n\nMEDIUMINT\n3B\n（-8 388 608，8 388 607）\n(0，16 777 215)\n大整数值\n\n\nINT\n4B\n(-2 147 483 648，2 147 483 647) (0，4 294 967 295)\n(0，4 294 967 295)\n大整数值\n\n\nBIGINT\n8B\n(-9 233 372 036 854 775 808，9 223 372 036 854 775 807)\n(0，18 446 744 073 709 551 615)\n极大整数值\n\n\nint系列的大小，是固定的，那么int(8)代表什么呢？\n8代表显示的长度，如果你开启了零填充，存储了一个1，那么此时你查到的数据为0000 0001\n默认创建的数据库（这是使用Navicat生成的数据库，转储后的sql内容）\nDROP TABLE IF EXISTS `player`;CREATE TABLE `player`  (  `player_id` int(11) NOT NULL AUTO_INCREMENT, # AUTO_INCREMENT自增  `team_id` int(11) NOT NULL,  `player_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,  `height` float(3, 2) NULL DEFAULT NULL,  PRIMARY KEY (`player_id`) USING BTREE,  UNIQUE INDEX `player_name`(`player_id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;# 默认使用Innodb存储引擎# 默认编码为utf8# 默认排序方式为utf8_general_ci，这是一个大小写不敏感的排序方式# utf8_bin这个排序方式对大小写敏感# 默认行格式为Dynamic\n\nID字段【待补充】","categories":["MySQL"],"tags":["MySQL"]},{"title":"粘包半包与Netty的解决方案","url":"/2022/07/25/Netty/%E7%B2%98%E5%8C%85%E5%8D%8A%E5%8C%85%E4%B8%8ENetty%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","content":"\n引言：粘包半包与Netty的解决方案\n\n\n\n粘包半包与Netty的解决方案粘包半包问题之前在NIO那一节，介绍过关于粘包半包问题，此处来更加详细的介绍一下。\nTCP粘包与半包假设客户端发送data1、data2两个数据包给服务器。\n\n粘包：指服务器一次性接收到了data1、data2两个数据包\n\n半包（拆包）：指服务端两次接收到了两个包，并且第一次接收到了data1与半个data2，第二次接收到另一半data2\n\n\n出现的原因TCP协议是一个流式协议，所谓流式协议，就是没有具体界限的数据，（作为对比UDP协议则是一个数据包一个数据包的发送数据）\n\n因此有可能出现粘包半包问题，具体出现的原因有以下三种情况：\n\n应用程序write写入的字节大小大于套接口发送缓冲区大小\n\n数据发送的流程大致为：\n​        用户发送数据包A-&gt;调用write系统调用-&gt;用户态转到内核态-&gt;数据从用户内存复制到内核的缓冲区-&gt;缓冲区满-&gt;数据从缓冲区发送到网卡-&gt;经过物理链路发送\n注意这个过程中，如果发送的一个数据ABC，缓冲区只能容下AB，那么此时就会拆为两个包\n\nMSS大小的TCP分段\n\n这里需要回忆一下TCP的网络知识，TCP协议规定了MSS\n\nMSS 最大报文段长度：仅包括数据部分，不包括头部\n在Internet标准下：IP协议MTU为576，那么TCP的MSS为536 byte (576 - 20ip的报头 - 20TCP的报头)\n如果使用以太网的话：IP协议MTU为1500，那么TCP的MSS为1460（同样减去两个协议的报头）\n注意：不同协议的MSS值不同，由具体的协议确定\n\n如果要发送1500字节的数据，那么TCP协议会拆为两个包：一个1460字节（数据部分，不包含头）、一个40字节（注意：根据Naggle算法，这40字节很可能会跟着另外一个包发送，并不会单独发送）\n\n额外需要注意的是：\nMSS的大小，是在三次握手中确定的，MSS的值会在SYN报文中发送，由握手双方确定\n（在第二次握手后就可以确定TCP中最大传输报文（MSS）大小）\n\n\n这里稍微岔开一点，介绍一下IP切片与TCP切片：\n以太网帧的payload大于MTU进行IP分片（UDP协议才会IP分片）\n如果数据链路层使用以太网的话（好像也没有使用其他的），那么数据如果超过这个大小也是会分片的。\n\n提问1：TCP不是都分了段了吗？怎么还有IP分片？\n答：这里指UDP协议！！UDP是没有MSS的！！\n提问2：那意思是，UDP也会粘包？\n答：不会的！！UDP虽然包有可能在IP层被拆了，但是，对端在接收到之后根据ip报文中的identification、flags、offset实现报文的重组，丢了怎么办？丢了就丢了，反正我叫UDP！\n注意：如果TCP分了段，那么以太网帧就不会分片了！\n\n\nNaggle算法：会把小的数据包掺加到一起发送\n\n解决措施\n固定消息长度：消息规定一个固定长度，剩余空间补空格\n优点：简单，方便\n缺点：占用带宽\n\n\n格式化数据：利用特殊字符隔断数据，例如在FTP协议中，使用回车换行符分隔\nTLV 格式：即 Type 类型、Length 长度、Value 数据，在类型和长度已知的情况下就可以方便的知道消息大小，分配合适的 buffer\n缺点：buffer需要提前分配，如果分配过大，影响 server 的吞吐量\nHTTP1.1 是 TLV 格式（先传输类型）\nHTTP2.0 是 LTV 格式（先传输长度）\n\n\n关闭Naggle算法：设置 TCP_NODELAY 就能关闭 Nagle 算法（严格意义上也算一种办法）\n\nNetty的解法\n固定长度解码器：Netty 提供了 FixedLengthFrameDecoder，它允许你指定固定长度的消息，这样在解码时就可以按照固定长度来切分数据帧，从而避免粘包和半包问题。这种方法适用于消息长度固定的场景。\n行分隔符解码器：Netty 提供了 LineBasedFrameDecoder，它根据换行符（例如 \\n 或 \\r\\n）将数据分割成不同的消息。这对于文本协议非常有用，因为通常文本消息以换行符分隔。\n分隔符解码器：Netty 提供了 DelimiterBasedFrameDecoder，它允许你指定一个自定义的分隔符，将数据按照分隔符来分割消息。这种方法适用于自定义协议中需要特定分隔符的情况。\n长度字段解码器：Netty 提供了 LengthFieldBasedFrameDecoder，它通过读取消息中的长度字段来分割消息。这种方法适用于自定义协议中包含长度字段的情况。\n自定义协议解码器：你可以根据自己的协议特点来编写自定义解码器，以确保消息能够被正确切分和解析。通过继承 ByteToMessageDecoder 类，你可以自定义解码逻辑，根据消息头部信息来切分消息。\nIdleStateHandler：虽然不直接解决粘包和半包问题，但 IdleStateHandler 可以帮助你检测连接的空闲状态，从而可以根据需要采取措施，例如关闭连接或发送心跳包。\n\n","categories":["Java","Netty"],"tags":["Java","Netty"]},{"title":"Python函数","url":"/2021/05/02/Python/Python%E5%87%BD%E6%95%B0/","content":"\n引言：\n\nPython函数\n\n\n\n\nPython函数Python函数函数基础# 1. 函数的定义&#x27;&#x27;&#x27;语法：def name(args):    body    return ret&#x27;&#x27;&#x27;def sayHi():    print(&#x27;hello!&#x27;)# 2. 函数调用：使用函数名加括号即可sayHi()print(sayHi) # &lt;function sayHi at 0x00000277B1E961F0&gt;\n\n参数传递后是否可以被可变在 python 中，strings,tuples, 和 numbers是不可更改的对象，而 list,dict 等则是可以修改的对象。\n\n不可变类型：变量赋值 a=5 后再赋值 a=10，这里实际是新生成一个 int 值对象 10，再让 a 指向它，而 5 被丢弃，不是改变a的值，相当于新生成了a。\n可变类型：变量赋值 la=[1,2,3,4] 后再赋值 la[2]=5 则是将 列表la 的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了\n\n由此，python的参数传递：\n对于不可变类型，传递值（类似值传递）：改变值不会影响原有的参数\n对于可变类型，传递引用（类似引用传递）：改变值，原有的值也会改变\n# 3. 参数传递# 3.1 不可变类型def changeType1(a):    a = &#x27;你好&#x27;    print(a)  # 打印 你好x = 1changeType1(x)print(x)  # 打印 1，可见x的值没有改变# 3.2 可变类型def changeType2(a):    for i in range(len(a)):        a[i] = 1arr = [1, 2, 3, 4]changeType2(arr)print(arr)  # 打印出：[1, 1, 1, 1]# 注意！！这种迭代将不会改变原有的值def changeType3(a):    for i in a:        i = 1arr = [1, 2, 3, 4]changeType3(arr)print(arr)  # 依然是：[1, 2, 3, 4]\n\n参数类型分为四类：\n\n必备参数：须以正确的顺序传入函数。调用时的数量必须和声明时的一样。\n关键字参数：函数调用可以使用关键字参数来确定传入的参数值\n默认参数：默认参数的值如果没有传入，则被认为是默认值\n不定长参数：\n\n下面我们依次给出例子：\n# 4. 参数类型# 4.1 必备参数def sum(a, b):    return a + b# print(sum()) 报错# print(sum(1)) 报错print(sum(1, 3))  # 成功 返回4# 4.2 关键字参数def devide(a, b):    return a / bprint(devide(1, 2))  # 0.5 默认按顺序print(devide(b=1, a=2))  # 2.0 可以使用关键字指定参数输入# 4.3 默认参数def multiply(a=10, b=5):    return a * bprint(multiply())  # 50 没有输入参数，全部默认print(multiply(1))  # 5 输入一个参数，另一个默认print(multiply(1, 9))  # 9 输入参数# 4.4 不定长参数def sumplus(*a): # 可变参数的标志，加一个*符号    res = 0    # 把可变参数当做列表使用即可    for i in a:        res += i    return resprint(sumplus()) # 0print(sumplus(1,2,3,4,5,6,7,8,9)) # 45\n\n匿名函数python中的匿名函数要点：\n\n只能包含一个表达式\n内部不能访问参数列表外的或是全局变量\n\npython中的lambda表达式更多用在很多方法里面，例如sort方法：\n# 5. 匿名函数（lambda函数）&#x27;&#x27;&#x27;语法：lambda [arg1 [,arg2,.....argn]]:expression&#x27;&#x27;&#x27;sumLambda = lambda a=1, b=2: a + bprint(sumLambda(1, 2))  # 3print(sumLambda())  # 3print(sumLambda) # &lt;function &lt;lambda&gt; at 0x000001D8D3630EE0&gt;\n\n全局变量与局部变量# 6. 全局变量和局部变量# 6.1 基本使用num = 10 # 这就是一个全局变量def var1():    print(num)var1() # 打印出 10def var2():    num = 1    print(num)# 因为局部变量存在，所以自动屏蔽全局变量var2() # 打印出 1# 6.2 global变量的使用# 函数内部定义的变量只在函数体内有效def var3():    cat = &quot;小黄猫&quot;#print(cat)  报错：NameError: name &#x27;cat&#x27; is not defined# 但是可以使用关键字global来声明变量def var4():    # global cat=&quot;小黄猫&quot; 注意声明和赋值必须分开，这样使用不正确    global cat    cat = &quot;小黄猫&quot;var4() # 注意要先调用这个函数，才会产生那个全局变量print(cat) # 打印出 小黄猫# 局部变量和全局变量混合使用dog = &quot;史努比&quot;def var5():    # print(dog) SyntaxError: name &#x27;dog&#x27; is used prior to global declaration    # 在全局变量声明前，不能使用这个变量    global dog    dog = &quot;史迪奇&quot;    print(dog) # 史迪奇var5()print(dog) # 史迪奇 ，可以看到 dog全局变量已经被改变# del dog 可以删除全局变量\n\n要点总结python函数的使用比较简单，但是要注意几个地方：\n\n函数名+括号()，代表调用这个函数，只使用函数名仅仅只代表一个地址\npython参数不需要指定类型\nreturn设置返回值，不写默认返回None\n传参时按默认顺序，可以使用关键字改变参数顺序\n可变参数使用符号*，使用时使用for i in var使用即可\n全局变量使用global声明、del删除\n\n","categories":["Python"],"tags":["Python"]},{"title":"Python序列","url":"/2021/05/01/Python/Python%E5%BA%8F%E5%88%97/","content":"\n引言：\n\nPython中的序列：列表、元组、字符串\n\n\n\n\nPython序列python序列序列：分为两种\n\n有序序列：列表、元组、字符串、（range、zip、map、enumerate等）\n无序序列：集合、字典\n\n也可以这么分：\n\n可变序列：列表、集合、字典\n不可变序列：元组、字符串、（range、zip、map、enumerate等）\n\n通常称序列就是有序序列，这里我们只讨论有序序列\n\n序列：Python中最基本的数据结构\n序列中的每个元素都分配一个数字 ——它的位置，或索引，第一个索引是0，第二个索引是1，依此类推\n\n六个内置序列python有六个内置序列\n\n列表\n元组\n字符串\nUnicode字符串（简单归在字符串中讨论）\nbuffer对象（不讨论）\nxrange对象（不讨论）\n\n列表列表是最常用的Python数据类型，它可以作为一个方括号内的逗号分隔值出现。\n要点：\n\n列表存储的内容不需要具有相同的数据类型\n列表支持切片操作（切片有基本的操作和较高阶的操作）\n区别列表的添加方法append、extend、insert\n列表的删除，注意区别remove和pop的区别\n列表的脚本操作\n\n列表存储的内容不需要具有相同的数据类型# 1. 列表的存储的数据不需要相同的数据类型arr = [1, 2, 3, 4, &quot;字符串&quot;, [&quot;另一个列表&quot;]]\n\n列表支持切片操作序列此处的切片方法类似，其他的序列将不再详细叙述切片操作\n# 2. 通过切片方式访问列表&#x27;&#x27;&#x27; 切片操作list[a:b:c]可以传入一个、两个、或三个参数一个参数：直接显示对应index的元素。        注意：正数从0开始，从左向右；负数从-1开始，从右向左两个参数：按两个参数对应的index截取出一个list。        注意：切片为左闭右开区间，即[a,b)，index为b的元素是不在其中的三个参数：第三个参数代表步进，默认为1，如果为负数，代表从右向左&#x27;&#x27;&#x27;arr = [1, 2, 3, 4, &quot;字符串&quot;, [&quot;另一个列表&quot;]]# 2.1 切片基本操作print(arr[:])  # 都不传表示整个列表print(arr[::-1])  # 逆向打印整个列表print(arr[3])  # 显示第四个元素，即4print(arr[-3])  # 显示倒数第三个元素，即4print(arr[1:4])  # 打印出[1,4)的内容，即[2, 3, 4]print(arr[1:4:2])  # 隔一个打印一个，打印出[2, 4]# 2.2 高阶操作print(arr[:4])  # 第一个参数省略，默认为0print(arr[1:])  # 第二个参数省略，默认为列表的长度print(arr[::2])  # 获取下标1,3,5...print(arr[1::2])  # 获取下标2,4,6...print(arr[1:3:-2])  # 打印出[]print(arr[3:1:-2])  # 打印出[4]&#x27;&#x27;&#x27;以上两个为什么是这样呢？我们可以这样理解：1. arr[1:3:-2]     其中1,3代表获得[1,3)的数据，是从左向右的，但是-2又是从右向左，方向不一致，因此打印的结果为空列表2. arr[3:1:-2]    其中3:1 从右向左获得[3,1)的数据，-2也是从右向左，方向一致，所以不为空&#x27;&#x27;&#x27;print(arr[3:1])  # 打印出[]，因为第三个参数默认为1print(arr[1:100])  # 第二个参数可以超过列表的长度print(arr[100:4:-1])  # 打印出[[&#x27;另一个列表&#x27;]]\n\n区别列表的添加方法append、extend、insert# 3. 列表的添加，区别 append、extend、insert# 3.1 append函数arr.append(&quot;添加&quot;)  # append添加一个元素print(arr)  # 打印出[1, 2, 3, 4, &#x27;字符串&#x27;, [&#x27;另一个列表&#x27;], &#x27;添加&#x27;]res = arr.append(&quot;会有返回值吗？&quot;)print(res)  # 打印出None，append方法没有返回值，只会修改原有的列表newArr = [985, 211]arr.append(newArr)  # 可以添加新的列表，注意：是把这个列表当做一个元素，添加到原有的列表中print(arr)# 打印如下：[1, 2, 3, 4, &#x27;字符串&#x27;, [&#x27;另一个列表&#x27;], &#x27;添加&#x27;, &#x27;会有返回值吗？&#x27;, [985, 211]]# 3.2 extendnewArr = [985, 211]print(len(arr))  # 9res = arr.extend(newArr)print(len(arr))  # 11，注意extend是将两个列表合并print(res)  # 也是None 没有返回值# 也可以用+来替代extendarr = arr + newArr# 注意：其实，+是返回的一个新的列表，不是原地操作。+=才与extend相同，均为原地操作，高效print(len(arr))  # 13# 3.3 insertnewArr = [985, 211]res = newArr.insert(0, &quot;双一流&quot;)print(newArr)  # 插入到第0个位置之前 [&#x27;双一流&#x27;, 985, 211]# 注意我这里的说法，插入到第0个元素之前，之前！！print(res)  # 也没有返回值newArr.insert(-1, &quot;C9&quot;)print(newArr)  # [&#x27;双一流&#x27;, 985, &#x27;C9&#x27;, 211]# 如果你记住了我说的插入到第x个元素之前，这里就好理解了\n\n总结一下三种添加操作的区别：\n\n\n\n函数\nappend\nextend\ninsert\n\n\n\n参数\n一个：要加入的元素\n一个：参数必须可迭代（例如列表、元组、字符串）\n两个：一个index，一个元素的值\n\n\n添加数组\n作为一个元素添加\n合并两个数组\n不能\n\n\n是否有返回值\n无\n无\n无\n\n\n列表的删除，注意区别remove和pop的区别# 4. 列表的删除，注意区别remove和pop的区别newArr = [985, 211, &quot;C9&quot;, &quot;Top2&quot;, &quot;双非&quot;]# 4.1 pop函数res = newArr.pop()  # 默认删除最后一个元素print(newArr)  # 打印出[985, 211, &#x27;C9&#x27;, &#x27;Top2&#x27;]print(res)  # 有返回值，返回被删除的元素 双非newArr.pop(1)  # 有一个参数，这个参数是indexprint(newArr)  # [985, &#x27;C9&#x27;, &#x27;Top2&#x27;]# newArr.pop(100) 报错，参数index不能超过列表范围# 4.2 remove函数res = newArr.remove(&quot;C9&quot;)print(res)  # None remove函数没有返回值# newArr.remove(&quot;不存在的元素&quot;) 不存在这个元素，会报错# 结合 in 使用：# if x in newArr:#     newArr.remove(x)\n\n区别一下两个删除操作：\n\n\n\n函数\npop\nremove\n\n\n\n参数\n一个：index，默认为最后一个下标\n一个：要删除的值，如果列表没有这个值，报错\n\n\n返回值\n有，被删除的元素\n无\n\n\n列表的脚本操作# 5 列表的脚本操作符# 5.1 求长度len(arr)# 5.2 组合：以下这两种方法一样的功能arr = arr + newArrarr.extend(newArr)# 5.3 重复newArr = [1]newArr *= 5  # 重复五次print(newArr)  # [1, 1, 1, 1, 1]# 5.4 in判断是否存在res = 1 in newArrprint(res)  # True# 5.5 迭代操作，列表可以作为迭代的范围newArr = [1, 2, 3, 4, 5]for i in newArr:    print(i)# 注意不能这样使用# for i in newArr:#     print(newArr[i]) 这里的i是列表内的每一个元素# 也可以这么用for i in range(len(newArr)):    print(newArr[i])\n\n\n\n元组\nPython的元组与列表类似，不同之处在于元组的元素不能修改。\n元组使用小括号，列表使用方括号。\n元组创建很简单，只需要在括号中添加元素，并使用逗号隔开即可。\n\n要点：\n\n元组的创建，尤其注意只有一个元素的情况，末尾要加逗号\n元组的访问\n元组不允许修改值，但是元组允许拼接\n元组不允许删除元素，只允许删除整个元组\n元组的脚本运算\n任意无符号的对象，以逗号隔开，默认为元组\n\n元组创建# 1. 元组的声明tup = ()  # 空元组tup = (1)  # 这样是 tup 是1，不是元组，下面才对tup = (1,)  # 元组中只包含一个元素时，需要在元素后面添加逗号tup = (1, 2, 3, &quot;你好&quot;, [1, 2])\n\n元组访问# 2. 元组的访问，同列表，这里不再多次叙述tup[0]tup[::-1]  # 逆序\n\n元组拼接# 3. 元组的拼接tup1 = (1, 3)tup2 = (2, 4)print(tup2 + tup1)  # 打印出：(2, 4, 1, 3)\n\n元组删除# 4. 元组的删除# 注意：元组中的元素值是不允许删除的，但我们可以使用del语句来删除整个元组del tup\n\n元组脚本操作# 5. 元组的脚本运算tup = (1, 2, 3, &quot;你好&quot;, [1, 2])# 5.1 长度len(tup)# 5.2 合并操作tup = tup + tup1# 5.3 判断元素是否存在res = 3 in tupprint(res)  # True# 5.4 重复(1,)*5 # 重复五次# 5.5 迭代操作for i in tup:    print(i)\n\n无关闭分隔符# 6. 无关闭分隔符# 任意无符号的对象，以逗号隔开，默认为元组# print &#x27;abc&#x27;, -4.24e93, 18+6.6j, &#x27;xyz&#x27; Python2中print支持不带括号，Python3必须带括号x, y = 1, 2  # 经常使用的交换元素的值默认就是元组的操作# 通过元组按照index进行赋值的方式进行重新赋值给两个变量print(x, y, sep=&quot; &quot;)\n\n\n\n字符串字符串是 Python 中最常用的数据类型。我们可以使用引号(&#39;或&quot;)来创建字符串。\n本节过于基础，不再进行多余叙述\n基础内容# 1. 字符串的创建str = &#x27;a&#x27;  # python中不存在单字符类型，这也是一个字符串str = &quot;你好&quot;# 2. 字符串访问，支持切片，不再叙述print(str[0])print(str[::-1])  # 逆序# 3. 字符串连接str1 = &quot;你&quot;str2 = &quot;好&quot;print(str1 + str2)# 4. 字符串in判断str = &quot;abcDefg&quot;print(&quot;b&quot; in str)  # Trueprint(&quot;d&quot; in str)  # False# 5. 字符串三引号# Python 中三引号可以将复杂的字符串进行赋值。errHTML = &#x27;&#x27;&#x27;&lt;HTML&gt;&lt;HEAD&gt;&lt;TITLE&gt;Friends CGI Demo&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;&lt;H3&gt;ERROR&lt;/H3&gt;&lt;B&gt;%s&lt;/B&gt;&lt;P&gt;&lt;FORM&gt;&lt;INPUT TYPE=button VALUE=BackONCLICK=&quot;window.history.back()&quot;&gt;&lt;/FORM&gt;&lt;/BODY&gt;&lt;/HTML&gt;&#x27;&#x27;&#x27;# 6. Unicode 字符串uStr = u&quot;Unicode String&quot;print(uStr)uStr = u&#x27;Hello\\u0020World !&#x27;  # \\u0020 是空格的Unicode编码，十六进制print(uStr)  # 打印出Hello World !print(ord(&quot; &quot;))  # ord函数返回对应的 ASCII 数值，这里返回空格的值为32print(chr(97))  # chr函数是ord函数的配对函数，输入ASCII数值，返回字符，这里返回a\n\n\n\n内置函数# 7. 字符串内置函数# 字符串最重要的内容，就是掌握使用字符串函数# 以下只展示比较重要的内置函数str = &quot;abcDa Bye&quot;print(str.capitalize())  # Abcda bye 如果第一个字符是小写字母，将它变为大写，其他字符变为小写print(str.count(&quot;b&quot;))  # 查询出现的次数，这里返回1print(&quot;第一个数&#123;&#125;第二个数&#123;&#125;&quot;.format(3, 4))  # 第一个数3第二个数4print(&quot;第二个数&#123;1&#125;第一个数&#123;0&#125;&quot;.format(1, 2))  # 第二个数2第一个数1，format函数可以设置位置print(str.index(&quot;a&quot;))  # 返回该字符第一次出现时的下标print(&quot;,&quot;.join(str))  # a,b,c,D,a, ,B,y,e 按前面的样子分隔后面的字符串print(str.lower())  # abcda byeprint(str.upper())  # ABCDA BYEprint(str.swapcase())  # 翻转大小写 ABCdA bYE# max、min加字符串，返回对应ascii码大的或小的元素print(max(str))  # 返回 yprint(min(str))  # 返回一个空格# 替换print(str.replace(&quot;a&quot;, &quot;A&quot;))  # AbcDA Bye 替换，第一个参数为老字符串，第二个参数为新字符串# 删除空格print(&quot;  str  &quot;.strip())  # 删除字符串两边的空格\n\n\n\n\n\n","categories":["Python"],"tags":["Python"]},{"title":"Python面向对象","url":"/2021/04/27/Python/Python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":"\n引言：\n\nPython面向对象方面的内容\n\n\n\n\n\nPython面向对象python面向对象本节主要讲述python中的面向对象，先直接阐述要点，再给出代码示例\n（可能之后本篇会进行更新）\n类的定义与使用要点：\n\n类的组成\n类的帮助信息（可以使用ClassName.__doc__查看）\n类体：\n类成员\n方法\n数据属性\n\n\n\n\n位置参数self\n仅仅表示一个位置，换成其他名字也可以，只要在第一个位置即可\n表示类的实例本身，注意是类的实例，即对象\n区分类的函数与普通函数的标志\n传参时不必传入self的值，通过对象调用公共方法时，会自动将对象隐式绑定到self参数\n\n\n注意实例化与赋值的区别，实例化才会调用__init__方法\n在类中定义的为类的变量，使用类名调用\n\nclass Fish:    &quot;鱼的基类&quot;  # 类的帮助信息，可以使用 ClassName.__doc__ 这里就可以使用 Fish.__doc__查看    totalNum = 0  # 类变量，在类的所有实例之间共享    def __init__(self, name, size):        # __init__是特殊的方法，当创建了这个类的实例时，就会被调用        # self 代表类的实例！！注意是类的实例，所以我们不能使用self.totalNum，应该是用类名进行调用        print(&quot;构造ing...&quot;)        Fish.totalNum += 1        self.name = name        self.size = sizeif __name__ == &#x27;__main__&#x27;:    a = Fish  # 这样代表赋值！！意思是a就如同Fish一样，不会进行实例化，不会调用__init__函数    print(id(a))    print(id(Fish))    #   上两行：a的id与Fish的id是一样的，也不会调用__init__函数    print(a)    print(Fish)    #   上两行：打印出&lt;class &#x27;__main__.Fish&#x27;&gt;    print(&quot;--------------------------------分割线---------------------------------------&quot;)    a = Fish(&quot;小黄鱼&quot;, 12)  # 加了括号，这才是实例化，会调用__init__构造方法    print(id(a))    print(id(Fish))    #   上两行：a的id与Fish的id不同    print(a)  # 打印出实例的地址 &lt;__main__.Fish object at 0x000001CC5F3F9190&gt;（没有重写str方法）    print(&quot;--------------------------------分割线---------------------------------------&quot;)    #   为了证明不加括号的确是赋值，我们可以这样尝试一下    fish = Fish    b = fish(&quot;小蓝鱼&quot;, 22)    print(b)  # 打印出&lt;__main__.Fish object at 0x000001CC5F3F9250&gt;    #   确实生成了新的实例，fish等同于Fish    print(&quot;--------------------------------分割线---------------------------------------&quot;)    #   查看类的帮助信息    print(Fish.__doc__)  # 打印出“鱼的基类”    print(&quot;--------------------------------分割线---------------------------------------&quot;)    print(a.totalNum)  # 打印2，因为我们实例化了两条鱼，小黄鱼和小蓝鱼    print(b.totalNum)  # 打印2    print(Fish.totalNum)  # 也可以使用类来打印\n\n\n\n类的函数与普通函数、类的内置属性、对象属性要点：\n\n类的函数与普通函数的最大的区别：类的函数有位置参数\n类的内置属性直接使用类名调用即可\n对象属性使用全局方法使用\n\n&quot;&quot;&quot;    类的函数与普通函数&quot;&quot;&quot;class Fish:    &quot;鱼的基类&quot;    totalNum = 0    def __init__(self, name, size):        print(&quot;构造ing...&quot;)        Fish.totalNum += 1        self.name = name        self.size = size    &quot;&quot;&quot;    def eat():        print(&quot;我想吃东西...&quot;)    #   不加self会报错！！eat() takes 0 positional arguments but 1 was given    &quot;&quot;&quot;    def hungry(abbccd):  # self只是一个位置参数，没有强求写成self，这里也是正确的        print(&quot;我想吃东西...&quot;)def normalFunction():  # 普通函数不需要位置参数    print(&quot;这是普通的方法&quot;)if __name__ == &#x27;__main__&#x27;:    normalFunction()  # 普通方法直接调用即可    c = Fish(&quot;小紫鱼&quot;, 5)    c.hungry()  # 使用对象调用    d = Fish(&quot;小红鱼&quot;, 9)    Fish.hungry(d)  # 也可以这样调用对象的方法，我们可以进一步理解位置参数的作用    print(&quot;--------------------------------分割线---------------------------------------&quot;)    # 类的内置属性    print(Fish.__dict__)  # 类的属性（一个字典），可以看到，我们定义的类的变量totalNum也在这里    # 打印出&#123;    #       &#x27;__module__&#x27;: &#x27;__main__&#x27;,     #       &#x27;__doc__&#x27;: &#x27;鱼的基类&#x27;,    #       &#x27;totalNum&#x27;: 2,    #       &#x27;__init__&#x27;: &lt;function Fish.__init__ at 0x000001CB3117D430&gt;,    #       &#x27;hungry&#x27;: &lt;function Fish.hungry at 0x000001CB313905E0&gt;,    #       &#x27;__dict__&#x27;: &lt;attribute &#x27;__dict__&#x27; of &#x27;Fish&#x27; objects&gt;,    #       &#x27;__weakref__&#x27;: &lt;attribute &#x27;__weakref__&#x27; of &#x27;Fish&#x27; objects&gt;    #       &#125;    print(Fish.__name__)  # 类名    print(Fish.__doc__)  # 类的帮助信息    print(Fish.__module__)  # 类定义所在的模块    print(Fish.__bases__)  # 类的所有父类构成元素（包含了一个由所有父类组成的元组）    print(Fish.__base__)  # 直接的父类    print(&quot;--------------------------------分割线---------------------------------------&quot;)    # 对象的属性访问    e = Fish(&quot;小绿鱼&quot;, 18)    print(hasattr(e, &#x27;name&#x27;))  # 判断是否 True    print(getattr(e, &#x27;size&#x27;))  # 18    print(setattr(e, &#x27;name&#x27;, &#x27;小白鱼&#x27;))    # 给值设值，本身没有返回值返回none    print(e.name)       # 打印出：小白鱼    print(delattr(e, &#x27;name&#x27;))   # 返回none    # print(e.name)   报错找不到该属性：&#x27;Fish&#x27; object has no attribute &#x27;name&#x27;\n\n\n\npython对象销毁（垃圾回收）要点：\n\nPython 使用了引用计数这一简单技术来跟踪和回收垃圾。\n\n在 Python 内部记录着所有使用中的对象各有多少引用。\n\n这个对象的引用计数变为0 时， 它将被垃圾回收。但是回收不是”立即”的， 由解释器在适当的时机，将垃圾对象占用的内存空间回收。\n\n\n&quot;&quot;&quot;    python对象销毁（垃圾回收）&quot;&quot;&quot;class Fish:    &quot;鱼的基类&quot;    totalNum = 0    def __init__(self, name, size):        Fish.totalNum += 1        self.name = name        self.size = size    def __del__(self):        print(self.__class__.__name__ + &quot;被销毁了&quot;)if __name__ == &#x27;__main__&#x27;:    a = Fish(&quot;小黑鱼&quot;, 1)    b = a  # 创建Fish的引用    c = a  # 创建Fish的引用    del (a)    print(1)    del (b)    print(2)    del (c)    print(3)\n\n打印的结果是：\n12Fish被销毁了3\n\n可以看到，我们创建了三个小黑鱼对象的引用，当全部的引用删除完成后，小黑鱼这个对象本身执行__del__函数，然后被析构\n类的继承要点：\n\n要继承哪个类，写入括号内，有多个父类用逗号隔开\n通过super()调用父类的方法，注意：super()是带有括号的（某些教材使用super(Class, self).xxx调用，这是python2.x的写法）\n子类可以调用父类的方法\n\n&quot;&quot;&quot;    类的继承&quot;&quot;&quot;class Fish(object):  # 不写括号，默认继承object类    &quot;鱼的基类&quot;    totalNum = 0    def __init__(self, name, size):        Fish.totalNum += 1        self.name = name        self.size = size    def __str__(self):        return str(&quot;FISHINFO&gt;&gt;&gt;&quot; + self.name + &quot;,&quot; + str(self.size))    def hungry(self):        print(&quot;我饿了！！&quot;)class Shark(Fish):  # 使用括号进行继承，如果有多个父类，就用“,”隔开    &quot;鲨鱼类&quot;    def __init__(self, name, size, age):        super().__init__(name, size)  # 调用父类的构造        self.age = age  # 鲨鱼类独有的变量，它有一个年龄    def __str__(self):        return super().__str__() + &quot;,&quot; + str(self.age)    def eat(self, fish):  # 鲨鱼类自己拥有的方法        if not isinstance(fish, Fish):  # 如果输入的是Fish类或其子类，那么返回true            raise Exception(&quot;你不能喂鲨鱼鱼以外的其他东西！&quot;)        print(&quot;大口吃鱼！！&quot;)        if fish.size &lt; self.size:            print(&quot;我变大了！&quot;)            self.size += 1            return True        else:            print(&quot;不行，我吃不掉它，它有&quot; + str(fish.size) + &quot;，我才&quot; + str(self.size))            return Falseif __name__ == &#x27;__main__&#x27;:    s = Shark(&quot;鲨鱼辣椒&quot;, 121, 3)  # 名字取自《铁甲小宝》    a = Fish(&quot;小绿鱼&quot;, 18)    b = Fish(&quot;大白鱼&quot;, 200)    print(s)    s.hungry()  # 子类调用父类的方法    s.eat(a)  # 子类调用自己独有的方法    print(s)    s.hungry()    s.eat(b)    # s.eat(&quot;我是一个字符串&quot;)  报错，因为输入的是一个字符串    print(Shark.__bases__)  # 打印一下鲨鱼类父类的元组\n\n\n\n类属性与方法要点：\n\n注意：在python中没有严格意义的访问限制\n\npython中的三种限制级别：\n\nname 公共成员。\n_name 私有成员。本类和子类访问。（非强制性，python建议。也就是说你依然可以在外部访问它）\n__name 强制性私有成员。只在本类访问。（但你依然可以通过_Classname__name的方式来蛮横访问）\n\n\n保护类型的变量不能用于 from module import *\n\n\n&quot;&quot;&quot;    类的私有属性与方法&quot;&quot;&quot;class Fish:    &quot;鱼的基类&quot;    totalNum = 0    __group = 1  # 使用两个下划线表示类的私有变量，外部不可以访问（但其实可以访问）    _age = 1  # 一个下划线表示受保护的，外部不建议访问（注意是 “不建议”），但是可以访问    def __init__(self, name, size):        Fish.totalNum += 1        self.name = name        self.size = size    def __str__(self):        # 内部可以调用私有变量和可继承变量        return str(&quot;FISHINFO&gt;&gt;&gt;&quot; + self.name + &quot;,&quot; + str(self.size) + &quot;,&quot; + str(self.__group) + &quot;,&quot; + str(self._age))    def __hungry(self):  # 私有方法        print(&quot;我想吃东西...&quot;)    def _eat(self):  # 保护的方法        print(&quot;吃东西&quot;)if __name__ == &#x27;__main__&#x27;:    a = Fish(&quot;小白鱼&quot;, 12)    print(a)    print(a.totalNum)  # 外部可以访问共有的变量    # print(a.__group)     报错，外部不能访问私有变量    print(a._age)  # 外部可以访问类的保护成员    print(a._Fish__group)  # 外部其实也可以调用类的私有变量，只要使用 objectname._Classname__name 来访问即可    a._eat()    # a.__hungry() 报错    a._Fish__hungry()\n\n","categories":["Python"],"tags":["Python"]},{"title":"Servlet","url":"/2019/10/11/Servlet/Servlet/","content":"\n\n引言：\nServelet\n\n\n\n\n\n\nServletserver applet\n概念：\n运行在服务端的小程序\n一个接口，定义了java类被浏览器访问到(tomcat识别)的规则\n将来我们自定义一个类，实现Servlet接口，复写方法\n\n快速入门\n创建一个JavaEE的项目\n定义一个类，实现Servelet接口\n实现接口中的抽象方法（共五个） /** * @author BlackKnight */public class servletDemo implements Servlet &#123;    @Override    public void init(ServletConfig servletConfig) throws ServletException &#123;    &#125;    @Override    public ServletConfig getServletConfig() &#123;        return null;    &#125;    @Override    //提供服务的方法    public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException &#123;        System.out.println(&quot;Hello Servlet&quot;);    &#125;    @Override    public String getServletInfo() &#123;        return null;    &#125;    @Override    public void destroy() &#123;    &#125;&#125;\n配置Servelet（配置web.xml文件） &lt;!--配置Servlet--&gt; &lt;servlet&gt;     &lt;servlet-name&gt;demo1&lt;/servlet-name&gt;     &lt;servlet-class&gt;servletDemo&lt;/servlet-class&gt; &lt;!--配置全类名，src目录下一层一层写--&gt; &lt;/servlet&gt; &lt;!--配置网页虚拟路径--&gt; &lt;servlet-mapping&gt;     &lt;servlet-name&gt;demo1&lt;/servlet-name&gt;     &lt;url-pattern&gt;/demo1&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;\n启动服务器，打开http://localhost:8080/demo1\n\nServlet 执行原理servlet执行的步骤：\n浏览器输入/demo1  –&gt;  Servlet自动匹配xml文件，找到xml文件中&lt;url-pattern&gt;的/demo1 ，匹配&lt;servlet-name&gt;\n–&gt;  匹配到&lt;servlet-name&gt;后，又由此匹配到&lt;servlet-class&gt;  –&gt; Tomcat通过这里的全类名对应的字节码文件加载进入内存\n–&gt; 由此通过反射机制创建对象 –&gt; 调用Service方法\n\n对象的创建和调用方法都依赖于web容器Tomcat来执行，不需要我们操作\nServlet方法public class servletDemo implements Servlet &#123;    /**     * 初始化方法     * 在Servlet被创建后只会执行一次     * @param servletConfig     * @throws ServletException     */    @Override    public void init(ServletConfig servletConfig) throws ServletException &#123;    &#125;    /**     * 获取ServletConfig对象     * ServletConfig，Servlet的配置对象     * @return     */    @Override    public ServletConfig getServletConfig() &#123;        return null;    &#125;    /**     * 提供服务的方法     * 每一次Servlet被访问时，就会调用一次此方法，执行多次     * @param servletRequest     * @param servletResponse     * @throws ServletException     * @throws IOException     */    @Override    public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException &#123;        System.out.println(&quot;Hello Servlet&quot;);    &#125;    /**     * 获取Servlet的一些信息的方法：版本，作者...     * 一般不会实现     * @return     */    @Override    public String getServletInfo() &#123;        return null;    &#125;    /**     * 销毁方法     * 在Servlet正常关闭时调用，执行一次     */    @Override    public void destroy() &#123;    &#125;&#125;\n\n生命周期\n被创建：执行init方法，只执行一次\n\n默认情况下第一次被访问时Servlet被创建\n可以配置执行Servlet的创建时机&lt;!--在Servlet标签下配置此内容--&gt;&lt;!--配置全类名,src目录下一层一层写--&gt;&lt;!--可以指定Servlet的创建时机    1. 第一次被访问时创建（值为负数，默认即为-1）    2. 在服务器启动时创建（值为0或者正整数）--&gt;&lt;load-on-startup&gt;-1&lt;/load-on-startup&gt;\nServlet的init方法，只执行一次，说明一个Servlet在内存中只存在一个对象，Servlet是单例的：这存在一个安全问题，多个对象同时访问了共享资源，可能出现线程安全问题\n解决：尽量不要在Servlet中定义成员变量，可以在方法内定义变量，即使定义了成员变量，也不要对其修改\n\n\n提供服务：执行servlet方法，执行多次\n\n每次访问Servlet时，Servlet方法都会被调用一次\n\n\n被销毁：执行destroy方法，正常关闭时调用，也只执行一次\n\nServlet被销毁时（销毁前）执行。服务器关闭时，Servlet会被销毁\n只有正常关闭时才会执行destroy方法\n\n\n\nServlet3.0好处：无需再配置web.xml\n步骤：\n\n创建JavaEE项目，选择Servlet版本3.0以上，可以不创建webxml\n定义一个类实现Servlet接口\n复写方法\n在类上使用@WebServelt注解进行配置 @WebServlet(urlPatterns = &quot;/demo&quot;)//可以这样配置url@WebServlet(&quot;/demo&quot;)//由于urlPatterns是value值，所以可以省略，直接写url即可\n\nIDEA与Tomcat的相关配置\nIDEA会为每一个tomcat部署的项目单独建立一个配置文件，\n\n查看控制台此配置信息，就是配置文件所在地\nUsing CATALINA_BASE:\n\n\n工作空间项目 和 tomcat部署的web项目文件\n\ntomcat实际访问的是tomcat“tomcat部署的web项目”，它位于工作空间项目下的web目录下的所有资源\nWEB-INF 目录下的资源不能被浏览器直接访问\n\n\n\nServlet体系结构Servlet接口下有一个抽象实现类GenericServlet 抽象类\n此类下还有一个子类HttpServlet 抽象类\nGenericServlet只有Service()方法进行了抽象，其他都是空方法\n所以我们继承此接口只需要重写一个方法\n其他的方法想要重写也是可以的\npublic class servletDemo extends GenericServlet &#123;    @Override    public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException &#123;    &#125;&#125;\n\nHttpServlet我们常在开发中使用此类，对Http协议的一种封装可以简化操作\n此类封装了HTTP并给出了Service等方法\n//Service()方法protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;    String method = req.getMethod();    //1. 接收方法的类型    long lastModified;    //2. 判断该方法是什么方法,共有七个方法，用字符串类的equals来判断等价    if (method.equals(&quot;GET&quot;)) &#123;        lastModified = this.getLastModified(req);        if (lastModified == -1L) &#123;            this.doGet(req, resp);            //3. 调用响应的doGet或者doPost方法        &#125; else &#123;            long ifModifiedSince;            try &#123;                ifModifiedSince = req.getDateHeader(&quot;If-Modified-Since&quot;);            &#125; catch (IllegalArgumentException var9) &#123;                ifModifiedSince = -1L;            &#125;            if (ifModifiedSince &lt; lastModified / 1000L * 1000L) &#123;                this.maybeSetLastModified(resp, lastModified);                this.doGet(req, resp);            &#125; else &#123;                resp.setStatus(304);            &#125;        &#125;    &#125; else if (method.equals(&quot;HEAD&quot;)) &#123;        lastModified = this.getLastModified(req);        this.maybeSetLastModified(resp, lastModified);        this.doHead(req, resp);    &#125; else if (method.equals(&quot;POST&quot;)) &#123;        this.doPost(req, resp);    &#125; else if (method.equals(&quot;PUT&quot;)) &#123;        this.doPut(req, resp);    &#125; else if (method.equals(&quot;DELETE&quot;)) &#123;        this.doDelete(req, resp);    &#125; else if (method.equals(&quot;OPTIONS&quot;)) &#123;        this.doOptions(req, resp);    &#125; else if (method.equals(&quot;TRACE&quot;)) &#123;        this.doTrace(req, resp);    &#125; else &#123;        String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;);        Object[] errArgs = new Object[]&#123;method&#125;;        errMsg = MessageFormat.format(errMsg, errArgs);        resp.sendError(501, errMsg);    &#125;&#125;\n\n\n使用步骤：\n\n定义类继承HTTPServlet\n覆写doGet/doPost方法\n\n//在web目录下建立一个login的html文件@WebServlet(urlPatterns = &quot;/login&quot;)public class servletDemo extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;doGet方法&quot;);    &#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;doPost方法&quot;);    &#125;&#125; \nlogin.html文件\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;index&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt;    &lt;input name=&quot;username&quot;&gt;    &lt;br&gt;    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n然后启动tomcat后，可以1在网页上打开此html，\n访问路径后控制台会打印doGet方法\n点击提交后控制台会打印doPost方法\nServlet相关配置@WebServlet注解底层\n@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface WebServlet &#123;    String name() default &quot;&quot;;    String[] value() default &#123;&#125;;        String[] urlPatterns() default &#123;&#125;;    // 是一个数组，可以为一个Servlet定义多个访问路径    int loadOnStartup() default -1;    WebInitParam[] initParams() default &#123;&#125;;    boolean asyncSupported() default false;    String smallIcon() default &quot;&quot;;    String largeIcon() default &quot;&quot;;    String description() default &quot;&quot;;    String displayName() default &quot;&quot;;&#125;\n\n一个Servlet可以写多个访问路径 @WebServlet(&#123;&quot;/login&quot;,&quot;/login1&quot;,&quot;/login2&quot;&#125;)\nurlpattern怎么写\n/xxx单层路径\n/xxx/xxx多层路径（目录结构）\n/user/*通配符写法\n*.do自定义一个拓展名(不加斜杠)\n\n\n\nHTTP概述Hiper Text Transfer Protocol 超文本传输协议\n\n传输协议：定义了客户端和服务器端通信时，发送数据的格式\n\n客户端给服务器端发送请求消息\n服务器端解析客户端的请求消息，给客户端发送响应消息\n特点\n基于TCP/IP的高级协议\n默认端口号 80\n基于请求/响应模型的：一次请求对应一次响应\n无状态的：每次请求之间相互独立，不能交互数据\n\n历史版本\n1.0版本：每一个图片，每一个css等配置文件，都是一个请求，每次都会重复申请连接\n1.1版本：复用连接\n\n请求消息数据格式Request格式分为四个部分\n\n请求行\n请求方式 请求url 请求协议/版本\n\n GET /login.html HTTP/1.1\n\n请求方式有七种，常见有两种\nGET:\n请求参数在请求行中\n请求的url长度有限\n不太安全\n\n\nPOST:\n请求参数在请求体中\n请求的url长度没有限制\n相对安全\n\n\n\n\n\n\n请求头\n请求头名称:请求值（键:值）\n\n\n请求空行\n空行,分隔请求头和请求体\n\n\n请求体（正文）\n封装Post请求消息的请求参数\n\n\n\n字符串格式\n//-------------请求行---------------GET /login.html HTTP/1.1//上面为请求行，底下为请求头//-------------请求头---------------Host: localhost//Host:请求主机是localhostUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0//User-Agent:浏览器告诉服务器，访问使用的浏览器版本信息//服务端获取该头信息，解决了浏览器的兼容性问题Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8//支持的响应格式Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2//支持的语言环境Accept-Encoding: gzip, deflate//支持的解析结构Content-Type: application/x-www-form-urlencodedContent-Length: 9Connection: keep-alive//keep-alive 表示连接都是可以复用的Referer: http://localhost/login.html//告诉服务器，当前请求是从哪里发出的//作用：1.防盗链：防止其他网页盗取链接 2.统计工作：获取来源处的某些信息，比如统计广告来源Upgrade-Insecure-Requests: 1//上面为请求头，底下为参数//------------参数----------------username = &quot;输入的内容&quot;\n\n","categories":["后台","Servlet"],"tags":["Servlet"]},{"title":"SpringBoot邮件实现","url":"/2020/08/22/Spring/Spring%20Boot%20%E5%AE%9E%E7%8E%B0%E9%82%AE%E4%BB%B6%E4%BC%A0%E8%BE%93/","content":"\n引言：SpringBoot实现简单的邮件传输\n\n\n\nSpringBoot实现邮件传输前提配置邮箱设置邮箱可以是QQ邮箱、163邮箱等等，这里使用163邮箱。\n\n登录163邮箱\n点开设置，里面有POP3/SMTP/IMAP这一个选项\n\n\n\n\n开启IMAP/SMTO和POP3/SMTP服务\n进行授权密码配置（扫描二维码、发送短信）\n记录返回的密码（注意，不是邮箱的登录密码）\n\nPOM文件添加&lt;!-- 邮件协议 --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt;\n\n项目文件配置spring:    mail:      host: smtp.163.com # 不同的邮箱有不同的host      password: 之前记录的密码值      username: 你的邮箱@163.com      default-encoding: UTF-8      protocol: smtp      from: 和username相同      properties:        mail:          smtp:            auth: true            starttls:              enable: true              required: true\n\nSpring下的文件配置\nMail文件设置service文件\n/** * @author 董文浩 * @Date 2020/8/18 9:27 */public interface MailService &#123;    /**     * 发送文本邮件     * @param to 收件人     * @param subject 主题     * @param content 内容     */    void sendSimpleMail(String to, String subject, String content);    /**     * 发送HTML邮件     * @param to 收件人     * @param subject 主题     * @param content 内容     */    public void sendHtmlMail(String to, String subject, String content);    /**     * 发送带附件的邮件     * @param to 收件人     * @param subject 主题     * @param content 内容     * @param filePath 附件     */    public void sendAttachmentsMail(String to, String subject, String content, String filePath);&#125;\n\n实现类：\nimport org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.core.io.FileSystemResource;import org.springframework.mail.SimpleMailMessage;import org.springframework.mail.javamail.JavaMailSender;import org.springframework.mail.javamail.MimeMessageHelper;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Service;import javax.annotation.Resource;import javax.mail.MessagingException;import javax.mail.internet.MimeMessage;import java.io.File;/** * @author 董文浩 * @Date 2020/8/18 9:28 */@Servicepublic class MailServiceImpl implements MailService &#123;    private final Logger logger = LoggerFactory.getLogger(this.getClass());    /**     * Spring Boot 提供了一个发送邮件的简单抽象，使用的是下面这个接口，这里直接注入即可使用     */    @Resource    private JavaMailSender mailSender;    /**     * 配置文件中我的qq邮箱     */    @Value(&quot;$&#123;spring.mail.from&#125;&quot;)    private String from;    /**     * 简单文本邮件     * @param to 收件人     * @param subject 主题     * @param content 内容     */    @Override    public void sendSimpleMail(String to, String subject, String content) &#123;        //创建SimpleMailMessage对象        SimpleMailMessage message = new SimpleMailMessage();        //邮件发送人        message.setFrom(from);        //邮件接收人        message.setTo(to);        //邮件主题        message.setSubject(subject);        //邮件内容        message.setText(content);        //发送邮件        mailSender.send(message);    &#125;    /**     * html邮件     * @param to 收件人     * @param subject 主题     * @param content 内容     */    @Override    public void sendHtmlMail(String to, String subject, String content) &#123;        //获取MimeMessage对象        MimeMessage message = mailSender.createMimeMessage();        MimeMessageHelper messageHelper;        try &#123;            messageHelper = new MimeMessageHelper(message, true);            //邮件发送人            messageHelper.setFrom(from);            //邮件接收人            messageHelper.setTo(to);            //邮件主题            message.setSubject(subject);            //邮件内容，html格式            messageHelper.setText(content, true);            //发送            mailSender.send(message);            //日志信息            logger.info(&quot;邮件已经发送。&quot;);        &#125; catch (MessagingException e) &#123;            logger.error(&quot;发送邮件时发生异常！&quot;, e);        &#125;    &#125;    /**     * 带附件的邮件     * @param to 收件人     * @param subject 主题     * @param content 内容     * @param filePath 附件     */    @Override    public void sendAttachmentsMail(String to, String subject, String content, String filePath) &#123;        MimeMessage message = mailSender.createMimeMessage();        try &#123;            MimeMessageHelper helper = new MimeMessageHelper(message, true);            helper.setFrom(from);            helper.setTo(to);            helper.setSubject(subject);            helper.setText(content, true);            FileSystemResource file = new FileSystemResource(new File(filePath));            String fileName = filePath.substring(filePath.lastIndexOf(File.separator));            helper.addAttachment(fileName, file);            mailSender.send(message);            //日志信息            logger.info(&quot;邮件已经发送。&quot;);        &#125; catch (MessagingException e) &#123;            logger.error(&quot;发送邮件时发生异常！&quot;, e);        &#125;    &#125;&#125;\n\n\n\n测试类测试import com.yunhuo.xcjd.utils.mail.MailService;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import javax.annotation.Resource;/** * @author 董文浩 * @Date 2020/8/18 08:47 */@RunWith(SpringRunner.class)@SpringBootTestpublic class UsermapperTest &#123;    /**     * 注入发送邮件的接口     */    @Resource    private MailService mailService;    /**     * 测试发送文本邮件     */    @Test    public void sendmail() &#123;        mailService.sendSimpleMail(                &quot;1046467756@qq.com&quot;,                &quot;主题：你好普通邮件&quot;,                &quot;内容：第一封邮件&quot;);    &#125;    @Test    public void sendmailHtml()&#123;        mailService.sendHtmlMail(                &quot;1046467756@qq.com&quot;,                &quot;主题：你好html邮件&quot;,                &quot;&lt;h1&gt;内容：第一封html邮件&lt;/h1&gt;&quot;);    &#125;&#125;\n\n测试成功！\n遇到报错\n检查配置文件是否设置正确\n检查是否可以ping通smtp.163.com\n\n","categories":["SpringBoot"],"tags":["SpringBoot"]},{"title":"MySQL的特殊查询","url":"/2021/09/02/MySQL/Mysql%E4%B8%8Elimit/","content":"\n引言：Mysql的特殊查询\n\n\n\n\nMysql独有的limitselect * from tableName limit i,n# tableName：表名# i：为查询结果的索引值(默认从0开始)，当i=0时可省略i# n：为查询结果返回的数量# i与n之间使用英文逗号&quot;,&quot;隔开limit n 等同于 limit 0,n\n\n使用limit去实现TOP k问题\nSELECT * FROM 表 order by 字段 desc limit k;# 可以查询前k个记录SELECT * FROM ql_article ORDER BY hits DESC LIMIT 1,3;# 查询第二页（注意是从0开始的），前三条记录\n\n举个例子：\n\n# 1、查询蓝框内容，就是前三条SELECT * FROM ql_article LIMIT 3;# 相当于这么写SELECT * FROM ql_article LIMIT 0, 3;# 2、查询红框内容SELECT * FROM ql_article LIMIT 3, 3;# 跳过前三条记录，取三条数据# 3、查询黄框内容SELECT * FROM ql_article LIMIT 8, 4;\n\n连接查询有四种连接\n\n左外连接left join\n右外连接right join\n内连接inner join\n全连接UNION（注意，和Oracle不同的！）\n\n区别要记住：\n\n左外连接中优先匹配左表，右表没有的显示为null\n右外连接是，右表全部有，左表可能为空；\n内连接中均不能为空；\n全连接都会匹配；\n\n基本语句为select xxxx from x1 left join x2 on x1.xx = x2.xx;（即记住表1 left join 表2 on 条件）\n优点枯燥，这里用栗子解释一下：\nselect ql_article.uid, ql_user.usernamefrom ql_article LEFT JOIN ql_user ON ql_article.uid = ql_user.uid;# 将写了文章的用户，查出他们的名字\n\n结果：\n\n全连接的语句有点特殊：\nselect uid, nullfrom ql_article UNION select uid,ql_user.usernamefrom ql_user;# 它会自动将你相同的键合在一起\n\n注意：\n\nUNION左右两个查询的列个数必须一样\n\n如果要排序请写在外面：\n(select id,name from A order by id) union all (select id,name from B order by id);#没有排序效果(select id,name from A ) union all (select id,name from B ) order by id;#有排序效果\n\n","categories":["后台","MySQL"],"tags":["MySQL"]},{"title":"Spring_AOP","url":"/2020/03/10/Spring/Spring-AOP/","content":"\n引言：\n\nSpring——AOP\n\n\n\nAOP\nAOP：Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期间动态代理实现程序功能的统一维护的一种技术\n\n在传统的开发中，如果我们想对一个方法进行增强（加强这个方法的功能：例如给保存功能加权限校验），就需要给这个方法中再加一个方法，但是如果这样的类非常多，有成百上千个，我们该怎么办？\n传统方式使用纵向继承，即子类继承父类，父类中有权限校验的代码，于是子类也可以调用\nAOP采用横向抽取机制，即通过动态代理Proxy来实现对代码的增强\n而Spring AOP 就是使用纯JAVA语言实现的，不需要专门的编译过程和类加载器，在运行期通过代理方式向目标类植入增强代码\nSpring AOP相关术语\n\nJoinpoint：（连接点）指被拦截到的点，spring中这些点是方法，因为Spring只支持方法类型的连接点\n\n\nPointcut：（切入点）指我们要对哪些Joinpoint进行拦截\n\n\nAdvice：（通知/增强）指拦截到Joinpoint类之后要做的事情，分为前置通知、后置通知、异常通知、最终通知、环绕通知（切面要完成的功能）\n\n\nIntroduction：（引介）一种特殊的通知，在不修改类代码的前提下、Introduction可以在运行期间，动态的添加一些方法或Field\n\n\nTarget：（目标对象）增强的目标，代理的目标对象\n\n\nWeaving：（织入）把Advice应用到Target来创建新的代理对象的过程，Spring采用动态代理来织入，而AspectJ采用编译期织入和类装载期织入\n\n\nProxy（代理）：一个类被AOP织入增强后，就产生一个结果代理类\n\n\nAspect（切面）：是切入点和通知（引介）的结合\n\n代理使用JDK动态代理我们现在使用动态代理来增强这个类的save方法\npublic interface UserDao &#123;    void save();&#125;\n实现类\npublic class UserDaoImpl implements UserDao &#123;    @Override    public void save() &#123;        System.out.println(&quot;保存数据&quot;);    &#125;&#125;\n代理类\npublic class MyProxy implements InvocationHandler &#123;    private UserDao userDao;    public MyProxy(UserDao userDao) &#123;        this.userDao = userDao;    &#125;    public Proxy creatProxy() &#123;        /**         * proxy的newInstance方法需要传入三个参数         * 第一个：类加载器         * 第二个：接口         * 第三个：InvocationHandler的实现类，这个类中有invoke方法，我们需要用这个方法来增强我们的方法         *        在这里传入了this，是因为这个类就实现了InvocationHandler接口         */        Proxy proxy = (Proxy) Proxy.newProxyInstance(                userDao.getClass().getClassLoader(),                userDao.getClass().getInterfaces(),                this);        return proxy;    &#125;    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        //如果调用的是save方法，就进行权限校验        if(&quot;save&quot;.equals(method.getName()))&#123;            System.out.println(&quot;权限校验&quot;);            return method.invoke(userDao,args);        &#125;        return method.invoke(userDao,args);    &#125;&#125;\n测试类\n@Test public void test1()&#123;    UserDao userDao = new UserDaoImpl();    UserDao userDaoProxy = (UserDao) new MyProxy(userDao).creatProxy();    userDaoProxy.save();&#125;//结果/*权限校验保存数据*/\n\n我们发现JDK的动态代理，只能适用于实现了接口的类，对于没有实现接口的类，我们没法使用JDK的动态代理\n使用CGLIB生成代理原理是：针对目标产生了一个子类\npublic class ProductDao &#123;    public void save() &#123;        System.out.println(&quot;数据保存&quot;);    &#125;&#125;\n\n/** * 注意是org.springframework.cglib.proxy这个包下的MethodInterceptor */public class MyCglibProxy implements MethodInterceptor &#123;    private ProductDao productDao;    public MyCglibProxy(ProductDao productDao) &#123;        this.productDao = productDao;    &#125;    public Object creatProxy()&#123;        //1. 核心类        Enhancer enhancer = new Enhancer();        //2. 设置父类        enhancer.setSuperclass(productDao.getClass());        //3. 设置回调，类似于InvocationHandler这个类        enhancer.setCallback(this);        Object proxy = enhancer.create();        return proxy;    &#125;    @Override    public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123;        if(&quot;save&quot;.equals(method.getName()))&#123;            System.out.println(&quot;权限检验&quot;);            return methodProxy.invokeSuper(proxy,args);        &#125;        return methodProxy.invokeSuper(proxy,args);    &#125;&#125;\n\n代理总结\nSpring在运行期生成动态代理对象，不需要特殊的编译器\nSpring AOP的底层就是通过JDK动态代理或CGLib动态代理技术为目标进行横向织入\n若目标实现了接口，则使用JDK的Proxy\n目标没有实现接口，则使用Spring的CGLib\n编程中尽量优先使用接口创建动态代理、便于解耦\n对于使用final的方法或类无法代理  \nSpring只支持方法连接点、不提供属性连接点\n\nSpringAOP 增强（通知）类型\nAdvice：（通知/增强）指拦截到Joinpoint类之后要做的事情，分为前置通知、后置通知、异常通知、最终通知、环绕通知（切面要完成的功能）\n\nAOP联盟定义了五个Advice类型，主要有：\n\n前置通知org.springframework.aop.MethodBeforeAdvice，在目标方法执行前实施增强\n后置通知org.springframework.aop.AfterReturningAdvice，在目标方法执行后实施增强\n环绕通知org.aopalliance.intercept.MethodInterceptor，在目标方法执行前、执行后实施增强\n异常抛出通知org.springframework.aop.IntroductionInterceptor，在方法抛出异常后实施增强\n引介通知，org.springframework.aop.IntroductionInterceptor，在目标类中添加一些新的方法和属性\n\n注意：Spring只有对于方法的连接点，而没有对于属性的连接点，所以Spring没有引介通知\nSpringAOP切面类型\nJoinpoint：（连接点）指被拦截到的点，spring中这些点是方法，因为Spring只支持方法类型的连接点\n\n\nPointcut：（切入点）指我们要对哪些Joinpoint进行拦截\n\n\nAspect（切面）：是切入点和通知（引介）的结合\n\n切面配置为了使用切面，除了引入beans core context expression之外，还需要引入\n&lt;dependency&gt;    &lt;groupId&gt;aopalliance&lt;/groupId&gt;    &lt;artifactId&gt;aopalliance&lt;/artifactId&gt;    &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-aop&lt;/artifactId&gt;    &lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;/dependency&gt;\n\n实际上我们并不需要自己去写代理类，Spring为我们提供了代理类ProxyFactoryBean，我们只需要配置它的信息即可\n// 可配置属性有：- target 代理的对象- proxyInterfaces 代理要实现的接口，接口很多时使用List来赋值- interceptorNames 需要织入目标的Advice（拦截名）- proxyTargetClass 是否对类代理而不是接口，设置为true时，使用CGLib代理- optimize 设置为true时，强制使用CGLib\n使用Advisor一般切面\nAdvisor：一般的切面，Advice（通知）本身就是一个切面，它会对对目标类所有方法进行拦截\n\nPointcutAdvicor：具有切入点的切面，可以指定拦截\n\nIntroductionAdvisor：代表引介切面、针对引介通知而使用切面\n\n\n同样，由于Spring原因，所以没有IntroductionAdvisor\n以下是一个小例子\n\n配置\n&lt;bean id=&quot;studentDao&quot; class=&quot;com.dongwenhao.demo08.StudentDaoImpl&quot; /&gt;&lt;bean id=&quot;myBeforeAdvice&quot; class=&quot;com.dongwenhao.demo08.MyBeforeAdvice&quot; /&gt;&lt;bean id=&quot;studentProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt;    &lt;!--配置目标类--&gt;    &lt;property name=&quot;target&quot; ref=&quot;studentDao&quot;/&gt;    &lt;!--配置接口--&gt;    &lt;property name=&quot;proxyInterfaces&quot; value=&quot;com.dongwenhao.demo08.StudentDao&quot;/&gt;    &lt;!--配置拦截的名称--&gt;    &lt;property name=&quot;interceptorNames&quot; value=&quot;myBeforeAdvice&quot; /&gt;&lt;/bean&gt;\n接口\npublic interface StudentDao&#123;    public void save();&#125;   \n类\npublic class StudentDaoImpl implements StudentDao &#123;    @Override    public void save() &#123;        System.out.println(&quot;保存信息&quot;);    &#125;&#125;\n使用前置通知\npublic class MyBeforeAdvice implements MethodBeforeAdvice &#123;    @Override    public void before(Method method, Object[] args, Object target) throws Throwable &#123;            System.out.println(&quot;权限校验&quot;);    &#125;&#125;\n\n使用 PointcutAdvisor 切点切面带有切点的切面可以对特定的切面进行处理\n常用PointcutAdvisor实现类\n\nDefaultPointcutAdvisor 最常用的切面类型，可以通过任意Pointcut和Advice组合定义切面\nJdkRegexpMethodPointcut构造正则表达式切点\n\n以下是例子\n\n这个例子没有接口，使用CGLib，且使用环绕通知\n配置\n&lt;bean id=&quot;customerDao&quot; class=&quot;com.dongwenhao.demo09.CustomerDao&quot; /&gt;&lt;bean id=&quot;myAroundAdvice&quot; class=&quot;com.dongwenhao.demo09.MyAroundAdvice&quot; /&gt;&lt;!--使用正则表达式切点--&gt;&lt;bean id=&quot;myAdvisor&quot; class=&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt;    &lt;property name=&quot;pattern&quot; value=&quot;.*&quot; /&gt;    &lt;!--这里配置正则表达式--&gt;    &lt;property name=&quot;advice&quot; ref=&quot;myAroundAdvice&quot; /&gt;    &lt;!--这里配置引用--&gt;&lt;/bean&gt;&lt;bean id=&quot;customerDaoProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt;    &lt;property name=&quot;target&quot; ref=&quot;customerDao&quot; /&gt;    &lt;property name=&quot;proxyTargetClass&quot; value=&quot;true&quot; /&gt;    &lt;!--设置为true，即使用CGLib--&gt;    &lt;property name=&quot;interceptorNames&quot; value=&quot;myAdvisor&quot; /&gt;&lt;/bean&gt;\n环绕通知\n/** * 这里的接口是org.aopalliance.intercept.MethodInterceptor; */public class MyAroundAdvice implements MethodInterceptor &#123;    @Override    public Object invoke(MethodInvocation invocation) throws Throwable &#123;        System.out.println(&quot;环绕前-&gt;-&gt;-&gt;&quot;);        Object proceed = invocation.proceed();        System.out.println(&quot;&lt;-&lt;-&lt;-环绕后&quot;);        return proceed;    &#125;&#125;\n\npublic class CustomerDao &#123;    public void save() &#123;        System.out.println(&quot;保存数据&quot;);    &#125;&#125;\n\n自动创建代理每个代理我们都使用ProxyFactoryBean织入切面代理的话，Bean的数量一多，工作量会非常的大\n自动创建代理的类有以下：\n\nBeanNameAutoProxyCreator 根据Bean名称创建代理\nDefaultAdvisorAutoProxyCreator 根据Advisor本身包含信息创建代理\nAnnotationAwareAspectJAutoProxyCreator 基于Bean中的AspectJ注解进行自动代理\n\n只需要简单的配置，我们就能完成这项工作了！\nBeanNameAutoProxyCreator&lt;!--只需要配置    1. 目标    2. 增强（Advice）   --&gt;&lt;bean id=&quot;customerDao&quot; class=&quot;com.dongwenhao.demo10.CustomerDao&quot; /&gt;&lt;bean id=&quot;studentDao&quot; class=&quot;com.dongwenhao.demo10.StudentDaoImpl&quot;/&gt;&lt;!--目标类--&gt;&lt;bean id=&quot;myAroundAdvice&quot; class=&quot;com.dongwenhao.demo10.MyAroundAdvice&quot; /&gt;&lt;bean id=&quot;myBeforeAdvice&quot; class=&quot;com.dongwenhao.demo10.MyBeforeAdvice&quot;/&gt;&lt;!--通知--&gt;&lt;bean class=&quot;org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator&quot;&gt;    &lt;property name=&quot;beanNames&quot; value=&quot;*Dao&quot; /&gt;    &lt;!--为所有以Dao结尾的Bean自动代理--&gt;    &lt;property name=&quot;interceptorNames&quot; value=&quot;myAroundAdvice&quot; /&gt;    &lt;!--选择通知--&gt;&lt;/bean&gt;&lt;!--自动代理--&gt;\n\nDefaultAdvisorAutoProxyCreator&lt;bean id=&quot;customerDao&quot; class=&quot;com.dongwenhao.demo10.CustomerDao&quot; /&gt;&lt;bean id=&quot;studentDao&quot; class=&quot;com.dongwenhao.demo10.StudentDaoImpl&quot;/&gt;&lt;bean id=&quot;myAroundAdvice&quot; class=&quot;com.dongwenhao.demo10.MyAroundAdvice&quot; /&gt;&lt;bean id=&quot;myBeforeAdvice&quot; class=&quot;com.dongwenhao.demo10.MyBeforeAdvice&quot;/&gt;&lt;bean id=&quot;myAdvisor&quot; class=&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt;    &lt;property name=&quot;pattern&quot; value=&quot;com.dongwenhao.demo10.StudentDaoImpl.save&quot; /&gt;    &lt;!--这里要配置到方法--&gt;    &lt;property name=&quot;advice&quot; ref=&quot;myAroundAdvice&quot; /&gt;    &lt;!--选择通知--&gt;&lt;/bean&gt;&lt;bean class=&quot;org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator&quot;/&gt;\n","categories":["Spring"],"tags":["Spring"]},{"title":"Spring_IOC入门","url":"/2020/03/07/Spring/Spring-IOC%E5%85%A5%E9%97%A8/","content":"\n引言：\n\nSpring_框架入门\n\n\n\n\n\nSpring是什么\nSpring是分层的 Java SE/EE应用 full-stack 轻量级开源框架, 以 IoC（Inverse Of Control： 反转控制）和 AOP（Aspect Oriented Programming：面向切面编程）为内核，提供了展现层 Spring MVC 和持久层 Spring JDBC 以及业务层事务管理等众多的企业级应用技术，还能整合开源世界众多著名的第三方框架和类库，逐渐成为使用最多的Java EE 企业应用开源框架\n\n\n轻量级：与EJB对比，依赖资源少\n分层：经典三层\nweb层：struts，spring-MVC\nservice层：spring\ndao层：hibernate，mybatis，jdbcTemplate\n\n\n核心：IOC和AOP\n\n看不懂一点也没关系，不影响看底下的内容\nSpring各模块一览浏览一下就好，都不认识没关系，有认识的那就更开心了\n\nIOC先来了解一下IOC的概念\n\nInverse Of Control 字面意思：控制反转\n\n那么就有两个问题：\n\nIOC控制什么？  控制对象的创建及销毁（生命周期）\nIOC反转什么？  将对象的控制权交给IOC容器\n\n为什么要用IOC为什么要使用IOC，要从开发的演变来说起。\n假设这样一个情形：张三要开一辆奥迪车回家\n根据**面向对象的思想(OOP)**，我们需要创建两个类：张三类和奥迪类\n\n奥迪车的类\npublic class Audi &#123;    public void start()&#123;        System.out.println(&quot;车辆启动&quot;);    &#125;    public void stop()&#123;        System.out.println(&quot;车辆停止&quot;);    &#125;    public void turnLeft()&#123;        System.out.println(&quot;车辆左转向&quot;);    &#125;    public void turnRight()&#123;        System.out.println(&quot;车辆右转向&quot;);    &#125;&#125;\n张三的类\npublic class ZhangSan &#123;    public void goHome()&#123;        Audi audi = new Audi();        audi.start();        audi.turnLeft();        audi.turnRight();        audi.stop();    &#125;&#125;\n张三是个程序员，最近996熬夜肝项目，挣了好多钱，又买了辆别克\n\n新建一个别克车的类\npublic class Buick &#123;    public void start()&#123;        System.out.println(&quot;车辆启动&quot;);    &#125;    public void stop()&#123;        System.out.println(&quot;车辆停止&quot;);    &#125;    public void turnLeft()&#123;        System.out.println(&quot;车辆左转向&quot;);    &#125;    public void turnRight()&#123;        System.out.println(&quot;车辆右转向&quot;);    &#125;&#125;\n但是张三的类我们还没改，如果要改的话，我们得把所有出现audi的地方改成buick，这显然是麻烦的，所以我们提出一个首行域\npublic class ZhangSan &#123;    Audi audi = new Audi();    public void goHome()&#123;        audi.start();        audi.turnLeft();        audi.turnRight();        audi.stop();    &#125;&#125;\n这样的话我们就可以轻松的改掉第一行为Buick audi = new Buick();，其他的保留原样，就实现了\n\n\n但我们转念一想：\n张三是程序员，只是需要一辆车，不同类型的车对他来说没什么不同\n所以我们要进行改动\n\n新增一个Car接口，让Audi和Buick都实现Car这个接口public interface Car &#123;    public void start();    public void stop();    public void turnLeft();    public void turnRight();&#125;\n张三的类，让Car从构造方法中传入public class ZhangSan &#123;    protected Car audi;    public ZhangSan(Car audi) &#123;        this.audi = audi;    &#125;    public void goHome()&#123;        audi.start();        audi.turnLeft();        audi.turnRight();        audi.stop();    &#125;&#125;\n这样我们就解决了刚才的两个问题，这就是面向接口的思想\n\n但此时，我们发现，有些不对劲，车还是由张三造的，作为一个996的程序员，他哪里会造什么车子呢\n所以我们需要新建一个CarFactory这个工厂类\npublic class CarFactory&#123;    public static Car getCar(Car car)&#123;        return new Car car;    &#125;&#125;\n这就是工厂模式，这样我们张三就和造车没有关系了，可以安安心心的敲代码了\n可是我们的张三和车厂有了关系（耦合），下次我们\n有了新的要求，我们还得去改代码，这样不符合**OCP原则(Open-Close Protocol)**，我们要求对程序扩展是open的，对修改程序代码时close的，尽量做到不修改程序的原码，而是修改对程序的扩展\n那么这时候，车辆该由谁来创建呢？ 该由IoC容器来创建，我们大大方方的交给Spring，让它来帮我们处理这个问题\nSpring其实就是使用工厂+反射+配置文件\n类似这样\n&lt;bean id=&quot;car&quot; class=&quot;com.xxx.xxx.Car&quot;&gt;&lt;/bean&gt;\nclass CarFactory&#123;    public static Obejct getBean(String id)    ...    反射&#125;\n\n\n再来认识IOC\nInverse Of Control 字面意思：控制反转\n\n他有两个特点\n\nIOC控制：  控制对象的创建及销毁（生命周期）\nIOC反转：  将对象的控制权交给IOC容器\n\n在官方文档中，有这么一段话\n\n IoC is also known as dependency injection (DI).\n\nIOC也被称为DI依赖注入，DI的意思是，对象的属性也可以在配置文件中定义，然后在Spring创建这个对象的同时，将这个对象所依赖的属性注入\n参考资料\n慕课网 及 官方文档\n\n","categories":["Spring"],"tags":["Spring"]},{"title":"Spring_AspectJ","url":"/2020/03/12/Spring/Spring-AspectJ/","content":"\n引言：\n\nSpring——AspectJ    \n\n\n\n\nAspectJ\n一个基于Java语言开发的AOP框架\n\n&lt;!--SpringAOP相关--&gt;&lt;dependency&gt;    &lt;groupId&gt;aopalliance&lt;/groupId&gt;    &lt;artifactId&gt;aopalliance&lt;/artifactId&gt;    &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-aop&lt;/artifactId&gt;    &lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--AspectJ--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt;    &lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.aspectj&lt;/groupId&gt;    &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;    &lt;version&gt;1.8.9&lt;/version&gt;&lt;/dependency&gt;\nAspectJ依赖于原本的AOP，所以需要以上四个\n然后再xml文件中配置\n&lt;!-- 开启AspectJ注解开发，自动代理 --&gt;&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;\n现在我们就能开始愉快的学习AspectJ了\n注解方式使用AspectJAspectJ同样提供了xml和注解两种方式，我们先来学习注解方式\nAspectJ提供的不同通知\n@Before 前置通知 相当于BeforeAdvice\n@AfterReturning 后置通知 相当于AfterReturningAdvice\n@Around 环绕通知 相当于MethodInterceptor\n@AfterThrowing 异常抛出通知 相当于ThrowAdvice\n@After 最终通知，不论是否发生异常，该通知都会执行\n@DeclareParents引介通知（暂不介绍）\n\n通知中定义切点语法：\nexecution(&lt;访问修饰符&gt; ? &lt;返回类型&gt; &lt;方法名&gt; (&lt;参数&gt;) &lt;异常&gt;)//访问修饰符可以省略\n\n例如\n//1. 匹配所有类public方法execution(public * *(..))//表示public 任意返回值* 任意方法名* 任意参数(..) 都会被返回//2. 匹配指定包下的所有类方法execution(* com.xxx.xxx.*(..))（不包含子包）execution(* com.xxx.xxx..*(..))（包含子包，多一个点）//第一个*表示任意返回类型//3. 匹配指定类所有方法execution(* com.xxx.xxx.AnClass.*(..))//4. 匹配实现特定接口所有类方法execution(* com.xxx.xxx.AnInterface+.*(..))（这里使用了+号表示所有子类）//5. 匹配所有save开头的方法execution(* save*(..))\n\n前置、后置通知&lt;!-- 开启AspectJ注解开发，自动代理 --&gt;&lt;aop:aspectj-autoproxy /&gt;&lt;bean id=&quot;productDao&quot; class=&quot;com.dongwenhao.demo11.ProductDao&quot; /&gt;&lt;bean id=&quot;myAspectAnno&quot; class=&quot;com.dongwenhao.demo11.MyAspectAnno&quot;&gt;&lt;/bean&gt;\n切点\npublic class ProductDao &#123;    public void save()&#123;        System.out.println(&quot;保存商品&quot;);    &#125;&#125;\n切面\n@Aspectpublic class MyAspectAnno &#123;    @Before(value = &quot;execution(* com.dongwenhao.demo11.ProductDao.*(..))&quot;)    public void before()&#123;        System.out.println(&quot;前置通知&quot;);    &#125;    @AfterReturning(value = &quot;execution(* com.dongwenhao.demo11.ProductDao.*(..))&quot;)    public void afterReturning()&#123;        System.out.println(&quot;后置通知&quot;);    &#125;&#125;\n测试类\n@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&quot;classpath:AspectJconfig.xml&quot;)public class SpringTest11 &#123;    @Resource(name = &quot;productDao&quot;)    private ProductDao productDao;    @Test    public void test()&#123;        productDao.save();    &#125;&#125;/*结果前置通知保存商品*/\n前置通知可以在方法中传入切入点对象，后置通知可以传入方法的返回值对象\n@Aspectpublic class MyAspectAnno &#123;    @Before(value = &quot;execution(* com.dongwenhao.demo11.ProductDao.*(..))&quot;)    public void before(JoinPoint joinPoint)&#123;        System.out.println(&quot;前置通知&quot; + joinPoint);    &#125;        @AfterReturning(value = &quot;execution(* com.dongwenhao.demo11.ProductDao.*(..))&quot;, returning = &quot;result&quot;)    public void afterReturning(Object result)&#123;        System.out.println(&quot;后置通知&quot; + result);    &#125;&#125;/*结果前置通知execution(void com.dongwenhao.demo11.ProductDao.save())保存商品*/\n\n环绕通知@Around(value = &quot;execution(* com.dongwenhao.demo11.ProductDao.*(..))&quot;)public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123;    System.out.println(&quot;环绕方法执行前&quot;);    Object proceed = joinPoint.proceed();    System.out.println(&quot;环绕方法执行后&quot;);    return proceed;&#125;\n环绕通知注解@Around，带有一个ProceedingJoinpoint，这个对象有一个方法proceed，如果不调用proceed方法，目标方法将会被拦截\n异常抛出通知@AfterThrowing(value = &quot;execution(* com.dongwenhao.demo11.ProductDao.*(..))&quot;,throwing = &quot;e&quot;)    public void afterThrowing(Throwable e)&#123;        System.out.println(&quot;异常抛出通知&quot; + e.getMessage());    &#125;\n正常情况下，异常抛出通知不会执行，只有当异常出现时，这个方法才会调用\n可以传入一个Throwable对象，获得异常的信息\n最终通知无论方法发生了什么，甚至有异常抛出，这个方法总会被执行\n@After(value = &quot;execution(* com.dongwenhao.demo11.ProductDao.*(..))&quot;)public void after()&#123;    System.out.println(&quot;最终通知&quot;);&#125;\n\n\n@Pointcut为切点命名@Pointcut(value = &quot;execution(* com.dongwenhao.demo11.ProductDao.*(..))&quot;)private void myPointcut()&#123;&#125;@Before(value = &quot;myPointcut()&quot;)public void before(JoinPoint joinPoint)&#123;    System.out.println(&quot;前置通知&quot; + joinPoint);&#125;\n为了简化开发，切入点不需要一个一个配置，我们可以使用这样的方式，配置一个切入点\n格式一般都是这样\n@Pointcut(value=&quot;execution(...)&quot;)private void pointcut()&#123;&#125;\n\n\nXML方式使用AspectJ这次我们写一个接口实现类的切点\n接口\npublic interface CustomerDao &#123;    public void save();&#125;\n实现类\npublic class CustomerImpl implements CustomerDao&#123;    @Override    public void save() &#123;        System.out.println(&quot;保存数据&quot;);    &#125;&#125;\n切面\npublic class MyAspectXml &#123;    public void before()&#123;        System.out.println(&quot;前置通知&quot;);    &#125;&#125;\n配置\n&lt;bean id=&quot;customerDao&quot; class=&quot;com.dongwenhao.demo12.CustomerImpl&quot; /&gt;&lt;bean id=&quot;aspectXml&quot; class=&quot;com.dongwenhao.demo12.MyAspectXml&quot;&gt;&lt;/bean&gt;&lt;aop:config&gt;    &lt;aop:pointcut id=&quot;pointcut1&quot; expression=&quot;execution(* com.dongwenhao.demo12.CustomerDao.*(..))&quot; /&gt;    &lt;aop:aspect ref=&quot;aspectXml&quot;&gt;        &lt;aop:before method=&quot;before&quot; pointcut-ref=&quot;pointcut1&quot;&gt;&lt;/aop:before&gt;    &lt;/aop:aspect&gt;&lt;/aop:config&gt;\n这里以前置通知示例，其他通知同理可以写出\n","categories":["Spring"],"tags":["Spring"]},{"title":"注解","url":"/2021/11/19/Spring/SpringBoot%E5%B8%B8%E7%94%A8%E7%9A%84%E6%B3%A8%E8%A7%A3/","content":"\n引言：什么是注解？注解的本质是什么？自己实现一个注解吧！顺便介绍一下项目内Spring的常用的注解\n\n\n\n\n\n注解Java注解注解的基本概念\n什么是注解？\n\n几种理解注解的方式：\n\n注解是一种标签：插入到源码中，可以与其他工具配合使用来完成一些工作，它们可以提供用来完整地描述程序所需的信息，而这些信息是无法用Java来表达的\n注解是一种接口：注解的本质是一个接口\n\n\n为什么引入了注解？\n\n\n注解在一定程度上是在把元数据与源代码文件结合在一起，而不是保存在外部文档中这一大的趋势之下所催生的\n\n受到C#语言的启发\n（其实就是迫于C#语言带来的压力：例如检测是否重写override这个功能C#有一个关键字，而在Java中，@Override是可选择的）\n\n\n创建注解编写注解的语法如下：\n// 注解需要使用 @interface 来标记这是一个注解public @interface MyAnnotation &#123;    // 在注解内，这些值称为“元素”    int value() default 0;    String description() default &quot;&quot;;&#125;\n\n可以看到，使用了@interface这个标记，并且注解元素的定义与定义接口方法类似\n创建一个注解：\n\n使用@interface标记这是一个注解\n添加元素的语法如同添加一个接口方法（如果一个元素都不给，这种注解称为标记注解）\n使用default可以给这个元素加一个默认值\n\n注解的本质我们反编译一下上面的那个注解，javap -c MyAnnotation.class，就能看到注解的真实面目：\n// 所有的注解默认继承了Annotationpublic interface test.annotation.MyAnnotation     extends java.lang.annotation.Annotation &#123;    // 所谓的元素就是一个 public abstract修饰的方法    public abstract int value();    public abstract java.lang.String description();&#125;\n\n重点：\n\n所有注解默认继承自java.lang.annotation.Annotation\n注解的元素其实就是一个接口方法\n默认值是动态计算而来，没有与注解存储在一起！！（这也是反编译后我们找不到有关默认值设置的原因）\n\nJDK的注解JDK给我们提供了一些注解\n父接口Annotation所有接口都默认继承了这个接口！\n这个类java.lang.annotation.Annotation有四个方法：\npublic interface Annotation &#123;    boolean equals(Object obj);    int hashCode();    String toString();        // 返回Class对象    Class&lt;? extends Annotation&gt; annotationType();&#125;\n\n元注解\n元注解是JDK提供的，专门用来注解其他注解的注解（绕口令）\n\n有四种元注解：\n\n@Target：标记一个注解可以标记在什么地方\n@Retention：标记一个注解的级别\n@Documented：将此注解包含在JavaDoc内\n@Inherited：允许子类继承父类中的注解\n\n1、@Target可以标记的类型：\n由一个枚举类ElementType给出\npublic enum ElementType &#123;    TYPE, // 类（包括枚举）、接口（包括注解）    FIELD,// 域（或者叫属性）    METHOD,// 方法    PARAMETER,// 参数    CONSTRUCTOR,// 构造方法    LOCAL_VARIABLE,// 局部变量    ANNOTATION_TYPE,// 注解类型    PACKAGE,// 包（没错，可以标记包，但是要在特定的一个文件内）    TYPE_PARAMETER,//JDK1.8新增    TYPE_USE// JDK1.8新增&#125;\n\n例如这样使用：\n@Target(&#123;ElementType.METHOD, ElementType.FIELD&#125;)// 可以使用逗号隔开，这样表示我这个注解只能标记方法和属性// 如果只有一个，可以去掉&#123;&#125;，如下// @Target(ElementType.TYPE)public @interface MyAnnotation &#123;    ...&#125;\n\n如果一个注解没有被@Target标记，表示这个注解可以标记在任何地方！\n2、注解的级别：\n同样由一个枚举类RetentionPolicy给出：\n\nSOURCE：注解将被编译器丢弃\nCLASS：注解在class文件可用，但是会被VM丢弃\nRUNTIME：VM会保留这个注解（标记为RUNTIME才可以用反射获取）\n\npublic enum RetentionPolicy &#123;    SOURCE,    CLASS,    RUNTIME&#125;\n\n其他常见的JDK注解比如：\n\n@Override：标记方法使用，可以看到级别为SOURCE，表示这个注解编译时期就会被丢弃\n@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override &#123;&#125;\n@Deprecated：表示你使用的类或方法等已过期，不推荐使用\n@Documented@Retention(RetentionPolicy.RUNTIME)@Target(value=&#123;CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, PARAMETER, TYPE&#125;)public @interface Deprecated &#123;&#125;\n@SuppressWarnings：关闭不当的编译器警告信息\n@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.SOURCE)public @interface SuppressWarnings &#123;    String[] value();&#125;\n\n注解小实战\n要求：实现一个注解，对于标记了这个注解的方法在运行时会打印Hello 加对应的参数！\n\n注解：\n@Target(ElementType.METHOD)// 标记方法@Retention(RetentionPolicy.RUNTIME)// RUNTIME才可以被反射获取public @interface Hello &#123;    String value() default &quot;&quot;;&#125;\n\n给方法加注解：\npublic class User &#123;    @Hello(&quot;小明&quot;)    public void xiaoMing()&#123;&#125;    @Hello(&quot;小军&quot;)    public void xiaoJun()&#123;&#125;&#125;\n\n处理器：\npublic static void main(String[] args) &#123;    User user = new User();    Method[] methods = user.getClass().getDeclaredMethods();    for (Method method : methods) &#123;        Hello ann = method.getAnnotation(Hello.class);        if (ann != null) &#123;            // 非空说明此方法有注解            System.out.println(&quot;Hello&quot; + ann.value());        &#125;    &#125;&#125;/* 输出：    Hello小明    Hello小军*/\n\nSpring注解Bean相关注解\n交给Spring管理\n\n\n@Component：下面三个其实与上面的@Component一样，只是分工明确\n\n@Service：标记业务层，业务层经常需要注入Dao层的Bean\n\n@Repository：标记Dao层，表明这个类可以实现CRUD的功能\n\n@Controller：标记Controller，需要注入Service的Bean\n\n@RestController：此注解相当于@ResponseBody与@Controller\n\n@Configuration：配置类\n\n\n\n依赖注入\n\n\n@Autowired：默认按照类型ByType匹配\n与Qualifier(&quot;name&quot;)配合使用，可以实现与@Resource一样的按名称检索的功能\n加上required=false，表示找不到Bean也不会报错\n\n\n@Resource：默认按照名称ByName装配（此注解并不属于Spring，而是JDK自带的注解）\n\n\nBean的作用域\n\n@Scope：标记Bean的作用范围\n\nsingleton单例模式：全局有且仅有一个实例（默认就是单例模式）\nprototype原型模式：每次获取Bean的时候会有一个新的实例\nrequest ：表示该针对每一次HTTP请求都会产生一个新的bean，仅在请求中有效\nsession ：表示该针对每一次HTTP请求都会产生一个新的bean，在整个会话内有效\nglobalsession ：类似于标准的HTTP Session作用域，整个web应用有效\n\nHTTP请求SpringMVC的注解：\n\n@RequestMapping 注解，有三个元素：\nname：为映射地址指定别名\nvalue：默认属性，映射请求到一个方法或类上\nmethod：可以选择 POST、GET等请求方式\n\n\n@GetMapping：相当于@RequestMapping(method=RequestMethod.GET)，下面三个同理\n@PostMapping\n@PutMapping\n@DeleteMapping\n\n配置启动\n@ComponentScan\n配置扫描包的路径，相当于你之前在 xml中配置 bean\n\n@Configuration\n允许在上下文中注册额外的bean或导入额外的配置类\n\n@SpringBootApplication：SpringBoot的启动类需要添加的注解\n这个注解相当于三个注解：\n\n@EnableAutoConfiguration：启用自动装配机制（即如果你有）\n@ComponentScan\n@SpringBootConfiguration：其实就是@Configuration注解\n\n\n@EnableAutoConfiguration：类级别的注解，这个注解告诉 Spring Boot 根据添加的jar依赖猜测你想如何配置Spring\n非侵入式自动配置：即SpringBoot会自动为你装配，如果你有自己的配置，会优先使用你的配置\n\n\n参考资料\n《Java编程思想》一如既往的牛！\n《Java核心技术 卷二》讲的略差一些\n\n","categories":["Spring","SpringBoot"],"tags":["Java","Spring","注解"]},{"title":"SpringMVC","url":"/2021/06/03/Spring/SpringMVC/","content":"\n引言：\n\nSpringMVC框架学习\n\n\n\n\n\n\nSpringMVCSpringMVC初识\nSpringMVC是Spring提供的一个实现了Web MVC设计模式的轻量级Web框架\n\n额外需要两个包：\n&lt;!--  SpringMVC框架  --&gt;&lt;dependency&gt;\t&lt;groupId&gt;org.springframework&lt;/groupId&gt;\t&lt;artifactId&gt;spring-web&lt;/artifactId&gt;\t&lt;version&gt;4.3.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;\t&lt;groupId&gt;org.springframework&lt;/groupId&gt;\t&lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;\t&lt;version&gt;4.3.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;\n\nSpringMVC工作流程配置MVC四个主要的类MVC框架内部主要工作由四个构成，无需我们操作，只需要配置即可：\n\nDispatcherServlet前端控制器\nHandlerMapping处理器映射器\nHandlerAdapter处理器适配器\nViewResolver视图解析器\n\n以一个简单的demo来看他们的作用：\n简单的Demo\nweb.xml配置文件\n&lt;web-app&gt;    &lt;servlet&gt;        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;        &lt;servlet-class&gt;         &lt;!-- 配置前端控制器--&gt;               org.springframework.web.servlet.DispatcherServlet        &lt;/servlet-class&gt;        &lt;init-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;!-- 该文件的配置见下面--&gt;            &lt;param-value&gt;classpath:springmvc-config.xml&lt;/param-value&gt;        &lt;/init-param&gt;        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;    &lt;/servlet&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;        &lt;url-pattern&gt;/&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;&lt;/web-app&gt;\nspringmvc-config.xml配置文件\n&lt;!-- beans中配置 --&gt;     &lt;!-- handler 处理器：我们在此进行逻辑业务代码的实现 --&gt;    &lt;bean name=&quot;/myController&quot; class=&quot;com.dwh.controller.myController&quot; /&gt;     &lt;!-- handlerMapping 处理器映射器配置 --&gt;    &lt;bean class=&quot;org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping&quot; /&gt;     &lt;!-- handlerAdapter 处理器适配器配置--&gt;    &lt;bean class=&quot;org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter&quot;/&gt;     &lt;!-- ViewResolver 视图解析器配置 --&gt;    &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;/&gt;\nmyController：继承Controller接口，这就是我们所说的处理器handler\npublic class myController implements Controller &#123;    public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception &#123;        ModelAndView modelAndView = new ModelAndView();        modelAndView.addObject(&quot;msg&quot;,&quot;第一个SpringMVC程序&quot;);        modelAndView.setViewName(&quot;/WEB-INF/jsp/first.jsp&quot;);        return modelAndView;    &#125;&#125;\nfirst.jsp返回的JSP页面\n&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; isELIgnored=&quot;false&quot;%&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    $&#123;msg&#125;&lt;/body&gt;&lt;/html&gt;\ntomcat运行，访问http://localhost:8080/myController就会返回第一个SpringMVC程序这几个字了\n\n\nMVC工作流程如图：（图中橙色标记的是框架内部的实现，白色的（view与handler）是我们程序员需要编写的）\n\n流程详述：\n\n用户在浏览器，输入网址http://localhost:8080/myController后，请求会被SpringMVC的前端控制器(DispatcherServlet)拦截\n前端控制器拦截后，调用处理器映射器（HandlerMapping）\n处理器映射器根据URL，找到具体的处理器，生成处理器对象及处理器拦截器，一并返回给前端控制器\n前端控制器选择合适的处理器适配器（HandlerAdapter）\n处理器适配器调用处理器（Handler）（也被称为后端控制器），返回一个ModelAndView对象\n返回给HA\n返回给DS\n根据ModelAndView选择合适的视图解析器（ViewResolver）\nVR解析后，向DS发送具体的View\nDS对View进行渲染（将数据填充至视图中）\n显示在浏览器，展示给用户\n\nSpringMVC核心类前端控制器DispatcherServlet配置详解在web.xml中配置\n  &lt;servlet&gt;      &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;      &lt;servlet-class&gt;          org.springframework.web.servlet.DispatcherServlet      &lt;/servlet-class&gt;      &lt;init-param&gt;          &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;          &lt;param-value&gt;classpath:springmvc-config.xml&lt;/param-value&gt;      &lt;/init-param&gt;      &lt;!-- init-param 配置后，启动时加载对应路径下的配置文件；如果不配置此项，默认寻找 servletName-config.xml 文件--&gt;      &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;      &lt;!-- load-on-startup 为1表示启动时加载；不配置此项表示第一次访问时加载--&gt;  &lt;/servlet&gt;  &lt;servlet-mapping&gt;      &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;      &lt;url-pattern&gt;/&lt;/url-pattern&gt;  &lt;/servlet-mapping&gt;\n\nController相关注解@Controller注解@Controller注解可以帮助我们快速的实现后端控制器，而不需要再实现Controller接口重写handleRequest方法\n如下：\n@Controllerpublic class myController&#123;\t....&#125;\n\n@RequestMapping注解可以配置在类或是方法上，指明URL访问所调用的处理器\n@Controller@RequestMapping(&quot;/hello&quot;)public class myController&#123;    @RequestMapping(&quot;/userService&quot;)    public String userService(Model model)&#123;        model.addAttribute(&quot;msg&quot;,&quot;你好啊&quot;);        return &quot;first&quot;;    &#125;&#125;\n\n这样就可以访问http://localhost:8080/hello/userService，就会调用对应方法进行处理\n@RequestMapping有很多属性，这里提几个重要的属性：\n\nname：为映射地址指定别名\nvalue：默认属性，映射请求到一个方法或类上\nmethod：可以选择POST、GET等请求方式\n\n例如：\n@RequestMapping(&quot;/userService&quot;)\n\n等同于\n@RequestMapping(value = &quot;/userService&quot;)\n\n而且\n@RequestMapping(value = &quot;/userService&quot;,method=RequestMethod.GET)\n\n等同于\n@GetMapping(&quot;/userService&quot;)\n\nPostMapping、PutMapping等同理\n视图解析器ViewResolver配置在springmvc-config.xml文件中配置：\n&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;    &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot; /&gt;    &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt;&lt;/bean&gt;\n\n配置prefix与suffix就可以更改返回字符串的内容\n比如：\n@RequestMapping(&quot;/userService&quot;)public String userService(Model model)&#123;     model.addAttribute(&quot;msg&quot;,&quot;你好啊&quot;);     return &quot;first&quot;;&#125;\n\nSpringMVC支持的返回类型有很多种，最重要的有三种：\n\nModelAndView：可以添加Model数据\nString：跳转页面，但不能携带数据\nVoid：多用在异步请求\n\nString类型只可以跳转页面，配置VR就可以设置它的前缀与后缀，进而访问到对应的Jsp文件\n比如这里就访问到：/WEB-INF/jsp/first.jsp文件\n而且我们也能看到，String虽然不能携带数据，但是我们可以传入Model参数，间接传递数据\n重定向与请求转发​        SpringMVC中使用返回类型为String的方法来进行重定向与转发，只需要更改返回值即可\n重定向：\npublic String update(Model model)&#123;    ....    return &quot;redirect:first&quot;;&#125;\n\n请求转发：\npublic String update(Model model)&#123;    ....    return &quot;forward:first&quot;;&#125;\n\n\n\n扫描配置为了使我们的注解起作用，还需要进行配置扫描\n如下：\n&lt;mvc:annotation-driven/&gt;&lt;!--  开启Controller等注解  --&gt;&lt;context:component-scan base-package=&quot;com.dwh&quot; /&gt;\n\n\n不配置&lt;mvc:annotation-driven/&gt;有可能会扫描不到Controller等注解，进而导致404报错\n注意不要给一个handler映射多个路径\n\n以上可以解决问题，注意base-package配置你对应的位置\n","categories":["Spring"],"tags":["Spring","SpringMVC"]},{"title":"Java8新特性2","url":"/2020/08/23/Stream/Java8%E6%96%B0%E7%89%B9%E6%80%A72/","content":"\n引言：\n\nJava8新特性\n\n\n\nJava8新特性2新特性概览\nLambda表达式\n函数式接口\n方法引用与构造器的引用与数组引用\nStream API\n\n1、2、3、请看 Java8新特性1\n强大的StreamAPI\nStream 流：\n是一个数据渠道，可以对数据源（集合、数组）的数据进行一系列的操作。\n（集合讲的是数据，流讲的是计算）\n\n注意：\n\nStream 不会存储元素\nStream 不会改变源操作对象\nStream 是延迟执行的，等到需要的结果出现后才会执行\n\n步骤：\n\n创建Stream\n中间操作\n终止操作（中断操作）\n\n\n创建Stream流的四种方法 //1. 可以使用Collection集合提供的Stream()或parallelStream() （一个是串行流、一个是并行流）ArrayList&lt;String&gt; strings = new ArrayList&lt;&gt;();Stream&lt;String&gt; stream = strings.stream();//2. 可以使用Arrays的静态方法stream获取流Integer[] integers = new Integer[10];Stream&lt;Integer&gt; stream1 = Arrays.stream(integers);//3. 通过Stream类中的静态方法ofStream&lt;Integer&gt; stream2 = Stream.of(integers);//4. 创建无限流：会一直生成// 迭代Stream&lt;Integer&gt; stream3 = Stream.iterate(0, (x) -&gt; x + 2);// 需要两个参数：T seed 种子，UnaryOperator单元运算，继承了Function，给一个T，返回一个T// 可以加上中间操作来终止stream3.limit(10);// 生成// 参数是一个SupplierStream&lt;Double&gt; generate = Stream.generate(() -&gt; Math.random());generate.limit(10);\n\n\n\nStream的中间操作筛选与切片：\nfiter——接收lambda，从流中排除某些元素\nlimit——截断流，使其元素不超过给定的数量\nskip(n)——跳过元素，返回一个去除了前n个元素的流。若流元素不足n个，则返回一个空流，与limit(n)互补\ndistinct——筛选，通过流所生成的元素的hashCode()和equals()去除重复元素\n\n// 中间操作不会进行任何的处理，而在终止操作时，一次性全部处理。（称为：惰性求值）// 中间操作：Stream&lt;Student&gt; studentStream = students        .stream()        .filter(x -&gt; &#123;            System.out.println(&quot;中间操作&quot;);            return x.getAge() &gt; 30;        &#125;);// 终止操作：一次性执行全部内容studentStream.forEach(System.out::println);// limitStream&lt;Student&gt; stream1 = students.stream().limit(2);stream1.forEach(System.out::println);//skipStream&lt;Student&gt; stream2 = students.stream().skip(2);stream2.forEach(System.out::println);// distinct去重，需要重写hashCode和equals方法Stream&lt;Student&gt; stream3 = students.stream().distinct();stream3.forEach(System.out::println);\n\n\n\n映射\nmap——接收一个lambda，将元素转换为其他形式或提取信息。提取一个函数作为参数，该函数会被应用到每一个元素上，并将其映射为一个新的元素。\nflatMap——接收一个函数作为参数，将流中的每一个值都换成另一个流，然后把所有流连接成一个流\n\nList&lt;String&gt; strings = Arrays.asList(&quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot;);Stream&lt;String&gt; stream1 = strings.stream()        .map(x -&gt; x.toUpperCase());// map 是将该 流 添加到流中去stream1.forEach(System.out::println);System.out.println(&quot;-------flatMap------&quot;);// 返回一个流Function&lt;String,Stream&gt; fun = (x) -&gt; strings.stream();// flatMap使每一个流中的元素都添加到新流中Stream stream2 = strings        .stream()        .flatMap(fun::apply);stream2.forEach(System.out::println);System.out.println(&quot;--------map---------&quot;);// 对比map 会让流这个对象添加到新流中Stream stream3 = strings        .stream()        .map(fun::apply);stream3.forEach(System.out::println);\n\n运行结果如下：\n\n\n\n\n排序\n排序：\nsorted()——自然排序（Comparable），按照字典序\nsorted(Comparator com)——定制排序（Comparator）\n\n排序操作：\nList&lt;String&gt; strings = Arrays.asList(&quot;ccc&quot;, &quot;bbb&quot;, &quot;aaa&quot;);strings.stream().sorted().forEach(System.out::println);// 按字典序排列// 自定义排序：先按年龄排序，再按姓名排序students.stream()        .sorted((e1,e2)-&gt;&#123;            if(e1.getAge().equals(e2))&#123;                return e1.getName().compareTo(e2.getName());            &#125;else &#123;                return e1.getAge().compareTo(e2.getAge());            &#125;        &#125;)        .distinct()        .forEach(System.out::println);\n\n\n\n终止操作查找与匹配：\n查找与匹配操作：\nallMatch ——是否匹配所有元素\nanyMatch——是否至少匹配一个元素\nnoneMatch—— 是否没有匹配所有元素\nfindFirst——返回第一个元素，返回值是一个Optional对象，该对象可以防止为null\nfindAny——返回当前流中的任意元素\ncount——返回流中元素的总个数\nmax——返回流中最大值\nmin——返回流中最小值\n\n数据：\nList&lt;Student&gt; students =  Arrays.asList(        new Student(&quot;李白&quot;,15),        new Student(&quot;杜甫&quot;,27),        new Student(&quot;白居易&quot;,96),        new Student(&quot;孟浩然&quot;,77),        new Student(&quot;孟浩然&quot;,77),        new Student(&quot;孟浩然&quot;,77));\n\n\n\n// 是否所有人的年龄都是27岁？boolean b1 = students.stream()        .allMatch(x -&gt; x.getAge().equals(27));System.out.println(b1);// false// 是否有人的年龄是27岁？boolean b2 = students.stream()        .anyMatch(x -&gt; x.getAge().equals(27));System.out.println(b2);// true// 是否没有人的年龄是27岁？boolean b3 = students.stream()        .noneMatch(x -&gt; x.getAge().equals(27));System.out.println(b3);// falseOptional&lt;Student&gt; first = students.stream().sorted((e1, e2) -&gt; &#123;    return -e1.getAge().compareTo(e2.getAge());&#125;).findFirst();//first.orElse( other ); 这个方法的意思是：如果这个类为空，就可以使用other来替代System.out.println(first);Optional&lt;Student&gt; any = students.parallelStream().findAny();System.out.println(any);// 返回流中的个数long count = students.stream().count();// max和min中的参数也是predictOptional&lt;Student&gt; max = students.stream().max((e1, e2) -&gt; &#123;    return e1.getAge().compareTo(e2.getAge());&#125;);System.out.println(max);\n\n\n\n归约与收集\n归约：\nreduce(T identity, BinaryOperator)\nreduce(BinaryOperator)\n可以将流中的元素反复结合起来得到一个值。\n\n// 常配合 map 使用，这里将Student中每一个元素的年龄相加起来Optional&lt;Integer&gt; reduce = students.stream()        .map(Student::getAge)        .reduce(Integer::sum);System.out.println(reduce.get());\n\nmap-reduce组合常用在大数据当中\n\n收集：\ncollect——将流转换为其他形式，接收一个Collector接口的实现，用于给Stream中元素做汇总的方法\n\n// 把所有的名字放到list中List&lt;String&gt; collect = students        .stream()        .map(Student::getName)        .collect(Collectors.toList());collect.forEach(System.out::println);// 把所有的名字放到Hashset中HashSet&lt;String&gt; collect1 = students.stream()        .map(Student::getName)        .collect(Collectors.toCollection(HashSet::new));collect1.forEach(System.out::println);\n\n收集还有很多种方式，可以求最大最小等等，这里不再细说。\n并行流\n并行流：\n将一个内容分为多个数据块，使用不同的线程分别处理每个数据块的流，并且含有工作窃取，即一个核对应的任务完成后，会从其他核偷取任务来执行，大大提高了执行效率\n使用parallel切换为并行流\n使用sequential切换为串行流\n\n在之前有一个ForkJoin框架，这个框架就实现了对一个任务的拆分与合并，大大提高了处理速度。\n在Java8之后我们可以使用并行流来处理（底层其实还是ForkJoin框架）\nInstant start = Instant.now();LongStream.range(0,100000000000L)    .parallel()    .reduce(0,Long::sum);Instant end = Instant.now();System.out.println(Duration.between(start,end).toMillis());\n\n运算一千亿个数循环相加，用时12s，下图可见我的CPU利用率基本占满\n","categories":["Stream"],"tags":["Java8","Stream"]},{"title":"Java8新特性1","url":"/2020/08/23/Stream/Java8%E6%96%B0%E7%89%B9%E6%80%A71/","content":"\n引言：\n\nJava8新特性\n\n\n\n\nJava8新特性1新特性概览\nLambda表达式\n函数式接口\n方法引用与构造器的引用与数组引用\nStream API\n\nLambda表达式基础语法新的操作符：-&gt;\n​    左边：表达式的参数列表\n​    右边：表达式所需要实现的功能，称为Lambda体\n/** * Lambda表达式基础语法： * * 新的操作符：-&gt; * 左边：表达式的参数列表 * 右边：表达式所需要实现的功能，称为Lambda体 * * 语法格式一：无参，无返回值 * () -&gt; System.out.println(&quot;Hello&quot;); * */@Testpublic void grammerBase1()&#123;    //原来    Runnable run1 = new Runnable() &#123;        @Override        public void run() &#123;            System.out.println(&quot;hello&quot;);        &#125;    &#125;;    //使用Lambda表达式    Runnable r2 = () -&gt; System.out.println(&quot;hello&quot;);&#125;/** * 语法格式二：一个输入，无返回值 * 一个输入可以省略小括号 */@Testpublic void grammerBase2()&#123;    Consumer&lt;String&gt; con = x -&gt; System.out.println(x);    // 一个参数 -&gt; 左侧的小括号可以省略    // 等于： (x) -&gt; System.out.println(x)    con.accept(&quot;哈哈哈&quot;);&#125;/** * 语法格式三：两个以上的参数，有返回值，有多条语句 * 参数逗号隔开 * 返回值使用return返回 * 多条语句使用大括号包裹 */@Testpublic void grammerBase3()&#123;    Comparator&lt;Integer&gt; com = (x,y) -&gt; &#123;        System.out.println(&quot;函数式接口&quot;);        return Integer.compare(x,y);    &#125;;&#125;/** * 语法格式四：lambda体中只有一条语句 * * return和大括号都可以省略不写 */@Testpublic void grammerBase4()&#123;    // 使用grammerBase3的例子    Comparator&lt;Integer&gt; com = (x,y) -&gt; Integer.compare(x,y);&#125;/** * 语法格式五：参数的参数类型是否可写 * Lambda表达式的参数类型可以不写，JVM可以通过上下文推断出数据类型，称为类型推断 * 类型推断例如： *      String strs[] = &#123;&quot;123&quot;&#125;; 这样可以 * *      String strs[]; *      strs = &#123;&quot;123&quot;&#125;;          这样就不行了 * * 这就是因为JVM帮我们做了类型推断，自动推断&#123;&#125;内都是string类型，但是分开写，没有了上下文环境，就推断不出来了 * 通用的例子还有： *      ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); *      new 后面的尖括号内我们可以不写泛型，也是因为有着类型推断 */@Testpublic void grammerBase5()&#123;    // 使用grammerBase4的例子    // 如果要写参数类型，那么两个都要写    Comparator&lt;Integer&gt; com = (Integer x,Integer y) -&gt; Integer.compare(x,y);&#125;\n\n注意需要函数式接口的支持！！\n所谓函数式接口，就是只含有一个方法的接口，大于一个方法就不能使用Lambda表达式了\n可以使用注解@FunctionalInterface来检测一个接口是不是函数式接口\n例如：\n@FunctionalInterfacepublic interface MyInterface &#123;    public boolean test(Integer e);&#125;\n\n\n\n使用函数式接口\n@FunctionalInterfacepublic interface MyOpration &#123;    Integer it(Integer num);&#125;\n\n\n\npublic Integer calculate(Integer num , MyOpration myOpration)&#123;    return myOpration.it(num);&#125;\n\n使用\n@Testpublic void useLambda()&#123;    // 实现 平方    Integer calculate = calculate(5, x -&gt; x * x);    System.out.println(calculate);&#125;\n\n\n\n函数式接口函数式接口不需要我们来实现（除非及其特殊的情况），共有四个内置的核心函数式接口\n\nConsumer&lt;T&gt;：消费型接口\n\n返回值：void accept(T e)\n没有返回值，所以叫做消费型接口\n\n\nSupplier&lt;T&gt;：供给型接口\n\n返回值：T get()\n不需要输入，会返回一个对象，所以叫供给型接口\n\n\nFunction&lt;T,R&gt;：函数型接口\n\n返回值：R apply(T t)，R是返回值类型\n一个输入，一个输出\n\n\nPredicate&lt;T&gt;：断言型接口\n\n返回值：Boolean test(T)\n返回值是一个布尔类型\n\n\n\n其实相关的函数式接口还有很多，例如两个参数输入，一个参数输出的类型等等\n/** * 消费型接口： * 一个输入，没有输出 */@Testpublic void consumerTest()&#123;    lunch(100.0, x-&gt; System.out.println(&quot;今天午饭吃了&quot;+x+&quot;元饭&quot;));&#125;public void lunch(double money , Consumer&lt;Double&gt; con)&#123;    con.accept(money);&#125;/** * 供给型接口： * 产生指定个数的随机整数，放入集合当中 */@Testpublic void supplierTest()&#123;    List&lt;Integer&gt; numList = getNumList(5, () -&gt; (int)(Math.random() * 100));    numList.forEach(System.out::println);&#125;public List&lt;Integer&gt; getNumList(int num, Supplier&lt;Integer&gt; supplier)&#123;    List&lt;Integer&gt; list = new ArrayList&lt;&gt;();    for(int i =0;i&lt;num;i++)&#123;        list.add(supplier.get());    &#125;    return list;&#125;/** * 函数型接口： * 处理字符串 */@Testpublic void functionTest()&#123;    String s = strHandler(&quot;你好小朋友，\\t\\t\\t&quot;, str -&gt; str.trim());    System.out.println(s);&#125;public String strHandler(String str, Function&lt;String,String&gt;fun)&#123;    return fun.apply(str);&#125;/** * 断言型接口： * 处理字符串，将满足条件的字符串放入集合中去 */@Testpublic void predicateTest()&#123;    List&lt;String&gt; strings = Arrays.asList(&quot;你好&quot;, &quot;小朋友&quot;, &quot;1&quot;, &quot;85&quot;, &quot;学习学习学习&quot;);    List&lt;String&gt; res = filterList(strings, s -&gt; s.length() &gt;= 3);    res.forEach(System.out::println);&#125;public List&lt;String&gt; filterList(List&lt;String&gt; list , Predicate&lt;String&gt; pre)&#123;    List&lt;String&gt; strList = new ArrayList&lt;&gt;();    for (String s : list) &#123;        if(pre.test(s))&#123;            strList.add(s);        &#125;    &#125;    return strList;&#125;\n\n\n\n方法引用与构造器的引用与数组引用方法引用\n方法引用：\n如果Lambda表达式中的内容已经实现了，我们可以使用方法引用（可以理解为方法引用是Lambda表达式的另外一种表现形式）\n\n语法格式：\n\n对象 :: 实例方法名\n类 :: 静态方法名\n类 :: 实例方法名\n\nStudent libai = new Student(&quot;李白&quot;, 345);// 普通的使用方法Consumer&lt;String&gt; con1 = x -&gt; System.out.println(x);con1.accept(libai.getName());// 实例::方法名Supplier&lt;Integer&gt; sup = libai::getAge;System.out.println(sup.get());// 类::静态方法名//原来： Comparator&lt;Integer&gt; com = (x,y)-&gt;Integer.compare(x,y);Comparator&lt;Integer&gt; com = Integer::compareTo;// 类::实例方法名// 使用注意：第一个参数是实例方法的调用者，第二个参数是实例方法的参数时 才 可以使用类::实例方法名BiPredicate&lt;String,String&gt; bp1 = (x,y) -&gt; x.equals(y);BiPredicate&lt;String,String&gt; bp2 = String::equals;\n\n\n\n构造器引用\n构造器引用：使用类的构造器 ClassName::new\n\n@Testpublic void constructCiteTest()&#123;    // 原来    Supplier&lt;Student&gt; sup1 = ()-&gt; new Student();    // 构造器    Supplier&lt;Student&gt; sup2 = Student::new;&#125;\n\n如果构造器有很多，那么调用的构造器会是前面函数的参数的个数\n// 调用 Student(String name, Integer age) 方法BiFunction&lt;String,Integer,Student&gt; fun = Student::new;\n\n\n\n数组引用\n数组引用：\nType::new\n\n// 正常的lambdaFunction&lt;Integer,String[]&gt; fun1 = x -&gt; new String[x];String[] apply1 = fun1.apply(10);// 数组引用Function&lt;Integer,String[]&gt; fun2 = String[]::new;String[] apply2 = fun2.apply(10);\n\n\n\n","categories":["Stream"],"tags":["Java8","Stream"]},{"title":"Tomcat","url":"/2019/09/03/Tomcat/Tomcat/","content":"\n引言：\n\n服务器软件Tomcat\n\n\n\n\n\n服务器服务器：安装了服务器软件的计算机\n服务器软件：接收客户的请求，处理请求，做出响应\nweb服务器软件\n在web服务器软件中，可以部署web项目，让用户通过浏览器访问这些项目\n\nweb的服务器软件也叫web容器\n\n常见JavaWeb服务器软件\n\nwebLogic :Oracle公司，大型的JavaEE服务器，收费，支持所有的JavaEE规范\nwebSphere：IBM公司，大型的JavaEE服务器，收费\nJBOSS：JBOSS公司，同上\nTomcat：Apache基金组织，中小型的JavaEE服务器，仅仅支持少量的JavaEE规范，开源，免费\n\n\n\n（JavaEE：Java语言在企业级开发中使用的技术规范的总和，一共规定了13项大的规范）\nTomcatTomcat目录结构\nbin：可执行文件\nconf：配置文件\nlib：依赖jar包\nlogs：日志文件\ntemp：临时文件\nwebapps：存放web项目\nwork：存放运行时数据\n\n操作启动：bin目录下的starup.bat，双击运行该文件\n浏览器输入http://localhost:8080访问\n可能遇见的问题\n黑窗口闪退\n  原因：没有正确配置JAVA_HOME环境变量\n  解决：配置JAVA_HOME\n\n打开报错\n  原因：端口号被占用\n  解决：\n\n找到占用的端口号杀死该进程 cmd中输入netstat -ano找到占用端口号的程序，记下它的PID，打开任务管理器找到对应PID结束进程\n修改Tomcat自身的端口号 conf文件夹下的server.xml文件，找见connector标签，更改它的port，一般改为80\n\n\n\n关闭\n正常关闭：双击shutdown.bat或者输入CTRL+C\n\n强制关闭：点击启动窗口的关闭按钮\n\n\n部署\n部署项目的方式\n\n\n直接将项目放到webapps目录下即可\n /xxx项目的访问路径–&gt;也叫虚拟目录\n 简化配置：将html文件压缩为war格式，放在webapps内，会自动的装载出该文件的目录，删除war包也会自动删除对应的文件目录\n\n更改server.xml配置文件\n &lt;Context docBase=&quot;项目路径&quot; path=&quot;虚拟目录访问路径&quot; /&gt;\n 这样就部署完成了\n 但这样配置很不安全，容易把配置文件搞坏\n\n在conf\\Catalina\\localhost目录下创建xml文件\n 输入\n &lt;Context doBase=&quot;项目目录&quot; /&gt;\n 虚拟目录是xml文件的名称\n\n\n静态项目和动态项目目录结构：\nJava动态项目的目录结构\n项目的根目录\nWEB-INF目录\nweb.xml：web项目的核心配置文件\nclasses目录：放置字节码文件的目录\nlib目录：放置依赖的jar包\n\n\n\n\n\n将Tomcat集成到IDEA中将Tomcat集成到IDEA中并且创建JavaEE的项目，部署项目\n\n将Tomcat集成到IDEA\n\n\n打开最上边的run,再进入Edit configurations\n在Templates找见Tomcat server\n配置Application server为Tomcat的目录\n点击ok\n创建项目\n勾选Java Enterprise\n勾选java版本7，为了学习之后的内容\n勾选web application\n点击创建\n再回到第二步，勾选两个都为Update resources热更新\n启动项目即可\n\n","categories":["后台","Tomcat"],"tags":["Tomcat"]},{"title":"Swagger","url":"/2020/09/06/Util/Swagger/","content":"\n前端要接口文档？\n\nNO！\nSwagger就够了\n\n\n\n\nSwagger前端要接口文档？\nNO！\n直接甩给他http://xxx:8080/swagger-ui.html~\nSwagger\n号称世界上最流行的API框架\nRestFul Api 文档在线自动生成工具 ，APi与Api定义同步更新\n直接运行，可以在线测试API接口\n支持多种语言：Java、PHP…\n\n使用Swagger\n导入依赖：\n\n&lt;!-- spring swagger2整合 --&gt;&lt;dependency&gt;    &lt;groupId&gt;io.springfox&lt;/groupId&gt;    &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;    &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;io.springfox&lt;/groupId&gt;    &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;    &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;\n\n\n\n\n设置配置：\n\n需要配置Swagger的bean实例——Docket\n@Configuration@EnableSwagger2public class Swagger2Config &#123;    @Bean    public Docket docket()&#123;        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                // 设置是否开启                .enable(true)                .select()                // 配置要扫描接口的方式                // basePackage(String path)：指定扫描的包                // any() 扫描全部                // none() 不扫描                // withClassAnnotation() 扫描类上的注解                // whthMethodAnnotation() 扫描方法上的注解                .apis(RequestHandlerSelectors.basePackage(&quot;com.yunhuo.xcjd.controller&quot;))                // 过滤                // ant() 扫描什么下的接口 例如扫描用户                // any() 扫描所有                .paths(PathSelectors.ant(&quot;/user/**&quot;))                .build();    &#125;    private ApiInfo apiInfo() &#123;        Contact contact = new Contact(&quot;mylord&quot;, &quot;www.yesmylord.cn&quot;, &quot;1046467756@qq.com&quot;);        return new ApiInfoBuilder()                .title(&quot;Swagger学习&quot;)                .description(&quot;学习Swagger的基本用法等等&quot;)                .contact(contact)                .version(&quot;1.0&quot;)                .build();    &#125;&#125;\n\n访问http://localhost:8080/swagger-ui.html，看到我们配置的结果\n\n\n\n设置为只有dev环境才开启swagger\n\n@Beanpublic Docket docket(Environment environment)&#123;        /**********获取项目的生产环境**********************/    Profiles profiles = Profiles.of(&quot;dev&quot;);    boolean env = environment.acceptsProfiles(profiles);    /********************************************************/    return new Docket(DocumentationType.SWAGGER_2)            .apiInfo(apiInfo())            // 设置是否开启            .enable(env)            .select()            // 配置要扫描接口的方式            // basePackage(String path)：指定扫描的包            // any() 扫描全部            // none() 不扫描            // withClassAnnotation() 扫描类上的注解            // whthMethodAnnotation() 扫描方法上的注解            .apis(RequestHandlerSelectors.basePackage(&quot;com.yunhuo.xcjd.controller&quot;))            // 过滤            // ant() 扫描什么下的接口 例如扫描用户            // any() 扫描所有            .paths(PathSelectors.ant(&quot;/user/**&quot;))            .build();&#125;private ApiInfo apiInfo() &#123;    Contact contact = new Contact(&quot;mylord&quot;, &quot;www.yesmylord.cn&quot;, &quot;1046467756@qq.com&quot;);    return new ApiInfoBuilder()            .title(&quot;Swagger学习&quot;)            .description(&quot;学习Swagger的基本用法等等&quot;)            .contact(contact)            .version(&quot;1.0&quot;)            .build();&#125;\n\n\n在测试中加上TOKEN，在docket中加上\n\nParameterBuilder tokenParam = new ParameterBuilder();List&lt;Parameter&gt; params = new ArrayList&lt;&gt;();tokenParam.name(AnswerConstant.HTTP_HEADER_ANSWER_ACCESS_TOKEN)        .description(&quot;accessToken&quot;)        .modelRef(new ModelRef(&quot;string&quot;))        .parameterType(&quot;header&quot;)        .required(false)        .build();params.add(tokenParam.build());\n\n\n相关注解使用注解\n\n@Api\n功能:描述controller类\n注解位置：类\n常用注解属性\ntags = &quot;&quot; // 描述此controller类\n\n\n\n\n@ApiOperation\n功能：描述一个方法或者一个API接口\n注解位置：方法\n常用注解属性\nvalue = &quot;&quot; // 描述方法\nnotes = &quot;&quot; // 描述方法详细信息\n\n\n\n\n@ApiImplicitParam\n功能：描述方法或接口参数\n注解位置：方法\n注解属性\nname = &quot;&quot; // 方法或接口的形参, 注意要与方法的参数名称相同\nvalue = &quot;&quot; // 对参数的描述\nparamType = &quot;&quot; // 参数传递方式，此属性的可选值 [&quot;header&quot;, &quot;query&quot;, &quot;path&quot;, &quot;body&quot;, &quot;form&quot;]\nheader，使用@RequestHeader获取的参数\nquery，使用@RequestParam获取的参数，常用于GET请求\npath，使用@PathVariable获取的参数\nbody，使用@RequestBody获取的参数，常用于POST请求，对象参数\n\n\ndataType = &quot;&quot; // 参数类型，例如 string, int, ArrayList, POJO类\n\n\n\n\n@ApiImplicitParams\n功能：汇集多个参数\n注解位置： 方法\n注解属性\n@ApiImplicitParam组成的列表\n\n\n\n\n@ApiModel\n功能：描述Form表单类\n注解位置：form表单类上\n\n\n@ApiModelProperty\n功能：描述表单类的各个字段\n注解位置：form表单类上的各个属性\n\n\n\n\nController\n\n@RestController@Api(tags = &quot;User&quot;)public class userController &#123;    @ApiOperation(value=&quot;hello&quot;, notes=&quot;无参数GET请求测试&quot;)    @GetMapping(&quot;/hello&quot;)    public String hello() &#123;        return &quot;Hello World!&quot;;    &#125;    @ApiOperation(value = &quot;helloUser&quot;, notes = &quot;单简单参数&quot;)    @ApiImplicitParam(name = &quot;name&quot;, value = &quot;姓名&quot;, paramType = &quot;query&quot;, dataType = &quot;String&quot;)    @GetMapping(&quot;/helloUser&quot;)    public String hello2(@RequestParam String name) &#123;        return &quot;Hello &quot; + name;    &#125;    @ApiOperation(value = &quot;hello3&quot;, notes = &quot;多简单参数&quot;)    @ApiImplicitParams(&#123;            @ApiImplicitParam(name = &quot;name&quot;, value = &quot;用户名&quot;, paramType = &quot;query&quot;, dataType = &quot;string&quot;),            @ApiImplicitParam(name = &quot;age&quot;, value = &quot;密码&quot;, paramType = &quot;query&quot;, dataType = &quot;string&quot;)    &#125;)    @GetMapping(&quot;/login1&quot;)    public String hello3(@RequestParam String name, @RequestParam Integer age) &#123;        return &quot;Hello &quot; + name + &quot;, age &quot; + age.toString();    &#125;    @ApiOperation(value = &quot;hello4&quot;, notes = &quot;传递对象参数&quot;)    @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户&quot;, paramType = &quot;body&quot;, dataType = &quot;Person&quot;)    @PostMapping(&quot;/login2&quot;)    public String hello4(@RequestBody UserForm userForm) &#123;        return &quot;Hello, &quot; + userForm.getUsername() + &quot; &quot; + userForm.getPassword();    &#125;    @ApiOperation(value = &quot;hello5&quot;, notes = &quot;传递集合参数&quot;)    @ApiImplicitParam(name = &quot;persons&quot;, value = &quot;集合列表&quot;, paramType = &quot;body&quot;, dataType = &quot;ArrayList&lt;String&gt;&quot;)    @PostMapping(&quot;/delete&quot;)    public String hello5(@RequestBody ArrayList&lt;String&gt; users) &#123;        StringBuilder sb = new StringBuilder();        users.forEach(t -&gt; sb.append(t).append(&quot;\\n&quot;));        return sb.toString();    &#125;&#125;\n\n\nForm\n\n@Data@ApiModel(&quot;用户表单类&quot;)public class UserForm &#123;    @ApiModelProperty(&quot;用户名&quot;)    private String username;    @ApiModelProperty(&quot;密码&quot;)    private String password;&#125;\n\n\n\n打开swagger-ui可以看到\n\n\n","categories":["util","Swagger"],"tags":["util","Swagger"]},{"title":"Hadoop安装与集群配置","url":"/2021/03/21/hadoop/Hadoop%E5%AE%89%E8%A3%85/","content":" \n引言：\n\nhadoop的安装与集群配置\n\n\n\n\nHadoop安装与集群配置安装Hadoop首先下载Hadoop，本篇使用hadoop2.7.3\n安装前提JDK环境安装JDK\n# 安装Javayum install -y java-1.8.0-openjdk.x86_64\n\nJDK环境在1.6以上，并在/etc/profile中配置环境变量\n# JavaHome，这里的路径根据自己的情况定export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64/jre80 export PATH=$PATH:$JAVA_HOME/bin\n\n注意：如果没有jps命令，是没有openjdk-devel这个包\nyum install java-1.8.0-openjdk-devel.x86_64\n\n\n\n虚拟机准备linux操作系统，ubuntu、centos都可以，这里创建了三个Centos7的虚拟机。\n每一个虚拟机给了10G的磁盘空间、其他默认，其中一台机器安装了图形界面，剩下的两个虚拟机最小安装，给三台虚拟机改名字，修改/etc/hostname文件\n# 这里起名为# 虚拟机1的hostname文件master# 虚拟机2的hostname文件slave1# 虚拟机3的hostname文件slave2\n\n\n\n解压并配置\n解压（这里解压到了/usr/local/hadoop）\n# 解压 ，可以加参数-C指定解压目录tar -zxvf hadoop-2.7.3.tar.gz\n配置hadoop/etc/hadoop/hadoop-env.sh中的Java环境为当前的Java环境（Java要求1.6以上）\n\n检测，进入hadoop/bin/下\n./hadoop version\n\n打印出hadoop版本信息即安装成功，打印的信息如下：\nHadoop 2.7.3Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccffCompiled by root on 2016-08-18T01:41ZCompiled with protoc 2.5.0From source with checksum 2e4ce5f957ea4db193bce3734ff29ff4This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar\n\n如果这一步报错，请检查Java环境变量是否正确\n\n将hadoop的命令配置环境变量，修改/etc/profile文件，添加如下\n# HadoopHome，根据自己安装的hadoop位置进行配置export HADOOP_HOME=/usr/local/hadoopexport PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin\n\nHadoop目录简介bin\t\t#hadoop的命令sbin \t #hdfs启动的命令logs \t #日志文件，namenode与datanode的日志文件都在这里etc \t #配置文件，下文会对这里的文件进行配置\n\n\n\nHadoop伪分布式安装伪分布式：即在一台机器上搭建\nSSH无密码登录hadoop不支持密码登录，所以我们要先使用SSH进行无密码验证\n# 1. 首先生成SSH秘钥ssh-keygen -t rsa# 2. 其次将公钥追加写入到authorized_keys文件内#\t（authorized_keys文件会自动创建）cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys\n\n检测一下\nssh localhost\n\n如果不需要密码，说明配置正确\netc文件配置修改etc/hadoop/下的文件\n\ncore-site.xml文件\n&lt;configuration&gt;        &lt;property&gt;            &lt;!-- 配置存放临时数据的目录，file代表本地目录 --&gt;                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;!-- fs.defaultFS表示HDFS的访问地址 --&gt;                &lt;name&gt;fs.defaultFS&lt;/name&gt;                &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;\nhdfs-xml.xml配置\n&lt;configuration&gt;        &lt;property&gt;            &lt;!-- 配置副本的数量，由于是伪分布式，所以这里仅能配 1 --&gt;                &lt;name&gt;dfs.replication&lt;/name&gt;                &lt;value&gt;1&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;!-- 配置名称节点的元数据的保存目录 --&gt;                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;!-- 配置数据结点的数据保存目录 --&gt;                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;\n\n格式化namenode执行命令\nhadoop namenode -format\n\n（如果没有配置hadoop环境变量，那么去bin下执行这行命令）\n执行这条命令后，我们会发现多了一个目录tmp\n启动hadoop执行命令\nstart-all.sh\n\n（如果没有配置hadoop环境变量，那么去sbin下执行这行命令）\n访问localhost:50070查看即可\nHadoop集群安装注意：\n\n三台虚拟机都得有java并配置环境变量\nslave虚拟机先不必安装hadoop\n\n网络配置首先确保三个虚拟机在同一个网段内，然后配置master虚拟机的/etc/hosts文件\n使用ip addr或者ifconfig查看对应虚拟机的ip地址\n向文件内添加如下\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4::1         localhost localhost.localdomain localhost6 localhost6.localdomain6 # 以下是添加的内容192.168.235.143 master192.168.235.144 slave1192.168.235.145 slave2\n\n使用ping命令查看master是否可以联系到slave1、slave2\nping slave1ping slave2\n\n\n\nSSH无密码登录\nMaster进行第二章的SSH配置后即可，不用再改动\n\n将Master的公钥分别复制一份到对应slave1、slave2虚拟机的~/.ssh/authorized_keys文件内（没有文件则创建对应文件）\n可以使用scp命令传输文件\n# 注意，首先要在对应虚拟机下创建对应的路径# scp 文件 虚拟机名称:路径scp id_rsa.pub slave1:~/.ssh/authorized_keysscp id_rsa.pub slave2:~/.ssh/authorized_keys\n检查配置是否成功\nssh slave1\n\n\n使用exit可以退回原主机\n\n\n配置文件修改etc/hadoop/下的文件\n\ncore-site.xml文件\n&lt;configuration&gt;        &lt;property&gt;            &lt;!-- 配置存放临时数据的目录，file代表本地目录 --&gt;                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;!-- fs.defaultFS表示HDFS的访问地址 --&gt;                &lt;name&gt;fs.defaultFS&lt;/name&gt;                &lt;value&gt;hdfs://master:9000&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;\nhdfs-xml.xml配置\n&lt;configuration&gt;         &lt;property&gt;            &lt;!-- 配置第二名称节点的管理端口 --&gt;                &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;                &lt;value&gt;Master:50090&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;!-- 配置副本的数量，这里配置为3 --&gt;                &lt;name&gt;dfs.replication&lt;/name&gt;                &lt;value&gt;3&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;!-- 配置名称节点的元数据的保存目录 --&gt;                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;!-- 配置数据结点的数据保存目录 --&gt;                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;\nmapred-site.xml配置（注意这个文件需要复制mapred-site.xml.template并改名）\n&lt;configuration&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;                &lt;value&gt;yarn&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;                &lt;value&gt;master:10020&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;                &lt;value&gt;master:19888&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;\n配置yarn-site.xml\n&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;        &lt;property&gt;                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;                &lt;value&gt;master&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;\n\n发送hadoop整个文件给slave虚拟机先将整个hadoop文件打包\n# tar -zcf 放置的位置 打包的文件或文件夹tar -zcf ~/hadoop.tar.gz hadoop/\n\n发送给两个虚拟机\nscp hadoop.tar.gz slave1:/usr/local/scp hadoop.tar.gz slave1:/usr/local/\n\n去对应虚拟机下解压即可\nmaster配置slaves文件在/etc/hadoop/目录下有一个slaves文件\n这个文件内，默认是localhost，如果我们master不仅仅想做namenode，还想做datanode的话，可以留着\n这里我改成了\nslave1slave2\n\n\n\n启动hadoop执行命令\nstart-all.sh\n\n（如果没有配置hadoop环境变量，那么去sbin下执行这行命令）\nmaster虚拟机使用jps查看进程：（左边的数字是进程号）\n[root@master ~]# jps71842 SecondaryNameNode71671 NameNode72007 ResourceManager73961 Jps\n\nslave虚拟机查看\n[root@slave1 hadoop]# jps4928 DataNode5026 NodeManager5496 Jps\n\n访问localhost:50070查看\n下滑可以看到我们存活的节点是2个\n\n点击可以查看详细情况\n\n这里就完成了\n注意：如果显示的节点是0的话，是防火墙的问题，关掉防火墙即可\nsystemctl stop firewalld.service\n\n\n\n\n\n报错处理总共遇到三个问题\n\njps命令找不到\n解决：安装openjdk-devel这个库\nyum install java-1.8.0-openjdk-devel.x86_64\n配置成功后，打开50070端口web应用，显示启动的datanode节点是0\n解决：关闭防火墙\nsystemctl stop firewalld.service\n\n","categories":["hadoop"],"tags":["大数据","hadoop"]},{"title":"kafka","url":"/2021/10/16/kafka/kafka%E5%85%A5%E9%97%A8/","content":"\n  引言:\n  Kafka——分布式发布/订阅模式消息队列\n\n\n\nKafka可以从其他很多知识中，串联到kafka中，很多设计思想都是相同的。\nKafka是什么\n在0.9.0版本中，Kafka的官方定义是一个分布式、分区、复制的提交日志服务。它提供消息传递系统的功能。\n\n在0.10.0版本中，Kafka的官方定义是分布式的流处理平台\n\n\nKafka起源于Linkedin公司，2010年贡献给Apache开源基金会，2012年成为顶级项目，2014年成立了Confluent商业化公司，目前为止，Kafka的版本更新到了3.5。\nkafka的发行版有很多，除了商业化的Confluent Kafka，还有Cloudera Kafka和Hortonworks Kafka两个面向于大数据的Kafka发行版。\n常见的消息模型及消息队列首先需要介绍几种消息通信模型：\n\nJMS：Java Message Service API（Java消息服务）\n专门针对于Java语言\n定义两种通信方式：点对点模型（P2P）、发布订阅模型（Pub/Sub）\n代表实现有：ActiveMQ\n\n\nAMQP：Advanced Message Queuing Protocol（高级消息队列协议）\n支持事务，数据一致性高，多用于银行、金融行业\n协议模型：队列（queues）信箱（exchanges）绑定（bindings），消息先放于信箱，根据绑定的不同的路由规则，再发送到对应的队列中。 \n代表实现有：RabbitMQ、Spring AMQP、Spring JMS\n\n\nMQTT：Message Queuing Telemetry Transport\n用于IOT\n为小型无声设备之间通过低带宽发送短消息而设计\n\n\n\nkafka的消息格式与传输方式消息引擎主要的作用就是发送消息，消息的格式如何以及如何发送消息是消息引擎的主要设计的内容，也是核心\n\n消息格式：\n可以使用JSON、CSV、XML格式等\n也可以直接使用开源序列化框架：Protocol Buffer等\n\n\n传输模型：一般来说主要有两种传输模型\n**点对点模型 (Peer to Peer)**：指的是A发送的消息只可以传输给B（不能有其他系统染指）\n\n发布订阅模型 (Pub / Sub)：发布订阅机制，有一个主题的概念，发送方（发布者）与接收方（订阅者）可以关注同一个主题，相同的主题下接收方可以接收到发送方发送的消息\n\n\n\n\nKafka的选择：kafka同时提供了P2P与Pub/Sub两种模式，消息在kafka内以日志的方式记录\n为什么要使用消息引擎？三个原因：\n\n为了信息传输的松耦合\n\n当下的数据存储方案很多很多：mysql、Flume、SparkStreaming、Flink，他们之间的数据传输可以使用消息队列来进行解耦的数据传输。\n\n削峰填谷（这也是根本原因）\n\n\n何为削峰填谷？\n\n上游的服务一般会由很多下游的服务提供，如果上游的请求量在一瞬间达到了很大的程度，那么很有可能冲垮下游的服务，导致雪崩（类似于Redis缓存雪崩的概念）\n削峰填谷就是要将上游的流量以一种平滑的方式将数据传输给下游。\n举个例子：如果上游突然激增TPS（每秒事务请求数），引入Kafka 能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的 TPS，同时也给下游子服务留出了充足的时间去消费它们\n\n异步通信\n\n比如：用户在官网投递了A公司的简历，官网的页面会立即返回“投递成功”，但是发送短信和发送邮件的操作会先发送给消息队列（因为这两步的操作也有耗时时间），然后由下游的短信模块和邮件模块慢慢消费。\nkafka基本结构Kafka角色\n生产者：即向主题发送消息的客户端\n消费者：从主题接收消息的客户端\n客户端：统称生产者与消费者\n\nkafka核心组成\n**主题(Topic)**：它存放同一类的消息，比如点赞、评论、收藏各是一个Topic\n\n分区（Partition）：Topic会划分为多个分区(Partition)：每个分区都是一组有序的、不可变的消息日志（日志的格式就是key、value键值对）\n\n消息的存储是以键值对的方式，如果key为null，那么就按照轮询的方式写到不同的分区中（同一个Topic的不同分区）；如果key不为null，相同key的消息会有序的排放在相同的分区中。\n生产者生产的消息只会被发送到一个分区中（如果一个Topic有2个Partition，只会被发到其中一个中，不在partition0就在partition1）\n\n\nReplication：一个主题有多个分区，一个分区可以有多个副本\n\n\n与Hadoop的分区容备不同的是，kafka的副本分为Leader和follower，Leader负责读写请求，follower不负责读！只是实时复制leader的变化。\n图中还显示了一个ISR的集合，这个集合存储了分区的副本的ID，如果有一个副本掉队，就会删除，等到其跟上leader的进度，才会将其填入。\n\n\nBroker：主题的服务器端（消息代理），他有两个主要的作用\n\n接收和处理客户端发送来的请求\n消息持久化：将消息写入到磁盘\n\n\n\nKafka集群结构3.0之前的kafka需要Zookeeper来配合使用\n\n一台服务器可以有多个Broker（但是一般一个服务器只维护一个Broker）\n一个Broker可以有多个Topic（不同Broker的Topic是一样的）\n一个Topic可以有多个Partition\n一个Partition可以有多个Replication\n\n如图示：\n\n上图表示的集群中：有4个Broker，2个Topic；Topic0有5个分区（0-4），每个分区有2个副本；Topic1有3个分区（0-2），每个分区有3个副本；标为红色的副本表示其为leader，绿色的为follower；\n\n在上图的集群中：有8个Broker，1个Topic；8个Partition；每个Partition有3个replication\n\nKafka工作总共有三层结构：\n\n【第一层：主题层】\n\n每个主题可以配置M个分区\n每个分区又可以配置N个副本\n\n\n【第二层：分区层】\n\n每个分区可以有多个副本\n但只能有一个领导者副本，其他全为追随者副本\n\n\n【第三层：消息层】\n\n分区是一个有序的消息队列，消息的位移从0开始\n\n\n\nKafka的消费者\nKafka的Consumer为什么是一组一组的Consumer group？\n\n为了实现P2P模型，前面说到，kafka不仅提供了发布订阅这种模型，而且支持P2P这种方式，因此引入了消费者组\n一个消费者组中的消费者都是消费相同主题的消费者\n这样做也可以提高整个消费者端的吞吐量\nKafka的高可用Kafka提供高可用的手段主要有两个：\n\nkafka集群\n备份机制\n\nkafka集群即将：Broker进程分配在不同PC上，每台PC都可以运行很多Broker进程，通过Zookeeper将不同的PC联系起来，这样就构建成了kafka集群\n\n为什么要这么做？\n\nBroker是可以全部到一台机器上的，但是通常都会分配到不同的机器上\n这样可以避免一个PC宕机的时候，其他的PC还能正常工作，依然可以继续对外提供服务\n备份机制类似于hadoop、redis、mysql，很多都有备份机制来保证高可用\n在Kafka中，每一个主题有很多分区，每一个分区可以配置N个副本\n（还是此图）\n\n在这些副本中，分为两类：\n\n领导者副本（Leader Replica）：负责提供与客户端（消费者与生产者）的服务\n追随者副本（Follower Replica）：负责跟进领导者的副本（不提供服务）\n\n（在Redis、Mysql中，从库是可以对外提供读服务的）\n（在以前这也被称为master、slave体系（主从体系）但是由于漂亮国某些政治正确的原因，改为Leader Follower这种体系）\n\n为什么kafka的主题要分区？\n\n为了解决伸缩性问题，即如果leader副本积累了太多的数据，以至于一台Broker都无法存储了\n分区就是为了解决伸缩性问题的\n\n为什么kafka的追随者副本不设计为可以对外提供读服务呢？（就和redis、mysql一样）\n\n两个原因：\n\n首先mysql是为了负载均衡，平衡主库压力（主库需要负责读写操作），才设计从库来负责读，尽量分摊主库压力；而kafka中，每个Broker分布在不同的PC上，本来就进行了负载均衡\n消费者组读取数据，有一个消费者位移，如果follower也要提供读服务的话，那么设计实现会比较复杂（涉及到一致性问题，需要同步leader与follower的进度）\n\nkafka数据的持久化\nkafka如何持久化数据？\n\nkafka使用消息日志（log）来持久化数据，而且是追加写（类似于Mysql的bin log）\n\n追加写满了怎么办？\n\nkafka将日志又细分为多个日志段（Log segment），消息被追加写到最新的日志段中\n\n写满后，kafka会自动切分出一个新的日志段，并将老的日志段封存起来\n\nkafka在后台还有定时任务会定期的检查老的日志段是否能被删除回收\n\n\n","categories":["kafka"],"tags":["kafka","消息队列"]},{"title":"01.Vue的开始认识","url":"/2019/07/03/Vue/01-Vue%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E7%9A%84%E4%BA%86%E8%A7%A3/","content":"\n引言：\n\nVue是著名的前端框架，从今天开始要慢慢了解它，本节粗略介绍了Vue的基本知识点\n先从一个Hello world开始吧\n加油加油！！\n\n\n\n\nHello world从Vue官网上下载Vue的源代码，初学我们可以直接用\n&lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt;\n我们可以直接将它放在一个单独的文件当中，然后放在head的位置，用script标签来引入，这样就可以使用vue了\n这里是一个Hello world小实例\n如果使用纯js的话\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt; &lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;app&quot;&gt;&lt;/div&gt;    &lt;script&gt;        var iApp = document.getElementById(&#x27;app&#x27;);        iApp.innerHTML=&#x27;hello world&#x27;;        setTimeout(function() &#123;            iApp.innerHTML = &#x27;bye,world&#x27;        &#125;, 2000)    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt;    &lt;!--CDN引入vue包--&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;root&quot;&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;&lt;!--省去了DOM操作，可以直接控制这里的数据--&gt;&lt;script&gt;    let vm = new Vue(&#123;//创建一个Vue的实例        el: &#x27;#root&#x27;,        //接管哪一个页面上的element，实现了绑定,el代表掌管页面上的哪一块区域        data:&#123;            msg: &quot;hello world&quot;        &#125;    &#125;)        setTimeout(function() &#123;        app.$data.msg = &#x27;bye,world&#x27;    &#125;, 2000)    //$data是Vue实例当中data对象的别名&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n挂载点、模板之间的关系挂载点&lt;body&gt;&lt;!--挂载点、模板、实例的关系--&gt;&lt;div id=&quot;root&quot;&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;&lt;!--这里是挂载点--&gt;&lt;div&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;&lt;!--这里不是挂载点，所以页面内会直接显示出原本的内容--&gt;&lt;script&gt;    new Vue(&#123;        el: &#x27;#root&#x27;,        data: &#123;            msg: &quot;hello world&quot;        &#125;    &#125;)&lt;/script&gt;&lt;/body&gt;\n模板模板就是指挂载点内部的内容\n&lt;div id=&quot;root&quot;&gt;    &lt;h1&gt;hello &#123;&#123;msg&#125;&#125;&lt;/h1&gt;&lt;!--模板：挂载点内部的内容--&gt;&lt;/div&gt;\n还有另一种的表现方式\n&lt;body&gt;&lt;!--挂载点、模板、实例的关系--&gt;&lt;div id=&quot;root&quot;&gt;&lt;/div&gt;&lt;script&gt;    new Vue(&#123;        el: &#x27;#root&#x27;,        template:&#x27;&lt;h1&gt;hello &#123;&#123;msg&#125;&#125;&lt;/h1&gt;&#x27;,        //模板可以写在挂载点内部，也可以写在实例的template的属性内部        data: &#123;            msg: &quot;hello world&quot;        &#125;    &#125;)&lt;/script&gt;&lt;/body&gt;\n\n数据的显示&lt;body&gt;&lt;div id=&quot;root&quot;&gt;    &lt;h1&gt;&#123;&#123;msg&#125;&#125;&lt;/h1&gt;    &lt;!--1.我们把数据放在两个大括号的内部，这种语法，叫做插值表达式--&gt;    &lt;h2 v-text=&quot;msg&quot;&gt;&lt;/h2&gt;    &lt;!--2.v-text：这个指令意思是，h2当中的内容由这个变量来指定,    这里的意思就是把msg的内容显示到这里--&gt;    &lt;h3 v-html=&quot;msg&quot;&gt;&lt;/h3&gt;    &lt;!--3.v-html：表示也是可以的--&gt;    &lt;!--那么他们俩的区别是什么呢--&gt;    &lt;h4 v-text=&quot;content&quot;&gt;&lt;/h4&gt;&lt;!--会转义，将标签内容直接打印出来--&gt;    &lt;h4 v-html=&quot;content&quot;&gt;&lt;/h4&gt;&lt;!--不会转义，效果和template一样--&gt;&lt;/div&gt;&lt;script&gt;    new Vue(&#123;        el: &#x27;#root&#x27;,        data: &#123;            msg: &quot;hello world&quot;,            content:&quot;&lt;h4&gt;会不会转义&lt;/h4&gt;&quot;        &#125;    &#125;)&lt;/script&gt;&lt;/body&gt;\n方法的添加&lt;body&gt;&lt;div id=&quot;root&quot;&gt;    &lt;div v-on:click=&quot;handleClick&quot;&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;    &lt;!--这里可以把 v-on:简写为@--&gt;    &lt;div @click=&quot;handleClick&quot;&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;    &lt;!--绑定一个事件--&gt;&lt;/div&gt;&lt;script&gt;    new Vue(&#123;        el: &#x27;#root&#x27;,        data: &#123;            msg: &quot;hello&quot;,        &#125;,        methods: &#123;//把方法添加到这个属性内部            handleClick: function () &#123;                this.msg = &#x27;world&#x27;                //直接这样就可以调用数据了，vue会直接改变页面的现实数据            &#125;        &#125;    &#125;)&lt;/script&gt;&lt;/body&gt;\n\n属性绑定&lt;body&gt;    &lt;div id=&quot;root&quot;&gt;        &lt;div v-bind:title=&quot;title&quot;&gt;hello world&lt;/div&gt;        &lt;!--1.title属性:当鼠标放在上面的时候，会出现一个框，内容就是title的内容--&gt;        &lt;!--2.当title内部想要使用data的数据的时候，直接写title:&quot;title&quot;是不行的            必须进行绑定--&gt;        &lt;!--3.此时后面的内容就是一个表达式了，可以进行js的更改--&gt;        &lt;!--例如--&gt;        &lt;div v-bind:title=&quot;&#x27;你好啊&#x27;+title&quot;&gt;hello world&lt;/div&gt;        &lt;!--4.v-bind可以缩写为:--&gt;        &lt;div :title=&quot;&#x27;你好啊&#x27;+title&quot;&gt;hello world&lt;/div&gt;    &lt;/div&gt;    &lt;script&gt;        new Vue(&#123;            el:&quot;#root&quot;,            data:&#123;                title:&quot;this is hello world&quot;            &#125;        &#125;)    &lt;/script&gt;&lt;/body&gt;\n\n双向数据绑定单向数据：数据决定页面的显示，但是页面无法决定数据里的内容&lt;body&gt;    &lt;div id=&quot;root&quot;&gt;        &lt;div :title=&quot;title&quot;&gt;hello world&lt;/div&gt;        &lt;input :value=&quot;content&quot;/&gt;        &lt;div&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;        &lt;!--单向绑定：数据决定页面的显示，但是页面无法决定数据里的内容--&gt;    &lt;/div&gt;    &lt;script&gt;        new Vue(&#123;            el:&quot;#root&quot;,            data:&#123;                title:&quot;this is hello world&quot;,                content:&quot;this is content&quot;            &#125;        &#125;)    &lt;/script&gt;&lt;/body&gt;\n双向数据：数据决定页面的显示，页面也可以决定数据里的内容&lt;body&gt;    &lt;div id=&quot;root&quot;&gt;        &lt;div :title=&quot;title&quot;&gt;hello world&lt;/div&gt;        &lt;input v-model=&quot;content&quot;/&gt;        &lt;div&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;        &lt;!--双向绑定：数据决定页面的显示，页面也能决定数据里的内容--&gt;        &lt;!--v-model双向数据绑定--&gt;    &lt;/div&gt;    &lt;script&gt;        new Vue(&#123;            el:&quot;#root&quot;,            data:&#123;                title:&quot;this is hello world&quot;,                content:&quot;this is content&quot;            &#125;        &#125;)    &lt;/script&gt;&lt;/body&gt;\nVue中的计算属性和侦听器计算属性&lt;body&gt;    &lt;div id=&quot;root&quot;&gt;        姓：&lt;input v-model=&quot;firstName&quot; /&gt;        名：&lt;input v-model=&quot;lastName&quot; /&gt;        &lt;div&gt;&#123;&#123;firstName&#125;&#125;&#123;&#123;lastName&#125;&#125;&lt;/div&gt;        &lt;!--最好写成以下的这个样子--&gt;        &lt;div&gt;&#123;&#123;fullName&#125;&#125;&lt;/div&gt;    &lt;/div&gt;    &lt;script&gt;        new Vue(&#123;            el:&quot;#root&quot;,            data:&#123;                firstName:&#x27;&#x27;,                lastName:&#x27;&#x27;            &#125;,            computed:&#123;//计算属性computed                fullName:function () &#123;                    return this.firstName +&quot;&quot;+this.lastName                &#125;                //当firstName和lastName没有变的时候，fullName会使用缓存值                //只有当依赖的数据发生变化的时候，才会重新计算            &#125;        &#125;)    &lt;/script&gt;&lt;/body&gt;\n监听器&lt;body&gt;    &lt;div id=&quot;root&quot;&gt;        姓：&lt;input v-model=&quot;firstName&quot; /&gt;        名：&lt;input v-model=&quot;lastName&quot; /&gt;        &lt;div&gt;&#123;&#123;fullName&#125;&#125;&lt;/div&gt;        &lt;div&gt;&#123;&#123;count&#125;&#125;&lt;/div&gt;    &lt;/div&gt;    &lt;script&gt;        new Vue(&#123;            el:&quot;#root&quot;,            data:&#123;                firstName:&#x27;&#x27;,                lastName:&#x27;&#x27;,                count:0            &#125;,            computed:&#123;                fullName:function () &#123;                    return this.firstName +&quot;&quot;+this.lastName                &#125;            &#125;,            watch:&#123;//监听某一个数据的变化，一旦这个数据变化，则可以在这里看到他的变化                fullName:function () &#123;                    this.count++                &#125;            &#125;        &#125;)    &lt;/script&gt;&lt;/body&gt;\n\n常见命令的使用v-if&lt;body&gt;    &lt;div id=&quot;root&quot;&gt;        &lt;div v-if=&quot;show&quot;&gt;hello world&lt;/div&gt;        &lt;!--v-if指令可以判断条件再来选择是否显示--&gt;        &lt;!--v-show指令也可以做到这一点，但是他们有区别--&gt;        &lt;!--1.v-if是直接在DOM树上抹去了这一个标签--&gt;        &lt;!--2.v-show则是给这个标签添加了一个display:none的属性--&gt;        &lt;button @click=&quot;handleClick&quot;&gt;toggle&lt;/button&gt;        &lt;ul&gt;            &lt;li v-for=&quot;item of list&quot;&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt;            &lt;!--每次循环都把list的每一个项传递到item这个变量中然后显示出来--&gt;            &lt;li v-for=&quot;item of list&quot; :key=&quot;item&quot;&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt;            &lt;!--记得要加一个key的属性，会提升每一项渲染的性能--&gt;            &lt;!--key值要求每一项不可以相同，这里可以直接用item,但当重复的时候我们会这样写--&gt;            &lt;li v-for=&quot;(item,index) of list&quot; :key=&quot;index&quot;&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt;            &lt;!--我们不需要对排序进行变更及类似的操作，index这样写没有问题，但这样写是会有问题的！--&gt;        &lt;/ul&gt;    &lt;/div&gt;    &lt;script&gt;        new Vue(&#123;            el:&quot;#root&quot;,            data:&#123;                show:true,                list:[1,2,3]            &#125;,            methods:&#123;                handleClick:function () &#123;                    this.show=!this.show                &#125;            &#125;,        &#125;)    &lt;/script&gt;&lt;/body&gt;\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"Spring_JDBCTemplate","url":"/2020/03/13/Spring/Spring-JDBCTemplate/","content":"\n引言：\n\nSpring——JDBCTemplate    \n\n\n\n\nJDBC TemplateSpring为了简化JDBC的持久化操作，提供了JDBC Template\n//原本操作数据库的流程我们的代码 -&gt; JDBC API -&gt; JDBC驱动 -&gt; MySql//现在我们的代码 -&gt; JDBC Template -&gt; JDBC API -&gt; JDBC驱动 -&gt; MySql\nMaven配置：\n&lt;!--Mysql--&gt;&lt;dependency&gt;    &lt;groupId&gt;mysql&lt;/groupId&gt;    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;    &lt;version&gt;5.1.44&lt;/version&gt;&lt;/dependency&gt;&lt;!--JDBC--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;    &lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--事务管理--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;    &lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;/dependency&gt;\n\n配置SpringConfig文件\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!--约束文件--&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans.xsd    http://www.springframework.org/schema/context    http://www.springframework.org/schema/context/spring-context.xsd    http://www.springframework.org/schema/aop    http://www.springframework.org/schema/aop/spring-aop.xsd    http://www.springframework.org/schema/tx    http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt;    &lt;!--配置JDBC--&gt;    &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot; &gt;        &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt;        &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/selection_course?useUnicode=true&amp;amp;characterEncoding=utf-8&quot; /&gt;        &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt;        &lt;property name=&quot;password&quot; value=&quot;root&quot; /&gt;    &lt;/bean&gt;    &lt;!--配置JDBCTemplate--&gt;    &lt;bean id=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;&lt;/beans&gt;\n\n增删改相关方法update方法（对数据进行增删改）int update(String sql, Obejct[] args)//参数是SQL语句和一个数组int update(String sql, Obejct... args)//参数是SQL和任意个参数\n例如以下的操作\nString sql1 = &quot;insert into student(name,sex) values(?,?)&quot;;String sql2 = &quot;update student set sex=? where id=?&quot;;jdbcTemplate.update(sql1,new Object[]&#123;&quot;李白&quot;,&quot;男&quot;&#125;);jdbcTemplate.update(sql2,&quot;女&quot;,1);\n\nbatchUpadate方法（批量增删改操作）int[] batchUpdate(String[] sql)//执行一个数组内的全部sqlint[] batchUpdate(String sql,List&lt;Obejct[]&gt; args)//可以将一个sql语句分别插入不同的值执行\n例如以下操作\n@Testpublic void testBatchUpdate1()&#123;    String[] sql = &#123;            &quot;insert into student(name,sex) values(&#x27;杜哺&#x27;,&#x27;男&#x27;)&quot;,            &quot;insert into student(name,sex) values(&#x27;孟浩然&#x27;,&#x27;男&#x27;)&quot;,            &quot;insert into student(name,sex) values(&#x27;李清照&#x27;,&#x27;女&#x27;)&quot;&#125;;    jdbcTemplate.batchUpdate(sql);&#125;@Testpublic void testBatchUpdate2()&#123;    String sql = &quot;insert into selection(student,course) values(?,?)&quot;;    List&lt;Object[]&gt; list = new ArrayList&lt;&gt;();    list.add(new Object[]&#123;13,1001&#125;);    list.add(new Object[]&#123;15,1002&#125;);    list.add(new Object[]&#123;14,1003&#125;);    jdbcTemplate.batchUpdate(sql,list);&#125;\n\n查询相关方法简单的查询查询结果只有一个字段，例如查询个数，查询所有的男生名字等等\n\n获取一个T queryForObeject(String sql, Class&lt;T&gt; type)//参数是Sql语句和查询结果是一个什么类T queryForObeject(String sql, Object[] args,Class&lt;T&gt; type)T queryForObeject(String sql, Class&lt;T&gt; type, Object... arg)\n例如以下操作String sql = &quot;select count(*) from student&quot;;int count = jdbcTemplate.queryForObject(sql, Integer.class);System.out.println(count);\n\n\n\n获取多个\n\nList&lt;T&gt; queryForList(String sql, Class&lt;T&gt; type)List&lt;T&gt; queryForList(String sql, Obejct[] args,Class&lt;T&gt; type)List&lt;T&gt; queryForList(String sql, Class&lt;T&gt; type, Object... arg)\n例如下面的操作\nString sql = &quot;select name from student where sex=?&quot;;List&lt;String&gt; names = jdbcTemplate.queryForList(sql, String.class,&quot;女&quot;);System.out.println(names);\n\n复杂的查询复杂的查询会封装为Map类型\n\n获取一个Map queryForMap(String sql)Map queryForMap(String sql, Object[] args)Map queryForMap(String sql, Object... arg)\n例如下面的操作String sql = &quot;select * from student where id=?&quot;;Map&lt;String, Object&gt; stu = jdbcTemplate.queryForMap(sql, 13);System.out.println(stu);\n\n\n获取多个\n\nList&lt;Map&lt;String, Object&gt;&gt; queryForList(String sql)List&lt;Map&lt;String, Object&gt;&gt; queryForList(String sql, Object[] args)List&lt;Map&lt;String, Object&gt;&gt; queryForList(String sql, Object... arg)\n看完会发现，只要我们不指定返回的类型，他就是一个查询多个字段获取多个字段的方法\n例如下面操作\nString sql = &quot;select * from student&quot;;List&lt;Map&lt;String, Object&gt;&gt; stus = jdbcTemplate.queryForList(sql);System.out.println(stus);\n查询复杂对象（并封装为实体对象）方法主要有：\n\n获取一个\nT queryForObject(String sql, RowMapper&lt;T&gt; mapper)T queryForObject(String sql, Obeject[] args,RowMapper&lt;T&gt; mapper)T queryForObject(String sql, RowMapper&lt;T&gt; mapper, Object... arg)\n例如下面的操作，其中Student类已经写出，只是一个示意\nString sql = &quot;select * from student where id = ?&quot;;Student student = jdbcTemplate.queryForObject(sql, new RowMapper&lt;Student&gt;() &#123;    @Override    public Student mapRow(ResultSet rs, int rowNum) throws SQLException &#123;        Student stu = new Student();        stu.setId(rs.getInt(&quot;id&quot;));        stu.setName(rs.getString(&quot;name&quot;));        stu.setSex(rs.getString(&quot;sex&quot;));        stu.setBorn(rs.getDate(&quot;born&quot;));        return stu;    &#125;&#125;, 13);System.out.println(student);\n获取多个\nList&lt;T&gt; query(String sql, RowMapper&lt;T&gt; mapper)List&lt;T&gt; query(String sql, Object[] args,RowMapper&lt;T&gt; mapper)List query(String sql, RowMapper&lt;T&gt; maooer,Object... arg)\n\nRowMapper接口可以实现封装为实体对象,例如下面这个操作\nString sql = &quot;select * from student&quot;;List&lt;Student&gt; student = jdbcTemplate.query(sql, new RowMapper&lt;Student&gt;() &#123;    @Override    public Student mapRow(ResultSet rs, int rowNum) throws SQLException &#123;        Student stu = new Student();        stu.setId(rs.getInt(&quot;id&quot;));        stu.setName(rs.getString(&quot;name&quot;));        stu.setSex(rs.getString(&quot;sex&quot;));        stu.setBorn(rs.getDate(&quot;born&quot;));        return stu;    &#125;&#125;);System.out.println(student);\n\n","categories":["Spring"],"tags":["Spring"]},{"title":"04.Vue基本语法介绍一","url":"/2019/07/19/Vue/04-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%B8%80/","content":"\n引言：\n\n这一节介绍有关事件，事件处理的基本知识，\n加油加油！！\n\n\n\n\nVue入门Vue是什么一套用于构建用户界面的渐进式框架\n1.声明式渲染与指令Vue.js的核心是:用一种简单的模板语法来将数据渲染进入DOM\n插值表达式\n&lt;div id=&quot;app&quot;&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;var app = new Vue(&#123;    el:&quot;#app&quot;,    data:&#123;        msg:&#x27;hello&#x27;    &#125;&#125;)\n\nv-bind:绑定元素，可以简写为一个冒号:\n&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&lt;span v-bind:title=&#x27;msg&#x27;&gt;悬停此处查看信息&lt;/span&gt;\t\t\t\t&lt;span :title=&#x27;msg&#x27;&gt;这里是简写形式&lt;/span&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;,\t\t\tdata:&#123;\t\t\t\tmsg:&#x27;页面加载于&#x27;+new Date().toLocaleString()\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n带有前缀v-的被称为指令\n他们是Vue提供的特殊特性，他们会在渲染的DOM上应用特殊的响应式行为\nv-bind:title=’msg’ 意思是：  将这个元素节点的 title 特性与Vue实例的 msg 属性保持一致\n2.条件与循环条件\n&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&lt;p v-if=&#x27;seen&#x27;&gt;条件&lt;/p&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;,\t\t\tdata:&#123;\t\t\t\tseen:true\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n更改seen的布尔值会发现“条件”两字会显示和“消失”（注意这里是消失,直接在DOM上去除）\n循环\n&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&lt;ul&gt;\t\t\t&lt;li v-for=&quot;todo in todos&quot;&gt;&#123;&#123;todo.text&#125;&#125;&lt;/li&gt;\t\t&lt;/ul&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;,\t\t\tdata:&#123;\t\t\t\ttodos:[\t\t\t\t&#123;text: &#x27;学习java&#x27;&#125;,\t\t\t\t&#123;text: &#x27;学习js&#x27;&#125;,\t\t\t\t&#123;text: &#x27;学习Vue&#x27;&#125;\t\t\t\t]\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n注意这里的v-for后面是赋值符号\n&lt;li v-for=&quot;todo in todos&quot;&gt;&#123;&#123;todo.text&#125;&#125;&lt;/li&gt;\nin的前面是自定义的一个名字，in的后面是data里面的一个数组\n3.处理用户输入v-on事件监听器\n&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&lt;p&gt;&#123;&#123;msg&#125;&#125;&lt;/p&gt;\t\t&lt;button v-on:click=&#x27;reverMsg&#x27;&gt;逆序消息&lt;/button&gt;\t\t&lt;button @click=&#x27;reverMsg&#x27;&gt;简写&lt;/button&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;,\t\t\tdata:&#123;\t\t\t\tmsg:&#x27;全面学习Vue&#x27;\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\treverMsg:function () &#123;\t\t\t\t\tthis.msg=this.msg.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\nv-on:可以简写为@符号\n\nv-model来实现表单输入和应用状态的双向绑定\n&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&lt;p&gt;&#123;&#123;msg&#125;&#125;&lt;/p&gt;\t\t&lt;input v-model=&#x27;msg&#x27;&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;,\t\t\tdata:&#123;\t\t\t\tmsg:&#x27;&#x27;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n4.组件化应用构建我们可以用组件来组成一个大型的应用\n一个组件在Vue中即是一个Vue的实例\nVue中注册组件\n&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&lt;todo-item&gt;这是一个新的组件&lt;/todo-item&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;todo-item&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;li&gt;这是一个自定义的组件&lt;/li&gt;&#x27;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n但是这样毫无意义，下面是一个小的实例\n&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&lt;todo-item\t\t\tv-for=&#x27;item in List&#x27;\t\t\t:todo=&#x27;item&#x27;\t\t\t:key=&#x27;item.id&#x27;\t\t&gt;&lt;/todo-item&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\t//子类\t\t\tVue.component(&#x27;todo-item&#x27;,&#123;\t\t\tprops:[&#x27;todo&#x27;],//子类接收父类的信息\t\t\ttemplate:&#x27;&lt;li&gt;&#123;&#123;todo.text&#125;&#125;&lt;/li&gt;&#x27;\t\t&#125;)\t\t//父类\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;,\t\t\tdata:&#123;\t\t\t\tList:[\t\t\t\t&#123;id:0,text:&#x27;java&#x27;&#125;,\t\t\t\t&#123;id:1,text:&#x27;js&#x27;&#125;,\t\t\t\t&#123;id:2,text:&#x27;Vue&#x27;&#125;\t\t\t\t]\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"02.Vue-从一个Todolist开始","url":"/2019/07/19/Vue/02-Vue-%E4%BB%8E%E4%B8%80%E4%B8%AATodolist%E5%BC%80%E5%A7%8B/","content":"\n引言：\n\n这一节用Vue做了一个Todolist的小实例，\n并且给他拆成了组件\n还有简单的组件间传值该怎么办呢？\n加油加油！！\n\n\n\n\n##Vue做一个TodoList做一个TodoList的完整功能，来复习的知识\n&lt;body&gt;&lt;div id=&quot;root&quot;&gt;    &lt;div&gt;        &lt;input         v-model=&quot;inputValue&quot;/&gt;        &lt;!--v-model代表双向绑定，        当输入内容改变或者实例中的inputValue改变，        另一个也会随之改变，        是相互影响的！--&gt;        &lt;button @click=&quot;handleSubmit&quot;&gt;提交&lt;/button&gt;    &lt;/div&gt;    &lt;ul&gt;        &lt;li         v-for=&quot;(item,index) of list&quot;         :key=&quot;index&quot;&gt;        &#123;&#123;item&#125;&#125;        &lt;/li&gt;    &lt;/ul&gt;&lt;/div&gt;&lt;script&gt;    new Vue(&#123;        el: &quot;#root&quot;,        data: &#123;            inputValue: &#x27;&#x27;,            list: [],        &#125;,        methods: &#123;            handleSubmit: function () &#123;                this.list.push(this.inputValue);//记住要加this,添加到数组当中                this.inputValue = &#x27;&#x27;;//输入完成后清空输入框            &#125;        &#125;    &#125;)&lt;/script&gt;&lt;/body&gt;\n接下来我们对它进行组件拆分定义局部的组件&lt;div id=&quot;root&quot;&gt;    &lt;div&gt;        &lt;input v-model=&quot;inputValue&quot;/&gt;        &lt;button @click=&quot;handleSubmit&quot;&gt;提交&lt;/button&gt;    &lt;/div&gt;    &lt;ul&gt;        &lt;todo-item        v-for=&quot;(item,index) of list&quot;        :key=&quot;index&quot;        :content=&quot;item&quot;        &gt;&lt;/todo-item&gt;        &lt;!--这样就可以把参数传给组件--&gt;    &lt;/ul&gt;&lt;/div&gt;&lt;script&gt;    let TodoItem = &#123;        props:[&#x27;content&#x27;],        template: &#x27;&lt;li&gt;&#123;&#123;content&#125;&#125;&lt;/li&gt;&#x27;    &#125;;    new Vue(&#123;        el: &quot;#root&quot;,        data: &#123;            inputValue: &#x27;&#x27;,            list: [],        &#125;,        methods: &#123;            handleSubmit: function () &#123;                this.list.push(this.inputValue);//添加到数组当中                this.inputValue = &#x27;&#x27;;//输入完成后清空输入框            &#125;        &#125;,        //局部变量要进行注册        components: &#123;            &#x27;todo-item&#x27;: TodoItem        &#125;,    &#125;)&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n定义全局的组件&lt;body&gt;&lt;div id=&quot;root&quot;&gt;    &lt;div&gt;        &lt;input v-model=&quot;inputValue&quot;/&gt;        &lt;button @click=&quot;handleSubmit&quot;&gt;提交&lt;/button&gt;    &lt;/div&gt;    &lt;ul&gt;        &lt;li v-for=&quot;(item,index) of list&quot; :key=&quot;index&quot;&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt;    &lt;/ul&gt;    &lt;ul&gt;        &lt;todo-item&gt;&lt;/todo-item&gt;        &lt;!--我们在这里使用自定义的组件--&gt;    &lt;/ul&gt;&lt;/div&gt;&lt;script&gt;    //Vue提供了我们自定义组件的功能    Vue.component(&#x27;todo-item&#x27;,&#123;        //这里定义的名字可以是TodoItem,        //但在使用的时候依然要用todo-Item        template: &#x27;&lt;li&gt;全局组件&lt;/li&gt;&#x27;    &#125;);//这里是全局组件    new Vue(&#123;        el: &quot;#root&quot;,        methods: &#123;            handleSubmit: function () &#123;                this.list.push(this.inputValue);//添加到数组当中                this.inputValue = &#x27;&#x27;;//输入完成后清空输入框            &#125;        &#125;    &#125;)&lt;/script&gt;&lt;/body&gt;\n\n把li标签拆成了组件&lt;body&gt;&lt;div id=&quot;root&quot;&gt;    &lt;div&gt;        &lt;input v-model=&quot;inputValue&quot;/&gt;        &lt;button @click=&quot;handleSubmit&quot;&gt;提交&lt;/button&gt;    &lt;/div&gt;    &lt;ul&gt;        &lt;todo-item                v-for=&quot;(item,index) of list&quot;                :key=&quot;index&quot;                :content=&quot;item&quot;        &gt;&lt;/todo-item&gt;        &lt;!--        ！！父组件给子组件传值：        1.         对于外层的内容来说，        我们自建的组件属于外部的一个子组件，        我们可以使用v-bind命令来对子组件进行传值        例如这里的 :content=&#x27;item&#x27;         --&gt;        &lt;!--这样就可以把参数传给组件--&gt;    &lt;/ul&gt;&lt;/div&gt;&lt;script&gt;    //Vue提供了我们自定义组件的功能    Vue.component(&#x27;todo-item&#x27;,&#123;        props:[&#x27;content&#x27;],        //2. 子组件光接收不行，还得接收!!        template: &#x27;&lt;li&gt;&#123;&#123;content&#125;&#125;&lt;/li&gt;&#x27;    &#125;);//这里是全局组件    new Vue(&#123;        el: &quot;#root&quot;,        data: &#123;            inputValue: &#x27;&#x27;,            list: [],        &#125;,        methods: &#123;            handleSubmit: function () &#123;                this.list.push(this.inputValue);//添加到数组当中                this.inputValue = &#x27;&#x27;;//输入完成后清空输入框            &#125;        &#125;    &#125;)&lt;/script&gt;&lt;/body&gt;\n其实每一个Vue的实例都是一个组件，而当你不输入template的内容时，它默认会是挂载点下的所有内容作为其模板\n//Vue中的组件都是Vue的一个实例，可以给他们绑定一个事件    Vue.component(&#x27;todo-item&#x27;, &#123;        props: [&#x27;content&#x27;],        template: &#x27;&lt;li @click=&quot;handleClick&quot;&gt;&#123;&#123;content&#125;&#125;&lt;/li&gt;&#x27;,        methods: &#123;            handleClick:function () &#123;                alert(&#x27;clicked&#x27;)            &#125;        &#125;    &#125;);\n我们再添加一个删除功能\n&lt;body&gt;&lt;div id=&quot;root&quot;&gt;    &lt;div&gt;        &lt;input v-model=&quot;inputValue&quot;/&gt;        &lt;button @click=&quot;handleSubmit&quot;&gt;提交&lt;/button&gt;    &lt;/div&gt;    &lt;ul&gt;        &lt;todo-item                v-for=&quot;(item,index) of list&quot;                :key=&quot;index&quot;                :content=&quot;item&quot;                :index=&quot;index&quot;                @delete=&quot;handleDelete&quot;        &gt;&lt;/todo-item&gt;        &lt;!--这样就可以把参数传给组件--&gt;    &lt;/ul&gt;&lt;/div&gt;&lt;script&gt;    //Vue中的组件都是Vue的一个实例，可以给他们绑定一个事件    Vue.component(&#x27;todo-item&#x27;, &#123;        props: [&#x27;content&#x27;, &#x27;index&#x27;],        template: &#x27;&lt;li @click=&quot;handleClick&quot;&gt;&#123;&#123;content&#125;&#125;&lt;/li&gt;&#x27;,        methods: &#123;            handleClick: function () &#123;                this.$emit(&#x27;delete&#x27;, this.index)                //!!子组件向父组件传值                //触发当前实例上的事件            &#125;,        &#125;    &#125;);    new Vue(&#123;        el: &quot;#root&quot;,        data: &#123;            inputValue: &#x27;&#x27;,            list: [],        &#125;,        methods: &#123;            handleSubmit: function () &#123;                this.list.push(this.inputValue);                this.inputValue = &#x27;&#x27;;            &#125;,            handleDelete: function (index) &#123;                this.list.splice(index, 1)//删除当前索引后的一个元素            &#125;        &#125;    &#125;)&lt;/script&gt;\n\n总结一下简单的组件间传值\n父组件给子组件传值\n\n\n在子组件上用v-bind来对子组件传值\n子组件填入props的属性，接收传来的值，就可以使用了\n\n\n子组件给父组件传值\n\n\n使用this.$emit()这个函数\n子组件要监听emit所发出的事件名并对其有相应的反应\n\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"03.Vue-cli的创建与使用","url":"/2019/07/19/Vue/03-Vue-cli%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8/","content":"\n引言：\n\n这一节介绍了Vue-cli如何安装，还有一个Todolist的小实例\n加油加油！！\n\n\n\n\nVue-cli安装命令行工具(cli)，他会为我们快速搭建繁杂的脚手架\n在终端输入\nnpm install --global vue-cli\n\n创建一个基于webpack模板的新项目\nvue init webpack my-project\n安装依赖\ncd my-project\n进入创建的目录下，run运行\nnpm run dev\n\n文件目录build文件：放置一些webpack配置文件,不动\nconfig文件：是针对于开发环境和线上环境的配置文件，不动\nnode-modules文件：项目的依赖\nsrc文件：源代码放置的目录\nstatic文件：放置的是一些静态的资源\nindex.html文件：整个网页最外层的html文件，带有一个id为app的挂载点\n其他都不动\n\nsrc下的文件main.js:是我们整个项目的入口文件，内部已经注册了一个叫做app的组件\napp.js:我们要自行设计的页面，我们在这里设计的组件通过main.js内的挂载点显示在页面上\n\n单文件组件编码一个文件代表一个组件\n而这个组件内有必要的代码\n\ntemplate模板\nscrpit逻辑\nstyle样式\n\n\n我们使用vue-cli来开发todolist1. main.js这里是文件的入口，我们创建的组件在这里要引入\nimport Vue from &#x27;vue&#x27;import Todolist from &#x27;./TodoList&#x27;//1.import引入Vue.config.productionTip = false/* eslint-disable no-new */new Vue(&#123;  el: &#x27;#app&#x27;,  components: &#123; Todolist &#125;,//2.注册组件  template: &#x27;&lt;Todolist/&gt;&#x27;//3.改完这里就可以使用了&#125;);&lt;!--我们在这里引入我们自定义的 Todolist 组件--&gt;\n2. 自定义的TodoList组件组件一般也由三个部分组成，要放在components的目录下\n&lt;template&gt;  &lt;li class=&quot;item&quot; @click=&quot;handleDelete&quot;&gt;&#123;&#123;content&#125;&#125;&lt;/li&gt;&lt;/template&gt;&lt;script&gt;  export default &#123;    props:[&#x27;content&#x27;,&#x27;index&#x27;],    methods:&#123;      handleDelete:function () &#123;        this.$emit(&#x27;delete&#x27;,this.index)        //触发父类的事件      &#125;    &#125;  &#125;&lt;/script&gt;&lt;!--这里使用了scoped来限制css的作用域，使我们的css只作用于本组件--&gt;&lt;style scoped&gt;  .item&#123;    color: green;  &#125;&lt;/style&gt;\n3.TodoList页面TodoList.vue文件就放置在与main.js文件相同的位置即可\n&lt;template&gt;  &lt;div&gt;    &lt;div&gt;      &lt;input v-model=&quot;inputValue&quot;/&gt;      &lt;button @click=&quot;handleSubmit&quot;&gt;提交&lt;/button&gt;    &lt;/div&gt;    &lt;ul&gt;      &lt;todo-item        v-for=&quot;(item,index) of list&quot;        :key=&quot;index&quot;        :content=&quot;item&quot;        :index=&quot;index&quot;        @delete=&quot;handleDelete&quot;      &gt;&lt;/todo-item&gt;      &lt;!--这里使用了我们自建的组件--&gt;    &lt;/ul&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;  import TodoItem from &#x27;./components/TodoItem&#x27;  export default &#123;    components:&#123;      &#x27;todo-item&#x27;: TodoItem      &lt;!--这种声明方式可以让我们直接使用todo-item这个标签来使用我们的组件--&gt;    &#125;,    data : function () &#123;      return&#123;        inputValue:&#x27;&#x27;,        list:[]      &#125;    &#125;,    methods: &#123;      handleSubmit:function()&#123;        this.list.push(this.inputValue);        this.inputValue=&#x27;&#x27;;      &#125;,      handleDelete:function () &#123;        this.list.splice(this.index,1)      &#125;    &#125;  &#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"05.Vue基本语法介绍二","url":"/2019/07/20/Vue/05-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%BA%8C/","content":"\n引言：\n\n介绍了数据与方法，\n解释了生命周期钩子\n加油加油！！\n\n\n\n\nVue入门创建一个Vue实例var vm = new Vue(&#123;    //内容&#125;)\n\n注意Vue的V要大写，没有完全遵循MVVM模型，但是一般都用vm(ViewModel)这个变量名来表示Vue实例\n所有的Vue组件都是Vue的实例，并且接受相同的选项对象\n数据与方法当Vue实例被创建的时候，它会把data内的所有的属性加入到Vue的响应式系统中\n当这些属性值发生变化，视图也会跟着变化\n// 我们的数据对象var data = &#123; a: 1 &#125;// 该对象被加入到一个 Vue 实例中var vm = new Vue(&#123;  data: data&#125;)// 获得这个实例上的属性// 返回源数据中对应的字段vm.a == data.a // =&gt; true// 设置属性也会影响到原始数据vm.a = 2data.a // =&gt; 2// ……反之亦然data.a = 3vm.a // =&gt; 3\n注意：\n\n改变任意一个值，会影响到原始的数据\n只有当实例被创建的时候data中的数据才是响应式的\n\n比如这里,新添加一个新的属性，是不会发生响应的\nvm.b=&#x27;你好&#x27;\n但是一开始设置为空的话就可以响应式了，所以我们要对所有需要响应变化的数据在data中设定它的初始值\n例如：\ndata: &#123;  newTodoText: &#x27;&#x27;,  visitCount: 0,  hideCompletedTodos: false,  todos: [],  error: null&#125;\n\n但是有唯一的例外Object.freeze方法会阻止修改现有的属性，意味着响应系统无法再追踪变化\n&lt;body&gt;  &lt;div id=&quot;app&quot;&gt;    &lt;p&gt;&#123;&#123;foo&#125;&#125;&lt;/p&gt;    &lt;button @click=&#x27;foo=&quot;baz&quot;&#x27;&gt;点击刷新&lt;/button&gt;  &lt;/div&gt;  &lt;script&gt;    var obj= &#123;      foo:&#x27;bar&#x27;    &#125;;    // Object.freeze(obj);    new Vue(&#123;      el:&#x27;#app&#x27;,      data:obj    &#125;);  &lt;/script&gt;&lt;/body&gt;\n\nvm.$data === datavm.$el === document.getElementById(&quot;example&quot;)// $watch 是一个实例方法vm.$watch(&#x27;a&#x27;, function (newValue, oldValue) &#123;  // 这个回调将在 `vm.a` 改变后调用&#125;)\n\n实例声明周期钩子Vue实例在被创建时要经过一系列初始化过程,在这个过程中会运行一些叫做生命周期钩子的函数\n例如\ncreated钩子可以用来在一个实例被创建之后执行代码\nnew Vue(&#123;  data: &#123;    a: 1  &#125;,  created: function () &#123;    // `this` 指向 vm 实例    console.log(&#x27;a is: &#x27; + this.a)  &#125;&#125;)// =&gt; &quot;a is: 1&quot;\n注意：不要在选项属性或回调上使用箭头函数\n生命周期图\n图中我们可以看到：\n\n创建一个Vue实例\n初始化事件和生命周期\nbeforeCreate()\n处理外部的注入及双向的绑定\ncreated()\n是否有el选项\n是否有template选项\n\n当有el选项没有template,会默认把el外层的整个html标签当做template使用：即以下两种是相同的\n&lt;div id=&quot;app&quot;&gt;    hello world&lt;/div&gt;  &lt;script&gt;    var vm= new Vue(&#123;      el:&#x27;#app&#x27;,    &#125;)  &lt;/script&gt;\n&lt;div id=&quot;app&quot;&gt;&lt;/div&gt;  &lt;script&gt;    var vm= new Vue(&#123;      el:&#x27;#app&#x27;,      template:&#x27;&lt;div&gt;hello world&lt;/div&gt;&#x27;    &#125;)  &lt;/script&gt;\n\n有template则正常执行 \nbeforeMount()\n开始渲染页面\nmounted()\n等待数据更新\nbeforeUpdate()\n虚拟DOM重新渲染匹配\nupdated()\n当销毁组件的时候vm.$destroy()\nbeforeDestroy()\n销毁监听，子组件还有监听事件\ndestroyed()\n\nvue共有十一个生命周期函数\n还有三个生命周期函数以后说明,他们是：\nactivated()\ndeactivated()\nerrorCaptured()\n代码:\n生命周期函数千万不要放在methods内\n&lt;body&gt;  &lt;div id=&quot;app&quot;&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;  &lt;script&gt;    //生命周期函数就是在某个时间点自动执行的函数    var vm= new Vue(&#123;      el:&#x27;#app&#x27;,      data:&#123;        content:&#x27;hello world&#x27;      &#125;,      //生命周期函数不要写在methods内      beforeCreate()&#123;        console.log(&quot;第一个&quot;);        console.log(this.$el);        //undefined      &#125;,      created()&#123;        console.log(&quot;第二个&quot;);        console.log(this.$el);        //undefined      &#125;,      beforeMount()&#123;        console.log(&quot;第三个&quot;);        console.log(this.$el);        //&lt;div id=&quot;app&quot;&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;      &#125;,      mounted()&#123;        console.log(&quot;第四个&quot;);        console.log(this.$el);        //&lt;div id=&quot;app&quot;&gt;hello world&lt;/div&gt;      &#125;,      //当数据更新的时候      //控制台输入vm.content=&#x27;bye world&#x27;      beforeUpdate()&#123;        console.log(&quot;第五个&quot;);        console.log(this.$el);        //&lt;div id=&quot;app&quot;&gt;bye world&lt;/div&gt;      &#125;,      updated()&#123;        console.log(&quot;第六个&quot;);        console.log(this.$el);        //&lt;div id=&quot;app&quot;&gt;bye world&lt;/div&gt;      &#125;,      //控制台执行vm.$destroy()函数      beforeDestroy()&#123;        console.log(&quot;第七个&quot;);        console.log(this.$el);        //&lt;div id=&quot;app&quot;&gt;bye world&lt;/div&gt;      &#125;,      destroyed()&#123;        console.log(&quot;第八个&quot;);        console.log(this.$el);        //&lt;div id=&quot;app&quot;&gt;bye world&lt;/div&gt;      &#125;    &#125;)  &lt;/script&gt;&lt;/body&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"09.Vue基本语法介绍六","url":"/2019/07/20/Vue/09-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%85%AD/","content":"\n引言：\n\n这一节介绍有关条件渲染的基本知识，\n加油加油！！\n\n\n\n\n条件渲染条件渲染v-ifv-id用于条件性的渲染一块内容，只有当真值的时候才会被渲染\n&lt;h1 v-if=&quot;awesome&quot;&gt;Vue is awesome!&lt;/h1&gt;\n还可以添加一个v-else\n&lt;body&gt;\t\t&lt;div id=&quot;demo&quot;&gt;\t\t&lt;h1 v-if=&#x27;awesome&#x27;&gt;我能不能出来&lt;/h1&gt;\t\t&lt;h1 v-else&gt;OOOOOh-------&lt;/h1&gt;\t\t&lt;button @click=&#x27;isUp&#x27;&gt;按钮&lt;/button&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tnew Vue(&#123;\t\t\tel:&quot;#demo&quot;,\t\t\tdata:&#123;\t\t\t\tawesome:true,\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\tisUp:function()&#123;\t\t\t\t\treturn this.awesome=!this.awesome;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n在&lt;template&gt;元素上使用v-if条件渲染分组v-if只能添加到一个元素上，当我们想切换多个元素的时候，可以把一个template元素当做不可见的包裹元素，并在上面使用v-if\n&lt;template v-if=&quot;ok&quot;&gt;  &lt;h1&gt;Title&lt;/h1&gt;  &lt;p&gt;Paragraph 1&lt;/p&gt;  &lt;p&gt;Paragraph 2&lt;/p&gt;&lt;/template&gt;\n还有v-else-if&lt;body&gt;\t\t&lt;div id=&quot;demo&quot;&gt;\t\t&lt;h1 v-if=&#x27;awesome===2&#x27;&gt;我能不能出来&lt;/h1&gt;\t\t&lt;h1 v-else-if=&#x27;awesome===1&#x27;&gt;我有点慌&lt;/h1&gt;\t\t&lt;h1 v-else&gt;OOOOOh-------&lt;/h1&gt;\t\t&lt;button @click=&#x27;isUp&#x27;&gt;按钮&lt;/button&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tnew Vue(&#123;\t\t\tel:&quot;#demo&quot;,\t\t\tdata:&#123;\t\t\t\tawesome:2,\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\tisUp:function()&#123;\t\t\t\t\treturn this.awesome=this.awesome-1;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n用 key 管理可复用的元素&lt;template v-if=&quot;loginType === &#x27;username&#x27;&quot;&gt;  &lt;label&gt;Username&lt;/label&gt;  &lt;input placeholder=&quot;Enter your username&quot;&gt;&lt;/template&gt;&lt;template v-else&gt;  &lt;label&gt;Email&lt;/label&gt;  &lt;input placeholder=&quot;Enter your email address&quot;&gt;&lt;/template&gt;\n那么在上面的代码中切换 loginType 将不会清除用户已经输入的内容。因为两个模板使用了相同的元素，&lt;input&gt; 不会被替换掉——仅仅是替换了它的 placeholder。\n但有时我们需要两个元素独立，不要复用他们，只需要加一个key即可\n&lt;template v-if=&quot;loginType === &#x27;username&#x27;&quot;&gt;  &lt;label&gt;Username&lt;/label&gt;  &lt;input placeholder=&quot;Enter your username&quot; key=&quot;username-input&quot;&gt;&lt;/template&gt;&lt;template v-else&gt;  &lt;label&gt;Email&lt;/label&gt;  &lt;input placeholder=&quot;Enter your email address&quot; key=&quot;email-input&quot;&gt;&lt;/template&gt;\n注意， 元素仍然会被高效地复用，因为它们没有添加 key 属性。\n总被渲染的v-show&lt;h1 v-show=&quot;ok&quot;&gt;Hello!&lt;/h1&gt;\n不同的是v-show的元素始终会被渲染并保存在DOM中。v-show只是简单地切换元素的css属性display\n注意，v-show 不支持  元素，也不支持 v-else。\nv-if和v-show的区别v-if 是“真正”的条件渲染，因为它会确保在切换过程中条件块内的事件监听器和子组件适当地被销毁和重建。\nv-if 也是惰性的：如果在初始渲染时条件为假，则什么也不做——直到条件第一次变为真时，才会开始渲染条件块。\n相比之下，v-show元素总是会被渲染，并且只是简单地基于 CSS 进行切换。\n所以：\n如果需要非常频繁地切换，则使用 v-show 较好；如果在运行时条件很少改变，则使用 v-if 较好。\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"06.Vue基本语法介绍三","url":"/2019/07/20/Vue/06-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%B8%89/","content":"\n引言：\n\n介绍模板语法的基本知识，\n加油加油！！\n\n\n\n\n插值文本文本插值法\n&lt;span&gt;Message: &#123;&#123; msg &#125;&#125;&lt;/span&gt;\n无论何时只要msg的值发生变化，视图就会更新\n一次性的插值,该值不会更新\n&lt;span v-once&gt;不会改变: &#123;&#123; msg &#125;&#125;&lt;/span&gt;\nv-text也能实现相同的功能,但是v-text不会转化标签代码\n&lt;div id=&quot;app&quot;&gt;\t\t&lt;div v-text=&#x27;name&#x27;&gt;&lt;/div&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;,\t\t\tdata:&#123;\t\t\t\tname:&#x27;dell&#x27;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;\n原始HTML为了输出真正的HTML\n&lt;p&gt;Using v-html directive: &lt;span v-html=&quot;rawHtml&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;!--这里的rawHTML是一个标签表达式，span标签的内部会被替换成它的属性值--&gt;\n\n特性文本插值法不能作用在HTML特性上面，因此需要用到v-bind\n&lt;button v-bind:disabled=&quot;isButton&quot;&gt;Button&lt;/button&gt;\n对于布尔特性，如果isButton这个值为null、undefined，false则disabled特性甚至不会被包含在渲染出来的中\n使用JavaScript表达式所有的指令后都可以使用js的表达式，\n插值表达式内也可以使用表达式\n&#123;&#123; number + 1 &#125;&#125;&#123;&#123; ok ? &#x27;YES&#x27; : &#x27;NO&#x27; &#125;&#125;&#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125;&lt;div v-bind:id=&quot;&#x27;list-&#x27; + id&quot;&gt;&lt;/div&gt;\n有个限制就是，每个绑定都只能包含单个表达式，所以下面的例子都不会生效。\n&lt;!-- 这是语句，不是表达式 --&gt;&#123;&#123; var a = 1 &#125;&#125;&lt;!-- 流控制也不会生效，请使用三元表达式 --&gt;&#123;&#123; if (ok) &#123; return message &#125; &#125;&#125;\n模板表达式都被放在沙盒中，只能访问全局变量的一个白名单，如 Math 和 Date 。你不应该在模板表达式中试图访问用户定义的全局变量。\n指令带有v-前缀的特性如v-if\n&lt;p v-if=&quot;seen&quot;&gt;现在你看到我了&lt;/p&gt;\n参数一些指令可以接收一个参数，在指令名称之后以冒号表示\n例如：v-bind可以用于响应式的更新HTML,简写为:\n&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;\n这里的href就是参数，告知v-bind指令将该元素的href特性与表达式url的值绑定\n又例如：v-on指令，简写为@\n&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt;\n用于监听DOM事件，这里的参数click就是监听的事件名\n动态参数可以用方括号括起来的 JavaScript 表达式作为一个指令的参数：\n&lt;a v-bind:[attributeName]=&quot;url&quot;&gt; ... &lt;/a&gt;\n这里的attributeName会被作为一个js的表达式来动态求值，求得的值会作为最终的参数来使用。\n例如，如果你的 Vue 实例有一个data属性attributeName，其值为”href”，那么这个绑定将等价于 v-bind:href。\n也可以使用动态参数为一个动态的事件名绑定处理函数\n&lt;a v-on:[eventName]=&quot;doSomething&quot;&gt; ... &lt;/a&gt;\n当 eventName 的值为 “focus” 时，v-on:[eventName] 将等价于 v-on:focus\n动态参数的值的约束动态参数预期会求出一个字符串，异常情况是null\n这个null值可以被显性的用于移除绑定\n动态参数表达式的约束因为某些字符在html的特性名内无效，所以在DOM使用模板要回避大写键名（例如空格和引号）\n&lt;!-- 这会触发一个编译警告 --&gt;&lt;a v-bind:[&#x27;foo&#x27; + bar]=&quot;value&quot;&gt; ... &lt;/a&gt;\n变通的办法是使用没有空格或引号的表达式，或用计算属性替代这种复杂表达式。\n另外，如果你在 DOM 中使用模板 (直接在一个 HTML 文件里撰写模板)，需要留意浏览器会把特性名全部强制转为小写\n修饰符半角句号 . 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定。\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"07.Vue基本语法介绍四","url":"/2019/07/20/Vue/07-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%9B%9B/","content":"\n引言：\n\n介绍有关计算属性的基本知识，\n加油加油！！\n\n\n\n\n计算属性和监听器计算属性对于任何的复杂处理都应该使用计算属性\n例子\n&lt;body&gt;\t&lt;div id=&quot;example&quot;&gt;\t\t&lt;p&gt;Original msg:&quot;&#123;&#123;msg&#125;&#125;&quot;&lt;/p&gt;\t\t&lt;p&gt;Computed reversed msg:&quot;&#123;&#123;revermsg&#125;&#125;&quot;&lt;/p&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#example&#x27;,\t\t\tdata:&#123;\t\t\t\tmsg:&#x27;这条信息会被逆转&#x27;\t\t\t&#125;,\t\t\tcomputed:&#123;\t\t\t\t//计算属性的getter\t\t\t\trevermsg:function () &#123;\t\t\t\t\t//this指向vm\t\t\t\t\treturn this.msg.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;);\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n当原属性发生变化的时候，vue会自动重新计算计算属性，他们俩都会变化\n计算属性缓存vs方法上述的例子，我们可以使用方法来解决如：\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;\t&lt;meta charset=&quot;UTF-8&quot;&gt;\t&lt;title&gt;\t&lt;/title&gt;\t&lt;script src=&quot;js/vue.js&quot; &gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;\t&lt;div id=&quot;example&quot;&gt;\t\t&lt;p&gt;Original msg:&quot;&#123;&#123;msg&#125;&#125;&quot;&lt;/p&gt;\t\t&lt;p&gt;Computed reversed msg:&quot;&#123;&#123;revermsg()&#125;&#125;&quot;&lt;/p&gt;&lt;!-- 这里要加括号 --&gt;\t\t\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#example&#x27;,\t\t\tdata:&#123;\t\t\t\tmsg:&#x27;这条信息会被逆转&#x27;\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\trevermsg: function () &#123;\t\t\t\t\treturn this.msg.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;);\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;    \n这两种方法（计算属性与方法）都可以达到效果，区别是：\n计算属性是基于他们的响应式依赖进行缓存的只在相关响应式依赖发生改变时才会重新求值\n意味着只要msg没有发生改变，多次访问reversemsg计算属性会立即返回之前的结果，而不必再次执行函数\n因为拥有缓存，再次渲染的时候不需要重新计算该值，增加了渲染的速度\n计算属性vs监听属性计算属性一般会比监听更加的方便例如：\n监听属性\n&lt;body&gt;\t&lt;div id=&quot;demo&quot;&gt;\t\t&#123;&#123;fullName&#125;&#125;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#demo&#x27;,\t\t\tdata:&#123;\t\t\t\tfirstName:&#x27;foo&#x27;,\t\t\t\tlastName:&#x27;bar&#x27;,\t\t\t\tfullName:&#x27;foo bar&#x27;,\t\t\t&#125;,\t\t\twatch:&#123;\t\t\t\tfirstName:function(val)&#123;\t\t\t\t\tthis.fullName = val + &quot;&quot;+ this.lastName\t\t\t\t&#125;,\t\t\t\tlastName:function(val)&#123;                \tthis.fullName=this.firstName+&#x27;&#x27;+val\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n而使用计算属性就方便了许多\n&lt;body&gt;\t&lt;div id=&quot;demo&quot;&gt;\t\t&#123;&#123;fullName&#125;&#125;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#demo&#x27;,\t\t\tdata:&#123;\t\t\t\tfirstName:&#x27;foo&#x27;,\t\t\t\tlastName:&#x27;bar&#x27;,\t\t\t\tfullName:&#x27;foo bar&#x27;,\t\t\t&#125;,\t\t\tcomputed:&#123;\t\t\t\tfullName:function()&#123;\t\t\t\t\treturn this.firstName+this.lastName\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n当需要在数据变化时执行异步或开销大的操作时，这个方式是最有用的\n计算属性的getter和setter例子：\n&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&#123;&#123;fullName&#125;&#125;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;,\t\t\tdata:&#123;\t\t\t\tfirstName:&#x27;Dell&#x27;,\t\t\t\tlastName:&#x27;Lee&#x27;,\t\t\t&#125;,\t\t\tcomputed:&#123;\t\t\t\t//fullName可以写为一个对象\t\t\t\tfullName: &#123;\t\t\t\t\tget()&#123;\t\t\t\t\t\treturn this.firstName+&#x27; &#x27;+this.lastName\t\t\t\t\t&#125;,\t\t\t\t\tset(value)&#123;\t\t\t\t\t\tvar arr = value.split(&#x27; &#x27;);\t\t\t\t\t\t//用空格将其打散\t\t\t\t\t\tthis.firstName = arr[0];//得到firstName\t\t\t\t\t\tthis.lastName =  arr[1];//得到lastName\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"08.Vue基本语法介绍五","url":"/2019/07/20/Vue/08-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%BA%94/","content":"\n引言：\n\n介绍Vue中有关CSS与Style绑定的基本知识，\n加油加油！！\n\n\n\n\nCSS与Style绑定绑定HTML Class对象语法我们可以动态的切换class\n&lt;div v-bind:class=&quot;&#123; active: isActive &#125;&quot;&gt;&lt;/div&gt;\n表示：active这个class存在与否将取决于数据属性isActive的真值\n记住形式:class=&#39;&#123;active: isActive&#125;&#39;\n多个值的切换\n&lt;div  class=&quot;static&quot;  v-bind:class=&quot;&#123; active: isActive, &#x27;text-danger&#x27;: hasError &#125;&quot;&gt;&lt;/div&gt;\ndata: &#123;  isActive: true,  hasError: false&#125;\n结果就是\n&lt;div class=&quot;static active&quot;&gt;&lt;/div&gt;\n当isActive和hasError发生变化的时候，class列表会相应的更新\n绑定的数据对象可以写在组件里\ndata: &#123;  classObject: &#123;    active: true,    &#x27;text-danger&#x27;: false  &#125;&#125;\n还可以绑定一个返回对象的计算属性\n&lt;body&gt;\t&lt;div \t\tid=&quot;demo&quot; \t\t:class=&#x27;classObject&#x27;\t\t&gt;&lt;/div&gt;\t&lt;script&gt;\t\tdata:&#123;\t\t\tisActive:true,\t\t\terror:null\t\t&#125;,\t\tcomputed:&#123;\t\t\tclassObject:function () &#123;\t\t\t\treturn&#123;\t\t\t\t\tactive: this.isActive&amp;&amp;!this.error,\t\t\t\t\t&#x27;text-danger&#x27;:this.error&amp;&amp;this.error.type===&#x27;fatal&#x27;\t\t\t\t\t//text-danger是bootstrap的一个属性，这里理解原理即可\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t&lt;/script&gt;&lt;/body&gt;\n\n数组语法我们可以把一个数组传给v-bind:class\n&lt;div v-bind:class=&quot;[activeClass, errorClass]&quot;&gt;&lt;/div&gt;\ndata:&#123;    activeClass:&#x27;active&#x27;,    errorClass:&#x27;text-danger&#x27;&#125;\n渲染为:\n&lt;div class=&#x27;active text-danger&#x27;&gt;&lt;/div&gt;\n\n要加入条件可以使用三元表达式\n&lt;div v-bind:class=&quot;[isActive ? activeClass : &#x27;&#x27;, errorClass]&quot;&gt;&lt;/div&gt;\n\n这样始终有errorClass但是activeClass会根据真值来判断是否添加\n在数组语法中也可以使用对象语法\n&lt;div v-bind:class=&quot;[&#123; active: isActive &#125;, errorClass]&quot;&gt;&lt;/div&gt;\n\n用在组件上当在一个自定义组件上使用class属性的时候，这些类将被添加到该组件的根元素上面，这个元素上已经存在的类不会被覆盖\n&lt;body&gt;\t&lt;div id=&quot;demo&quot;&gt;\t\t&lt;my-component class=&#x27;baz boo&#x27;&gt;&lt;/my-component&gt;\t&lt;/div&gt;\t\t\t&lt;script&gt;\t\tVue.component(&#x27;my-component&#x27;, &#123;  \t\t\ttemplate: &#x27;&lt;p class=&quot;foo bar&quot;&gt;Hi&lt;/p&gt;&#x27;\t\t&#125;)\t\tnew Vue(&#123;\t\t\tel:&#x27;#demo&#x27;\t\t&#125;)//new Vue一定要放在组件注册的后面，否则会显示组件没有注册\t\t\t&lt;/script&gt;\t&lt;/body&gt;\nHTMl将被渲染为\n&lt;p class=&quot;foo bar baz boo&quot;&gt;Hi&lt;/p&gt;\n绑定内嵌样式对象语法v-bind:style 的对象语法十分直观——看着非常像 CSS，但其实是一个 JavaScript 对象\nCSS 属性名可以用驼峰式 或 短横线分隔(括号括起来) 来命名\n&lt;div v-bind:style=&quot;&#123; color: activeColor, fontSize: fontSize + &#x27;px&#x27; &#125;&quot;&gt;&lt;/div&gt;\ndata: &#123;  activeColor: &#x27;red&#x27;,  fontSize: 30&#125;\n直接绑定到一个样式对象上更好\n&lt;div v-bind:style=&quot;styleObject&quot;&gt;&lt;/div&gt;\ndata: &#123;  styleObject: &#123;    color: &#x27;red&#x27;,    fontSize: &#x27;13px&#x27;  &#125;&#125;\n数组语法v-bind:style 的数组语法可以将多个样式对象应用到同一个元素上：\n&lt;div v-bind:style=&quot;[baseStyles, overridingStyles]&quot;&gt;&lt;/div&gt;\n多重值&lt;div :style=&quot;&#123; display: [&#x27;-webkit-box&#x27;, &#x27;-ms-flexbox&#x27;, &#x27;flex&#x27;] &#125;&quot;&gt;&lt;/div&gt;\n这样写只会渲染数组中最后一个被浏览器支持的值。在本例中，如果浏览器支持不带浏览器前缀的 flexbox，那么就只会渲染 display: flex。\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"13-Vue基本语法介绍十","url":"/2019/07/21/Vue/13-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%8D%81/","content":"\n引言：\n\n这一节介绍Vue组件的基本知识，\n加油加油！！\n\n\n\n\n组件基础基本示例// 定义一个名为 button-counter 的新组件Vue.component(&#x27;button-counter&#x27;, &#123;  data: function () &#123;    return &#123;      count: 0    &#125;  &#125;,  template: &#x27;&lt;button v-on:click=&quot;count++&quot;&gt;You clicked me &#123;&#123; count &#125;&#125; times.&lt;/button&gt;&#x27;&#125;)\n组件是可以重复使用的Vue实例，且带有一个名字，例如&lt;button-counter&gt;。\n我们可以在一个通过new Vue创建的Vue根实例中把这个组件作为自定义元素来使用\n&lt;div id=&quot;components-demo&quot;&gt;  &lt;button-counter&gt;&lt;/button-counter&gt;&lt;/div&gt;\nnew Vue(&#123; el: &#x27;#components-demo&#x27; &#125;)\n组件的复用组件可以任意次复用\n&lt;div id=&quot;components-demo&quot;&gt;  &lt;button-counter&gt;&lt;/button-counter&gt;  &lt;button-counter&gt;&lt;/button-counter&gt;  &lt;button-counter&gt;&lt;/button-counter&gt;&lt;/div&gt;\n注意当点击按钮时，每个组件都会各自独立维护它的 count。\n因为你每用一次组件，就会有一个它的新实例被创建。\ndata必须是一个函数当我们定义这个 &lt;button-counter&gt; 组件时，你可能会发现它的 data 并不是像这样直接提供一个对象：\ndata: &#123;  count: 0&#125;\n取而代之的是，一个组件的 data 选项必须是一个函数，因此每个实例可以维护一份被返回对象的独立的拷贝：\ndata: function () &#123;  return &#123;    count: 0  &#125;&#125;\n如果 Vue 没有这条规则，点击一个按钮就可能会影响到其它所有实例\n组件的组织通常一个应用会以一棵嵌套的组件树的形式来组织：例如，你可能会有页头、侧边栏、内容区等组件，每个组件又包含了其它的像导航链接、博文之类的组件。\n为了能在模板中使用，这些组件必须先注册以便 Vue 能够识别。\n这里有两种组件的注册类型：全局注册和局部注册。\n至此，我们的组件都只是通过 Vue.component 全局注册的：\nVue.component(&#x27;my-component-name&#x27;, &#123;  // ... options ...&#125;)\n全局注册的组件可以用在其被注册之后的任何 (通过 new Vue) 新创建的 Vue 根实例，也包括其组件树中的所有子组件的模板中。\n通过 Prop 向子组件传递数据Prop 是你可以在组件上注册的一些自定义特性。\n当一个值传递给一个 prop 特性的时候，它就变成了那个组件实例的一个属性。\n为了给博文组件传递一个标题，我们可以用一个 props 选项将其包含在该组件可接受的 prop 列表中：\nVue.component(&#x27;blog-post&#x27;, &#123;  props: [&#x27;title&#x27;],  template: &#x27;&lt;h3&gt;&#123;&#123; title &#125;&#125;&lt;/h3&gt;&#x27;&#125;)\n一个组件默认可以拥有任意数量的 prop，任何值都可以传递给任何 prop。\n在上述模板中，你会发现我们能够在组件实例中访问这个值，就像访问 data 中的值一样。\n一个 prop 被注册之后，你就可以像这样把数据作为一个自定义特性传递进来：\n&lt;blog-post title=&quot;My journey with Vue&quot;&gt;&lt;/blog-post&gt;&lt;blog-post title=&quot;Blogging with Vue&quot;&gt;&lt;/blog-post&gt;&lt;blog-post title=&quot;Why Vue is so fun&quot;&gt;&lt;/blog-post&gt;\n\n然而在一个典型的应用中，你可能在 data 里有一个博文的数组：\nnew Vue(&#123;  el: &#x27;#blog-post-demo&#x27;,  data: &#123;    posts: [      &#123; id: 1, title: &#x27;My journey with Vue&#x27; &#125;,      &#123; id: 2, title: &#x27;Blogging with Vue&#x27; &#125;,      &#123; id: 3, title: &#x27;Why Vue is so fun&#x27; &#125;    ]  &#125;&#125;)\n&lt;blog-post  v-for=&quot;post in posts&quot;  v-bind:key=&quot;post.id&quot;  v-bind:title=&quot;post.title&quot;&gt;&lt;/blog-post&gt;\n\n单个根元素当构建一个&lt;blog-post&gt; 组件时，你的模板最终会包含的东西远不止一个标题\n最最起码，你会包含这篇博文的正文：\n&lt;h3&gt;&#123;&#123; title &#125;&#125;&lt;/h3&gt;&lt;div v-html=&quot;content&quot;&gt;&lt;/div&gt;\n\n然而如果你在模板中尝试这样写，Vue 会显示一个错误，并解释道 every component must have a single root element (每个组件必须只有一个根元素)。\n你可以将模板的内容包裹在一个父元素内，来修复这个问题\n&lt;div class=&quot;blog-post&quot;&gt;  &lt;h3&gt;&#123;&#123; title &#125;&#125;&lt;/h3&gt;  &lt;div v-html=&quot;content&quot;&gt;&lt;/div&gt;&lt;/div&gt;\n\n看起来当组件变得越来越复杂的时候，我们的博文不只需要标题和内容，还需要发布日期、评论等等。为每个相关的信息定义一个 prop 会变得很麻烦：\n&lt;blog-post  v-for=&quot;post in posts&quot;  v-bind:key=&quot;post.id&quot;  v-bind:title=&quot;post.title&quot;  v-bind:content=&quot;post.content&quot;  v-bind:publishedAt=&quot;post.publishedAt&quot;  v-bind:comments=&quot;post.comments&quot;&gt;&lt;/blog-post&gt;\n所以是时候重构一下这个 &lt;blog-post&gt; 组件了，让它变成接受一个单独的 post prop：\n&lt;blog-post  v-for=&quot;post in posts&quot;  v-bind:key=&quot;post.id&quot;  v-bind:post=&quot;post&quot;&gt;&lt;/blog-post&gt;\nVue.component(&#x27;blog-post&#x27;, &#123;  props: [&#x27;post&#x27;],  template: `    &lt;div class=&quot;blog-post&quot;&gt;      &lt;h3&gt;&#123;&#123; post.title &#125;&#125;&lt;/h3&gt;      &lt;div v-html=&quot;post.content&quot;&gt;&lt;/div&gt;    &lt;/div&gt;  `&#125;)\n现在，不论何时为 post 对象添加一个新的属性，它都会自动地在 &lt;blog-post&gt; 内可用。\n监听子组件事件在我们开发 &lt;blog-post&gt; 组件时，它的一些功能可能要求我们和父级组件进行沟通。\n例如我们可能会引入一个辅助功能来放大博文的字号，同时让页面的其它部分保持默认的字号。\n在其父组件中，我们可以通过添加一个 postFontSize 数据属性来支持这个功能：\nnew Vue(&#123;  el: &#x27;#blog-posts-events-demo&#x27;,  data: &#123;    posts: [/* ... */],    postFontSize: 1  &#125;&#125;)\n它可以在模板中用来控制所有博文的字号：\n&lt;div id=&quot;blog-posts-events-demo&quot;&gt;  &lt;div :style=&quot;&#123; fontSize: postFontSize + &#x27;em&#x27; &#125;&quot;&gt;    &lt;blog-post      v-for=&quot;post in posts&quot;      v-bind:key=&quot;post.id&quot;      v-bind:post=&quot;post&quot;    &gt;&lt;/blog-post&gt;  &lt;/div&gt;&lt;/div&gt;\n现在我们在每篇博文正文之前添加一个按钮来放大字号：\nVue.component(&#x27;blog-post&#x27;, &#123;  props: [&#x27;post&#x27;],  template: `    &lt;div class=&quot;blog-post&quot;&gt;      &lt;h3&gt;&#123;&#123; post.title &#125;&#125;&lt;/h3&gt;      &lt;button&gt;        Enlarge text      &lt;/button&gt;      &lt;div v-html=&quot;post.content&quot;&gt;&lt;/div&gt;    &lt;/div&gt;  `&#125;)\n问题是这个按钮不会做任何事：\n&lt;button&gt;  Enlarge text&lt;/button&gt;\n当点击这个按钮时，我们需要告诉父级组件放大所有博文的文本。\n幸好 Vue 实例提供了一个自定义事件的系统来解决这个问题。\n父级组件可以像处理 native DOM 事件一样通过 v-on 监听子组件实例的任意事件：\n&lt;blog-post  ...  v-on:enlarge-text=&quot;postFontSize += 0.1&quot;&gt;&lt;/blog-post&gt;\n同时子组件可以通过调用内建的 $emit 方法 并传入事件名称来触发一个事件：\n&lt;button v-on:click=&quot;$emit(&#x27;enlarge-text&#x27;)&quot;&gt;  Enlarge text&lt;/button&gt;\n有了这个 v-on:enlarge-text=&quot;postFontSize += 0.1&quot; 监听器，父级组件就会接收该事件并更新 postFontSize 的值。\n使用事件抛出一个值有时候我们需要用一个事件来抛出一个特定的值。\n例如我们可能想让&lt;blog-post&gt;组件决定他的文本要放大多少，这时我们可以用$emit的第二个参数来提供这个值：\n&lt;button v-on:click=&quot;$emit(&#x27;enlarge-text&#x27;, 0.1)&quot;&gt;  Enlarge text&lt;/button&gt;\n然后当在父级组件监听这个事件的时候，我们可以通过$event访问到被抛出的这个值\n&lt;blog-post  ...  v-on:enlarge-text=&quot;postFontSize += $event&quot;&gt;&lt;/blog-post&gt;\n或者,这个事件处理函数是一个方法\n&lt;blog-post  ...  v-on:enlarge-text=&quot;onEnlargeText&quot;&gt;&lt;/blog-post&gt;\n那么这个值会作为第一个参数传入这个方法\nmethods: &#123;  onEnlargeText: function (enlargeAmount) &#123;    this.postFontSize += enlargeAmount  &#125;&#125;\n\n在组件上使用v-model自定义事件也可以作用于创建支持v-model的自定义输入组件\n&lt;input v-model=&quot;searchText&quot;&gt;\n等价于:\n&lt;input  v-bind:value=&quot;searchText&quot;  v-on:input=&quot;searchText = $event.target.value&quot;&gt;\n当作用在组件上时，v-model则会这样\n&lt;custom-input  v-bind:value=&quot;searchText&quot;  v-on:input=&quot;searchText = $event&quot;&gt;&lt;/custom-input&gt;\n\n为了让他正常工作这个组件内的&lt;input&gt;必须：\n\n将其value特性绑定到一个名叫value的prop上\n在其input事件被触发时，将新的值通过自定义的input事件抛出\n\n完成的代码是这样:\nVue.component(&#x27;custom-input&#x27;, &#123;  props: [&#x27;value&#x27;],  template: `    &lt;input      v-bind:value=&quot;value&quot;      v-on:input=&quot;$emit(&#x27;input&#x27;, $event.target.value)&quot;    &gt;  `&#125;)\n\n现在v-model就能在这个组件上完美的工作了\n&lt;custom-input v-model=&quot;searchText&quot;&gt;&lt;/custom-input&gt;\n\n通过插槽分发内容和HTML元素一样，我们经常需要向一个组件传递内容\n&lt;alert-box&gt;  Something bad happened.&lt;/alert-box&gt;\n\nVue自定义的&lt;slot&gt;元素会非常简单\nVue.component(&#x27;alert-box&#x27;, &#123;  template: `    &lt;div class=&quot;demo-alert-box&quot;&gt;      &lt;strong&gt;Error!&lt;/strong&gt;      &lt;slot&gt;&lt;/slot&gt;    &lt;/div&gt;  `&#125;)\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"10.Vue基本语法介绍七","url":"/2019/07/20/Vue/10-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%B8%83/","content":"\n引言：\n\n这一节介绍有关列表，列表渲染的基本知识，\n加油加油！！\n\n\n\n\n列表渲染用v-for把一个数组对应为一组元素我们可以用 v-for 指令基于一个数组来渲染一个列表。v-for 指令需要使用 item in items 形式的特殊语法，其中 items 是源数据数组，而 item 则是被迭代的数组元素的别名。\n&lt;ul id=&quot;example-1&quot;&gt;  &lt;li v-for=&quot;item in items&quot;&gt;    &#123;&#123; item.message &#125;&#125;  &lt;/li&gt;&lt;/ul&gt;\nvar example1 = new Vue(&#123;  el: &#x27;#example-1&#x27;,  data: &#123;    items: [      &#123; message: &#x27;Foo&#x27; &#125;,      &#123; message: &#x27;Bar&#x27; &#125;    ]  &#125;&#125;)\n\nv-for块中我们可以访问所有父作用域的属性，v-for还支持一个可选的第二个参数，即当前项的索引值\n&lt;ul id=&quot;example-2&quot;&gt;  &lt;li v-for=&quot;(item, index) in items&quot;&gt;    &#123;&#123; parentMessage &#125;&#125; - &#123;&#123; index &#125;&#125; - &#123;&#123; item.message &#125;&#125;  &lt;/li&gt;&lt;/ul&gt;\nvar example2 = new Vue(&#123;  el: &#x27;#example-2&#x27;,  data: &#123;    parentMessage: &#x27;Parent&#x27;,    items: [      &#123; message: &#x27;Foo&#x27; &#125;,      &#123; message: &#x27;Bar&#x27; &#125;    ]  &#125;&#125;)\n其中的in我们可以换成of，这两个都可以\n当我们需要包裹多个div时，又不想要多用一个div，就可以使用模板占位符&lt;template&gt;&lt;template&gt;来替代这个div\n在v-for里使用对象也可以用v-for来遍历一个对象的属性\n&lt;ul id=&quot;v-for-object&quot; class=&quot;demo&quot;&gt;  &lt;li v-for=&quot;value in object&quot;&gt;    &#123;&#123; value &#125;&#125;  &lt;/li&gt;&lt;/ul&gt;\n\nnew Vue(&#123;  el: &#x27;#v-for-object&#x27;,  data: &#123;    object: &#123;      title: &#x27;How to do lists in Vue&#x27;,      author: &#x27;Jane Doe&#x27;,      publishedAt: &#x27;2016-04-10&#x27;    &#125;  &#125;&#125;)\n也可以提供键名\n&lt;div v-for=&quot;(value, name) in object&quot;&gt;  &#123;&#123; name &#125;&#125;: &#123;&#123; value &#125;&#125;&lt;/div&gt;\n在此之上还可以加上索引\n&lt;div v-for=&quot;(value, name, index) in object&quot;&gt;  &#123;&#123; index &#125;&#125;. &#123;&#123; name &#125;&#125;: &#123;&#123; value &#125;&#125;&lt;/div&gt;\n在遍历对象时，会按 Object.keys() 的结果遍历，但是不能保证它的结果在不同的 JavaScript 引擎下都一致。\n维护状态当 Vue 正在更新使用 v-for 渲染的元素列表时，它默认使用“就地更新”的策略。\n如果数据项的顺序被改变，Vue 将不会移动 DOM 元素来匹配数据项的顺序，而是就地更新每个元素\n只适用于不依赖子组件状态或临时 DOM 状态 (例如：表单输入值) 的列表渲染输出\n所以我们需要给每一项提供一个唯一的key属性来确保Vue能正确的跟踪每一个节点\n&lt;div v-for=&quot;item in items&quot; v-bind:key=&quot;item.id&quot;&gt;  &lt;!-- 内容 --&gt;&lt;/div&gt;\n注意：\n不要使用对象或数组之类的非基本类型值作为 v-for 的 key。请用字符串或数值类型的值。\n数组更新检测变异方法Vue 将被侦听的数组的变异方法进行了包裹，所以它们也将会触发视图更新。这些被包裹过的方法包括：\n\npush()\npop()\nshift()\nunshift()\nsplice()\nsort()\nreverse()\n\n替换数组我们也可以用不变异的方法，返回一个新的数组代替旧的数组\n\nfilter()\nconcat()\nslice()\n\n注意事项Vue不能检测到如下数组的变动\n\n当使用索引直接设置一个数组项的时候,例如：vm.items[indexOfItem] = newValue\n当修改数组长度的时候,例如vm.items.length = newLength\n\n例如：\nvar vm = new Vue(&#123;  data: &#123;    items: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]  &#125;&#125;)vm.items[1] = &#x27;x&#x27; // 不是响应性的vm.items.length = 2 // 不是响应性的\n\n为了解决第一类问题，以下两种方式都可以实现和 vm.items[indexOfItem] = newValue 相同的效果，同时也将在响应式系统内触发状态更新：\n// Vue.setVue.set(vm.items, indexOfItem, newValue)// Array.prototype.splicevm.items.splice(indexOfItem, 1, newValue)\n也可以使用 vm.$set 实例方法，该方法是全局方法 Vue.set 的一个别名：\nvm.$set(vm.items, indexOfItem, newValue)\n为了解决第二类问题，你可以使用 splice：\nvm.items.splice(newLength)\n\n对象变更检测注意事项Vue不能检测对象属性的添加或删除\nvar vm = new Vue(&#123;  data: &#123;    a: 1  &#125;&#125;)// `vm.a` 现在是响应式的vm.b = 2// `vm.b` 不是响应式的\n对于已经创建的实例，Vue 不允许动态添加根级别的响应式属性。\n但是，可以使用 Vue.set(object, propertyName, value) 方法向嵌套对象添加响应式属性\n例如：\nvar vm = new Vue(&#123;  data: &#123;    userProfile: &#123;      name: &#x27;Anika&#x27;    &#125;  &#125;&#125;)\n\n可以添加一个新的 age 属性到嵌套的 userProfile 对象：\nVue.set(vm.userProfile, &#x27;age&#x27;, 27)\n\n还可以使用 vm.$set 实例方法，它只是全局 Vue.set 的别名：\nvm.$set(vm.userProfile, &#x27;age&#x27;, 27)\n\n有时你可能需要为已有对象赋值多个新属性，比如使用 Object.assign() 或 _.extend()。\n在这种情况下，你应该用两个对象的属性创建一个新的对象\n不要这样做\nObject.assign(vm.userProfile, &#123;  age: 27,  favoriteColor: &#x27;Vue Green&#x27;&#125;)\n而要这样做\nvm.userProfile = Object.assign(&#123;&#125;, vm.userProfile, &#123;  age: 27,  favoriteColor: &#x27;Vue Green&#x27;&#125;)\n\n显示过滤/排序后的结果我们想要显示一个数组经过过滤或排序后的版本，而不实际改变或重置原始数据\n在这种情况下，可以创建一个计算属性，来返回过滤或排序后的数组。\n&lt;li v-for=&quot;n in evenNumbers&quot;&gt;&#123;&#123; n &#125;&#125;&lt;/li&gt;\ndata: &#123;  numbers: [ 1, 2, 3, 4, 5 ]&#125;,computed: &#123;  evenNumbers: function () &#123;    return this.numbers.filter(function (number) &#123;      return number % 2 === 0    &#125;)  &#125;&#125;\n\n在计算属性不适用的情况下 (例如，在嵌套 v-for 循环中) 你可以使用一个方法：\n&lt;li v-for=&quot;n in even(numbers)&quot;&gt;&#123;&#123; n &#125;&#125;&lt;/li&gt;\ndata: &#123;  numbers: [ 1, 2, 3, 4, 5 ]&#125;,methods: &#123;  even: function (numbers) &#123;    return numbers.filter(function (number) &#123;      return number % 2 === 0    &#125;)  &#125;&#125;\n在 v-for 里使用值范围v-for 也可以接受整数。在这种情况下，它会把模板重复对应次数\n&lt;body&gt;\t\t&lt;div id=&#x27;demo&#x27;&gt;  \t\t&lt;span v-for=&quot;n in 10&quot;&gt;&#123;&#123; n &#125;&#125; &lt;/span&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tnew Vue(&#123;\t\t\tel:&#x27;#demo&#x27;,\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n在 &lt;template&gt; 上使用 v-for类似于 v-if，你也可以利用带有 v-for 的  来循环渲染一段包含多个元素的内容。比如：\n&lt;ul&gt;  &lt;template v-for=&quot;item in items&quot;&gt;    &lt;li&gt;&#123;&#123; item.msg &#125;&#125;&lt;/li&gt;    &lt;li class=&quot;divider&quot; role=&quot;presentation&quot;&gt;&lt;/li&gt;  &lt;/template&gt;&lt;/ul&gt;\n\nv-if的优先级低于v-for\n当你只想为部分项渲染节点时，这种优先级的机制会十分有用，如下：\n&lt;li v-for=&quot;todo in todos&quot; v-if=&quot;!todo.isComplete&quot;&gt;  &#123;&#123; todo &#125;&#125;&lt;/li&gt;\n上面的代码将只渲染未完成的 todo\n而如果你的目的是有条件地跳过循环的执行，那么可以将 v-if 置于外层元素 (或 )上\n&lt;ul v-if=&quot;todos.length&quot;&gt;  &lt;li v-for=&quot;todo in todos&quot;&gt;    &#123;&#123; todo &#125;&#125;  &lt;/li&gt;&lt;/ul&gt;&lt;p v-else&gt;No todos left!&lt;/p&gt;\n\n能响应的刷新页面的方法总结在各类方法中，共有三种方法可以使我们动态的更新页面上的对象和数组\n\n使用八种变异方法（只对数组有效）\n改变引用，更换地址\n使用全局的Vue.set方法(推荐)\n\n在组件上使用v-for在自定义组件上，你可以像在任何普通元素上一样使用 v-for 。\n&lt;my-component v-for=&quot;item in items&quot; :key=&quot;item.id&quot;&gt;&lt;/my-component&gt;\nkey 现在是必须的\n任何数据都不会被自动传递到组件里，因为组件有自己独立的作用域。为了把迭代数据传递到组件里，我们要使用 prop\n&lt;my-component  v-for=&quot;(item, index) in items&quot;  v-bind:item=&quot;item&quot;  v-bind:index=&quot;index&quot;  v-bind:key=&quot;item.id&quot;&gt;&lt;/my-component&gt;\n\n不自动将 item 注入到组件里的原因是，这会使得组件与 v-for 的运作紧密耦合。明确组件数据的来源能够使组件在其他场合重复使用。\n下面是一个完整的实例\n&lt;div id=&quot;todo-list-example&quot;&gt;  &lt;form v-on:submit.prevent=&quot;addNewTodo&quot;&gt;    &lt;label for=&quot;new-todo&quot;&gt;Add a todo&lt;/label&gt;    &lt;input      v-model=&quot;newTodoText&quot;      id=&quot;new-todo&quot;      placeholder=&quot;E.g. Feed the cat&quot;    &gt;    &lt;button&gt;Add&lt;/button&gt;  &lt;/form&gt;  &lt;ul&gt;    &lt;li      is=&quot;todo-item&quot;      v-for=&quot;(todo, index) in todos&quot;      v-bind:key=&quot;todo.id&quot;      v-bind:title=&quot;todo.title&quot;      v-on:remove=&quot;todos.splice(index, 1)&quot;    &gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/div&gt;\nVue.component(&#x27;todo-item&#x27;, &#123;  template: &#x27;\\    &lt;li&gt;\\      &#123;&#123; title &#125;&#125;\\      &lt;button v-on:click=&quot;$emit(\\&#x27;remove\\&#x27;)&quot;&gt;Remove&lt;/button&gt;\\    &lt;/li&gt;\\  &#x27;,  props: [&#x27;title&#x27;]&#125;)new Vue(&#123;  el: &#x27;#todo-list-example&#x27;,  data: &#123;    newTodoText: &#x27;&#x27;,    todos: [      &#123;        id: 1,        title: &#x27;Do the dishes&#x27;,      &#125;,      &#123;        id: 2,        title: &#x27;Take out the trash&#x27;,      &#125;,      &#123;        id: 3,        title: &#x27;Mow the lawn&#x27;      &#125;    ],    nextTodoId: 4  &#125;,  methods: &#123;    addNewTodo: function () &#123;      this.todos.push(&#123;        id: this.nextTodoId++,        title: this.newTodoText      &#125;)      this.newTodoText = &#x27;&#x27;    &#125;  &#125;&#125;)\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"11-Vue基本语法介绍八","url":"/2019/07/21/Vue/11-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%85%AB/","content":"\n引言：\n\n这一节介绍有关事件，事件处理的基本知识，\n加油加油！！\n\n\n\n\n事件处理监听事件v-on监听事件\n示例：\n&lt;div id=&quot;example-1&quot;&gt;  &lt;button v-on:click=&quot;counter += 1&quot;&gt;Add 1&lt;/button&gt;  &lt;p&gt;The button above has been clicked &#123;&#123; counter &#125;&#125; times.&lt;/p&gt;&lt;/div&gt;\nvar example1 = new Vue(&#123;  el: &#x27;#example-1&#x27;,  data: &#123;    counter: 0  &#125;&#125;)\n\n事件处理方法许多事件的逻辑复杂，js代码写在v-on中显然不可行，因此v-on可以接受一个需要调用的方法名称\n示例：\n&lt;div id=&quot;example-2&quot;&gt;  &lt;!-- `greet` 是在下面定义的方法名 --&gt;  &lt;button v-on:click=&quot;greet&quot;&gt;Greet&lt;/button&gt;&lt;/div&gt;\nvar example2 = new Vue(&#123;  el: &#x27;#example-2&#x27;,  data: &#123;    name: &#x27;Vue.js&#x27;  &#125;,  // 在 `methods` 对象中定义方法  methods: &#123;    greet: function (event) &#123;      // `this` 在方法里指向当前 Vue 实例      alert(&#x27;Hello &#x27; + this.name + &#x27;!&#x27;)      // `event` 是原生 DOM 事件      if (event) &#123;        alert(event.target.tagName)        //这里可以获得触发事件的元素      &#125;    &#125;  &#125;&#125;)// 也可以用 JavaScript 直接调用方法example2.greet() // =&gt; &#x27;Hello Vue.js!&#x27;\n\n内联处理器中的方法除了直接绑定到一个方法，也可以在内联js语句中调用方法\n&lt;div id=&quot;example-3&quot;&gt;  &lt;button v-on:click=&quot;say(&#x27;hi&#x27;)&quot;&gt;Say hi&lt;/button&gt;  &lt;button v-on:click=&quot;say(&#x27;what&#x27;)&quot;&gt;Say what&lt;/button&gt;&lt;/div&gt;\n\nnew Vue(&#123;  el: &#x27;#example-3&#x27;,  methods: &#123;    say: function (message) &#123;      alert(message)    &#125;  &#125;&#125;)\n\n事件修饰符由于 方法只有纯粹的逻辑，不去处理DOM事件细节 这样更好\n所以Vue提供了事件修饰符，由点开头的指令后缀\n\n.stop\n.prevent\n.capture\n.self\n.once\n.passive\n\n他们的作用如下\n&lt;!-- 阻止单击事件继续传播 --&gt;&lt;a v-on:click.stop=&quot;doThis&quot;&gt;&lt;/a&gt;&lt;!-- 提交事件不再重载页面 --&gt;&lt;form v-on:submit.prevent=&quot;onSubmit&quot;&gt;&lt;/form&gt;&lt;!-- 修饰符可以串联 --&gt;&lt;a v-on:click.stop.prevent=&quot;doThat&quot;&gt;&lt;/a&gt;&lt;!-- 只有修饰符 --&gt;&lt;form v-on:submit.prevent&gt;&lt;/form&gt;&lt;!-- 添加事件监听器时使用事件捕获模式 --&gt;&lt;!-- 即元素自身触发的事件先在此处理，然后才交由内部元素进行处理 --&gt;&lt;div v-on:click.capture=&quot;doThis&quot;&gt;...&lt;/div&gt;&lt;!-- 只当在 event.target 是当前元素自身时触发处理函数 --&gt;&lt;!-- 即事件不是从内部元素触发的 --&gt;&lt;div v-on:click.self=&quot;doThat&quot;&gt;...&lt;/div&gt;&lt;!-- 点击事件将只会触发一次 --&gt;&lt;a v-on:click.once=&quot;doThis&quot;&gt;&lt;/a&gt;&lt;!-- 滚动事件的默认行为 (即滚动行为) 将会立即触发 --&gt;&lt;!-- 而不会等待 `onScroll` 完成  --&gt;&lt;!-- 这其中包含 `event.preventDefault()` 的情况 --&gt;&lt;div v-on:scroll.passive=&quot;onScroll&quot;&gt;...&lt;/div&gt;\n注意：\n修饰符顺序很重要；相应的代码会以同样的顺序产生。\n因此，用 v-on:click.prevent.self 会阻止所有的点击，而 v-on:click.self.prevent 只会阻止对元素自身的点击。\n不要把 .passive 和 .prevent 一起使用，因为 .prevent 将会被忽略，同时浏览器可能会向你展示一个警告。\n请记住，.passive 会告诉浏览器你不想阻止事件的默认行为。\n按键修饰符在监听键盘事件时，我们需要检查详细的按键\n&lt;!-- 只有在 `key` 是 `Enter` 时调用 `vm.submit()` --&gt;&lt;input v-on:keyup.enter=&quot;submit&quot;&gt;\n\n系统修饰键可以用如下修饰符来实现仅在按下相应按键时才触发鼠标或键盘事件的监听器。\n注意：在 Mac 系统键盘上，meta 对应 command 键 (⌘)。在 Windows 系统键盘 meta 对应 Windows 徽标键 (⊞)。\n&lt;!-- Alt + C --&gt;&lt;input @keyup.alt.67=&quot;clear&quot;&gt;&lt;!-- Ctrl + Click --&gt;&lt;div @click.ctrl=&quot;doSomething&quot;&gt;Do something&lt;/div&gt;\n\n请注意修饰键与常规按键不同，在和 keyup 事件一起用时，事件触发时修饰键必须处于按下状态。\n换句话说，只有在按住 ctrl 的情况下释放其它按键，才能触发 keyup.ctrl。而单单释放 ctrl 也不会触发事件\n.exact修饰符.exact 修饰符允许你控制由精确的系统修饰符组合触发的事件。\n&lt;!-- 即使 Alt 或 Shift 被一同按下时也会触发 --&gt;&lt;button @click.ctrl=&quot;onClick&quot;&gt;A&lt;/button&gt;&lt;!-- 有且只有 Ctrl 被按下的时候才触发 --&gt;&lt;button @click.ctrl.exact=&quot;onCtrlClick&quot;&gt;A&lt;/button&gt;&lt;!-- 没有任何系统修饰符被按下的时候才触发 --&gt;&lt;button @click.exact=&quot;onClick&quot;&gt;A&lt;/button&gt;\n\n\n鼠标按钮修饰符\n.left\n.right\n.middle\n\n这些修饰符会限制处理函数仅响应特定的鼠标按钮。\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"12-Vue基本语法介绍九","url":"/2019/07/21/Vue/12-Vue%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%B9%9D/","content":"\n引言：\n\n这一节介绍有关表单元素，表单输入的基本知识，\n加油加油！！\n\n\n\n\n表单输入绑定基础用法用v-model在表单&lt;input&gt;&lt;textarea&gt;&lt;select&gt;元素上创建双向数据绑定\n注意：\nv-model 会忽略所有表单元素的 value、checked、selected 特性的初始值而总是将 Vue 实例的数据作为数据来源。\n你应该通过 JavaScript 在组件的 data 选项中声明初始值。\n在文本区域插值 (&lt;textarea&gt;&#123;&#123;text&#125;&#125;&lt;/textarea&gt;) 并不会生效，应用 v-model 来代替。\n文本&lt;input v-model=&quot;message&quot; placeholder=&quot;edit me&quot;&gt;&lt;p&gt;Message is: &#123;&#123; message &#125;&#125;&lt;/p&gt;\n&lt;span&gt;Multiline message is:&lt;/span&gt;&lt;p style=&quot;white-space: pre-line;&quot;&gt;&#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;br&gt;&lt;textarea v-model=&quot;message&quot; placeholder=&quot;add multiple lines&quot;&gt;&lt;/textarea&gt;\n\n复选框单个复选框，绑定到布尔值：\n&lt;input type=&quot;checkbox&quot; id=&quot;checkbox&quot; v-model=&quot;checked&quot;&gt;&lt;label for=&quot;checkbox&quot;&gt;&#123;&#123; checked &#125;&#125;&lt;/label&gt;\n\n多个复选框，绑定到同一个数组：\n&lt;div id=&#x27;example-3&#x27;&gt;  &lt;input type=&quot;checkbox&quot; id=&quot;jack&quot; value=&quot;Jack&quot; v-model=&quot;checkedNames&quot;&gt;  &lt;label for=&quot;jack&quot;&gt;Jack&lt;/label&gt;  &lt;input type=&quot;checkbox&quot; id=&quot;john&quot; value=&quot;John&quot; v-model=&quot;checkedNames&quot;&gt;  &lt;label for=&quot;john&quot;&gt;John&lt;/label&gt;  &lt;input type=&quot;checkbox&quot; id=&quot;mike&quot; value=&quot;Mike&quot; v-model=&quot;checkedNames&quot;&gt;  &lt;label for=&quot;mike&quot;&gt;Mike&lt;/label&gt;  &lt;br&gt;  &lt;span&gt;Checked names: &#123;&#123; checkedNames &#125;&#125;&lt;/span&gt;&lt;/div&gt;\n\nnew Vue(&#123;  el: &#x27;#example-3&#x27;,  data: &#123;    checkedNames: []  &#125;&#125;)\n\n单选按钮&lt;div id=&quot;example-4&quot;&gt;  &lt;input type=&quot;radio&quot; id=&quot;one&quot; value=&quot;One&quot; v-model=&quot;picked&quot;&gt;  &lt;label for=&quot;one&quot;&gt;One&lt;/label&gt;  &lt;br&gt;  &lt;input type=&quot;radio&quot; id=&quot;two&quot; value=&quot;Two&quot; v-model=&quot;picked&quot;&gt;  &lt;label for=&quot;two&quot;&gt;Two&lt;/label&gt;  &lt;br&gt;  &lt;span&gt;Picked: &#123;&#123; picked &#125;&#125;&lt;/span&gt;&lt;/div&gt;\nnew Vue(&#123;  el: &#x27;#example-4&#x27;,  data: &#123;    picked: &#x27;&#x27;  &#125;&#125;)\n\n选择框\n单选时&lt;div id=&quot;example-5&quot;&gt;  &lt;select v-model=&quot;selected&quot;&gt;    &lt;option disabled value=&quot;&quot;&gt;请选择&lt;/option&gt;    &lt;option&gt;A&lt;/option&gt;    &lt;option&gt;B&lt;/option&gt;    &lt;option&gt;C&lt;/option&gt;  &lt;/select&gt;  &lt;span&gt;Selected: &#123;&#123; selected &#125;&#125;&lt;/span&gt;&lt;/div&gt;\nnew Vue(&#123;  el: &#x27;...&#x27;,  data: &#123;    selected: &#x27;&#x27;  &#125;&#125;)\n如果 v-model 表达式的初始值未能匹配任何选项，&lt;select&gt; 元素将被渲染为“未选中”状态。\n\n在 iOS 中，这会使用户无法选择第一个选项。因为这样的情况下，iOS 不会触发 change 事件。\n因此，更推荐像上面这样提供一个值为空的禁用选项。\n\n多选时&lt;div id=&quot;example-6&quot;&gt;  &lt;select v-model=&quot;selected&quot; multiple style=&quot;width: 50px;&quot;&gt;    &lt;option&gt;A&lt;/option&gt;    &lt;option&gt;B&lt;/option&gt;    &lt;option&gt;C&lt;/option&gt;  &lt;/select&gt;  &lt;br&gt;  &lt;span&gt;Selected: &#123;&#123; selected &#125;&#125;&lt;/span&gt;&lt;/div&gt;\nnew Vue(&#123;  el: &#x27;#example-6&#x27;,  data: &#123;    selected: []  &#125;&#125;)//拖动才能多选\n也可以用v-for来循环&lt;select v-model=&quot;selected&quot;&gt;  &lt;option v-for=&quot;option in options&quot; v-bind:value=&quot;option.value&quot;&gt;    &#123;&#123; option.text &#125;&#125;  &lt;/option&gt;&lt;/select&gt;&lt;span&gt;Selected: &#123;&#123; selected &#125;&#125;&lt;/span&gt;\nnew Vue(&#123;  el: &#x27;...&#x27;,  data: &#123;    selected: &#x27;A&#x27;,    options: [      &#123; text: &#x27;One&#x27;, value: &#x27;A&#x27; &#125;,      &#123; text: &#x27;Two&#x27;, value: &#x27;B&#x27; &#125;,      &#123; text: &#x27;Three&#x27;, value: &#x27;C&#x27; &#125;    ]  &#125;&#125;)\n\n值绑定对于单选按钮，复选框及选择框的选项，v-model 绑定的值通常是静态字符串 (对于复选框也可以是布尔值):\n&lt;!-- 当选中时，`picked` 为字符串 &quot;a&quot; --&gt;&lt;input type=&quot;radio&quot; v-model=&quot;picked&quot; value=&quot;a&quot;&gt;&lt;!-- `toggle` 为 true 或 false --&gt;&lt;input type=&quot;checkbox&quot; v-model=&quot;toggle&quot;&gt;&lt;!-- 当选中第一个选项时，`selected` 为字符串 &quot;abc&quot; --&gt;&lt;select v-model=&quot;selected&quot;&gt;  &lt;option value=&quot;abc&quot;&gt;ABC&lt;/option&gt;&lt;/select&gt;\n但有时我们可能想把值绑定在Vue实例的一个动态属性，可以用v-bind实现\n复选框&lt;input  type=&quot;checkbox&quot;  v-model=&quot;toggle&quot;  true-value=&quot;yes&quot;  false-value=&quot;no&quot;&gt;\n// 当选中时vm.toggle === &#x27;yes&#x27;// 当没有选中时vm.toggle === &#x27;no&#x27;\n\n单选按钮&lt;input type=&quot;radio&quot; v-model=&quot;pick&quot; v-bind:value=&quot;a&quot;&gt;\n// 当选中时vm.pick === vm.a\n\n选择框的选项&lt;select v-model=&quot;selected&quot;&gt;    &lt;!-- 内联对象字面量 --&gt;  &lt;option v-bind:value=&quot;&#123; number: 123 &#125;&quot;&gt;123&lt;/option&gt;&lt;/select&gt;\n// 当选中时typeof vm.selected // =&gt; &#x27;object&#x27;vm.selected.number // =&gt; 123\n\n\n修饰符.lazy在默认情况下，v-model 在每次 input 事件触发后  将输入框的值与数据进行同步 (除了上述输入法组合文字时)。\n你可以添加 lazy 修饰符，从而转变为使用 change 事件进行同步：\n&lt;!-- 在“change”时而非“input”时更新 --&gt;&lt;input v-model.lazy=&quot;msg&quot; &gt;\n.number如果想自动将用户的输入值转为数值类型，可以给 v-model 添加 number 修饰符：\n&lt;input v-model.number=&quot;age&quot; type=&quot;number&quot;&gt;\n\n.trim如果要自动过滤用户输入的首尾空白字符，可以给 v-model 添加 trim 修饰符：\n&lt;input v-model.trim=&quot;msg&quot;&gt;\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"14.Vue基础巩固","url":"/2019/07/22/Vue/14-Vue%E5%9F%BA%E7%A1%80%E5%B7%A9%E5%9B%BA/","content":"\n引言：\n\n这一节复习巩固这几节的内容，加强对经常出现的Vue语法的记忆\n加油加油！\n\n\n\n\n\nVue重新认识基本实例当挂载点写为类，时默认会挂载到第一个此类上\n&lt;div class=&quot;bg&quot;&gt;你好&#123;&#123;msg&#125;&#125;&lt;/div&gt;&lt;div class=&quot;bg&quot;&gt;你好&#123;&#123;msg&#125;&#125;&lt;/div&gt;\nnew Vue(&#123;\tel:&#x27;.bg&#x27;,\tdata:&#123;\t\tmsg:&#x27;Vue&#x27;\t&#125;&#125;)\n所以我们要用唯一的id来避免这种情况：\n&lt;div id=&quot;app&quot;&gt;\t&lt;div class=&quot;bg&quot;&gt;\t\t你好&#123;&#123;msg&#125;&#125;\t&lt;/div&gt;\t&lt;div class=&quot;bg&quot;&gt;\t\t你好&#123;&#123;msg&#125;&#125;\t&lt;/div&gt;&lt;/div&gt;\nnew Vue(&#123;\tel:&#x27;#app&#x27;,\tdata:&#123;\t\tmsg:&#x27;Vue&#x27;\t&#125;&#125;)\n模板语法Vue的基本结构一个Vue主要由三个部分构成\n\n样式style\n模板template\n脚本script\n\n例如我们的Demo\n\n样式.bg&#123;\tcolor: red&#125;\n模板&lt;div id=&quot;app&quot;&gt;\t&lt;div class=&quot;bg&quot;&gt;\t\t你好&#123;&#123;msg&#125;&#125;\t&lt;/div&gt;\t&lt;div class=&quot;bg&quot;&gt;\t\t你好&#123;&#123;msg&#125;&#125;\t&lt;/div&gt;&lt;/div&gt;\n脚本\n\nnew Vue(&#123;\tel:&#x27;#app&#x27;,\tdata:&#123;\t\tmsg:&#x27;Vue&#x27;\t&#125;&#125;)\n\n\n我们惯用的插入文本的方法就是用两个大括号&#123;&#123;msg&#125;&#125;\n这里面可以是表达式&#123;&#123;count+1&#125;&#125;\n还可以包含模板&#123;&#123;template&#125;&#125;\n当然如果template是一个标签语法，类似&lt;div&gt;hello&lt;/div&gt;的话\n会直接打印出整个代码的内容， 如果我们只是想要它显示div内部的内容\n那么我们需要加一个v-html=\nv-bind给页面的元素绑定一个值v-on绑定某一个事件\n&lt;div id=&quot;app&quot;&gt;\t&#123;&#123;msg&#125;&#125;\t&#123;&#123;count+1&#125;&#125;\t&lt;!-- 表达式 --&gt;\t&#123;&#123;template&#125;&#125;\t&lt;!-- 这样会原样打出哦 --&gt;\t&lt;a :href=&#x27;url&#x27;&gt;百度&lt;/a&gt;\t&lt;!-- 链接到百度 --&gt;\t&lt;button @click=&#x27;sum()&#x27;&gt;加&lt;/button&gt;\t&lt;div v-html=&quot;template&quot;&gt;&lt;/div&gt;&lt;/div&gt;\n\nnew Vue(&#123;\tel:&#x27;#app&#x27;,\tdata:&#123;\t\tmsg:&#x27;Vue&#x27;,\t\tcount:0,\t\ttemplate: &#x27;&lt;div&gt;你好啊&lt;/div&gt;&#x27;,\t\turl:&#x27;http://www.baidu.com&#x27;\t&#125;,\tmethods:&#123;\t\tsum()&#123;\t\t\treturn this.count++\t\t&#125;\t&#125;&#125;)\n\n计算属性与侦听器计算属性computed\n侦听器  watch\n&lt;div id=&quot;app&quot;&gt;\t&#123;&#123;msg&#125;&#125;\t&lt;br&gt;\t&#123;&#123;msg1&#125;&#125;\t&lt;br&gt;\t&#123;&#123;another&#125;&#125;&lt;/div&gt;\nvar vm=new Vue(&#123;\tel:&#x27;#app&#x27;,\tdata:&#123;\t\tmsg:&#x27;hello&#x27;,\t\tanother:&#x27;另一个&#x27;\t&#125;,\tcomputed:&#123;\t\tmsg1()&#123;\t\t\treturn &#x27;computed:  &#x27;+this.msg+this.another;\t\t\t//这两个值任意一个值发生了变化都会影响到msg1的值\t\t&#125;\t&#125;,\twatch:&#123;\t\tmsg:function (newValue,oldValue) &#123;\t\t\tconsole.log(&#x27;新的值&#x27;+newValue);\t\t\tconsole.log(&#x27;旧的值&#x27;+oldValue);\t\t\tconsole.log(&#x27;另一个值&#x27;+this.another)\t\t&#125;\t\t// 把监听的量写在这里，函数可以传两个值，一个是新的值一个是旧的值\t\t// 监听只能监听到本实例当中的变量\t&#125;&#125;)\n区别：watch经常用在异步场景中compute数据联动\n条件渲染，列表渲染，Class与Style绑定v-if，v-else-if,v-else真值渲染\n不再举例\nv-for\n&lt;div id=&quot;app&quot;&gt;\t&lt;div\t\tv-for=&#x27;(item,index) in list&#x27;\t\t:key=&quot;index&quot;\t\t:style=&#x27;msgStyle&#x27;\t&gt;\t\t&#123;&#123;item.name&#125;&#125;\t\t&#123;&#123;item.age&#125;&#125;\t&lt;/div&gt;&lt;/div&gt;\nvar vm=new Vue(&#123;\tel:&#x27;#app&#x27;,\tdata:&#123;\t\tmsg:&#x27;hello&#x27;,\t\tlist:[\t\t&#123;\t\t\tname:&#x27;A&#x27;,\t\t\tage:32\t\t&#125;,&#123;\t\t\tname:&#x27;B&#x27;,\t\t\tage:20\t\t&#125;\t\t],\t\tmsgStyle:&#123;\t\t\tcolor:&#x27;red&#x27;,\t\t\tfontSize: 20+&#x27;px&#x27;\t\t&#125;\t&#125;,&#125;)","categories":["前端","Vue"],"tags":["Vue"]},{"title":"14.Vue-cli","url":"/2019/07/22/Vue/15-Vue-cli/","content":"\n引言：\n\n开始认识vue-cli,进行工程化开发把\n从安装到设置路由，学习风格…\n加油加油!\n\n\n\n\nVue-cli认识Vue-cli在cmd中输入如下代码\n安装\nnpm install -g @vue/cli# ORyarn global add @vue/cli\n创建一个项目\nvue create my-project# ORvue ui\n进入选项选择\n选择Manually select features后我们手动配置\n进入选择组件，以下就是常用组件\n? Check the features needed for your project: (*) Babel ( ) TypeScript ( ) Progressive Web App (PWA) Support (*) Router             路由组件 (*) Vuex                (*) CSS Pre-processors css预编译组件&gt;(*) Linter / Formatter ( ) Unit Testing ( ) E2E Testing\n是否使用历史    -yes\n是否使用ESlint  -Airbnb\npick css?       -SCSS\n是否保存到将来的项目 -no\n进入所建目录，运行\ncd xxxnpm run server\n\n\n运行成功我们来看目录\nnode_modules (依赖文件)\nsrc (放置源文件)关键\nmain.js\nviews (内部放置各个视图)\n\n\npublic (公共资源)关键\nindex.html (入口文件)\n\n\npackage.json (对整个项目的解释说明)关键\n\n\nindex.html内有挂载点，默认id为app\nmain.js创建了Vue实例，而且引入了两个东西\n\nrouter路由\nstore这个是Vuex的引入，管理组件之间的状态\n\n内部代码如下：\nnew Vue(&#123;  router,  store,  render: h =&gt; h(App),&#125;).$mount(&#x27;#app&#x27;);//这里就相当于原本index文件代码的el:&#x27;#app&#x27;\n\n\nVue组件化思想为什么要组件化？实现了模块的复用，利于维护\n可以高效的执行\n降低单页面复杂难度\n怎么拆分300行原则\n复用原则\n业务复杂性原则\n带来的问题用什么解决组件状态管理 Vuex\n多组件混合使用，业务复杂 vue-router\n组件之间传参、消息、事件管理 props,emit/on,bus\n风格指南详情点击这里，Vue官方的风格指南\nVue-router 路由怎么把一个组件拓展到路由内呢？\n\n新建一个组件Info.vue&lt;template&gt;  &lt;div&gt;    怎么设置路由  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;  export default &#123;    name: &#x27;&#x27;  &#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt;\n在src文件下的router.js内的routers里面添加这个组件的信息,并在开头记住引包\n\nimport Info from &#x27;./views/Info.vue&#x27;;\n\n&#123;  path: &#x27;/&#x27;,  name: &#x27;home&#x27;,  component: Home,&#125;,\n\n\n打开App.vue文件，设置页面上的链接，设置router-link\n\n完成\n\nVuexVuex是什么为vue.js开发的状态管理模式\n组件状态集中管理\n组件状态改变遵循统一的规则\n怎么使用Vuexsrc目录下的store.js文件：\nimport Vue from &#x27;vue&#x27;;import Vuex from &#x27;vuex&#x27;;Vue.use(Vuex);export default new Vuex.Store(&#123;  state: &#123;    //组件的状态  &#125;,  mutations: &#123;    //唯一可以改变的vuex状态的方法集  &#125;,  actions: &#123;  &#125;,&#125;);\n\n步骤:\n\n在自建的组件Info.vue内添加以下内容\n\n&lt;template&gt;  &lt;div&gt;    怎么使用Vuex    &lt;button @click=&quot;InfoAdd()&quot;&gt;添加&lt;/button&gt;    &lt;!--1.在这里添加一个事件吧--&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;  import store from &#x27;@/store&#x27;  //2.引包，这里的 @ 是src目录  export default &#123;    name: &#x27;Info&#x27;,    store,//3.还要在这里声明一下，在这里引入    methods: &#123;      InfoAdd() &#123;        console.log(&#x27;add Event from info&#x27;)      &#125;    &#125;  &#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt;\n\n\n打开store.js文件\n\nimport Vue from &#x27;vue&#x27;;import Vuex from &#x27;vuex&#x27;;Vue.use(Vuex);export default new Vuex.Store(&#123;  state: &#123;    count: 0,//1. 这里添加状态  &#125;,  mutations: &#123;    increase() &#123;//2. 这里添加方法      this.state.count += 1;    &#125;,  &#125;,  actions: &#123;&#125;,&#125;);\n\n&lt;template&gt;  &lt;div&gt;    怎么使用Vuex    &lt;button @click=&quot;InfoAdd()&quot;&gt;添加&lt;/button&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;  import store from &#x27;@/store&#x27;  export default &#123;    name: &#x27;Info&#x27;,    store,    methods: &#123;      InfoAdd() &#123;        console.log(&#x27;add Event from info&#x27;)        store.commit(&#x27;increase&#x27;)        //3. 使用 commit 方法，括号内参数是第二步的方法名称      &#125;    &#125;  &#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt;\n这样我们就完成了Vuex的使用，那么怎么给另一个页面传值呢\n&lt;template&gt;  &lt;div class=&quot;about&quot;&gt;    &lt;h1&gt;This is an about page&lt;/h1&gt;    &#123;&#123;msg&#125;&#125;    &lt;!--1. 在这里插入显示的值--&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;  import store from &#x27;@/store&#x27;  //2. 引入vuex  export default &#123;    name:&#x27;about&#x27;,    store,//3. 这里也要声明    data()&#123;      return&#123;        msg: store.state.count        //4. 直接在这里返回就行了      &#125;    &#125;  &#125;&lt;/script&gt;\n\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"17.MVVM设计模式","url":"/2019/07/24/Vue/17-MVVM%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","content":"\n引言：\n\nMVVM设计模式到底是什么呢？\n它和传统的MVP设计模式相比优点是什么呢?\n\n\n\n\n传统的MVP设计模式M: Model数据层\nV: View视图层\nP: Prestenter呈现层，控制层\nM  &lt;–&gt; P &lt;–&gt; V\n视图层V发生事件，交给控制层P,核心层是P\n代表语言: jquery\n他们之间依次交流，交换信息，简化了DOM操作，但还是没有解决”DOM无关于业务逻辑，不应该出现在编辑的代码中的问题”\n逐步淘汰\nMVVM设计模式M: Model数据层\nV: View视图层\nVM: ViewModel(桥梁:不需要关注这层怎么实现)\n\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"18.Vue组件使用细节","url":"/2019/07/24/Vue/18-Vue%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8%E7%BB%86%E8%8A%82/","content":"\n引言：\n\n描述组建的使用细节\n防止运行的错误\n\n\n\n\n\ntable元素&lt;body&gt;\t&lt;div id=&quot;app&quot;&gt;\t\t&lt;table&gt;\t\t\t&lt;tbody&gt;\t\t\t\t&lt;row&gt;&lt;/row&gt;\t\t\t\t&lt;row&gt;&lt;/row&gt;\t\t\t\t&lt;row&gt;&lt;/row&gt;\t\t\t&lt;/tbody&gt;\t\t&lt;/table&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;row&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;tr&gt;&lt;td&gt;this is a row&lt;/td&gt;&lt;/tr&gt;&#x27;\t\t&#125;)\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#app&#x27;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\nH5规范tbody内必须有tr，所以浏览器会出错\n当这样使用模板的时候，乍一看页面没有问题，但是实际上，自定义的组件到了它的外面\n解决办法，使用is属性,更改一下HTML即可\n&lt;table&gt;\t&lt;tbody&gt;\t\t&lt;tr is=&#x27;row&#x27;&gt;&lt;/tr&gt;\t\t&lt;tr is=&#x27;row&#x27;&gt;&lt;/tr&gt;\t\t&lt;tr is=&#x27;row&#x27;&gt;&lt;/tr&gt;\t&lt;/tbody&gt;&lt;/table&gt;\nol，select，li同理\ndata当在非根组件定义data时，必须要求data是一个函数，否则会报错\n引用ref当有复杂的动画特效时，有时只有Vue不能满足\n需要我们对DOM进行操控\n这时我们就要用到引用ref属性\n当ref使用在原有标签上的时候，我们用ref标签会得到他的DOM节点：\n点击hello world字样的时候会在控制台打印出他的内容\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;div \t\t\t@click=&#x27;handleClick&#x27;\t\t\tref=&#x27;hello&#x27;\t\t&gt;hello world&lt;/div&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\t//$refs指所有的引用\t\t\t\t\tconsole.log(this.$refs.hello.innerHTML)\t\t\t\t\t//这个就是此处的DOM节点\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n当在自定义组件上使用ref的时候，获取到的是这个组件的引用\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;counter \t\tref=&#x27;one&#x27;\t\t@change=&#x27;handleChange&#x27;&gt;&lt;/counter&gt;\t\t&lt;counter \t\t@change=&#x27;handleChange&#x27;\t\tref=&#x27;two&#x27;\t\t&gt;&lt;/counter&gt;\t\t&lt;div&gt;&#123;&#123;total&#125;&#125;&lt;/div&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;counter&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div @click=&quot;handleClick&quot;&gt;&#123;&#123;number&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tdata()&#123;\t\t\t\treturn &#123;\t\t\t\t\tnumber: 0\t\t\t\t&#125;\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.number ++;\t\t\t\t\tthis.$emit(&#x27;change&#x27;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata()&#123;\t\t\t\treturn&#123;\t\t\t\t\ttotal: 0\t\t\t\t&#125;\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleChange()&#123;\t\t\t\t\treturn this.total = this.$refs.one.number+this.$refs.two.number\t\t\t\t\t//直接用.即可获取自定义组件内的内容\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"19.Vue父子组件的数据传递","url":"/2019/07/24/Vue/19-Vue%E7%88%B6%E5%AD%90%E7%BB%84%E4%BB%B6%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BC%A0%E9%80%92/","content":"\n引言：\n\n早在第二节我们就讲述了父子组件的传值方法\n现在我们更加系统的了解一下父子组件之间如何传值\n\n\n\n\n\n父组件-&gt;子组件父组件通过绑定属性传给子组件\n子组件绑定一个想要传递的值\n子组件内使用props来接收父组件传递的值\n这样，子组件就可以在模板内使用了\n\n例子\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t\t&lt;counter :count=&#x27;0&#x27;&gt;&lt;/counter&gt;\t\t\t&lt;counter :count=&#x27;1&#x27;&gt;&lt;/counter&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\t//子组件,局部组件方式\t\tvar counter = &#123;\t\t\ttemplate: &#x27;&lt;div&gt;&#123;&#123;count&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops: [&#x27;count&#x27;]\t\t&#125;\t\t//根组件\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tcomponents:&#123;\t\t\t\tcounter:counter\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n当我们使用父组件传来的值，要注意：\n在Vue内有一个单向数据流，要求子组件不能改变父组件的值\n因为有可能同时还有其他的组件使用着这个数据，一个改变，则全都要改变\n直接更改父组件传来的值，Vue会给出警告\n所以我们需要copy一份父组件传来的数据\n例子：\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t\t\t\t&lt;counter :count=&#x27;0&#x27;&gt;&lt;/counter&gt;\t\t\t&lt;counter :count=&#x27;1&#x27;&gt;&lt;/counter&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\t//子组件,局部组件方式\t\tvar counter = &#123;\t\t\ttemplate: &#x27;&lt;div @click=&quot;handleClick&quot;&gt;&#123;&#123;number&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops: [&#x27;count&#x27;],\t\t\tdata()&#123;\t\t\t\treturn&#123;\t\t\t\t\tnumber: this.count\t\t\t\t&#125; \t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.number++\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\t//根组件\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tcomponents:&#123;\t\t\t\tcounter:counter\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n子组件-&gt;父组件子组件传递给父组件通过事件来传值\n使用eimt通过事件来传递数据，emit可以添加多个参数，第一个参数是事件名称，其他都可以是传递的数据\n在子组件上添加监听事件，监听事件的名称就是emit内填入的名称，类似@事件名称=父组件要做出反应的事件名称\n父组件定义相对应的反应方法，有接收的参数记得写在函数的参数部位 \n\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t\t\t\t&lt;counter \t\t\t@change=&#x27;handleSum&#x27;\t\t\t:count=&#x27;0&#x27;&gt;&lt;/counter&gt;\t\t\t&lt;counter\t\t\t@change=&#x27;handleSum&#x27; \t\t\t:count=&#x27;1&#x27;&gt;&lt;/counter&gt;\t\t\t&lt;div&gt;&#123;&#123;total&#125;&#125;&lt;/div&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\t//子组件,局部组件方式\t\tvar counter = &#123;\t\t\ttemplate: &#x27;&lt;div @click=&quot;handleClick&quot;&gt;&#123;&#123;number&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops: [&#x27;count&#x27;],\t\t\tdata()&#123;\t\t\t\treturn&#123;\t\t\t\t\tnumber: this.count,\t\t\t\t\tstep: 1\t\t\t\t&#125; \t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.number = this.number + this.step;\t\t\t\t\t//子组件传给父组件通过事件来传值\t\t\t\t\t//emit函数第一个是事件名，还可以往后添加想要传递的数据\t\t\t\t\tthis.$emit(&#x27;change&#x27;,this.step)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\t//根组件\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata:&#123;\t\t\t\ttotal: 1\t\t\t&#125;,\t\t\tcomponents:&#123;\t\t\t\tcounter:counter\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleSum(step)&#123;\t\t\t\t\t//这里记住要写入参数，接收子组件传来的数据\t\t\t\t\tthis.total += step; \t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"20.Vue组件校验与非props特性","url":"/2019/07/24/Vue/20-Vue%E7%BB%84%E4%BB%B6%E6%A0%A1%E9%AA%8C%E4%B8%8E%E9%9D%9Eprops%E7%89%B9%E6%80%A7/","content":"\n引言：\n\n组件参数校验是怎么一回事？\n非props特性是什么？\n\n\n\n\n\n组件参数校验组件之间传值的时候，我们常常会需要特定类型的值，比如说只要String类型等等，\n这时我们就需要检验参数\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child :content=&#x27;&quot;hello world&quot;&#x27;&gt;&lt;/child&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops:&#123;\t\t\t\tcontent: String\t\t\t&#125;//如果对得到的参数有要求，可以在props内写成这种样子\t\t&#125;)\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t&#125;) \t&lt;/script&gt;&lt;/body&gt;\n\n如果想要得到的参数是String或Number类型的任意一个，可以写成:\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child :content=&#x27;&quot;hello world&quot;&#x27;&gt;&lt;/child&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops:&#123;\t\t\t\tcontent: [Number,String]\t\t\t&#125;//可以写为这样的数组形式\t\t&#125;)\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t&#125;) \t&lt;/script&gt;&lt;/body&gt;\n也可以这样, 也表示只能传入Number类型\nVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops:&#123;\t\t\t\tcontent: &#123;\t\t\t\t\ttype: Number\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\n还可以指定传入的内容是否必须要有某个类型,当没有传入时会警告\nVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops:&#123;\t\t\t\tcontent: &#123;\t\t\t\t\ttype: Number,\t\t\t\t\trequired: true\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\n还可以设定默认值\nVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops:&#123;\t\t\t\tcontent: &#123;\t\t\t\t\ttype: String,\t\t\t\t\trequired: false,\t\t\t\t\tdefault: &#x27;default value&#x27;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)      \n还可以写更加复杂的检验逻辑，使用默认的validator函数\nVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;&#x27;,\t\t\tprops:&#123;\t\t\t\tcontent: &#123;\t\t\t\t\ttype: String,\t\t\t\t\tvalidator(value)&#123;\t\t\t\t\t\treturn value.length&gt;5;\t\t\t\t\t&#125;\t\t\t\t\t//子组件接收一个值，要求其长度必须大于5\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\n\n非props特性props特性：父组件传递的内容在子组件的props内有声明\n特点：\n\n不会在DOM属性上显示\n子组件可以直接使用插值表达式使用\n\n上述的例子都是props特性\n非props：子组件没有用props声明要接受父组件的内容\n特点：\n\n没法用\n非props特性会显示在DOM的属性内\n\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"21.Vue非父子组件之间的传值","url":"/2019/07/24/Vue/21-Vue%E9%9D%9E%E7%88%B6%E5%AD%90%E7%BB%84%E4%BB%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BC%A0%E5%80%BC/","content":"\n引言：\n\n非父子之间，\n该怎么传值呢\n\n\n\n\n\n非父子之间传值使用总线机制，来给他们传值\n这里用一个兄弟组件的例子\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child content=&quot;Dell&quot;&gt;&lt;/child&gt;\t\t&lt;child content=&quot;Lee&quot;&gt;&lt;/child&gt;\t\t\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.prototype.bus = new Vue()\t\t//给Vue的prototype挂一个bus的属性，\t\t//因为每个组件都是Vue创建的，所以创建的每个组件都有了一个bus的属性\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\tdata()&#123;\t\t\t\treturn &#123;\t\t\t\t\tselfContent: this.content\t\t\t\t\t//拷贝一份传来的数据，单向数据原则！\t\t\t\t&#125;\t\t\t&#125;,\t\t\tprops:&#123;\t\t\t\tcontent: String\t\t\t&#125;,\t\t\ttemplate:&#x27;&lt;div @click=&quot;handleClick&quot;&gt;&#123;&#123;selfContent&#125;&#125;&lt;/div&gt;&#x27;,\t\t\t//在子组件内绑定一个事件\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.bus.$emit(&#x27;change&#x27;,this.content)\t\t\t\t\t//this.bus指这个组件的bus属性，\t\t\t\t\t//因为这个属性又是一个Vue的实例，所以它又有了$emit这个方法\t\t\t\t\t//所以可以这么使用\t\t\t\t&#125;\t\t\t&#125;,\t\t\tmounted()&#123;\t\t\t\tvar this_ = this;\t\t\t\tthis.bus.$on(&#x27;change&#x27;,function(msg)&#123;\t\t\t\t\tthis_.selfContent = msg\t\t\t\t\t//这里的this是函数内的this，发生了变化,所以我们得在外部保存this指针\t\t\t\t&#125;)\t\t\t\t//挂载到mouted这个生命钩子上去监听\t\t\t\t//同样，因为this.bus是一个Vue的实例，所以他也有on方法\t\t\t&#125;\t\t\t&#125;)\t\tvar vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"22.如何给组件编写原生事件","url":"/2019/07/26/Vue/22-%E5%A6%82%E4%BD%95%E7%BB%99%E7%BB%84%E4%BB%B6%E7%BC%96%E5%86%99%E5%8E%9F%E7%94%9F%E4%BA%8B%E4%BB%B6/","content":"\n引言：\n\n给自定义组件编写的自定义事件直接声明是没有作用的\n那么该怎么触发组件的事件呢？\n\n\n\n\n\n如果像这样,发现点击一下，没有触发这个事件\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child @click=&quot;handleClick&quot;&gt;&lt;/child&gt;\t\t&lt;!--是自定义事件，这里的事件并没有触发,  --&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;child&lt;/div&gt;&#x27;,\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\talert(&quot;click&quot;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n想要触发这个事件\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child @click=&quot;handleClick&quot;&gt;&lt;/child&gt;\t\t&lt;!--是自定义事件，这里的事件并没有触发,  --&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div @click=&quot;handleChildClick&quot;&gt;child&lt;/div&gt;&#x27;,\t\t\t//是原生事件，这里会触发\t\t\tmethods:&#123;\t\t\t\thandleChildClick()&#123;\t\t\t\t\talert(&quot;child&quot;);\t\t\t\t\t//想要触发自定义事件\t\t\t\t\tthis.$emit(&quot;click&quot;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\talert(&quot;click&quot;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n但是这样也太麻烦了，\n我就想给它加原生事件，怎么办呢\n&lt;div id=&quot;root&quot;&gt;\t&lt;child @click.native=&quot;handleClick&quot;&gt;&lt;/child&gt;    &lt;!--事件加一个.native就可以把这个事件变为原生事件--&gt;&lt;/div&gt;\n很简单，这样就解决了\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"25.Vue-CSS过渡动画原理","url":"/2019/07/26/Vue/25-Vue-CSS%E8%BF%87%E6%B8%A1%E5%8A%A8%E7%94%BB%E5%8E%9F%E7%90%86/","content":"\n引言：\n\n介绍Vue中的css过渡动画\n各种情况下的过渡\n动画封装\n\n\n\n\n\n原理我们可以用transition标签来包裹我们想要添加css动画的部分\n原理：\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;transition name=&#x27;fade&#x27;&gt;\t\t\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;\t\t&lt;/transition&gt;\t\t&lt;button @click=&quot;handleClick&quot;&gt;切换&lt;/button&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata:&#123;\t\t\t\tshow: true\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.show=!this.show\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n当一个元素被transition标签包裹的时候，Vue会自动的分析css的样式，并且构建一个css流程：\n这是出现时的流程\n\n在动画即将被执行的一瞬间，会向内部的标签增加两个class：\n\n\nfade-enter\nfade-enter-active\n\n&lt;style&gt;\t.fade-enter&#123;\t\topacity: 0;\t&#125;\t.fade-enter-active&#123;\t\ttransition: opacity 1s;\t&#125;&lt;/style&gt;\n这就是一个淡入的效果\n\n当运行至第二帧执行时，去掉fade-enter，增添一个fade-enter-to的class\n\n\n执行到结束的时候，会把所有的class全部去掉\n\n都以fade为开头是因为我给transition起名为fade，默认的名字以v开头即可\n这是离开时的流程:\n同理\n\n填入两个clss\n\n\nfade-leave\nfade-leave-active\n\n\n去掉fade-enter，填入fade-enter-to\n去掉所有的class\n\n.fade-leave-to&#123;\topacity: 0  &#125;.fade-leave-active&#123;\ttransition: opacity 1s;&#125;\n\n不论v-if,v-show,还是过度组件，都会有过渡动画效果\n多元素.v-enter, .v-leave-to&#123;\topacity: 0;&#125;.v-enter-active,.v-leave-active&#123;\ttransition: opacity 1s;&#125;\n\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;div&gt;\t\t\t&lt;transition&gt;\t\t\t\t&lt;div v-if=&quot;show&quot; key=&#x27;hello&#x27;&gt;你好&lt;/div&gt;\t\t\t\t&lt;div v-else key=&#x27;bye&#x27;&gt;Bye World&lt;/div&gt;        &lt;!--这里要加不同的key值，因为vue会对DOM复用--&gt;\t\t\t&lt;/transition&gt;\t\t\t&lt;button @click=&quot;handleClick&quot;&gt;切换&lt;/button&gt;\t\t&lt;/div&gt;\t&lt;/div&gt;&lt;script&gt;\tlet vm = new Vue(&#123;\t\tel:&#x27;#root&#x27;,\t\tdata:&#123;\t\t\tshow: true\t\t&#125;,\t\tmethods:&#123;\t\t\thandleClick()&#123;\t\t\t\tthis.show=!this.show\t\t\t&#125;,\t\t\thandleBeforeEnter(el)&#123;\t\t\t\tel.style.opacity = 0;\t\t\t&#125;,\t\t\thandleEnter(el,done)&#123;\t\t\t\tVelocity(el,&#123;opacity: 1&#125;,&#123;duration:1000,complete:done&#125;);\t\t\t&#125;,\t\t\thandleAfterEnter(el)&#123;\t\t\t\talert(&#x27;动画结束&#x27;)\t\t\t&#125;\t\t&#125;\t&#125;)&lt;/script&gt;&lt;/body&gt;\n\n还可以在transition上面加mode属性\nmode属性有两个值\n\nmode=”in-out” 两个元素先进后出\nmode=”out-in” 两个元素先出后进\n\n&lt;transition mode=&#x27;out-in&#x27;&gt;\t&lt;div v-if=&quot;show&quot; key=&#x27;hello&#x27;&gt;你好&lt;/div&gt;\t&lt;div v-else key=&#x27;bye&#x27;&gt;Bye World&lt;/div&gt;&lt;/transition&gt;\n\n多组件我们需要用到动态组件\n其他相同\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;\t&lt;meta charset=&quot;UTF-8&quot;&gt;\t&lt;title&gt;\t&lt;/title&gt;\t&lt;script src=&quot;./js/vue.js&quot;&gt;&lt;/script&gt;\t&lt;link rel=&quot;stylesheet&quot; href=&quot;js/animate.css&quot;&gt;\t&lt;script src=&quot;js/velocity.js&quot;&gt;&lt;/script&gt;\t\t&lt;style&gt;\t\t.v-enter, .v-leave-to&#123;\t\t\topacity: 0;\t\t&#125;\t\t.v-enter-active,.v-leave-active&#123;\t\t\ttransition: opacity 0.5s;\t\t&#125;\t&lt;/style&gt;&lt;/head&gt;&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t\t&lt;transition mode=&#x27;out-in&#x27;&gt;\t\t\t\t&lt;component :is=&#x27;type&#x27;&gt;&lt;/component&gt;\t\t\t&lt;/transition&gt;\t\t\t&lt;button @click=&quot;handleClick&quot;&gt;切换&lt;/button&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&quot;child-one&quot;,&#123;\t\t\ttemplate: &#x27;&lt;div&gt;child-one&lt;/div&gt; &#x27;\t\t&#125;)\t\tVue.component(&quot;child-two&quot;,&#123;\t\t\ttemplate: &#x27;&lt;div&gt;child-two&lt;/div&gt; &#x27;\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata:&#123;\t\t\t\ttype:&#x27;child-one&#x27;\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.type = this.type === &#x27;child-one&#x27;?&#x27;child-two&#x27;:&#x27;child-one&#x27;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n列表过渡使用一个新的标签&lt;transition-group&gt;来实现列表的渲染\n&lt;div id=&quot;root&quot;&gt;\t&lt;transition-group&gt;\t&lt;div v-for=&#x27;item of list&#x27; :key=&#x27;item.id&#x27;&gt;\t\t&#123;&#123;item.title&#125;&#125;\t&lt;/div&gt;\t&lt;/transition-group&gt;\t&lt;button @click=&#x27;handleClick&#x27;&gt;Add&lt;/button&gt;&lt;/div&gt;\n\n.v-enter, .v-leave-to&#123;\topacity: 0;&#125;.v-enter-active,.v-leave-active&#123;\ttransition: opacity 0.5s;&#125;\n\nlet count = 0;let vm = new Vue(&#123;\tel:&#x27;#root&#x27;,\tdata:&#123;\t\tlist:[]\t&#125;,\tmethods:&#123;\t\thandleClick()&#123;\t\t\tthis.list.push(&#123;\t\t\t\tid:count++,\t\t\t\ttitle:&#x27;hello&#x27;\t\t\t&#125;)\t\t&#125;\t&#125;&#125;)\n\n封装Vue.component(&#x27;fade&#x27;,&#123;\tprops:[&#x27;show&#x27;],\ttemplate:&#x27;&lt;transition @before-enter=&quot;handleBeforeEnter&quot; @enter=&quot;handleEnter&quot;&gt;&lt;slot v-if=&quot;show&quot;&gt;&lt;/slot&gt;&lt;/transition&gt;&#x27;,\tmethods:&#123;\t\thandleBeforeEnter(el)&#123;\t\t\tel.style.color = &#x27;red&#x27;\t\t&#125;,\t\thandleEnter(el,done)&#123;\t\t\tsetTimeout(()=&gt;&#123;\t\t\t\tel.style.color =&#x27;green&#x27;\t\t\t&#125;,2000)\t\t&#125;\t&#125;&#125;)\n这样封装起来，我们就可以直接使用了\n&lt;fade :show=&#x27;show&#x27;&gt;\t&lt;div&gt;你好&lt;/div&gt;&lt;/fade&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"24.动态组件与v-once指令","url":"/2019/07/26/Vue/24-%E5%8A%A8%E6%80%81%E7%BB%84%E4%BB%B6%E4%B8%8Ev-once%E6%8C%87%E4%BB%A4/","content":"\n引言：\n\n动态组件是什么？\nv-once指令可以干什么？\n\n\n\n\n\n动态组件我想实现一个切换组件的功能\n直接写代码，应该是这个样子的\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child-one v-if=&#x27;type===&quot;child-one&quot;&#x27;&gt;&lt;/child-one&gt;\t\t&lt;child-two v-if=&#x27;type===&quot;child-two&quot;&#x27;&gt;&lt;/child-two&gt;\t\t&lt;button @click=&#x27;handleClick&#x27;&gt;change&lt;/button&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child-one&#x27;,&#123;\t\t\ttemplate: &#x27;&lt;div&gt;child-one&lt;/div&gt;&#x27;\t\t\t&#125;)\t\tVue.component(&#x27;child-two&#x27;,&#123;\t\t\ttemplate: &#x27;&lt;div&gt;child-two&lt;/div&gt;&#x27;\t\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata:&#123;\t\t\t\ttype: &#x27;child-one&#x27;\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.type = (this.type===&#x27;child-one&#x27;?&#x27;child-two&#x27;:&#x27;child-one&#x27;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n我们可以使用更加方便的方式来完成我们的目的\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;component :is=&quot;type&quot;&gt;&lt;/component&gt;\t\t&lt;!--component是vue的自带组件，指一个动态组件 ,通过is属性就可以实现这件事情--&gt;\t\t&lt;button @click=&#x27;handleClick&#x27;&gt;change&lt;/button&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child-one&#x27;,&#123;\t\t\ttemplate: &#x27;&lt;div&gt;child-one&lt;/div&gt;&#x27;\t\t\t&#125;)\t\tVue.component(&#x27;child-two&#x27;,&#123;\t\t\ttemplate: &#x27;&lt;div&gt;child-two&lt;/div&gt;&#x27;\t\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata:&#123;\t\t\t\ttype: &#x27;child-one&#x27;\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.type = (this.type===&#x27;child-one&#x27;?&#x27;child-two&#x27;:&#x27;child-one&#x27;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n这样就方便了许多\nv-once指令Vue.component(&#x27;child-one&#x27;,&#123;\t\t\ttemplate: &#x27;&lt;div&gt;child-one&lt;/div&gt;&#x27;\t\t\t&#125;)\t\tVue.component(&#x27;child-two&#x27;,&#123;\t\t\ttemplate: &#x27;&lt;div&gt;child-two&lt;/div&gt;&#x27;\t\t\t&#125;)\n当我们使用这样的代码时，底层都会创建一个组件，销毁一个组件，这样十分消耗性能\n我们只需加一个v-once的命令，这样就可以把此组件放入内存，每次调用不需要再重新创建销毁，节约了性能\nVue.component(&#x27;child-one&#x27;,&#123;\t\t\ttemplate: &#x27;&lt;div v-once&gt;child-one&lt;/div&gt;&#x27;\t\t\t&#125;)\t\tVue.component(&#x27;child-two&#x27;,&#123;\t\t\ttemplate: &#x27;&lt;div v-once&gt;child-two&lt;/div&gt;&#x27;\t\t\t&#125;)\n\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"23.Vue插槽","url":"/2019/07/26/Vue/23-Vue%E6%8F%92%E6%A7%BD/","content":"\n引言:\n\nVue的插槽如何使用呢\n来看看吧\n\n\n\n\n\nVue插槽当我们在开发中，总会有这样的需求\n&lt;div id=&quot;root&quot;&gt;\t\t&lt;child content=&#x27;&lt;p&gt;我想加这个内容&lt;/p&gt;&#x27;&gt;&lt;/child&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\tprops:[&quot;content&quot;],\t\t\ttemplate:&#x27;&lt;div&gt;&lt;p&gt;hello&lt;/p&gt;&#123;&#123;content&#125;&#125;&lt;/div&gt;&#x27;,\t\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;\t\t&#125;)\t&lt;/script&gt;\n但这样传入content会被转义,即直接显示&lt;p&gt;我想加这个内容&lt;/p&gt;\n这显然不是我们想要的\n我们想让他直接的显示出来\n我们之前学过一个指令v-html可以解决这个问题\nVue.component(&#x27;child&#x27;,&#123;\tprops:[&quot;content&quot;],\ttemplate:&#x27;&lt;div&gt;&lt;p&gt;hello&lt;/p&gt;&lt;div v-html=&quot;content&quot;&gt;&lt;/div&gt;&lt;/div&gt;&#x27;,\t//这里使用template站位符没有作用,会导致渲染不出来\t&#125;)\n但是这种方法，还会给外部增加一个div\nVue提供给我们一个插槽属性来实现这个功能\n使用插槽：\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child&gt;\t\t\t&lt;p&gt;使用插槽&lt;/p&gt;\t\t&lt;/child&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;\t\t\t            &lt;p&gt;hello&lt;/p&gt;\t\t\t            &lt;slot&gt;这里还可以添加默认值&lt;/slot&gt;\t\t            &lt;/div&gt;&#x27;,\t\t\t//当没有插入任何值，会启用这个函数\t\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n我们还可以给插槽起名字，像是这个样子:\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child&gt;\t\t\t&lt;p slot=&#x27;name1&#x27;&gt;第一个插槽&lt;/p&gt;\t\t\t&lt;p&gt;使用插槽&lt;/p&gt;\t\t\t&lt;p slot=&#x27;name2&#x27;&gt;第二个插槽&lt;/p&gt;\t\t&lt;/child&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\ttemplate:&#x27;&lt;div&gt;\t\t\t            &lt;slot name=&quot;name1&quot;&gt;默认值1&lt;/slot&gt;\t\t\t            &lt;p&gt;hello&lt;/p&gt;\t\t\t            &lt;slot name=&quot;name2&quot;&gt;默认值2&lt;/slot&gt;\t\t            &lt;/div&gt;&#x27;,\t\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\nVue的作用域插槽当我们想在子组件渲染循环\nVue.component(&#x27;child&#x27;,&#123;\tdata()&#123;\t\treturn &#123;\t\t\tlist: [1,2,3,4]\t\t&#125;\t&#125;,\ttemplate:&#x27;&lt;div&gt;&lt;li v-for=&quot;item of list&quot;&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt;&lt;/div&gt;&#x27;,\t\t&#125;)\n但我们可能不想循环&lt;li&gt;标签，我们想让外部决定怎么渲染\n这时我们就需要用到作用域插槽\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;child&gt;\t\t\t&lt;template slot-scope=&#x27;props&#x27;&gt;\t\t\t\t&lt;h1&gt;&#123;&#123;props.item&#125;&#125;&lt;/h1&gt;\t\t\t\t&lt;!--传过来的内容存入了props内--&gt;\t\t\t&lt;/template&gt;\t\t&lt;/child&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tVue.component(&#x27;child&#x27;,&#123;\t\t\tdata()&#123;\t\t\t\treturn &#123;\t\t\t\t\tlist: [1,2,3,4]\t\t\t\t&#125;\t\t\t&#125;,\t\t\ttemplate:&#x27;&lt;div&gt;&lt;slot v-for=&quot;item of list&quot; :item=item &gt;&#123;&#123;item&#125;&#125;&lt;/slot&gt;&lt;/div&gt;&#x27;,\t\t\t//这里想插槽内传入想要他显示的内容\t\t\t&#125;)\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"27.Vue中的js动画与Velocity.js库结合","url":"/2019/07/26/Vue/27-Vue%E4%B8%AD%E7%9A%84js%E5%8A%A8%E7%94%BB%E4%B8%8EVelocity-js%E5%BA%93%E7%BB%93%E5%90%88/","content":"\n引言:\n\njs写动画\n再加上Velocity库\n\n\n\n\n\njs动画我们可以借助生命钩子来实现动画\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;div&gt;\t\t\t&lt;transition\t\t\tname=&#x27;fade&#x27;\t\t\t@before-enter=&#x27;handleBeforeEnter&#x27;\t\t\t@enter=&#x27;handleEnter&#x27;\t\t\t@after-enter=&#x27;handleAfterEnter&#x27;\t\t\t&gt;\t\t\t\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;\t\t\t&lt;/transition&gt;\t\t\t&lt;button @click=&quot;handleClick&quot;&gt;切换&lt;/button&gt;\t\t&lt;/div&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata:&#123;\t\t\t\tshow: true\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.show=!this.show\t\t\t\t&#125;,\t\t\t\thandleBeforeEnter(el)&#123;\t\t\t\t\tel.style.color=&#x27;red&#x27;\t\t\t\t&#125;,\t\t\t\t//这里有一个参数el\t\t\t\thandleEnter(el,done)&#123;\t\t\t\t\tsetTimeout(() =&gt; &#123;\t\t\t\t\t\tel.style.color=&#x27;green&#x27;\t\t\t\t\t&#125;,2000);\t\t\t\t\tsetTimeout(() =&gt; &#123;\t\t\t\t\t\tdone()//没有事件也要加上，表示动画已经结束\t\t\t\t\t&#125;,4000)\t\t\t\t&#125;,\t\t\t\t//两个参数,el和done，done是一个回调函数\t\t\t\thandleAfterEnter(el)&#123;\t\t\t\t\tel.style.color=&#x27;#000&#x27;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;\n\n使用Velocity库\n引包\n\n&lt;script src=&quot;js/velocity.js&quot;&gt;&lt;/script&gt;\t\n\n\n使用\n\n&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;div&gt;\t\t\t&lt;transition\t\t\tname=&#x27;fade&#x27;\t\t\t@before-enter=&#x27;handleBeforeEnter&#x27;\t\t\t@enter=&#x27;handleEnter&#x27;\t\t\t@after-enter=&#x27;handleAfterEnter&#x27;\t\t\t&gt;\t\t\t\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;\t\t\t&lt;/transition&gt;\t\t\t&lt;button @click=&quot;handleClick&quot;&gt;切换&lt;/button&gt;\t\t&lt;/div&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata:&#123;\t\t\t\tshow: true\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.show=!this.show\t\t\t\t&#125;,\t\t\t\thandleBeforeEnter(el)&#123;\t\t\t\t\tel.style.opacity = 0;\t\t\t\t&#125;,\t\t\t\thandleEnter(el,done)&#123;\t\t\t\t\tVelocity(el,&#123;opacity: 1&#125;,&#123;duration:1000,complete:done&#125;);//这里要加done函数\t\t\t\t&#125;,\t\t\t\thandleAfterEnter(el)&#123;\t\t\t\t\talert(&#x27;动画结束&#x27;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"26.Vue中使用Animate.css库","url":"/2019/07/26/Vue/26-Vue%E4%B8%AD%E4%BD%BF%E7%94%A8Animate-css%E5%BA%93/","content":"\n引言：\n\nAnimate.css库的使用\n\n\n\n\n\n如何使用\n去官网下载Animate的库文件Animate官网\n\n引包\n\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;\t&lt;meta charset=&quot;UTF-8&quot;&gt;\t&lt;title&gt;\t&lt;/title&gt;\t&lt;script src=&quot;./js/vue.js&quot;&gt;&lt;/script&gt;\t&lt;link rel=&quot;stylesheet&quot; href=&quot;js/animate.css&quot;&gt;&lt;/head&gt;&lt;body&gt;\t&lt;div id=&quot;root&quot;&gt;\t\t&lt;transition \t\tname=&#x27;fade&#x27;\t\tenter-active-class=&#x27;animated swing&#x27;\t\tleave-active-class=&#x27;animated shake&#x27;\t\t&gt;\t\t\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;\t\t&lt;/transition&gt;\t\t&lt;button @click=&quot;handleClick&quot;&gt;切换&lt;/button&gt;\t&lt;/div&gt;\t&lt;script&gt;\t\tlet vm = new Vue(&#123;\t\t\tel:&#x27;#root&#x27;,\t\t\tdata:&#123;\t\t\t\tshow: true\t\t\t&#125;,\t\t\tmethods:&#123;\t\t\t\thandleClick()&#123;\t\t\t\t\tthis.show=!this.show\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;)\t&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n首次加载即有动画加两个类名\n\nappear\nappear-active-class\n\n&lt;transition name=&#x27;fade&#x27;appearenter-active-class=&#x27;animated swing&#x27;leave-active-class=&#x27;animated shake&#x27;appear-active-class=&#x27;animated swing&#x27;&gt;\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;&lt;/transition&gt;\n\n如何同时使用过渡和动画&lt;transition \t\tname=&#x27;fade&#x27;\t\tappear\t\tenter-active-class=&#x27;animated swing fade-enter-active&#x27;\t\tleave-active-class=&#x27;animated shake fade-leave-active&#x27;\t\tappear-active-class=&#x27;animated swing&#x27;\t\t&gt;\t\t\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;\t\t&lt;/transition&gt;\n在动画的名后加上对应的过渡动画名即可，过渡动画要自己设置\n怎么解决过渡与动画时间不统一加一个type或者duration即可\ntype:\n&lt;transition\t\ttype=&quot;transition&quot;\t\tname=&#x27;fade&#x27;\t\tappear\t\tenter-active-class=&#x27;animated swing fade-enter-active&#x27;\t\tleave-active-class=&#x27;animated shake fade-leave-active&#x27;\t\tappear-active-class=&#x27;animated swing&#x27;\t\t&gt;\t\t\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;\t\t&lt;/transition&gt;\n\nduration:单位是ms\n&lt;transition\t\t:duration=&#x27;5000&#x27;\t\tname=&#x27;fade&#x27;\t\tappear\t\tenter-active-class=&#x27;animated swing fade-enter-active&#x27;\t\tleave-active-class=&#x27;animated shake fade-leave-active&#x27;\t\tappear-active-class=&#x27;animated swing&#x27;\t\t&gt;\t\t\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;\t\t&lt;/transition&gt;\n甚至可以添加起止时间\n&lt;transition\t\t:duration=&#x27;&#123;enter: 5000,leave:5000&#125;&#x27;\t\tname=&#x27;fade&#x27;\t\tappear\t\tenter-active-class=&#x27;animated swing fade-enter-active&#x27;\t\tleave-active-class=&#x27;animated shake fade-leave-active&#x27;\t\tappear-active-class=&#x27;animated swing&#x27;\t\t&gt;\t\t\t&lt;div v-if=&quot;show&quot;&gt;你好&lt;/div&gt;\t\t&lt;/transition&gt;","categories":["前端","Vue"],"tags":["Vue"]},{"title":"28.Vuex状态管理","url":"/2019/07/27/Vue/28-Vuex%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/","content":"\n\n引言：\nVuex是什么？\n\n\n\n\n\nVuex是什么专为Vue.js开发的状态管理模式\n集中式存储管理应用的所有组件状态，\n并以对应的规则保证状态以一种可预测的方式发生变化\n什么是状态管理模式new Vue(&#123;//state  data()&#123;  return &#123;  \tcount: 0  &#125;  &#125;,  //view  template:&#x27;&lt;div&gt;&#123;&#123;count&#125;&#125;&lt;/div&gt;&#x27;,  //actions  methods:&#123;  increment()&#123;  \tthis.count++  &#125;&#125;&#125;)\n\n\nstate,驱动应用的数据源\nview,以声明方式将state映射到视图\nactions,响应在view上的用户输入导致的状态变化\n\nvue特性之一就是 “单向数据流”但是，当我们需要多个组件共享状态时\n单向数据流的概念很容易被破坏：\n\n多视图依赖于同一个状态\n不同的行为需要变更同一个状态\n\n一般的方法难以维护\n所以，Vue把共享状态抽取出来，以一个全局单例模式管理\n不管在树的哪一个位置，任何组件都能获取状态或者触发行为\nVuex使用Vuex核心是store(仓库),store内有着应用中大部分的状态state\nVuex与全局对象的区别\nVuex的状态存储是响应式的\n不能直接改变store的状态，唯一只能通过显式的提交mutation\n\n简单的Store// 如果在模块化构建系统中，请确保在开头调用了 Vue.use(Vuex)const store = new Vuex.Store(&#123;  state: &#123;    count: 0  &#125;,  mutations: &#123;    increment (state) &#123;      state.count++    &#125;  &#125;&#125;)\n可以通过store.state获取状态对象\n通过store.commit触发状态变更\nstore.commit(&#x27;increment&#x27;)//加方法的名称console.log(store.state.count) // -&gt; 1\n\n再次强调，\n我们通过提交 mutation 的方式，而非直接改变 store.state.count，是因为我们想要更明确地追踪到状态的变化\n核心概念State单一状态树Vue只用一个对象包含全部的应用层级状态\n每个应用仅仅包含一个store实例\n单一状态树方便我们管理\n在Vue组件中获得Vuex状态从 store 实例中读取状态\n最简单的方法就是在计算属性中返回某个状态：\n// 创建一个 Counter 组件const Counter = &#123;  template: `&lt;div&gt;&#123;&#123; count &#125;&#125;&lt;/div&gt;`,  computed: &#123;    count () &#123;      return store.state.count    &#125;  &#125;&#125;\n\n另一种更好的办法\nVuex 通过 store 选项，提供了一种机制将状态从根组件“注入”到每一个子组件中（需调用 Vue.use(Vuex)）：\nconst app = new Vue(&#123;  el: &#x27;#app&#x27;,  // 把 store 对象提供给 “store” 选项，这可以把 store 的实例注入所有的子组件  store,  components: &#123; Counter &#125;,  template: `    &lt;div class=&quot;app&quot;&gt;      &lt;counter&gt;&lt;/counter&gt;    &lt;/div&gt;  `&#125;)\n把 store 对象提供给 “store” 选项，这可以把 store 的实例注入所有的子组件\n通过在根实例中注册 store 选项，该 store 实例会注入到根组件下的所有子组件中，且子组件能通过 this.$store 访问到。\n让我们更新下 Counter 的实现：\nconst Counter = &#123;  template: `&lt;div&gt;&#123;&#123; count &#125;&#125;&lt;/div&gt;`,  computed: &#123;    count () &#123;      return this.$store.state.count    &#125;  &#125;&#125;\n\nGetter有时我们需要从store中的state派生出一些状态\n例如对列表进行过滤并计数\ncomputed: &#123;  doneTodosCount () &#123;    return this.$store.state.todos.filter(todo =&gt; todo.done).length  &#125;&#125;\n如果有多个组件需要用到此属性，\n我们要么复制这个函数，\n或者抽取到一个共享函数然后在多处导入它——无论哪种方式都不是很理想。\nVuex 允许我们在 store 中定义“getter”（可以认为是 store 的计算属性）。\n就像计算属性一样，getter 的返回值会根据它的依赖被缓存起来，且只有当它的依赖值发生了改变才会被重新计算。\nGetter 接受 state 作为其第一个参数：\nconst store = new Vuex.Store(&#123;  state: &#123;    todos: [      &#123; id: 1, text: &#x27;...&#x27;, done: true &#125;,      &#123; id: 2, text: &#x27;...&#x27;, done: false &#125;    ]  &#125;,  getters: &#123;    doneTodos: state =&gt; &#123;      return state.todos.filter(todo =&gt; todo.done)    &#125;  &#125;&#125;)\n\n通过属性访问Getter 会暴露为 store.getters 对象，你可以以属性的形式访问这些值：\nstore.getters.doneTodos // -&gt; [&#123; id: 1, text: &#x27;...&#x27;, done: true &#125;]\n\nGetter 也可以接受其他 getter 作为第二个参数：\ngetters: &#123;  // ...  doneTodosCount: (state, getters) =&gt; &#123;    return getters.doneTodos.length  &#125;&#125;\nstore.getters.doneTodosCount // -&gt; 1\n我们很容易的在任何组件中使用它\ncomputed: &#123;  doneTodosCount () &#123;    return this.$store.getters.doneTodosCount  &#125;&#125;\n注意，getter 在通过属性访问时是作为 Vue 的响应式系统的一部分缓存其中的\n通过方法访问通过让 getter 返回一个函数，来实现给 getter 传参。在你对 store 里的数组进行查询时非常有用。\ngetters: &#123;  // ...  getTodoById: (state) =&gt; (id) =&gt; &#123;    return state.todos.find(todo =&gt; todo.id === id)  &#125;&#125;\n\nstore.getters.getTodoById(2) // -&gt; &#123; id: 2, text: &#x27;...&#x27;, done: false &#125;\n注意，getter 在通过方法访问时，每次都会去进行调用，而不会缓存结果。\nMutation更改 Vuex 的 store 中的状态的唯一方法是提交 mutation\nVuex 中的 mutation 非常类似于事件：\n每个 mutation 都有一个字符串的 事件类型 (type) 和 一个 回调函数 (handler)。\n这个回调函数就是我们实际进行状态更改的地方，并且它会接受 state 作为第一个参数：\nconst store = new Vuex.Store(&#123;  state: &#123;    count: 1  &#125;,  mutations: &#123;    increment (state) &#123;      // 变更状态      state.count++    &#125;  &#125;&#125;)\n\n要唤醒一个 mutation handler，你需要以相应的 type 调用 store.commit 方法：\nstore.commit(&#x27;increment&#x27;)\n\n提交载荷（Payload）你可以向 store.commit 传入额外的参数，即 mutation 的 载荷（payload）：\n// ...mutations: &#123;  increment (state, n) &#123;    state.count += n  &#125;&#125;\nstore.commit(&#x27;increment&#x27;, 10)\n在大多数情况下，载荷应该是一个对象，这样可以包含多个字段并且记录的 mutation 会更易读：\n// ...mutations: &#123;  increment (state, payload) &#123;    state.count += payload.amount  &#125;&#125;\nstore.commit(&#x27;increment&#x27;, &#123;  amount: 10&#125;)\n\n对象风格的提交方式提交 mutation 的另一种方式是直接使用包含 type 属性的对象：\nstore.commit(&#123;  type: &#x27;increment&#x27;,  amount: 10&#125;)\n当使用对象风格的提交方式，整个对象都作为载荷传给 mutation 函数，因此 handler 保持不变：\nmutations: &#123;  increment (state, payload) &#123;    state.count += payload.amount  &#125;&#125;\n\nMutation需要遵守Vue的响应规则\n最好提前在你的store中初始化所有的所需属性\n在需要在对象上添加新属性时，应该\n使用Vue.set(obj, &#39;newProp&#39;, 123)\n或者以新对象替换老对象,例如利用 stage-3 的对象展开运算符state.obj = &#123; ...state.obj, newProp: 123 &#125;\n\n\n\n在组件中提交 Mutation你可以在组件中使用 this.$store.commit(&#39;xxx&#39;) 提交 mutation    \n在 Vuex 中，mutation 都是 同步事务store.commit(&#x27;increment&#x27;)// 任何由 &quot;increment&quot; 导致的状态变更都应该在此刻完成。\n\nActionAction和Mutation的区别:\n\nAction 提交的是 mutation ,而不是直接变更状态\nAction 可以包含任意异步操作\n\n简单的action例子\nconst store = new Vuex.Store(&#123;  state: &#123;    count: 0  &#125;,  mutations: &#123;    increment (state) &#123;      state.count++    &#125;  &#125;,  actions: &#123;    increment (context) &#123;      context.commit(&#x27;increment&#x27;)    &#125;  &#125;&#125;)\nAction 函数接受一个与 store 实例具有相同方法和属性的 context 对象，\n因此你可以调用 context.commit 提交一个 mutation，\n或者通过 context.state 和 context.getters 来获取 state 和 getters。\n实践中，我们会经常用到 ES2015 的 参数解构 来简化代码（特别是我们需要调用 commit 很多次的时候）：\nactions: &#123;  increment (&#123; commit &#125;) &#123;    commit(&#x27;increment&#x27;)  &#125;&#125;\n分发ActionAction 通过 store.dispatch 方法触发：\nstore.dispatch(&#x27;increment&#x27;)\n\n乍一眼看上去感觉多此一举，我们直接分发 mutation 岂不更方便？\n实际上并非如此，还记得 mutation 必须同步执行这个限制么？\nAction 就不受约束！我们可以在 action 内部执行异步操作：\nactions: &#123;  incrementAsync (&#123; commit &#125;) &#123;    setTimeout(() =&gt; &#123;      commit(&#x27;increment&#x27;)    &#125;, 1000)  &#125;&#125;\nActions 支持同样的载荷方式和对象方式进行分发：\n// 以载荷形式分发store.dispatch(&#x27;incrementAsync&#x27;, &#123;  amount: 10&#125;)// 以对象形式分发store.dispatch(&#123;  type: &#x27;incrementAsync&#x27;,  amount: 10&#125;)\n来看一个更加实际的购物车示例，涉及到调用异步 API 和分发多重 mutation：\nactions: &#123;  checkout (&#123; commit, state &#125;, products) &#123;    // 把当前购物车的物品备份起来    const savedCartItems = [...state.cart.added]    // 发出结账请求，然后乐观地清空购物车    commit(types.CHECKOUT_REQUEST)    // 购物 API 接受一个成功回调和一个失败回调    shop.buyProducts(      products,      // 成功操作      () =&gt; commit(types.CHECKOUT_SUCCESS),      // 失败操作      () =&gt; commit(types.CHECKOUT_FAILURE, savedCartItems)    )  &#125;&#125;\n注意我们正在进行一系列的异步操作，并且通过提交 mutation 来记录 action 产生的副作用（即状态变更）\n在组件中分发Action你在组件中使用 this.$store.dispatch(&#39;xxx&#39;) 分发 action\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"30.多页应用VS单页应用","url":"/2019/07/28/Vue/30-%E5%A4%9A%E9%A1%B5%E5%BA%94%E7%94%A8VS%E5%8D%95%E9%A1%B5%E5%BA%94%E7%94%A8/","content":"\n引言：\n\n多页面vs单页面\n他们各自的特点是什么\n\n\n\n\n\n多页面应用每次页面的跳转，后端都会提供html文件\n优点：首屏时间短，SEO（搜索引擎优化）效果好\n缺点：页面切换慢\n单页面应用js动态的感知页面的变化，判断页面显示内容\n并不向后台发送内容，切换不需要接收html的内容\n优点：页面切换快\n缺点：首屏时间稍慢，SEO差\n通过服务器渲染技术，可以克服这两个缺点\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"LoongSon大牛的讲话","url":"/2020/08/17/%E5%85%B6%E4%BB%96/Loongson%E6%80%BB%E5%85%AC%E5%8F%B8%E7%A0%94%E7%A9%B6%E5%91%98%E7%8E%8B%E6%B4%AA%E8%99%8E%E8%80%81%E5%B8%88%E7%9A%84%E8%AE%B2%E8%AF%9D/","content":"\n龙芯总公司研究员王洪虎老师的讲话，体会有感\n\n\n\n\nLoongson总公司大牛的讲话\n2020.08.05总公司研究员王洪虎老师讲话，获益匪浅，记录一下，虽然未来不一定要去Loongson工作，但是和这样直率诚恳的技术大咖交流的机会，是十分难得的，所以专门记录了一下。\n\n\n关于生态\n关于项目\n关于结果\n关于我们\n关于解决问题\n关于团队与个人\n\n关于生态龙芯造国产的CPU，必然需要给下游的一些应用开发厂家、中间件厂家给予一个生态平台，这是非常重要的一个方面，生态是从软件、硬件、核心库、中间件等等一系列CS配套产业，打造一个生态是成片的\n关于项目完成一个项目，项目的目的是什么，过程是什么。。\n以下举例就拿我们组目前的这个项目——数据恢复软件\n\n明确方向，制定需求。\n需求依然依然依然依然是一个项目的重中之重，完成一个项目，你得知道你完成的这个项目最终得完成什么样的需求，完成什么样的目标。\n做一个数据恢复软件，我们的需求可能就是，我们要完成U盘的数据恢复呢、还是硬盘的数据恢复呢、还是光盘等等的数据恢复呢，我们要找到我们要完成的目标需求是什么。\n\n\n定义设计方案。进行调研\n项目设计的方案，进行调研，了解这个项目的背景、等等情况。\n做数据恢复软件，我们就得去调研windows下是怎么数据恢复的，Linux下是怎么数据恢复的，有成品的项目软件需求，我们需要先去了解这些已经成型的技术，才方便我们完成和实现这个项目\n\n\n核心技术\n了解我们这个项目的核心技术，核心难点在什么方面首先我们就得清楚操作系统是如何存储一个数据的\n做一个数据恢复软件，就需要去了解各个文件的存储方式是什么，文件系统是什么，操作系统是如何存储一个数据的，如果要恢复一个数据，就得去找这个数据对应的表啊等等一系列的东西\n\n\n风险点\n在完成以上工作后，我们应该就对这个项目有了比较清晰的了解了，我们这个时间就应该对这个项目需要多长时间完成，完成后我们实现的大概是一个什么样子这个过程有了很多的了解\n\n\n\n关于完成项目的过程中完成一个项目的过程就是不断的积累：\n\n日志：日志是每天的一个小总结，记录今天完成的结果，记录面对的难点，根据今天的工作做一个总结\n固定的例会：组内良好的沟通是非常的必要的，这个例会不限于组的形式，可以找指导老师啊，可以问技术大牛呀等等，例会的时间也没有什么要求，可能是三五分钟啊，也可能是半个小时，根据项目我们可以几天开一次会啊等等\n周报：日志是对每天的一个小总结，一天可能忙来忙去，最后也不知道自己到底完成了什么东西，可以每周做一个周报，来总结这一周做了什么东西，\n寻求指导：遇到困难是必不可免的，要及时的去找人帮忙给出一个方向\n\n关于结果完成一个项目，我们最后肯定是要得到一个结果的，不管这个结果怎么样，我们都要对这个结果进行一个分析与总结\n\n固化：项目的结果最后一定要固化下来，落到实地\n测试大纲：测试大纲测试项目，这要覆盖我们当初做项目的需求，一项项分析我们是不是严格的完成了项目\n测试报告：测试完成一定要求有测试报告来总结\n完成后的工作总结：项目完成了，这个时候一定要做工作总结，工作总计要包含，在这个项目中我做过什么，我完成过什么，我解决过什么问题，什么问题困扰很久还没有解决，查漏而补缺，温故而知新\n\n关于CS专业我们计算机学生\n源码：基本的编码能力是基础，是很重要的东西，这里面包括了很多很多东西，例如debug工具、数据结构、算法、操作系统，这是解决一个问题和找到项目的原因的基础\n二进制：不管我们使用什么语言，最后的结果都一定是转换为了机器语言，比如说Linux软件打包运行，包有两个大类，rpm包和deb包，解决一个问题，可能最后都要找到这个层次才能成功的解决\n质量：完成项目一定要有质量，做完与做好是两个层次。有以下四点\n功能是否完备呢？\n性能是否能再一次优化呢？\n算法优化：比如排序，有各种各样的的算法，我们是不是用另一个排序算法会更快更好\n程序优化：程序调优，改改源码，什么地方重构一下会更好呀，等等\n架构优化：使用不同的软件架构，最后得到的性能一定是不同的。(先了解，目前还是太菜了)\n\n\n稳定性：是否完备、健壮（这也是一个大的问题）\n兼容性\n\n\n文档：记录所学的东西，文档报告。我们经常会去百度呀，谷歌呀，我们查到CSDN的东西他们的文档，都是别人记录下来的文档，我们也要这么做，搞一个博客啊，进行记录\n有开源社区的经验，如果我们能力够了（当然远远不够），我们就可以去各样的开源社区，我们看他们的项目，发生了bug我们提交解决了这个bug，人家接收了我们的补丁，这就是一个很牛的事情了，至少可以表现出我们的能力是够的，面试也会+分的\n\n关于解决问题的办法中国航天是非常牛的，我们要解决一个问题，可以学习中国航天解决问题（人家叫问题归零）的办法，有五步：\n\n问题复现：重新构建出这个问题出现的环境，分析这个问题是从哪儿冒出来的\n定位准确：对于冒出的这个问题要定位到准确的位置\n基理清楚：这就需要用到我们的基础的知识了，找到这个问题我们需要知道这个问题是为什么出来的，要解决他我们就要了解这其中的知识\n措施有效：采取有效的、方便的方式\n举一反三：想想这个问题是不是还会在其他地方出现呢，之类的\n\n我的想法关于技术与业务很早之前有看过一个面试视频，其中讲到了技术与业务的关系，说实话，平常我也觉得技术是非常重要的东西，但是最近真的感觉到业务的重要性，完成一个业务，技术只是实现业务的一个方法，业务好的人会知道要做些什么，技术好的人可以更好的去做。这两个是不相同的，不冲突的\n关于团队与个人之前加入云顶被问到过一个问题，将忠诚、个人、团队进行一个排序。\n当时我思索了一番，给学长这么一个答案：忠诚 &gt; 个人 &gt; 团队\n学长问我为什么？ 我回答：忠诚肯定是第一位的，关于个人和团队，我把个人排到前面，是因为我觉得如果不提高个人技术的话，可能在团队中像是一个混子吧。\n现在呢，如果要让我重新排的话，我会把团队放到前面吧，因为越牛的团队，越强的企业，是不可能依赖于一个人的个人技术的，所以团队是更加重要的东西。\nem。。感觉自己理解的越来越深刻了，加油\n:wq\n","categories":["其他"],"tags":["其他"]},{"title":"服务架构演进","url":"/2023/03/07/%E5%85%B6%E4%BB%96/%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B%E5%8F%B2/","content":"\n了解服务架构的历史，并且总结几点规律\n\n\n\n\n服务架构演进原始分布式时代\n“使用多个独立的分布式服务共同构建一个更大型系统的设想与实际尝试，反而要比今天大家所了解的大型单体系统出现的时间更早”\n\n1970-1980，此时8086CPU刚诞生，算力严重不足，此时提出的分布式主要是为了解决算力不足的问题。\nOSF开放软件基金会（就是指定Unix系统技术标准的那个基金会）与很多主流的计算机厂商制定了DCE(Distribute Computing Environment)分布式运算环境\nDCE较为详细的回答了分布式可能会遇到的问题（服务在哪里？有多少个？出现分区、超时、服务出错怎么办等等）\n但是DCE计划破产，原因有两个：\n\n解决了分布式遇到的问题，但是远程的调用方法，更加耗时耗资源，与原本想利用分布式提高算力的初衷相违背\n开发要求Coder有极高的水平\n\n破产得到一个教训：\n\n某个功能能够进行分布式，并不意味着它就应该进行分布式，强行追求透明的分布式操作，只会自寻苦果\n\n单体系统时代\n（Monolithic Application 单体架构，也译作巨石系统）\n单体：指的是项目跑在一个进程内，连IPC（进程间调用）都不存在\n\n1980开始，摩尔定律的黄金时代，计算机算力日新月异，单体系统完全可以支撑当时业务的要求。\n单体系统可以纵向划分层次，比如最最传统的Controller层、业务层、持久层、数据库\n但是随着项目规模的主键庞大，单体系统暴露出一些弊端：\n\n不隔离：单体系统运行在同一进程内，优点是无需考虑网络问题、对象操作方便；但是如果代码存在缺陷，譬如内存泄漏、线程爆炸、阻塞、死循环等问题，那么就只能停止服务，重启整个项目。\n技术不异构：单体系统往往由同一种语言或技术开发，无法兼容多个语言的优势。\n不允许程序出错：从“追求尽量不出错”，到“出错是必然”的观念转变，要求系统可以自治，出现错误依然可以保持对外提供服务。\n为了性能与算力：单体对外可以接收的流量太小，分布式集群承载力会更大\n\nSOA时代\nSOA 架构（Service-Oriented Architecture） 面向服务的架构是一次具体地、系统性地成功解决分布式服务主要问题的架构模式。\n\n简单理解，SOA相比于单体时代，他将子系统进行了拆分，跑在了多个进程内；相比于之后的微服务时代，他的划分粒度并没有那么细致。\nSOA就是“不那么微的微服务”\nSOA时代也有很多种方案：\n\n烟囱式架构：也叫信息孤岛，子系统之间不允许任何往来\n微内核架构：也叫插件式架构，比如浏览器的插件与内核、操作系统与软件之间的关系都属于此类；子系统可以与内核交互，但是子系统之间不允许交流。\n事件驱动架构：维护一个事件队列的管道，子系统之间通过事件来进行交互\n\n最终SOA时代迎来了巅峰：SOAP协议：协议规定的十分详细，对开发中譬如服务之间的松散耦合、注册、发现、治理，隔离、编排都有规定\n但是SOAP夭折了，原因是SOAP协议规定的过于详细了：\n\n规定十分复杂繁琐，Coder需要了解完整的流程，懂得复杂的概念（脱离了群众）\n\n微服务时代微服务一开始是SOA的轻量化补救方案，在波兰克拉科夫举行的“33rd Degree Conference”大会后，微服务才真正脱离SOA（作者的观点）\n此时的微服务才是我们今天所熟知的微服务：\n\n微服务架构（Microservices）：微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。\n各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。\n服务之间采取轻量级的通信机制和自动化的部署机制实现通信与运维。\n\n微服务追求的是更加自由的架构风格，摒弃了几乎所有 SOA 里可以抛弃的约束和规定。\n因此对于服务的注册发现、跟踪治理、负载均衡、故障 隔离、认证授权、伸缩扩展、传输通信、事务处理每一个过程都由很多个框架可以选择。\n\n仅一个服务间远程调用问题，可以列入解决方案的候选清单的就有：RMI（Sun/Oracle）、Thrift（Facebook）、Dubbo（阿里巴巴）、gRPC（Google）、Motan2（新浪）、Finagle（Twitter）、brpc（百 度）、Arvo（Hadoop）、JSON-RPC、REST，等等；\n仅一个服务发现问题，可以选择的就 有：Eureka（Netflix）、Consul（HashiCorp）、Nacos（阿里巴巴）、ZooKeeper（Apac he）、Etcd（CoreOS）、CoreDNS（CNCF），等等。\n\n对于“拧螺丝”的程序员来说，微服务无疑是友善的，有多种选择。\n但是对于架构师来说，需要承担选择对应技术的风险（一般都会选择团队熟悉的技术）\n后微服务时代\n后微服务时代（Cloud Native 云原生）：\n从软件层面独立应对微服务架构问题，发展到软、硬合力应对架构问题的时代。\n\n虚拟化技术与容器化技术：Docker与K8s\n与Spring Cloud从应用层面相比，k8s在基础设施层面也解决了一些类似的问题：\n\n\n\n\nKubernetes\nSpring Cloud\n\n\n\n弹性伸缩\nAutoscaling\nN/A\n\n\n服务发现\nKubeDNS / CoreDNS\nSpring Cloud Eureka\n\n\n配置中心\nConfigMap / Secret\nSpring Cloud Config\n\n\n服务网关\nIngress Controller\nSpring Cloud Zuul\n\n\n负载均衡\nLoad Balancer\nSpring Cloud Ribbon\n\n\n服务安全\nRBAC API\nSpring Cloud Security\n\n\n跟踪监控\nMetrics API / Dashboard\nSpring Cloud Turbine\n\n\n降级熔断\nN/A\nSpring Cloud Hystrix\n\n\n但是k8s解决问题的粒度比较粗，对于应用层与基础设施边缘的问题难以精细化处理。\n为了解决这一问题，引入了服务网格（service mesh）的边车代理模式（Sidecar Proxy）\n无服务时代无服务的愿景是让开发者只需要纯粹地关注业务，不需要考虑技术组件，后端的技术组件是现成的，可以直接取用，没有采购、版权和选型的烦恼；不需要考虑如何部署，部署过 程完全是托管到云端的，工作由云端自动完成；\n无服务以简单为卖点：只设计两块内容：后端设施与函数\n\n后端设施：一类用于支撑业务逻辑运行，但本身无业务含义的技术组件（比如数据库、消息队列、日志、存储，等等），这些后端设施都运行在云中，无服务中称其为“后端即服务”（Backend as a Service，BaaS 后端即服务）\n函数：非常接近于编码角度的函数，但区别在于其运行在云端，不必考虑算力问题（需要考虑费用问题），被称为“函数即服务”（Function as a Service，FaaS）。\n\n比如腾讯微信小程序的云开发，就属于是函数即服务的典型。\n总结服务器架构这么多年的迭代，我们会发现一些规律规律：\n\n简单替代复杂：比如原始分布时代的DCE与SOA时代的SOAP协议，都是典型的复杂设计，都被淘汰，人们都喜欢使用封装好复杂细节的轮子，而不是使用八股文去写APP。\n为了分布式而追求分布式，结果只会灭亡：对于比较小的项目，我们完全没必要上分布式、或者上微服务，只是增加麻烦\n“尽量避免错误”到“出错是必然”的观念转变：我们的目标不应该是不犯错，而是犯错后依然能提供服务\n面对发展遇到的问题，总是软件到硬件的去解决问题：总是先用软件去解决，在硬件性能提高后，再使用硬件补充软件的不足，然后遇到问题再先用软件解决，依次反复。\n服务架构发展的目标：上帝的归上帝，凯撒的归凯撒，业务与技术完全分离，远程与本地完全透明\n\n","categories":["其他"],"tags":["其他"]},{"title":"Redis分布式锁","url":"/2022/02/14/Redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","content":"\n    引言：前天写了第一个分布式锁，记录一下。\n\n\n\n\nRedis分布式锁redis实现分布式锁主要实现有以下方式：\n\n法一：setnx+expire\n（value使用时间戳）\n法三：lua脚本+法一\n法四：set\n法五：Redssion框架\n法六：Redlock+Redission\n\n法一：setnx+expire\nsetnx key value：  Set if not exists 如果不存在就设置\n两个参数：\n\n key 表示锁 id：锁ID\n value通常设置为：UUID\n\n返回值：\n\n为0：表示已经存在锁（可以不断尝试获取）\n为1：表示设置成功（即获得该锁）\n\n\n原理：setnx，如果key不存在则设置，设置成功返回1，否则返回0，因此可以使用setnx抢占key，然后使用expire给该key设置过期时间\n缺点：加锁与设置过期时间并不是原子操作，如果在加锁后系统错误，没设置过期时间，那么其他线程再也无法获取到锁\n法二：setnx+value原理：为了解决不是setnx与expire不是原子操作的问题，可以将value设计为系统时间+过期时间的方式，这样就无需多一次expire操作，在每次请求时，判断时间是否到期\n伪代码：\nif(setnx == 1)&#123;    // 拿到锁，设置了value&#125;else&#123;    // 没拿到锁    get//锁时间    if(时间已过期)&#123;    \t//重新设置过期时间    &#125;&#125;\n\n缺点：\n\n过期时间是本地客户端产生，分布式环境下的不同系统的时间可能存在误差\n如果在锁过期的一瞬间，有多个请求同时获取锁，可能会出现锁的过期时间被其他锁覆盖的情况（锁只有一个请求拿到，但是校验锁过期的逻辑由其他线程来完成）。\n锁的value设置为时间，可能会存在被其他线程误释放的问题\n\n法三：lua脚本+法一redis可以保证lua脚本的原子性，因此可以使用lua+setnx+expire\n法四：set在Redis2.6.12 起，set命令完全覆盖了setnx，而且还可以设置过期时间\n\nset key value [EX seconds] [PX milliseconds] [NX|XX]\n\nEX seconds：设置失效时长，单位秒\nPX milliseconds：设置失效时长，单位毫秒\nNX：key不存在时设置value，成功返回OK，失败返回(nil)\nXX：key存在时设置value，成功返回OK，失败返回(nil)\n\n\n存在的问题：\n\n可能锁时间过期了，但是业务逻辑还没有执行完成：此时锁就会被错误释放\n锁可能会被别的线程错误删除（这种错误可以给value设置一个唯一值解决）\n\n法五：Redssion框架为了解决锁过期，但是业务还没执行完成的问题，Redssion给出了一种解决方案：\n在某一个线程拿到锁后，额外启动一个线程watchdog看门狗，每隔10s，检测对应线程是否还持有锁，如果还持有，那么就延长锁时间。\n法六：Redlock法一到法六均是单击情况下的redis，对于分布式方案使用Redlock\n\nRedlock：是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布 式锁了，否则加锁失败。 \n\n加锁步骤：\n\n客户端获取当前时间\n客户端按顺序依次向N个Redis实例执行加锁操作\n客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时\n\n只有满足两个条件，才算真正的加锁成功：\n\n有半数以上的Redis节点加锁成功\n总耗时没有超过锁的有效时间\n\n","categories":["Redis"],"tags":["Redis"]},{"title":"Redis容量估计","url":"/2024/02/24/Redis/Redis%E5%AE%B9%E9%87%8F%E4%BC%B0%E8%AE%A1/","content":"\n引言：\n我们经常会使用到Redis，但是如何估计我们的数据量可能会占用多大的Redis内存呢？\n\n\n\n\nRedis容量估计\n错误的理解：误以为序列化后的Size与存到redis后的Size差不多，但实际上，差距还是蛮大的。\n\n实际工程中，可以直接使用这个工具快速判断可能的占用大小：Redis容量估计工具\n错误的估计现有任务1与任务2需要向redis写入数据：任务1：\n\n其一天的的数据个数有：293, 659, 385个（约3亿数据）\n其序列化后的value的大小共有：50.14 GB\n均到3亿数据上，大约每一个value大小为：180 字节\n\n任务2：\n\n其一天的数据个数有：231419688个（约2.3亿数据）\n其序列化后的value的大小有：23.55GB\n均到2.3亿数据上，平均每一个value大小为：107 字节\n\n就认为总共的数据也就：23 + 50 GB，但是实际占用Redis集群空间：303 GB（2倍副本，实际存储150GB数据）这和预估数据远远不符，因此使用Redis容量预估工具 http://www.redis.cn/redis_memory/ 重新进行估算：\n预估的容量为89GB与49GB，和为138GB（与实际占用150GB差距不大)\n原理探究为什么我们23 + 50 GB的数据存入Redis变为了150GB？Redis都维护了怎样的结构？\nRedis String的编码方式由于我们只使用了redis的String存储结构（本质是byte[]），因此这里只分析String。String在redis内有三种编码方式（如下图所示）\n\nint 编码：在保存 64 位有符号整数时\nembstr编码：在保存的字符串小于 44 字节时\nraw 编码：大于 44 字节时（embstr与raw的区别仅在于SDS是否与元数据的指针紧挨）\n\n\nRedis存储数据需要维护的结构Redis存储数据，需要维护的数据有：（如下图所示）\n\ndictEntry结构：24字节，向上取整为32字节\nkey：存储键key，自己维护9字节的信息，因此大小为key+9，且大小向上取整 16/32/64/128/256/…字节\nredisObjet：16字节\n元数据：存放LRU、LFU的关键信息：时间戳、频次\n指针：指向具体结构，对于String就是一个SDS（简单动态字符串）\n\n\nvalue：存储对应value，由于存储String，也需要维护9字节信息，也是向上取整16/32/64/128/256/…字节\nbucket个数信息：key的个数增多，redis需要rehash扩展Dict数组，每一个数组的元素是一个8字节指针，因此需要存储key的个数的幂次向上取整。（比如有2000个key，需要有2048个bucket，每个bucket需要8字节）\n\n\nRedis容量预估计算公式因此，可以得出Redis容量计算的推理公式：\n-- 此处 Pow(x) 表示对x求 最近的2的幂次且向上取整RedisSize = (32 + Pow(Size(key) + 9) + 16 + Pow(Size(value) + 9)) * Num + Pow(Num)*8\n我们可以自己估算一下，上一节提到的两个任务的大小：\n对于任务1：\nValue = (32 + Pow(22 + 9) + Pow(180 + 9) + 16) * 300_000_000 + Pow(300_000_000) * 8= (32 + 32 + 256 + 16) * 300_000_000 + 2^29 * 8= 100800000000 + 4294967296= 105094967296 Byte\n105094967296换算为97GB，这与Redis容量工具计算基本一致 \n对于任务2：\nValue = (32 + 32 + 128 + 16) * 230_000_000 + 2^28 * 8= 47840000000 + 268_435_456 * 8= 49987483648\n49987483648字节换算为46GB，这也与Redis容量工具计算基本一致\n","categories":["Redis"],"tags":["Redis"]},{"title":"区块链技术","url":"/2022/11/04/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF/","content":"\n引言：区块链技术——内容繁杂，拆成多个文章\n\n\n\n\n\n\n《区块链技术》\n\n区块链技术区块链技术的内容包罗万象：分布式技术、密码学、金融等等内容\n什么是区块链？关于区块链的理解有很多：一种数据结构、一种交易数据库、一种分布式数据库技术\n\n狭义上，区块链是一种以区块为基本单位的链式数据结构，区块中利用数字摘要对之前的交易历史进行校验，适合分布式记账场景下防篡改和可扩展性的需求。\n\n\n广义上，区块链还指代基于区块链结构实现的分布式记账技术，包括分布式共识、隐私与安全保护、点对点通信技术、网络协议、智能合约等\n\n基本原理可以看看这个视频：Anders\n\n交易（Transaction）：一次对账本的操作，导致账本状态的一次改变，如添加一条转账记录；\n区块（Block）：记录一段时间内所有交易和状态结果等，是对当前账本状态的一次共识；\n链（Chain）：由区块按照发生顺序串联而成，是整个账本状态变化的日志记录。\n\n特点：\n1、 Chain类似于一个链表，每一个节点都是一个Block，每个Block上打包了多笔Transaction\n2、 每个Block存放上一个Block的哈希值（数字摘要），如何查看交易是否合法，就是查看这个hash值是否变化\n3、 每一笔Transaction都会改变一次账本的状态；每一个Block都是共识的结果\n比特币的区块链构建流程首先比特币网络的结构：用户及其客户端、网络中的多个节点（矿工）\n\n客户使用client向网络中发布一笔Transaction\nClient向整个net中广播\n每个Node接收到后，将该时间段所有的待确认的Transaction打包在一起，加上前一个Block的hash值，并试图寻找一个Nonce值（比如在Sha256算法中，规定前导零，运算次数越多的节点，算到Nonce的概率越大）\n当有一个Node计算出Nonce值后，向Net内广播\n其他Node值接收到消息后，验证是否合法，合法就将这个新的Block保存在自己本地的Chain上\n继续下一笔交易\n\n区块链的分类按照参与者的范围来划分：\n\n私有链：内部少数人使用（与传统的中心化记账方式区别不大）\n联盟链：介于两者之间，由若干组织一起合作（如供应链机构或银行联盟等）维护一条区块链，使用该链必须有权限（超级账本）\n公有链：任何人都可以参与和维护的（比特币、以太坊）\n\n三者的可信任程度依次上升：因为节点数越多，作恶的难度会成倍上升\n按照使用场景来划分：\n\n货币链：以太币、比特币、狗狗币\n产权链：各种产权证明等等\n众筹链：众筹相关\n通用链：没有具体的场景的区块链\n\n区块链关键问题与挑战\n隐私保护：平衡共享协同信息和隐私保护\n分布式共识：共识机制——Paxos、拜占庭算法、PoW、PoS\n交易性能：比特币大约每秒7笔、以太坊每秒几十笔，之前基于区块链的游戏CryptoKitties造成网络拥堵\n提升单个节点性能\n将交易处理放在链下，只用区块链存储最后结果\n\n\n扩展性：与传统分布式系统只需增加节点不同，区块链对单个节点的性能具有一定的要求\n网络中每个参与维护的核心节点都要保持一份完整的存储，并且进行智能合约的处理\n\n\n安全防护：区块链首先要考虑传统的网络安全（认证、过滤、攻防）、信息安全（密码配置、密钥管理）、管理安全（审计、风险分析控制）、新场景下的安全挑战\n数据库和存储系统：区块链有大量的读写操作、Hash 计算和验证操作，甲骨文、AWS已经开始做针对于区块链特性的“账本数据库”\n互操作与运营治理：\n互操作：指现有的商业流程和信息系统集成时的平滑度\n运营治理：如何维护好区块链的运行\n\n\n\n核心内容\n分布式技术\n密码学\n比特币\n以太坊\n超级账本\n\n","categories":["区块链"],"tags":["区块链","分布式"]},{"title":"比特币&以太坊","url":"/2022/11/11/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81%E4%B8%8E%E4%BB%A5%E5%A4%AA%E5%9D%8A/","content":"\n引言：比特币 and 以太坊\n\n\n\n\n比特币交易规则交易\n账户地址：160位的字符串，是公钥经过一些列Hash及Base58Check 编码运算生成的，一般还会加前导字节和4字节的校验字节\n\n付款方和收款方均有一个账户地址\n比特币中的奖励来源：\n\n挖矿奖励，每四年减半\n交易费用 Transaction Fee：输入与输出的差值\n\n交易的金额有一定限制：\n\n交易中金额的最小单位是“聪”，即一亿分之一（10^-8）比特币\n目前规定每笔交易的交易费用不能小于 0.0001BTC\n\n\n比特币的交易输入和输出：\n\n\nUTXO（Unspent Transaction Outputs）：未经使用的交易的输出\nSTXO（Spent Transaction Outputs）：已经使用的交易的输出\n\n在比特币中，一笔合法的交易输入必须是UTXO，并生成新的UTXO\n一笔交易一般包括几个内容：\n\n付款人：账户地址、数字签名、UTXO的交易ID\n收款人：账户地址\n交易的金额、时间戳\n\n比如：\n\n\n\n交易号\n交易\n输入\n输出\n签名\n奖励\n\n\n\nT0\nA转给B\n他人转给A的输出\nB可以使用这笔交易\nA签名确认\n输入与输出的差额\n\n\nT1\nB转给C\nT0的输出\nC可以使用这笔交易\nB签名确认\n输入与输出的差额\n\n\n注意：刚完成的交易并不能得到确认，需要等再生成几个区块才可以（防止该区块被推翻，一般是等待 6 个块，这需要大概一小时的时间（10min一个块））\n网络中将会检查几个项目：\n\n交易是否已经处理过\n交易是否合法：地址是否合法、付款人是否拥有账户地址、是否是UTXO\n交易输入之和是否大于输出之和\n\n检查通过后，将交易标记为合法的未确认消息，进行广播\n如图所示：图来源，下文中若无标识，图片均来自此处\n\n交易脚本上一节的最后一个图，可以看到有InputScripts和OutputScript，这是交易脚本。\n\n交易脚本：用于检验交易是否合法，当所依附的交易发生时被触发\n一般交易包括两个脚本：\n\n负责输入的解锁脚本 scriptSig：证明自己对某个交易的拥有权\n负责输出的锁定脚本 scriptPubKey：由付款方设置，比如设置为只有拥有此公钥才可以花费这比交易\n\n\n输出脚本格式支持两种类型：P2PKH、P2SH，此处以前者为例\n# 输出脚本scriptPubKey: OP_DUP OP_HASH160 &lt;pubKeyHash&gt; OP_EQUALVERIFY OP_CHECKSIG\n\n输出脚本中：OP_DUP代表复制栈顶元素；OP_HASH160表示计算hash值；OP_EQUALVERIFY表示判断两者是否相等；OP_CHECKSIG表示判断签名是否合法；\n组合起来的意思就是，复制栈顶元素并计算其hash后，与自己的公钥hash比较，判断是否相等，检查签名是否合法，如果合法代表此人可以花费这笔交易\n# 输入脚本scriptSig: &lt;sig&gt; &lt;pubKey&gt;\n\n输入脚本中：用公钥对应的私钥对交易的Hash值进行签名\n交易验证的完整指令如下，就是输入脚本+输出脚本：\n&lt;sig&gt; &lt;pubKey&gt; OP_DUP OP_HASH160 &lt;pubKeyHash&gt; OP_EQUALVERIFY OP_CHECKSIG\n\n将scriptSig、scriptPubKey依次放入栈中处理，此时栈顶就是pubkey，输出脚本将栈顶复制并求hash后于pubKeyHash比较是否相同，如果相同再比较签名（类似于Bob给Alice传递消息，需要传递消息本身+签名（hash后再加密））\n挖矿比特币中的奖励来源：\n\n挖矿奖励，每四年减半\n交易费用 Transaction Fee：输入与输出的差值\n\n每个区块的奖励最初是 50 个比特币，每4年时间（每隔 21 万个区块），最终比特币总量稳定在 2100 万个，因此比特币不会通货膨胀\n区块一个Block包含多笔交易，不能超过1MB，主要包含：\n\nBlock大小：4Byte\nBlock head：80Byte\n版本号：4Byte\n上一个block的head的hash值：（对上一个头进行两次SHA256操作）32Byte\n时间戳：4Byte\n难度指标：4Byte\nNonce：4字节（PoW的答案）\n\n\n交易个数的计数：1-9Byte\n交易的具体内容（Merkle树存储）\n\n\n挖矿过程（PoW机制）比特币通过PoW机制来解决拜占庭问题\n\n具体过程：参与者（矿工）去做系统给出的“题”，谁做出来，谁就有将所有新交易打包成新区块的权利。\n\n题目是：矿工新打包的Block的hash值需要小于网络给定的一个值\n（矿工根据上一个区块的hash值、新的验证过的交易内容、自己猜测的Nonce值生成一个新的区块，需要让新Block的hash值小于网络给定的一个值）\n\n如何控制题目的难度？\n\n系统每两周（2016个区块）根据上一周的挖矿时间来调整挖矿难度（据此估算出目前系统中拥有的算力大小）然后根据算力大小，设定SHA256的前缀0的个数（个数越多，难度呈指数型上升）将新Block的出现控制在10min左右\n因为Hash几乎不可逆，所以矿工们只能一个一个尝试\n细节部分查看Paper\n\n缺陷：浪费了大量的算力、电力，而且系统的吞吐量很低，每秒只能处理7笔交易，实在是划不来\n\n闪电网络由于比特币的交易性能太差：每秒7笔交易，而且每笔交易的确认需要1h的等待\n因此为了提高交易性能提出了新的设计\n\n闪电网络：将大量的交易放到比特币区块链之外进行，只把关键环节放到链上进行确认\n\n闪电网络引入了两个核心概念：（借鉴了智能合约的思想）\n\nRSMC（Recoverable Sequence Maturity Contract 可撤销的顺序成熟度合约）：解决链下交易的确认问题\nHTLC（Hashed Timelock Contract 哈希的带时钟合约）：解决支付通道问题\n\nRSMC\nR 可撤销 S顺序 M成熟度 C合约 ：可撤销的顺序成熟度合约\n解决链下交易的确认问题\n原理：资金池机制\n\n\n初始：双方预存资金到资金池（微支付通道）中，假设甲乙初始投入资金比2:1\n发生交易A：\n双方对交易A之后的分配结果进行确认，假如甲乙新的交易发生后变为7:2\n签字作废旧的交易2:1\n可能会重复1-2的过程\n\n\n提现时：将双方签署过的交易7:2写入区块链中（只有提现才需要区块链）\n\nRSMC还有一些其他措施防止出错：\n双方签名：这个过程可能会产生多笔合约，比如2:1 -&gt; 7:2 -&gt; 5:4，每一笔合约都需要双方签名。\n罚没机制：如果甲方想要提现，但甲为了多拿点，就使用了7:2的合约，乙发现后，提供了最新的合约5:4，证明之前的合约已经作废，那么资金罚没给乙方（罚没机制确保了没人会故意拿一个旧的交易结果来提现）\n先提后到：双方都确认了某次提现，首先提出提现一方的资金到账时间要晚于对方\n通过这样的机制就可以保证交易在链外完成，只把提现放在链上\nHTLC\nH 哈希 TL时钟 C合约：哈希的带时钟合约\n解决支付通道问题\n\nRSMC中的资金池（微支付通道）就是使用HTLC实现的，即限时转账\n转账放冻结一笔钱并提供一个哈希值A，如果在一定时间内有人可以提出一个字符串，使得它的hash值B能与A匹配，则将钱转给对方\n（如果陌生人猜到了这个哈希值也是可以拿这笔钱！）\n侧链侧链机制\n侧链 Sidechain：允许资产在比特币区块链和其他区块链之间互转\n\n出现的原因：以太坊等项目的竞争+山寨币的横行，比特币开发者希望拓展比特币的底层协议\n\n侧链机制：以比特币区块链作为主链（Parent chain），其他区块链作为侧链，二者通过双向挂钩（Two-way peg），可实现比特币从主链转移到侧链进行流通\n\n\n侧链的特点：\n\n可以是一个独立的区块链，可以有自己按需定制的账本、共识机制、交易类型、脚本和合约的支持等\n不能发行比特币，但可以通过支持与比特币区块链挂钩来引入和流通一定数量的比特币\n当比特币在侧链流通时，主链上对应的比特币会被锁定，直到比特币从侧链回到主链（如何实现？有多种方式，下面介绍SPV+双向挂钩 ）\n\nSPV证明有时候用户只想知道交易是否合法（在区块链中且已被网络承认）\n\nSPV （Simplified Payment Verification）简单支付证明\n能以较小的代价判断某个交易是否已经被验证过（存在于区块链中），以及得到了多少算力保护（定位包含该交易的区块在区块链中的位置）\n\nSPV 客户端只需要下载所有区块的区块头（Block Header），并进行简单的定位和计算工作就可以给出验证结论\n一个 SPV 证明包括两部分内容：\n\n一组区块头的列表，表示工作量证明\n一个特定输出确实存在于某个区块中的密码学证明\n\n双向挂钩\n如何确保发送资产的链上的币被可靠锁定？\nSPV+双向挂钩\n\n如图所示：\n\n整个过程类似于加锁、释放锁的过程：假设用户想要将一些比特币转移到侧链\n\n在主链创建交易，等待网络确认\n在侧链创建交易，获取比特币（指明是那一笔交易，且需要SPV证明）\n等待一段竞争期，防止双花\n比特币在侧链自由流通\n\n流回主链的过程与上述过程相反\n以太坊【未完成】以太坊将比特币针对数字货币交易的功能拓展到复杂和灵活的应用场景\n用户不再受限于仅能使用比特币脚本所支持的简单逻辑，而是可以自行设计任意复杂的合约逻辑（智能合约）\n\n参考以太坊官网\n\n重要概念智能合约\n智能合约 Smart Contract：其本质是一个运行在以太坊虚拟机 EVM（Ethereum Virual Machine）中的应用\n\n智能合约是对比特币上交易脚本的扩展，从一个简单交易的脚本拓展到了更加复杂的合约逻辑\n\nEVM 以太坊虚拟机：是一个隔离的轻量级的虚拟机环境（无法访问本地网络、文件或是其他进程）一个智能合约往往在多个EVM中备份，其数据层是区块链\n\n智能合约编写完毕后，用编译器编译为EVM专用的二进制格式，客户端上传该二进制到区块链中，运行在矿工的EVM上\n简单理解：可以将只能合约理解为一个自动售卖机，需要支付以太币，然后换取想要的服务，比如金融、游戏等（用户输入参数，参数代入到智能合约，运行在矿工的EVM上，最后的结果存储在区块链中）\n账户\n比特币中不存在账户的概念，而是通过UXTO与账户地址（一个160bit的串）进行交易记录，而以太坊有账户的概念\n\n账户分为两种类型：\n\n合约账户（Contracts Accounts）：存储智能合约的代码（代码控制的账户），只能被外部账户调用\n外部账户 EOA（Externally Owned Accounts）：以太币拥有者账户，对应到某公钥\n\n当合约账户被调用时，存储其中的智能合约会在矿工处的虚拟机中自动执行，并消耗一定的燃料（燃料通过外部账户中的以太币进行购买）\n账户有四个字段：\n\nnonce：\n对于EOA：发送交易数量的计数器\n对于合约账户：合约数量\n\n\nbalance：ETH的账户余额\ncodeHash：无法更改\n对于EOA：空字符串的hash值\n对于合约账户：EVM上的账户代码\n\n\nstorageRoot：trie的根节点\n\n以太币\n以太币ETH 类似于比特币，是以太坊中的money\n\n\n\n\n面额\nETH 值\n常见用法\n\n\n\nWei\n10^-18\n技术实施\n\n\nGwei\n10^-9\n描述gas费用\n\n\n1、以太币的总发行量：取决于验证者的数量和它们质押的以太币数量（区别与比特币的固定数量）\n2、以太币可以铸造也可以销毁：铸造指产生新的ETH，奖励区块的提议者和验证者；每一笔交易都会发生以太币销毁（燃料）\n","categories":["区块链"],"tags":["区块链","以太坊","比特币"]},{"title":"比特币白皮书","url":"/2022/11/01/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81%E7%99%BD%E7%9A%AE%E4%B9%A6/","content":"\n引言：中本聪——比特币白皮书\n\n\n\n比特币：一种点对点的电子现金系统内容参考：\n\n中本聪比特币paper\n\n区块链技术指南\n\n\nAbstract\n比特币：一种纯粹的点对点peer2peer的无需金融机构介入的电子现金系统 electronic payments\n\n本文提出一种使用p2p网络解决双重支出问题的解决方案，从而避免第三方机构的介入。\n\n双重支付double spending：即一份钱花了两次甚至多次（这是数字货币存在的问题，因为数字货币就是一串数字，通常的避免方式是用第三方金融机构，比如银行来鉴定这个数字货币的真伪）\n\n手段：使用p2p网络将事务hash散列在一个不断增长的以工作量证明proof-of-work的链上，工作量证明的最长的链一定在CPU算力高的区域，如果攻击者不能完全控制这片高算力池，那么原本的最长链会不断发展，超过攻击者。\nIntroduction传统的解决双重支付的手段是让第三方机构进行校验，这样存在几个问题：\n\n限制了小型的交易\n无法对不可逆的服务提供完全不可逆的交易 Completely non-reversible transactions\n\n（理解：仲裁机构有着绝对的话语权，如果买卖双方发生纠纷，一定会去寻找仲裁。仲裁调解本身也需要成本，也就导致小型的交易骗局只能让买卖有一方吃亏（限制了小型交易）；对于较为大型的交易，也必须有一个双方都信任的机构，比如碰到老赖，我们只能去法院打官司，如果法官被收买，我们也只能吃亏）\n\n即：原本的交易系统是依赖于信任的，现有的交易需要政府提供的公信力\n\n比特币的解决措施：解决信任问题，即提供一种基于密码证明cryptographic proof而不是信任的电子支付系统（使用密码学替代信任）\nTransactions\n定义：将一枚电子硬币electronic coin定义为一个数字签名链 digital signatures\n\n（图片来自）\n\n当所有者1想把一枚货币转给所有者2时（交易），需要在数字签名链的末尾附加上数字签名（如图所示）\n数字签名的构成：\n\n上一笔交易的hash值 \n新的所有者的公钥\n\n收款人可以验证签名去验证数字签名链的所有权\n\n这种方式依然有double spending的问题，解决方式两种：\n\n中心化：比如银行、铸币厂，拥有所有交易的记录，可以验证此交易是否存在过\n去中心化：将所有的交易记录公开，维护一个可以让参与者认同唯一的一个交易历史的系统；若大多数节点可以认同这比交易，那么交易就是正常的\n\nTimestamp server这种解决方案起步于一种时间戳服务器\n\n时间戳服务器的工作方式：为一组记录（一个block）的hash打上时间戳，然后将hash广播出去。每个hash包含着之前的时间戳，形成一个链，如图所示：\n\n\nProof of Work\n区块如何避免双重支付？PoW\n\n先了解一下散列函数：\n\n散列函数y=hash(x)：对于相同的x返回相同的y，但是几乎无法从y反推x\n如果x1与x2差距很小，其y1与y2值差距会相当大（雪崩效应）\n比如sha256：他可以指定前导0，前导0越多，计算量将指数级增加\n\n工作量证明：不断的在区块增加随机数Nonce，直到一个满足条件的数值被找到（什么条件？我们指定前缀0的个数）CPU耗费算力得到的结果就是工作量证明，一旦得到工作量证明，这个区块将不能再被更改\n\n（从图中我们可以看到，一个区块包含多个交易）\n以CPU算力为基础的工作量证明解决了“谁能代表大多数”的问题：如果是基于IP的话，很容易被拥有IP多的人操纵\n如果大多数的CPU算力是诚实honest的，那么这个诚实链就会发展的很快，如果想要篡改一个已经证明的区块：\n\n重新完成那一个区块的证明\n完成那个区块之后的所有区块链的证明、\n追上并超过其他的诚实节点\n\n这些条件是极其苛刻的，并且链越长越难以篡改\nNetwork网络中的工作步骤：\n\n新的交易向所有node广播\n每个node将新交易打包到一个区块block\n每个node计算工作量证明PoW\n当有一个node找到了PoW，它广播给其他nodes\nnodes接受这个block当且仅当：其中所有交易有效&amp;&amp;没有double spend\nnodes向网络中表达接受，在创建下一个block时，将把被接受区块的hash作为新区块的hash\n\n\n当两个node同时完成了PoW时：\n每一个node都始终认为最长的链是正确的\n一部分node会接受A，一部分node会接受B（但他们同时会保存另外一个链，产生一个branch）\n当下一个block加入后，更长的链会被认为是正确的，将分支取消掉\n\n\n新的交易不一定要广播到所有node，只要广播到足够多的node，就可以打包一个block\n\n\n如果广播的消息没有发送到某个node，这个node可能会少一个block，不过下一个区块他就会意识到缺失了，并且发出请求去补充区块\n\nIncentive奖励机制：为了保证我们有足够多的node的算力的支持，系统内需要提供一定的奖励机制\n\n每个block的第一笔交易：每个block包含很多个交易，但第一个交易比较特殊，它会生成一个新币，被生成者所有。\n交易费用的差值：如果一笔交易的输入小于它的输出，那么产生的差值奖励给将此交易打包到block的node\n\n奖励机制也保证，有足够能力的攻击者（即拥有比honest node更多算力的用户）顺从规则比改变规则带来的收益要更多。\nReclaiming Disk Space\nMerkle树（也称为哈希树）：链接\n\n树的特点：\n\n叶子结点存储数据或hash值\n非叶子节点是其两个子节点内容的hash值\n\nMerkle树的性质：\n\n底层数据的任何变动都会逐渐影响到根节点\n\nMerkle树的主要使用场景：（详细内容check链接）\n\n证明集合是否存在某个元素\n快速比较大量数据\n快速定位修改\n零知识证明\n\n\n区块链的存储如图所示：某笔交易之前的交易记录可以丢弃以节省空间，如图删除了Tx2节点（注意到hash2并没有删除！），之前的Tx0，Tx1都被删除\n\nSimplified Payment Verification上面介绍到了Merkle树的结构，就能知道快速的验证交易是否存在很简单。\nCombining and Splitting Value价值的组合与分割：意思是一个交易可能包含一个或多个输入和最多两个输出\n输入：\n\n情况1：单笔相对较大的输入\n情况2：多个小金额的输入\n\n输出：\n\n输出到收款方\n输出到找零方（可能没有这一个输出）\n\nPrivacy交易使用公钥匿名。公众可以看到某某向某某转账，但是没有却不能知道交易双方是谁（像是股票，可以看到时间和交易的金额）\n交易者每一笔交易都使用一对新的公司要，以便于他人无法追溯（如果公钥所有者被曝光，那么他的相关交易都会被曝光）\n","categories":["区块链"],"tags":["区块链","比特币"]},{"title":"抽奖系统","url":"/2024/02/24/%E5%B7%A5%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%8A%BD%E5%A5%96%E7%B3%BB%E7%BB%9F/","content":" \n引言：如何设计一个高并发系统？以抽奖系统为例\n\n\n\n\n抽奖系统高QPS系统需要有什么总结一个高QPS的业务，要做好：\n\n高qps服务承载：redis\n防止打爆下游服务可以使用削峰填谷的消息队列：kafka\n流量打入后要漏斗化：越接近底层的服务流量需要越少\n要有熔断机制：直接返回未中奖\n要有灾备机制：DB+log\n\n抽奖业务\n中奖逻辑：\n获得抽奖机会&gt;&gt;扣减抽奖机会&gt;&gt;概率计算是否可以中奖&gt;&gt;是否已经中过奖&gt;&gt;中奖&gt;&gt;结束\n\n抽奖系统：\n\n抽奖次数：有优先级，优先扣除顺序a-b-c\n\n每日有一次机会，不叠加\n\n奖品有再抽一次\n\n商品交易会增加抽奖次数\n\n\n\n奖品:\n\n大量的虚拟奖品（价值低）\n\n少量的实体奖品（价值高）：只有消费满一定资格，才有机会抽到\n\n\n\n\n业务特点：\n\nQPS很高，流量漏斗化越靠近底层，流量越少\n不能超发，会直接带来经济损失\n防刷，防止机器人或专业团队薅羊毛\n灾备\n\n系统设计\n与现有业务分离，防止抽奖影响到既有业务\n逐层淘汰不合规请求\n是否有中此奖品的权限：\n奖品是本交易免单，那么前提就是进行过交易\n奖品是实体，要求消费金额&gt;300元\n\n\n奖品数量：防止超发\n\n\nredis：保证提供高qps服务\n存储结构为Hash：Map&lt;String, Map&lt;String, Object&gt;&gt;\n分布式锁：setnx，防止刷奖\n存储抽奖次数信息: Key : Value\n每日一次抽奖：last_timestamp:timestamp\n再来一次奖励：one_more_time : cnt\n交易抽奖次数：transaction_time : cnt\n\n\nkafka：发奖，削峰填谷\n\n\n\n抽奖概率模型有几种概率模型：\n\n概率实现确定：画一个数轴，随机数落入哪里，就中什么奖品\n\n实现简单方便，但是大奖可能会早早被抽走\n\n\n不要求奖品一定要送完：\n\n抽奖概率可以随时间升高\n\n可以设置在某个时间后一定中奖\n\n\n\n\n发奖和中奖记录抽奖的奖品可能依赖的下游服务：\n\n优惠券服务\n邮寄服务\nvip服务\n\n抽奖的qps很高，为了不打垮下游服务，因此需要kafka做一个缓存，在中奖之后，写入kafka，再由下游慢慢消费。\n中奖记录：kafka+DB+log来存储中奖记录信息。\n兜底策略\n如果redis被打爆，那么直接返回未中奖\n中奖结果除了写入kafka、DB，还写入log，做最后兜底\n在关键点加报警\n做好补发奖品的脚本：查log日志，给中奖用户补发奖品\n\n","categories":["系统设计"],"tags":["系统设计"]},{"title":"定时任务的实现方式总结","url":"/2022/02/14/%E5%AE%9E%E6%88%98/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/","content":"\n引言：定时任务的实现方式总结\n\n\n\n\n\n\n定时任务的多种实现方式定时任务（延时任务）\n即定时完成的任务，或者说可以延迟一段时间完成的任务\n\n使用场景有很多：\n\n下订单，未支付，30min后自动取消订单\n24小时候红包自动退回账户\n每天凌晨自动备份\n每个月跑一次脚本等等\n\n最近我在实习的过程中也需要定时任务，因此就搜集资料整合了一下\n实现方式经过总结多方资料，有以下几种实现定时任务的方式：\n\n死循环的普通方式\n使用ScheduledExecutorService\n使用DelayQueue\n使用Spring的定时任务注解\n使用Redis\n使用定时任务框架\n外部调用\n\n【法一】死循环的方式死循环的方式：\n使用一个Map来保存任务信息，死循环反复遍历这个Map（比如使用迭代器遍历）\n每次循环记录当前的毫秒值，如果当前毫秒值大于等于我设定的值，那么就去执行\npublic void wayToImplementScheduled() &#123;    Map&lt;String, Long&gt; taskMap = new HashMap&lt;&gt;();    taskMap.put(&quot;任务1&quot;, Instant.now().plusSeconds(10).toEpochMilli());    // 执行定时任务    while (true) &#123;        Set&lt;String&gt; taskKey = taskMap.keySet();        Iterator&lt;String&gt; it = taskKey.iterator();        while (it.hasNext()) &#123;            String key = it.next();            // 如果设定的时间大于当前的时间，那么去执行任务            if (taskMap.get(key) &lt;= Instant.now().toEpochMilli()) &#123;                it.remove();                System.out.println(&quot;执行&quot; + key);            &#125;        &#125;    &#125;&#125;\n\n注意：Instant是Java8提供的新的类，常见的用法如下：\n//获取当前的InstantInstant instant = Instant.now();//将java.util.Date转换为Instant Instant instant = Instant.ofEpochMilli(new Date().getTime()); //从字符串类型中创建Instant类型的时间 Instant instant = Instant.parse(&quot;1995-10-23T10:12:35Z&quot;);\n\n【法二】使用ScheduledExecutorService使用一个ScheduledExecutorService实现\n@Overridepublic void wayToImplementScheduled() &#123;    ScheduledExecutorService ses = Executors.newScheduledThreadPool(3);    ses.scheduleWithFixedDelay(        ()-&gt;&#123;            System.out.println(&quot;执行任务&quot;);        &#125;,        1, // 初始延迟        10, // 间隔        TimeUnit.SECONDS    );&#125;\n\n【法三】使用DelayQueue注意DelayQueue的使用：\n\n泛型需要实现Delayed接口：这会导致需要重写两个方法\ngetDelay()：返回剩余的延迟时间\ncompareTo()：表明此队列的排序方式\n\n\n此处的示例构造函数还传入了Runnable接口\n\nclass DelayTask implements Delayed &#123;    long delay;    Runnable task;    public DelayTask(long delay, Runnable task) &#123;        this.delay = Instant.now().toEpochMilli() + delay;        this.task = task;    &#125;    // 返回剩余延迟    @Override    public long getDelay(TimeUnit unit) &#123;        return unit.convert(delay - Instant.now().toEpochMilli(), TimeUnit.MILLISECONDS);    &#125;    // 排序依据    @Override    public int compareTo(Delayed o) &#123;        if (this.getDelay(TimeUnit.MILLISECONDS) - o.getDelay(TimeUnit.MILLISECONDS) &gt; 0) &#123;            return 1;        &#125; else if (this.getDelay(TimeUnit.MILLISECONDS) - o.getDelay(TimeUnit.MILLISECONDS) &lt; 0) &#123;            return -1;        &#125; else &#123;            return 0;        &#125;    &#125;&#125;@Overridepublic void wayToImplementScheduled() &#123;    DelayQueue&lt;DelayTask&gt; delayQueue = new DelayQueue&lt;&gt;();    delayQueue.add(new DelayTask(5000,()-&gt;&#123;        System.out.println(&quot;执行任务1&quot;);    &#125;));    delayQueue.add(new DelayTask(3000,()-&gt;&#123;        System.out.println(&quot;执行任务2&quot;);    &#125;));    while (!delayQueue.isEmpty())&#123;        try &#123;            delayQueue.take().task.run();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n【法四】Spring的定时任务使用Spring的自带注解：\n首先给Spring的启动类加上注解@EnableScheduling\n比如这样：\n@EnableScheduling@SpringBootApplicationpublic class HynisApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(HynisApplication.class, args);    &#125;&#125;\n\n然后使用@Scheduled这个注解：\n@Target(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;) // 只能用在方法或是注解上@Retention(RetentionPolicy.RUNTIME) // 运行时依然存在@Documented@Repeatable(Schedules.class)public @interface Scheduled &#123;    String CRON_DISABLED = &quot;-&quot;;    String cron() default &quot;&quot;; // 可以写cron表达式    String zone() default &quot;&quot;;    long fixedDelay() default -1L; // 延迟时间，一个毫秒值    String fixedDelayString() default &quot;&quot;;    long fixedRate() default -1L;    String fixedRateString() default &quot;&quot;;    long initialDelay() default -1L; // 第一次执行的延迟时间    String initialDelayString() default &quot;&quot;;    TimeUnit timeUnit() default TimeUnit.MILLISECONDS;&#125;\n\n看@Scheduled注解源码可以了解到：\n\n可以标记注解与方法\n可以使用cron表达式\n\ndemo如下:\n@Override@Scheduled(cron = &quot;*/10 * * * * *&quot;) // cron表达式语法，每10s执行一次(秒分时天月周)public void wayToImplementScheduled() &#123;    System.out.println(&quot;定时任务执行：&quot; + LocalDateTime.now());&#125;\n\n【法五】使用Redis上面的任务调度方法都是单机的方式，遇到分布式场景会歇菜（除非借助第三方工具，或是加锁）\n待补充….\n【法六】使用定时任务框架Quartz待补充….\n【法七】外部调用可以使用比方说外部的一个curl，调用本机的一个接口的方式来实现定时调用\ncurl可以是一个我们自己实现的脚本去控制实现定时任务\n定时任务的实现要注意\n1、如何设置一个定时任务的执行周期\n\n注意定时任务的性能问题，避免在一个周期内，数据无法执行完，一般取50%，或者20%的时间比较合适\n\n2、注意改方法是否适合分布式场景\n\n参考资料\n博客：十种延迟任务的实现方式（大牛的博客，我对此博客进行了一定的扩展）\n\n使用外部crontab调用本机服务的方式实现定时任务\n\n\n","categories":["实战"],"tags":["实战"]},{"title":"登录模块总结","url":"/2021/09/02/%E5%AE%9E%E6%88%98/%E7%99%BB%E5%BD%95%E6%A8%A1%E5%9D%97%E6%80%BB%E7%BB%93/","content":"\n引言：之前做项目时，做了登录模块；当时的理解不是很深刻，所以这里特地重新翻出来，重新消化理解；本篇内容来源于我和雄哥讨论交流总结得到的结果。\n\n\n\n\n\n登录模块总结技术选型项目架构：SpringBoot+ Mybatis\n数据库：mysql\n缓存：Redis\n连接Redis：RedisTemplate\n登录验证原理：Redis+ token\ntoken生成：UUID随机生成32位的串\n用户密码加密：MD5 + salt\n用户ID生成：雪花算法\n登录相关逻辑\n验证码接口/verify：\n\n生成验证码（算法：随机获得字母、数字的4位混合串）\n存入Redis中：（k-v分别为sessionID : verifyCode）\n将验证码通过response.getOutputStream写回验证码图片\n\n\n登录接口/login：\n//前端传来：用户名、密码、验证码public class UserLoginForm &#123;    private String username;    private String password;    private String verifyCode;&#125;\n\n\n验证码校验：通过其sessionId去redis取对应的verifyCode值，校验用户输入的验证码是否正确\n用户名是否存在：查库，检查用户名是否存在（如果存在，此时可以获得其ID、加密后的密码、盐值等等数据）\n密码输入是否正确：将用户输入的密码用对应用户的盐值进行MD5加密，此结果再与库中存放的加密后的密码进行校验\n是否已经登录：通过其 ID 去Redis取对应的token，如果能取到，说明其已经登录过，如果登录过，那么要删除其原有的Redis中的token，重新生成token\n登录成功\n生成token串：使用UUID生成32位串，存入redis：userId: token、token: userId都要存储\n返回登录信息：将需要的信息存入dto对象，返回给前端（dto对象包含的内容有：用户名、token及其他用户信息）\n\n\n其他接口：\n\n拦截器拦截：Spring使用WebMvcConfigurer的实现类，将拦截器添加至项目中\n预检请求：就立即返回true\n查找token：在session的请求头或请求体中查找token\ntoken校验：使用前端传来的token去redis中取值，如果取不到，说明其传来的token不正确；如果成功取到，那么更新token的过期时间\n登陆成功：在ThreadLocal中存一份用户的数据\n\n\n\n代码实现登录逻辑@Servicepublic class UserServiceImpl implements UserService &#123;    @Resource    UserDao userDao;    @Resource    private RedisRepository redisRepository;    @Override    public ResponseVo login(HttpSession session, UserLoginForm loginForm) &#123;        // 处理session变化的问题        if(redisRepository.getVerifyCode(session.getId()) == null)&#123;            return ResponseVo.error(ResponseEnum.ERROR,&quot;Session地址变化&quot;);        &#125;        // 获取验证码，并将其验证        String verifyCode = loginForm.getVerifyCode();        if (!redisRepository.getVerifyCode(session.getId()).equalsIgnoreCase(verifyCode)) &#123;            redisRepository.delVerifyCode(session);            return ResponseVo.error(ResponseEnum.VERIFY_CODE_ERROR);        &#125;        // 验证码输入正确，也将redis内的该验证码删除        redisRepository.delVerifyCode(session);        // 使用用户名查库        User admin = userDao.selectUserByUsername(loginForm.getUsername());        // 不存在用户名        if (admin == null) &#123;            return ResponseVo.error(ResponseEnum.USERNAME_ERROR);        &#125;        // 密码判断，用盐值加密用户输入的密码与真实的密码进行比对校验        String loginPass = Md5Password.getMd5Passsword(admin.getSalt(), loginForm.getPassword());        // 密码不正确        if (!admin.getPassword().equals(loginPass)) &#123;            return ResponseVo.error(ResponseEnum.PASSWORD_ERROR);        &#125;        // 验证token是否已经登录        if (redisRepository.selectLoginAccessToken(admin.getUid()) != null) &#123;            // 如果已经登录，就删除其原本的token，顶号            redisRepository.deleteAccessToken(redisRepository.selectLoginAccessToken(admin.getUid()));            redisRepository.deleteLoginAccessToken(admin.getUid());        &#125;        // 验证成功        // 生成token，此处TokenInfo含有两个属性：UserId、Token        TokenInfo tokenInfo = new TokenInfo();        tokenInfo.setAccessToken(TokenUtil.genToken());        tokenInfo.setUserId(admin.getUid());        // 存入redis中，id、token双向存储，即id和token互为key、互为value        redisRepository.saveLoginAccessToken(tokenInfo);        redisRepository.saveAccessToken(tokenInfo);        // 返回给前端数据，有用户名、token        UserLoginDto userLoginDto = new UserLoginDto();        userLoginDto.setToken(tokenInfo.getAccessToken());        userLoginDto.setUsername(admin.getUsername());        return ResponseVo.success(userLoginDto);    &#125;&#125;\n\n拦截器@Componentpublic class LoginInterceptor implements HandlerInterceptor &#123;    @Autowired    private TokenService tokenService;    @Override    public boolean preHandle(HttpServletRequest request,                             HttpServletResponse response,                             Object handler) &#123;        // 如果是预检请求，让其通行        if (request.getMethod().equalsIgnoreCase(&quot;OPTIONS&quot;)) &#123;            return true;        &#125;        // 前端将token放在请求头内，这里从请求头获取token        String accessToken = request.getHeader(&quot;ACCESS_TOKEN&quot;);        // token为空，就去请求体里找        if (null == accessToken) &#123;            accessToken = request.getParameter(&quot;ACCESS_TOKEN&quot;);        &#125;        // 设置编码，防止乱码        response.setHeader(&quot;Content-Type&quot;, &quot;application/json;charset=utf-8&quot;);        // 如果token仍然为空，提醒其认证失败        if (null == accessToken) &#123;            ThreadLocalMap.remove(&quot;THREAD_LOCAL_KEY_LOGIN_USER&quot;);            try &#123;                response.getWriter().println(ResponseVo.error(ResponseEnum.ERROR, &quot;无Token&quot;));            &#125; catch (IOException e) &#123;                e.printStackTrace();            &#125;            return false;        &#125;        // 去redis里面找token        TokenInfo tokenInfo = tokenService.getTokenInfo(accessToken);        if (null == tokenInfo) &#123;            // 通过前端传来的token去redis中取id，如果取不到，说明传来的token不正确            ThreadLocalMap.remove(&quot;THREAD_LOCAL_KEY_LOGIN_USER&quot;);            try &#123;                response.getWriter().println(ResponseVo.error(ResponseEnum.ERROR, &quot;TOKEN错误&quot;));            &#125; catch (Exception e) &#123;                e.printStackTrace();            &#125;            return false;        &#125;        // 在 threadlocal 里面存一份用户的数据        User userInfoDto = new User();        userInfoDto.setUid(tokenInfo.getUserId());        ThreadLocalMap.put(&quot;THREAD_LOCAL_KEY_LOGIN_USER&quot;, userInfoDto);        return true;    &#125;    @Override    public void postHandle(HttpServletRequest request,                           HttpServletResponse response,                           Object handler, ModelAndView modelAndView) throws Exception &#123;        // 用完就remove，防止内存泄露        ThreadLocalMap.remove(&quot;THREAD_LOCAL_KEY_LOGIN_USER&quot;);    &#125;&#125;\n\n实现登录的几种方式目前了解到的有三种主流的登录验证方式：\n\n使用Session进行验证登录\n使用JWT进行验证登录\n使用Redis + token进行验证登录\n\nSession进行登录指在客户端存储一个Session Id。认证时，请求携带Session Id，并由服务器从Session数据存储中找到对应的Session。\n这种方式在很多网站框架下都有，经典的实现方式\n\nSession方式存在什么问题？\n\n\n如果系统不止一个，无法实现单点登录（或者说是不好实现）\n\n（PS：Tomcat集群可以共享Session，但是会降低Tomcat的运行速度）\n\nsession不好解决CSRF攻击（下一节介绍）\n\nJWT进行登录\nJWT(Json web Token)\n\nJWT方式中token由三部分组成：\nbase64(header).base64(json payload).signature\n\n\nheader存放一些基本信息：token的算法签名等\npayLoad是一串json，可以存放信息\nsignature是后端随机生成的，和payLoad绑在一起，防止客户端伪造token\n\n\n使用JWT有什么好处呢？\n\n使用JWT的目的，就是后端服务器可以不去存储token信息，因为jwt的token已经存储了信息\n后台只需要校验前端传来的JWT是否正确，如果正确，就可以信赖此token中存储的信息\n\nJWT存在什么问题吗？\n\n但是Jwt存在一些问题：\n\nJwt通过payLoad传输信息，这存在一个问题，jwt能存储多少信息？作为一个前端每个操作都要传来的数据，如果存太多的数据，势必增大网络和服务器的带宽IO开销\nJwt无法知悉用户的一些行为，对于用户退出、登录了几次服务器无法知悉，也不能强行踢掉一个不良用户\nJwt不好控制token失效的时间\n\n\nJwt为什么不能统计用户行为，我不能在redis里面存一下吗？\n\n可以，但是没有必要。\n使用JWT的原因之一就是为了减小服务器开销，如果你使用了redis来存储信息的话，还费事搞那么复杂的一个Jwt干嘛呢？\nredis+token进行登录本节使用的方式，就是redis+token，这里的token是一个随机的串，并不保存任何信息\n要注意的是，redis中存储的信息，id与token要双向绑定：\n\nid : token\n为什么要存这个值？为了保证此用户不会重复登录\n不存此值会存在一个问题：如果用户在A、B两台设备使用了相同的账号密码进行登录，我们会返回其不同的token，一个用户，两个token，这样显然不正常。\n如果存放了这个值，我们就能在其登录时判断其是否已经登陆过\n\n\ntoken : id ：\n为什么要存这个值？为了验证token是否正确\n如果我们使用前端传来的token，取不到对应的id，那么说明前端传来的token是不正确的\n\n\n\n\nredis + token 方式的优势\n\n\n可以解决单点登录问题（指，在后台多系统下保证我只需登录一次，就可以享受这个网站的所有服务，这些服务很可能是不同的系统实现的）\n如果使用Session保存用户信息来实现的，多系统即可能有多个Tomcat，而Session是依赖当前系统的Tomcat，所以系统A的Session和系统B的Session是不共享的\n\n存放的数据更多，因为使用redis，不再拘束与jwt实现时那么局促的空间\n\n可以很好的解决CSRF\n\n可以保证Token实时过期，对比JWT实现来说，使用Redis可以保证token准时过期\n\n\nCSRF跨站请求伪造\nCross Site Request Forgery 跨站请求伪造，劫持受信任用户向服务器发送非预期请求的攻击方式\n\n举个栗子：有两个网站，A与B（A是正经网站，B是不正经网站）\n\n你正常流程登录了A，A的服务器返回给你一个cookie，你存到了你的浏览器内，再以后的访问，你得带上cookie里存的值给服务器，服务器也是根据这个值来校验你这个人的\n后来，你访问了B，B很坏，诱骗你点击一个链接，这个链接会用你之前的cookie去访问A，模仿你本人的操作\n\n这就是跨站请求伪造\n使用Token+Redis可以避免发生CSRF\n\n为什么Token+Redis可以解决CSRF？\n\nCSRF 攻击之所以能够成功，是因为攻击者可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 Cookie 中，因此攻击者可以在不知道这些验证信息的情况下直接利用用户自己的 Cookie 来通过安全验证。\n要抵御 CSRF，关键在于在请求中放入攻击者所不能伪造的信息，并且该信息不存在于 Cookie 之中。\n可以在 HTTP 请求中以参数的形式加入一个随机产生的 Token，并在服务器端建立一个拦截器来验证这个 Token，如果请求中没有 Token 或者 Token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求\n其他问题\n1、为什么使用RedisTemplate，而不用Jedis、Redission或者其他的？\n\nSpring自己就封装了RedisTemplate，开箱即用，很简单方便。\n（轮子不用白不用，况且是Spring家的轮子）\n\n2、为什么用户密码加密要用MD5加盐值？\n\n​    MD5是很好的加密算法，因为其不会被被逆向破解，但是如果你去百度搜MD5在线破解，会有很多很多。\n因为就算不会被逆向破解，但MD5对于相同的串来说，生成的串也是相同的\n所以加个盐，把盐值存起来，加密时插到要加密的串之间，安全性更高\n\n3、为什么生成用户ID不用UUID，用了雪花算法？\n\n雪花算法其核心思想就是：使用一个 64 bit 的 long型的数字作为全局唯一 id\n雪花算法生成的ID大致由时间戳、数据中心、机器标识、序列号部分组成\nSnowFlake算法的优点：\n\n高性能高可用：生成时不依赖于数据库，完全在内存中生成。\n容量大：每秒中能生成数百万的自增ID。\n带有一定顺序：存入数据库中，索引效率高。\n\n第三点，就是为什么使用雪花而不用UUID的最重要的一点：\n​        用户ID一般会作为索引，作为索引存储时，如果使用UUID，生成的全是随机值，那么在生成一个新用户插入数据库时，索引的B+树为了保持有序自我会进行调整，所以使用雪花算法生成的值，带有一定顺序，可以减小数据库的压力。\n\n4、为什么Token不用雪花算法？\n\nToken又不往数据库存，只放在了redis里面，保证随机即可，没有对顺序的要求。\n总结\n本文讲述了实现登录的三种方法，并分析了他们的优点缺点\n着重讲述如何实现redis+token这种实现方式\n介绍了雪花算法\n\n","categories":["实战"],"tags":["实战"]},{"title":"Caffeine与缓存算法","url":"/2024/01/03/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%9E%84/Caffeine%E4%B8%8E%E7%BC%93%E5%AD%98%E7%AE%97%E6%B3%95/","content":"\n引言： 缓存算法与Java最棒的本地缓存Caffeine\n\n\n\n\nLRU及其变体LRU、LRU-KLRU 最近最少使用算法，最简单可以使用一个hashmap+linkedlist实现，越靠近头表示刚被访问，越靠近尾部表示越久时间没有被访问。\n所谓LRU-K，就是将最近使用过1次的普通LRU算法扩展到K次。\n\n优点：对于热点数据，LRU的表现很好\n缺点：对于偶发性的、周期性的批量操作，LRU会有比较明显的缓存污染情况，会缓存很多长尾数据。\n\nSLRUSegment LRU：将LRU分为保护段（protected segment）和试用段（probationary segment）\n\n试用段：存放只访问1次的数据\n保护段：存放访问至少2次的数据\n\n试用段只会接受新的数据，用这个结构来增加对偶发性、周期性批量操作的抗性。\n\n与ARC算法十分相似，可以认为是静态的ARC算法\n\nLFU及其变体LFU最近最少频次，需要维护访问的次数，通常会用一个最小堆来实现。相较于LRU：\n\n优点：LFU的效率更好，能避免周期性或是偶发性的命中率下降的问题。\n缺点：\n维护“频率”的计数需要大量内存\n如果数据的访问模式改变，那么LFU需要重新进行计数来适应新的访问模式。\n存在缓存污染问题，比如高频数据不再高频（比如上个礼拜的热点，现在已经不是了，但是计数居高不下）\n\n\n\nLFU-Aging为了解决高频数据不再高频的问题（即第三个缺点），引入了访问的时效性（即上次距上一次访问间隔的时长），以及衰减策略，但衰减策略的调节也是一个问题。\nRedis中就有LFU-Aging算法的思想，他将原本的LRU字段拆为两个，高位表示数据的访问时间戳，低位表示数据的访问次数，在淘汰时，先比较访问次数（低位），再比较时间戳（高位）\n\nLFU-Aging 主要是为了解决第三个问题：防止缓存污染\n\nWindow-LFU所谓的Window，就是不再维护所有数据的频率计数，而是维护一部分的，维护的这一部分就成为窗口。\n窗口可以是固定的也可以是滑动的，在滑动窗口满后，再添加新的元素，会淘汰滑动窗口内频次最小的元素。\n\nWindow-LFU的主要目的是解决LFU的第一个问题，即减少维护计数所需要的资源\n\nARC算法Adaptative Replacement Cache 自适应替代缓存一种结合了LRU、LFU思想的算法。\n实现ARC算法需要两个LRU Cache：\n\nL1 Cache：存储只访问过1次的\nL2 Cache：存储至少访问过2次的\n\n需要维护两种信息：\n\nT1子列表：最近访问\nT2子列表：最高频访问\n\n还需要记录被淘汰的数据信息：\n\nB1：记录T1子列表淘汰的数据，即LRU淘汰的数据\n\nB2：记录T2子列表淘汰的数据，即LFU的数据\n\n\n核心思想是：\n\n当L1、L2两个cache存满后，如果T1的数据被淘汰，则记录数据到B1；同理L2数据被淘汰，记录数据到B2。\n\n此后：\n\n如果B1的数据被访问，则会扩展T1的长度，此时表现更像LRU\n如果B2的数据被访问，则会扩展T2的长度，此时表现更像LFU\n\n\n\nTiny-LFU在介绍Tiny-LFU缓存算法之前，需要先了解两个概念：\nBloom Filter布隆过滤器用来判断元素是否存在，其本质是一个有多个Hash函数的bitmap，在存储一个元素时：\n\n使用 N 个Hash函数分别计算这个数据的哈希值，得到 N 个哈希值\n将哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置\n将对应的 bit 位置为 1\n\n这样布隆过滤器就可以保证绝对的判断不存在，相对的判断存在。\n\n在判断是否存在时可能会有误差。bitmap越大，哈希函数越多，错误率会越低。\n\nCM-SketchCM-Sketch用来求元素在集合中数量的布隆过滤器，本质是一个有多个Hash函数的二维数组\n\n与bloom过滤器将相应位置置1不同，CM-Sketch会将对应位置的元素+1：\n\n使用 N 个Hash函数分别计算这个数据的哈希值，得到 N 个哈希值\n每一个hash值会映射到二维数组的一个位置\n将对应位置+1\n\n这样在判断一个元素在集合中的数量的时候，求出不同的hash值，并取最小值就是该元素在集合中的数量Min&#123;hash1 , hash2, hash3&#125;。\n\n当然和布隆过滤器一样，也存在一定的误差。\n\nTiny-LFULFU算法需要计算“频率”，这是LFU算法淘汰元素的策略。\nTiny-LFU算法使用CM-Sketch来判断元素的访问次数（访问频次其实并不需要计算的很精确，使用CM-Sketch效率很高）\n简而言之：Tiny-LFU = CM-Sketch + 衰减策略\nSketch可以为了防止长尾数据带来的缓存污染问题，更进一步的是，Tiny-LFU还使用了布隆过滤器（称为Doorkeeper 门卫）\n核心思想是：使用Doorkeeper判断元素是否存在\n\n如果不存在插入到Doorkeeper\n如果存在插入到Sketch，且返回Sketch存储的计数再+1\n\nCaffeine的W-TinyLFUTinyLFU对一些突如其来的高频请求不够友好，Caffeine结合了Window-LFU、SLRU（ARC）、TinyLFU的思想，实现了W-TinyLFU结构如下：\n\n\n开始访问后，可以直接打到一个LRU上（Window Cache），在WindowCache被淘汰，才会进入一个Filter（TinyLFU，即Doorkeeper+Sketch），才有机会打到SLRU上（Main Cache)\nCaffeine是Java著名的本地缓存工具，Caffeine内部的增长逻辑如下：\npublic void increment(@NonNull E e) &#123;    if (isNotInitialized()) &#123;        return;    &#125;    // 避免质量不好的hash值，对hash值进行处理    int hash = spread(e.hashCode());    int start = (hash &amp; 3) &lt;&lt; 2;    // Loop unrolling improves throughput by 5m ops/s    // 使用不同的hash算法，计算不同的index值    int index0 = indexOf(hash, 0);    int index1 = indexOf(hash, 1);    int index2 = indexOf(hash, 2);    int index3 = indexOf(hash, 3);    // 判断是否需要增加    boolean added = incrementAt(index0, start);    added |= incrementAt(index1, start + 1);    added |= incrementAt(index2, start + 2);    added |= incrementAt(index3, start + 3);    // 如果值增加，判断是否需要频次衰减    if (added &amp;&amp; (++size == sampleSize)) &#123;        reset();    &#125;&#125;// 避免质量不好的hash值，对hash值进行处理int spread(int x) &#123;    x = ((x &gt;&gt;&gt; 16) ^ x) * 0x45d9f3b;    x = ((x &gt;&gt;&gt; 16) ^ x) * 0x45d9f3b;    return (x &gt;&gt;&gt; 16) ^ x;&#125;// SEED数组是不同的hash算法的种子，代表使用不同的hash算法int indexOf(int item, int i) &#123;    long hash = (item + SEED[i]) * SEED[i];    hash += (hash &gt;&gt;&gt; 32);    return ((int) hash) &amp; tableMask;&#125;boolean incrementAt(int i, int j) &#123;    int offset = j &lt;&lt; 2;    long mask = (0xfL &lt;&lt; offset);    if ((table[i] &amp; mask) != mask) &#123;        table[i] += (1L &lt;&lt; offset);        return true;    &#125;    return false;&#125;\n\n与其他统计频次的LFU算法一样，在运行一段时间后需要给LFU的频次“降温”（频次衰减）\nvoid reset() &#123;    int count = 0;    // 遍历整个数组，频次直接减半    for (int i = 0; i &lt; table.length; i++) &#123;        count += Long.bitCount(table[i] &amp; ONE_MASK);        table[i] = (table[i] &gt;&gt;&gt; 1) &amp; RESET_MASK;    &#125;    size = (size &gt;&gt;&gt; 1) - (count &gt;&gt;&gt; 2);&#125;\n\n相关链接\n很好的博文，算是论文的翻译：https://www.qin.news/tinylfu/\ncaffeine代码仓库：https://github.com/ben-manes/caffeine\n\n","categories":["缓存"],"tags":["Caffeine","LRU","LFU"]},{"title":"29.Vue-router的API","url":"/2019/07/27/Vue/29-Vue-router%E7%9A%84API/","content":"\n引言：\n\nvue-router的API参考\n\n\n\n\n\n取自官方文档\nrouter-link功能：支持用户在具有路由功能的应用中 (点击) 导航\n&lt;router-link&gt; 比起写死的 &lt;a href=&quot;...&quot;&gt; 会好一些，理由如下：\n\n无论是 HTML5 history 模式还是 hash 模式，它的表现行为一致，所以，当你要切换路由模式，或者在 IE9 降级使用 hash 模式，无须作任何变动。\n\n在 HTML5 history 模式下，router-link 会守卫点击事件，让浏览器不再重新加载页面。\n\n当你在 HTML5 history 模式下使用 base 选项之后，所有的 to 属性都不需要写 (基路径) 了\n\n\n将激活 class 应用在外层元素有时候我们要让激活 class 应用在外层元素，而不是 &lt;a&gt; 标签本身，那么可以用 &lt;router-link&gt; 渲染外层元素，包裹着内层的原生  标签：\n&lt;router-link tag=&quot;li&quot; to=&quot;/foo&quot;&gt;  &lt;a&gt;/foo&lt;/a&gt;&lt;/router-link&gt;\n在这种情况下，&lt;a&gt; 将作为真实的链接 (它会获得正确的 href 的)，而 “激活时的 CSS 类名” 则设置到外层的 &lt;li&gt;。\nPropsto类型: string | Location\nrequired\n表示目标路由的链接。\n当被点击后，内部会立刻把 to 的值传到 router.push()，\n所以这个值可以是一个字符串或者是描述目标位置的对象。\n&lt;!-- 字符串 --&gt;&lt;router-link to=&quot;home&quot;&gt;Home&lt;/router-link&gt;&lt;!-- 渲染结果 --&gt;&lt;a href=&quot;home&quot;&gt;Home&lt;/a&gt;&lt;!-- 使用 v-bind 的 JS 表达式 --&gt;&lt;router-link v-bind:to=&quot;&#x27;home&#x27;&quot;&gt;Home&lt;/router-link&gt;&lt;!-- 不写 v-bind 也可以，就像绑定别的属性一样 --&gt;&lt;router-link :to=&quot;&#x27;home&#x27;&quot;&gt;Home&lt;/router-link&gt;&lt;!-- 同上 --&gt;&lt;router-link :to=&quot;&#123; path: &#x27;home&#x27; &#125;&quot;&gt;Home&lt;/router-link&gt;&lt;!-- 命名的路由 --&gt;&lt;router-link :to=&quot;&#123; name: &#x27;user&#x27;, params: &#123; userId: 123 &#125;&#125;&quot;&gt;User&lt;/router-link&gt;&lt;!-- 带查询参数，下面的结果为 /register?plan=private --&gt;&lt;router-link :to=&quot;&#123; path: &#x27;register&#x27;, query: &#123; plan: &#x27;private&#x27; &#125;&#125;&quot;&gt;Register&lt;/router-link&gt;\n\nreplace类型: boolean\n默认值: false\n设置replace属性的话，当点击时，会调用 router.replace() 而不是 router.push()，于是导航后不会留下 history 记录。\n&lt;router-link :to=&quot;&#123; path: &#x27;/abc&#x27;&#125;&quot; replace&gt;&lt;/router-link&gt;\nappend类型: boolean\n默认值: false\n设置 append 属性后，则在当前 (相对) 路径前添加基路径。例如，我们从 /a 导航到一个相对路径 b，如果没有配置 append，则路径为 /b，如果配了，则为 /a/b\n&lt;router-link :to=&quot;&#123; path: &#x27;relative/path&#x27;&#125;&quot; append&gt;&lt;/router-link&gt;\n\ntag类型: string\n默认值: &quot;a&quot;\n有时候想要 &lt;router-link&gt; 渲染成某种标签，例如 &lt;li&gt;。 于是我们使用tagprop 类指定何种标签，同样它还是会监听点击，触发导航。\n&lt;router-link to=&quot;/foo&quot; tag=&quot;li&quot;&gt;foo&lt;/router-link&gt;&lt;!-- 渲染结果 --&gt;&lt;li&gt;foo&lt;/li&gt;\n\nactive-class类型: string\n默认值: &quot;router-link-active&quot;\n设置 链接激活时使用的 CSS 类名。默认值可以通过路由的构造选项 linkActiveClass 来全局配置。\nexact类型: boolean\n默认值: false\n“是否激活” 默认类名的依据是 inclusive match (全包含匹配)。\n举个例子，如果当前的路径是 /a 开头的，那么 &lt;router-link to=&quot;/a&quot;&gt; 也会被设置 CSS 类名。\n按照这个规则，每个路由都会激活&lt;router-link to=&quot;/&quot;&gt;！想要链接使用 “exact 匹配模式”，则使用 exact 属性：\n&lt;!-- 这个链接只会在地址为 / 的时候被激活 --&gt;&lt;router-link to=&quot;/&quot; exact&gt;\n\n\nevent类型: string | Array&lt;string&gt;\n默认值: &#39;click&#39;\n声明可以用来触发导航的事件。可以是一个字符串或是一个包含字符串的数组。\nexact-active-class类型: string\n默认值: &quot;router-link-exact-active&quot;\n配置当链接被精确匹配的时候应该激活的 class。注意默认值也是可以通过路由构造函数选项 linkExactActiveClass 进行全局配置的。\n&lt;router-view&gt;&lt;router-view&gt; 组件是一个 functional 组件，\n渲染路径匹配到的视图组件。\n&lt;router-view&gt; 渲染的组件还可以内嵌自己的 &lt;router-view&gt;，根据嵌套路径，渲染嵌套组件。\n其他属性 (非 router-view 使用的属性) 都直接传给渲染的组件，\n很多时候，每个路由的数据都是包含在路由参数中。\n因为它也是个组件，所以可以配合 &lt;transition&gt; 和 &lt;keep-alive&gt; 使用。如果两个结合一起用，要确保在内层使用 &lt;keep-alive&gt;：\n&lt;transition&gt;  &lt;keep-alive&gt;    &lt;router-view&gt;&lt;/router-view&gt;  &lt;/keep-alive&gt;&lt;/transition&gt;\n\nPropsname类型: string\n默认值: &quot;default&quot;\n如果 设置了名称，\n则会渲染对应的路由配置中 components 下的相应组件\nRouter构建选项routes类型: Array&lt;RouteConfig&gt;\nRouteConfig 的类型定义：看看就好\ndeclare type RouteConfig = &#123;  path: string;  component?: Component;  name?: string; // 命名路由  components?: &#123; [name: string]: Component &#125;; // 命名视图组件  redirect?: string | Location | Function;  props?: boolean | Object | Function;  alias?: string | Array&lt;string&gt;;  children?: Array&lt;RouteConfig&gt;; // 嵌套路由  beforeEnter?: (to: Route, from: Route, next: Function) =&gt; void;  meta?: any;  // 2.6.0+  caseSensitive?: boolean; // 匹配规则是否大小写敏感？(默认值：false)  pathToRegexpOptions?: Object; // 编译正则的选项&#125;\nmode类型: string\n默认值: &quot;hash&quot; (浏览器环境) | &quot;abstract&quot; (Node.js 环境)\n可选值: &quot;hash&quot; | &quot;history&quot; | &quot;abstract&quot;\n配置路由模式:\nhash: 使用 URL hash 值来作路由。支持所有浏览器，包括不支持 HTML5 History Api 的浏览器。\nhistory: 依赖 HTML5 History API 和服务器配置\nabstract: 支持所有 JavaScript 运行环境，如 Node.js 服务器端。如果发现没有浏览器的 API，路由会自动强制进入这个模式。\nbase类型: string\n默认值: &quot;/&quot;\n应用的基路径。\n例如，如果整个单页应用服务在 /app/ 下，然后 base 就应该设为 “/app/“。\nlinkActiveClass类型: string\n默认值: &quot;router-link-active&quot;\n全局配置 &lt;router-link&gt; 的默认“激活 class 类名”\nlinkExactActiveClass类型: string\n默认值: &quot;router-link-exact-active&quot;\n全局配置 &lt;router-link&gt; 精确激活的默认的 class\nscrollBehavior类型: Function\n签名:\ntype PositionDescriptor =  &#123; x: number, y: number &#125; |  &#123; selector: string &#125; |  ?&#123;&#125;type scrollBehaviorHandler = (  to: Route,  from: Route,  savedPosition?: &#123; x: number, y: number &#125;) =&gt; PositionDescriptor | Promise&lt;PositionDescriptor&gt;\n\nparseQuery / stringifyQuery类型: Function\n提供自定义查询字符串的解析/反解析函数。覆盖默认行为。\nfallback类型: ·boolean·\n当浏览器不支持 history.pushState 控制路由是否应该回退到 hash 模式。默认值为 true。\n在 IE9 中，设置为 false 会使得每个 router-link 导航都触发整页刷新。它可用于工作在 IE9 下的服务端渲染应用，因为一个 hash 模式的 URL 并不支持服务端渲染。\nRouter实例属性\nrouter.app\n\n类型: Vue instance\n配置了 router 的 Vue 根实例。\n\nrouter.mode\n\n类型: string\n路由使用的模式。\n\nrouter.currentRoute\n\n类型: Route\n当前路由对应的路由信息对象\nRouter实例方法\nrouter.beforeEach\nrouter.beforeResolve\nrouter.afterEach\n\n函数签名：\nrouter.beforeEach((to, from, next) =&gt; &#123;  /* must call `next` */&#125;)router.beforeResolve((to, from, next) =&gt; &#123;  /* must call `next` */&#125;)router.afterEach((to, from) =&gt; &#123;&#125;)\n\n在 2.5.0+ 这三个方法都返回一个移除已注册的守卫/钩子的函数\n\nrouter.push\nrouter.replace\nrouter.go\nrouter.back\nrouter.forward\n\n函数签名:\nrouter.push(location, onComplete?, onAbort?)router.replace(location, onComplete?, onAbort?)router.go(n)router.back()router.forward()\n路由对象一个路由对象 (route object) 表示当前激活的路由的状态信息，\n包含了当前 URL 解析得到的信息，还有 URL 匹配到的路由记录 (route records)。\n路由对象是不可变 (immutable) 的，每次成功的导航后都会产生一个新的对象。\n路由对象出现在多个地方:\n\n在组件内，即 this.$route\n\n在 $route 观察者回调内\n\nrouter.match(location) 的返回值\n\n导航守卫的参数：\nrouter.beforeEach((to, from, next) =&gt; &#123;  // `to` 和 `from` 都是路由对象&#125;)\nscrollBehavior 方法的参数:\nconst router = new VueRouter(&#123;  scrollBehavior (to, from, savedPosition) &#123;    // `to` 和 `from` 都是路由对象  &#125;&#125;)\n路由对象属性\n$route.path\n\n\n类型: string\n字符串，对应当前路由的路径，总是解析为绝对路径，如 &quot;/foo/bar&quot;。\n\n$route.params\n\n类型: Object\n一个 key/value 对象，包含了动态片段和全匹配片段，如果没有路由参数，就是一个空对象。\n\n$route.query\n\n类型: Object\n一个 key/value 对象，表示 URL 查询参数。例如，对于路径 /foo?user=1，则有 $route.query.user == 1，如果没有查询参数，则是个空对象。\n\n$route.hash\n\n类型: string\n当前路由的 hash 值 (带 #) ，如果没有 hash 值，则为空字符串。\n\n$route.fullPath\n\n类型: string\n完成解析后的 URL，包含查询参数和 hash 的完整路径。\n\n$route.matched\n\n类型: Array&lt;RouteRecord&gt;\n一个数组，包含当前路由的所有嵌套路径片段的路由记录 。\n路由记录就是 routes 配置数组中的对象副本 (还有在 children 数组)。\nconst router = new VueRouter(&#123;  routes: [    // 下面的对象就是路由记录    &#123; path: &#x27;/foo&#x27;, component: Foo,      children: [        // 这也是个路由记录        &#123; path: &#x27;bar&#x27;, component: Bar &#125;      ]    &#125;  ]&#125;)\n当 URL 为 /foo/bar，$route.matched 将会是一个包含从上到下的所有对象 (副本)。\n\n$route.name\n\n当前路由的名称，如果有的话。(查看命名路由)\n\n$route.redirectedFrom\n\n如果存在重定向，即为重定向来源的路由的名字\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"Java接口与抽象类","url":"/2019/08/10/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%9E%84/Java%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%8A%BD%E8%B1%A1%E7%B1%BB/","content":"\n引言：接口与抽象类\n\n\n\n\n\n接口接口是一种引用的数据类型，最重要的内容就是其中的抽象方法\n创建格式\npublic interface api &#123;&#125;\n换了关键字interface之后，编译生成的字节码文件仍然是.java -&gt; .class\n\nJava 7开始，接口中可以包含的内容有：\n\n常量\n\n抽象方法\n\n\n\nJava 8 开始，那么可以包含的还有：\n\n默认方法（重点：为什么要引入默认方法？）\n\n静态方法\n\n\n\nJava 9 开始：还能有\n\n私有方法\n\n\n\n抽象方法注意：\n\n接口不能直接使用，必须有一个实现类来实现该接口\n接口的实现类必须覆盖重写接口的所有抽象方法\n实现类一般起名字在最后加上Impl\n接口的抽象方法的关键字必须是固定的两个public void，但是他们可以省略public interface api &#123;    public abstract void method();    void method2(); // 这两个方法的定义效果一样&#125;\n接口和实现类继承时使用implements实现public interface api &#123;    public abstract void method();&#125;//接口\npublic class apiImpl implements api &#123;    @Override    public void method()&#123;        System.out.println(&quot;实现类的使用&quot;);    &#125;&#125;//实现类\n默认方法Java 8开始就可以在接口中定义默认方法\n\n\n目的是为了解决接口升级的问题，因为在投入使用后，如果给接口新加抽象方法会报错，这时候可以使用默认的接口方法\n\n默认方法的特点就是，可以重写，也可以不重写\npublic interface api &#123;    public abstract void method();    public default void method2()&#123;        // 有自己的实现题        System.out.println(&quot;添加的默认方法&quot;);    &#125;&#125;\npublic class apiImpl implements api &#123;    @Override    public void method()&#123;        System.out.println(&quot;实现类的使用&quot;);    &#125;    @Override    public void method2()&#123;        System.out.println(&quot;默认的方法也可以进行重写&quot;);    &#125;&#125;\n静态方法Java 8开始：同样，接口的静态方法也是属于这个接口的，调用时直接使用接口名调用即可\npublic interface api &#123;    public static void staticMethod()&#123;        System.out.println(&quot;静态方法&quot;);    &#125;&#125;\npublic static void main(String[] args) &#123;    api.staticMethod();    //直接使用接口名调用即可&#125;\n私有方法Java 9出现的接口的私有方法\n目的：是为了简化接口中默认方法的重复部分\npublic interface api &#123;    public default void method1()&#123;        intro();    &#125;    public default void method2()&#123;        intro();    &#125;    private void intro()&#123;        System.out.println(&quot;你好&quot;);    &#125;&#125;\n常量接口中可以定义成员变量，但是必须使用public static final三个修饰符来修饰（可以省略）\npublic static final int NUM = 10;// 前三个关键字可以省略，接口常量一旦赋值便不可更改\n注意：常量一般要完全大写，而且多单词要用下划线进行分隔\n同样常量属于接口，可以直接用接口名调用\npublic static void main(String[] args) &#123;    System.out.println(api.NUM);    //调用接口常量直接使用接口名&#125;\n\n接口与类的区别实现接口与实现类的区别：\n\n接口没有静态代码块、接口没有构造方法\n一个类的直接父类是唯一的，但是一个类可以实现多个直接接口\n\npublic class MyInterfaceImpl implements MyinerfaceA,MyinterfaceB&#123;//覆盖重写所有的抽象方法&#125;\n\n如果实现类实现的多个接口存在方法同名的情况，只需要覆盖重写一次即可\n如果没有覆盖重写所有的抽象方法，那么本类也只能是一个抽象类\n如果多个接口存在重复的默认方法，实现类也要对其覆盖重写\n一个类如果直接父类和接口当中的方法产生了冲突，会优先使用父类当中的方法\n\n接口继承接口\n接口之间可以多继承\n多个父接口抽象方法同名没有关系\n多个父接口的默认方法同名必须进行默认方法的覆盖重写\n\n抽象类定义：加关键字abstract\npublic abstract class dog &#123;    public abstract void eat();//抽象方法&#125;//抽象类\n\n注意：\n\n抽象方法没有实现体\n只有抽象类才能拥有抽象方法\n不能直接new抽象对象\n必须用子类来继承抽象父类\n子类必须覆盖重写抽象父类的所有的抽象方法，如果没有实现完所有的方法，那么这个子类还是一个抽象类\n抽象类不能创建对象\n抽象类可以有构造方法，供子类创建对象时初始化父类对象\n\npublic abstract class father &#123;    father()&#123;        System.out.println(&quot;父类抽象函数的构造&quot;);    &#125;&#125;\n\npublic class son extends father &#123;    son()&#123;        System.out.println(&quot;子类构造函数&quot;);    &#125;&#125;\n\npublic static void main(String[] args) &#123;   son xxx = new son();&#125;//打印出//父类抽象函数的构造//子类构造函数\n\n\n抽象类不一定含有抽象方法，但是含有抽象方法的一定是抽象类\n\n","categories":["后台","Java"],"tags":["Java"]},{"title":"Java默认的序列化流","url":"/2019/08/23/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%9E%84/%E5%BA%8F%E5%88%97%E5%8C%96%E6%B5%81/","content":"\n引言：Java默认的序列化流\n\n\n\n\n\n序列化流序列化是什么？\n序列化：把对象以流的方式写入到文件中保存，叫做写对象，也叫作对象的序列化\n\n对象中包含的不仅仅是字符，还有字节，所以要用字节流\n\n反序列化：把文件中保存的对象，以流的方式读取出来，叫做读对象，也叫作对象的反序列化\n\n读取的文件保存的都是字节，使用字节流\n\n实现序列化和反序列化的核心就是要使用：ObejctOutputStream与ObjectInputStream\nObejctOutputStream构造方法ObjectOutputStream(OutputStream out);//创建写入指定 OutputStream 的 ObjectOutputStream。\n核心APIpublic final void writeObject(Object obj)throws IOException//将指定的对象写入 ObjectOutputStream。\n\n步骤\nObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;D:\\\\a.txt&quot;));// 1. 创建ObjectOutputStream对象，构造方法中传递输出流oos.writeObject(new Person(&quot;李白&quot;,18));// 2. 使用ObjectOutputStream对象中的方法writeObejct把对象写入到文件中oos.close();// 3. 释放资源\n运行报错NotSerializableException，这个错是未序列化报错，序列化和反序列化会抛出这个错误我们必须实现一个标记性接口来启动这个序列化\n\n标记性接口：实现这个接口不需要实现其任何方法\n\n要进行序列化和反序列化的接口必须实现Serializable接口，就会给类添加一个标记\npublic class Person implements Serializable&#123;&#125;\n这样就可以运行了，输出的文件如下\naced 0005 7372 001d 636e 2e69 7463 6173742e 6461 7930 342e 6465 6d6f 3031 2e506572 736f 6ef6 1bb3 45ad 3a82 6202 00024900 0361 6765 4c00 046e 616d 6574 00124c6a 6176 612f 6c61 6e67 2f53 7472 696e673b 7870 0000 0012 7400 06e6 9d8e e799bd\n\nObejctInputStream核心API构造方法：ObjectInputStream(InputStream in) 传入一个字节输入流\n反序列化：readObject()，从输入流的位置读入文件，返回一个对象\n小demoObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;D:\\\\a.txt&quot;));// 1. 创建ObjectInputStream对象，构造方法传递字节输出流Object o = ois.readObject();// 2. 使用ObjectInputStream对象中的方法readObejct读取保存对象的文件ois.close();// 3. 释放资源System.out.println(o);\n\n注意：可能会报出ClassNotFoundException这个错误，是因为不存在对象的class文件时抛出异常\n所以反序列化必须实现两个东西\n\n类必须实现Serializable\n必须存在对应的Class文件\n\ntransient关键字\nstatic关键字：\n  被static修饰的成员变量不能被序列化的\n\ntransient关键字：\n  被transient修饰的成员变量，不能被序列化\n\n\n以后不想要成员变量被序列化，我们可以使用transient关键字修饰\nInvalidClassException异常\n当JVM反序列化对象时，能找到class对象，但是还会抛出一个InvalidClassException的异常，为什么？\n\n有可能是因为\n\n更改了class的内容，使得该类的序列版本号与读取到的类描述的版本号不匹配\n该类包含未知数据类型\n该类没有可访问的无参数构造\n\n原理：实现了Serializable接口，就会根据类的定义，给该类一个接口的序列号，反序列化时会比照两者的序列号，如果曾更改了类，会使得他们没有匹配序列号，导致报错\n解决方法：\n\n无论是否对类的定义进行修改都不重新生成新的序列号\n可以手动给类增加一个序列号\n\n\nSerializable接口规定：\n可序列化类可以通过声明名为 serialVersionUID 的字段（该字段必须是static final long serialVersionUID 型字段)\n\n\n在类中定义一个如下的成员变量即可\nprivate static final long serialVersionUID = 1L;\n\n序列化多个对象​        当我们想在文件中保存多个对象的时候，我们可以把多个对象存储到一个集合中，然后对集合进行序列化和反序列化\n分析：\n//1 定义一个存储Person对象的ArrayList集合ArrayList&lt;Person&gt; list = new ArrayList&lt;&gt;();//2 往ArrayList集合中存储Person对象list.add(new Person(&quot;李白&quot;,18));list.add(new Person(&quot;李黑&quot;,20));list.add(new Person(&quot;李太白&quot;,56));//3 创建一个序列化ObejctOutputStream对象ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;D:\\\\a.txt&quot;));//4 使用ObjectOutputStream对象中的方法writeObejct，对集合进行序列化oos.writeObject(list);//5 创建一个反序列化ObejctInputStreamObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;D:\\\\a.txt&quot;));//6 使用ObjectInputStream的readObejct读取文件中保存的集合Object o = ois.readObject();//7 把Obejct类型的集合转换为ArrayList集合ArrayList&lt;Person&gt; list1 = (ArrayList&lt;Person&gt;)o;//8 遍历集合for (Person person : list1) &#123;    System.out.println(person);&#125;//9 释放资源ois.close();oos.close();","categories":["序列化"],"tags":["序列化"]},{"title":"数据库Join原理","url":"/2024/04/08/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%9E%84/%E6%95%B0%E6%8D%AE%E5%BA%93Join%E5%8E%9F%E7%90%86/","content":"\n引言：数据库的Join原理\n\n\n\n\n\n\n基本的Join算法主要有三种基本的Join算法，各种数据库的Join只是对这三种Join的优化和补充：\n\nNested Loop Join (嵌套循环Join)\nHash Join\nSort Merge Join\n\nNested Loop Join\n最简单的关联方式，嵌套循环\n\n假设有表R、表S，那么 R Left join S的本质就是双层for循环，如下伪代码：\nfor (r : R) &#123;    for (s : S) &#123;        if (r satisfy condition s) &#123;            output &lt;r, s&gt;;        &#125;    &#125;&#125;\n所以此种方式，我们需要：读取R表 + R的行数*S表\nHash Join\n在Nested Loop Join的基础上，可以将较小的一个表存入hash，加快遍历速度\n\nhashTable = buildHashTable(S);for (r : R) &#123;    if (hashTable.containsKey(r.joinKey)) &#123; // 根据Join key建立hash表        output &lt;r, s&gt;;    &#125;&#125;\n所以此种方式，我们需要：读取R表 + S表\nSort Merge Join\n将两张表排序，然后各有一个指针分别开始从头遍历，遇到相同join key就输出，适用于具有相同排序键的两个表\n\n// 从小到大排序sortedR = sort(R);sortedS = sort(S);i, j = 0;while (i &lt; ortedR.length &amp;  j &lt; sortedS.length) &#123;    r = ortedR[i];    s = ortedS[j];    if (r.joinKey == s.joinKey) &#123;        output &lt;r, s&gt;    &#125; else (r.joinKey &lt; s.joinKey) &#123;        i++;    &#125; else (r.joinKey &gt; s.joinKey) &#123;        j++;    &#125;&#125;\n所以此种方式，我们需要：读取R表 + 排序R表 + 读取S表 + 排序S表\nMysql中的Join驱动表与被驱动表在介绍Mysql的Join之前，需要先了解驱动表和被驱动表两个概念\n\n驱动表（Driving Table）： 驱动表是在连接操作中先被访问的表。它是整个查询执行的起点，驱动表的每一行都会尝试与被驱动表的相应行进行匹配。在嵌套循环连接（Nested Loop Join）中，驱动表的每一行都会作为外层循环的一部分，执行内层循环以与被驱动表进行匹配。\n被驱动表（Driven Table）： 被驱动表是在连接操作中后被访问的表。在嵌套循环连接中，被驱动表的每一行都会被用于与驱动表进行匹配。\n\n可以说驱动表是真正执行时意义上的“外表”，被驱动表是真正意义上的“内表”\n\n到底哪一个表是驱动表呢？参考文章：https://blog.csdn.net/u010134642/article/details/134045154\n\n在没有where条件时，驱动表的选择逻辑如下：\n\nInner Join：优化器会先将小表作为驱动表，大表作为被驱动表\nLeft join：左表是驱动表\nRight join：右表是驱动表\n\n在有where条件时，驱动表的选择逻辑如下：\n\nInner Join：与之前相同，优化器会先将小表作为驱动表，大表作为被驱动表\nLeft join：\n没有where条件，左表是驱动表；\n有where条件：\nwhere字段有索引：使用where字段所在的表\nwhere字段没有索引：左表\n\n\n\n\nRight join：同理left join\n\n对于Nested Loop Join来说，驱动表的每一行都要去遍历一遍被驱动表，因此驱动表尽量要小，会减少计算量而且要给被驱动表建立索引，驱动表的索引是不会使用的\nIndex Nested Loop Join如果关联键是被驱动表的索引键，内层遍历会优化为通过索引查询将驱动表的每一行与被驱动表进行匹配。\n\n这样做的好处是什么呢？\n\n当内层表是索引查询时，由于B+树最多有3~4层，因此查询的I/O消耗其实是比较稳定的所以一般会选择小表作为驱动表（载入内存占用小），然后大表作为被驱动表（查询消耗稳定）\nBlock Nested Loop Join当关联键不是被驱动表的索引，且版本在V8.0.20之前的非等值查询时，会使用这种方式：与基本的Nested Loop Join的区别是，引入了一个Join buffer，与Index Nested Loop Join的区别是，提出了一个Block的概念：所谓Block就是将驱动表划分为各个“块”，然后每次匹配一个Block，这样可以减少IO次数（划分块后确实非常适合于非等值查询）\nHash Join关于hash join参考：https://cloud.tencent.com/developer/article/1684046v8.0.20开始全面使用HashJoin取代Block Nested Loop JoinMysql中的HashJoin的具体实现由两部分组成：\n\n建表 build：遍历表，使用hash函数计算连接键构建哈希链表\n探测 probe：遍历另一个，根据连接键计算hash值找到对应的桶\n\n注意：hash join 一般会选择比较小的表作hash表，不一定会选择驱动表\n\nInner Join：选择小表建立哈希表\nLeft join：选择右表建立哈希表\nRight join：选择左表建立哈希表\n\n因此hash join中LEFT JOIN时，尽量使用大表join小表\nMysql中Join的选择策略\n当关联键是索引：\nIndex Nested Loop Join\n\n\n当关联键不是索引：\nV8.0.20之前：\n等值查询：Hash Join\n非等值查询：Block Nested Loop Join\n\n\nV8.0.20之后：Hash Join\n\n\n\nHive中的Join见文档\n\n关于关系型数据库和非关系型数据库的Join原理有所区别：\n\n关系型数据库一般是为了获得某一个数据，比如今日最受欢迎的网站是哪一个（依赖于索引）\n非关系型数据一般是为了数据分析，需要获得某一组数据的结果，比如今日最受欢迎的网站分别属于哪些年龄段的人（全表扫描）\n\n\nSpark中的Join数据库有三种join：\n\nNested Loop join：最基本的JOIN策略（它会循环遍历第一个表的每一行，然后对于每一行，再循环遍历第二个表的所有行，以查找匹配的行），嵌套循环join（匹配n*n次）\nSort merge join：排序后匹配join，开销为O(nlogn)+O(n)，跟排序算法有关\n在Mysql中，SMJ的排序算法是归并排序（因为Mysql一般都是单机运行，且数据库系统一般关注稳定性，因此归并算法这种稳定算法比较适合，稳定指相同值的元素在排序前后顺序一致）\n在Spark中，SMJ的排序算法是快速排序（Spark是分布式计算引擎，因此快排这种原地排序算法更好，而且快排的速度很快）\n\n\nHash join：按hash分区后，每个分区内双层循环匹配，拆分分区后每个分区内匹配次数较少（3030 vs 1010 + 1010 + 1010）\n在哈希连接中，系统会为连接条件中的每个表构建哈希表，然后将两个表的哈希表进行匹配，以找到匹配的行\n\n\n\n大数据机器间的数据交互形式：\n\nbroadcast：即广播，driver端发送小表到每个executor上，此过程主要开销是网络io，以及executor的内存占用\nshuffle：洗牌，会经历按Hash（hash值mod分区数，得到一个值并发往相应分区）或Range（采样后按照采样分布重分区，尽可能让数据均匀）拆分数据得到分片，对应分片发往对应下游机器再进行处理的过程，此过程中重点是让数据分布均匀，否则会产生数据倾斜（单个节点数据量过大，处理时间过长，出现长尾效应）\n\n\nPS：shuffle是个比较重的动作：涉及到重分区以及大量的网络io开销，若数据量过大不够在内存中完全处理，还会落盘，涉及到磁盘io开销\n\n结合起来就是spark的五种join：\n\n适用等值join：broadcast hash join、shuffle hash join 、shuffle sortmerge join\n适用于非等值join：cartesian product join、broadcast nested loop join\n只是先机器之间怎么交互数据，再本地怎么匹配的问题\n\nBroadcast hash join也叫Map Join\n\n对于场景：大表Join小表，且是等值join的情况我们可以将小表广播，这样可以避免shuffle\n\n原理：driver 先把广播表（小的那一个表） collect， 然后分发到各 exectuor。exctuor 里面进行 hash join，这样规避了 shuffle\n（其实就是每一个executor除了大表的数据，还要存储小表的数据）\n使用这种方法的要求是：\n\n对driver、executor需要有足够的内存，广播的表要尽量小（表不能超过8G）\n只支持等值连接\n不支持 full outer join\n\n如何开启广播？ 方法一：使用hint（提示）【推荐】\n SELECT /*+ BROADCAST(r) */ * FROM records r JOIN src s ON r.key = s.key-- BROADCASTJOIN也可以是MAPJOIN，如果广播hint对两表都写了，spark自动选择小表生效\n方法二：设置参数，当某表小于此阈值，就会自动更改执行计划，spark会进行统计信息（但在统计信息出来前，不会进行广播，因此还是方法一比较好）\nspark.sql.autoBroadcastJoinThreshold = 10485760 --(默认10M，-1代表关闭)-- AQE开启时：spark.sql.adaptive.autoBroadcastJoinThreshold --（3.2.0版本新加参数，默认等于spark.sql.autoBroadcastJoinThreshold）\n\nshuffle hash join原理：没有避免两表的shuffle read，但是选择对小表构建hashmap，join时从hashmap读取数据比如我们按照a.sex=b.sex进行检索，他会进行如下的过程：\n\n在两端按照sex这个字段进行重分区，没有避免shuffle，原因是需要把相同sex的数据传输到同一个分区\n然后对较小的表建立一个hashmap，然后使用大表的分区数据去映射这个hashmap获取数据\n\n使用这种方法的要求是：\n\n构建 hashmap 也需要消耗内存，因此如果较小的表也很大，有可能会发生oom\n构建 hashmap 的耗时与 sort 耗时比较\n仅支持等值连接\n不支持 full outer join\n\n如何开启：   方法一：提示\nSELECT /*+ SHUFFLE_HASH(s) */ * FROM records r JOIN src s ON r.key = s.key\n\n方法二：将默认使用Sort Merge Join关闭\nspark.sql.join.prefersortmergeJoin = false -- 默认为true\n方法三：AQE，当每个分区大小小于下面的阈值时，AQE 自动更改执行计划为 SHJ，此时不管 spark.sql.join.prefersortmergeJoin 的值\n-- spark 3.2.0 后：spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold = 0 --（默认0）-- 并且阈值设定要大等于 ：spark.sql.adaptive.advisoryPartitionSizeInBytes = 64m --（自适应优化期间shffule分区的建议大小）\n\nSort Merge JoinSpark默认的join方式：一般在两张大表进行JOIN时，使用该方式。Sort Merge Join可以减少集群中的数据传输，该方式不会先加载所有数据的到内存，然后进行hashjoin，但是在JOIN之前需要对join key进行排序。Sort Merge Join主要包括三个阶段：\n\nShuffle Phase：两张大表根据Join key进行Shuffle重分区\nSort Phase：每个分区内的数据进行排序\nMerge Phase：对来自不同表的排序好的分区数据进行JOIN，通过遍历元素，连接具有相同Join key值的行来合并数据集\n\n要求：\n\n只支持等值链接\n支持所有的join\nJoin的key需要排序\n默认的join方式\n\nCartesian Join如果 Spark 中两张参与 Join 的表没指定join key（ON 条件）那么会产生 Cartesian product join，这个 Join 得到的结果其实就是两张行数的乘积。\nBroadcast Nested Loop Join该方式是在没有合适的JOIN机制可供选择时，最终会选择该种join策略。优先级为：Broadcast Hash Join &gt; Sort Merge Join &gt; Shuffle Hash Join &gt; cartesian Join &gt; Broadcast Nested Loop Join在Cartesian 与Broadcast Nested Loop Join之间，如果是内连接，或者非等值连接，则优先选择Broadcast Nested Loop策略，当是非等值连接并且一张表可以被广播时，会选择Cartesian Join。\n\n支持等值和非等值连接\n支持所有的JOIN类型，主要优化点如下：\n当右外连接时要广播左表\n当左外连接时要广播右表\n当内连接时，要广播左右两张表\n\n\n\n","categories":["数据库"],"tags":["数据库"]},{"title":"枚举类","url":"/2020/02/27/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%9E%84/%E6%9E%9A%E4%B8%BE%E7%B1%BB/","content":"\n    引言：枚举类；补充了一些额外知识点\n\n\n\n枚举类为什么要使用枚举类？\n安全性（使用枚举类不会被反射获取，不可以与其他类型的值进行比较，防止错误）\n易读性（枚举类比原本使用数字可以携带更多的信息，尤其是在日志记录时，更加容易）\n\nEnum类的核心API所有枚举类，默认继承自java.lang.Enum类，该类有以下几个方法\nString name() //返回枚举类常量的名称（即指定的String）String toString() //返回枚举类常量的名称int ordinal()//返回枚举常量的序数，取决于创建枚举类的位置\n\n注意：\n\n尽量使用name()方法来返回字符串等效串，而不去使用toString\n\n\n为什么要使用name()？\n\n因为你不能保证toString没有被重写！\n导致此枚举类在序列化时有可能使字符串失去等效性，而使用name()就没有这种情况\n一个枚举的Demopublic enum Color &#123;    RED(&quot;红色&quot;, 1),    GREEN(&quot;绿色&quot;, 2),    BLANK(&quot;白色&quot;, 3),    YELLO(&quot;黄色&quot;, 4); // 注意使用分号隔开    // 成员变量    private String name;    private int index;    // 构造方法，默认就是私有的，枚举类不允许外部创建    private Color(String name, int index) &#123;        this.name = name;        this.index = index;    &#125;    //覆盖方法    @Override    public String toString() &#123;        return &quot;Color&#123;&quot; +                &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; +                &quot;, index=&quot; + index +                &#x27;&#125;&#x27;;    &#125;&#125;\n\n测试一下API会返回什么？\nColor color = Color.BLANK;System.out.println(color.name()); // BLANKSystem.out.println(color.toString()); // Color&#123;name=&#x27;白色&#x27;, index=3&#125;System.out.println(color.ordinal()); // 2\n\n\n\n枚举类的特点\n枚举类继承自java.lang.Enum（因此枚举类不能继承其他类，但是可以实现接口）\n无法使用new创建实例（因为构造方法是私有的）\n定义的每个实例都是引用类型的唯一实例（唯一一个安全的构造单例模式的方法）\n可以在switch语句中使用\n\n枚举类的本质我们自己建立的枚举类\npublic enum Weekday &#123;    SUN, MON, TUE, WED, THU, FRI, SAT;&#125;\n在被编译器编译后是这样\npublic final class Weekday extends Enum &#123; // 继承自Enum，标记为final class    // 每个实例均为全局唯一:    public static final Weekday SUN = new Weekday();    public static final Weekday MON = new Weekday();    public static final Weekday TUE = new Weekday();    public static final Weekday WED = new Weekday();    public static final Weekday THU = new Weekday();    public static final Weekday FRI = new Weekday();    public static final Weekday SAT = new Weekday();        // private构造方法，确保外部无法调用new操作符:    private Color() &#123;&#125;&#125;\n由于ordinal()方法依赖于排序树，所以改变枚举类常量的顺序就会发生变化，不利于程序的鲁棒性\n建议枚举类代码写为\npublic enum Weekday &#123;    SUN(0), MON(1), TUE(2), WED(3), THU(4), FRI(5), SAT(6);    public final int dayValue;    //这里建议使用final修饰    Weekday(int dayValue) &#123;        this.dayValue = dayValue;    &#125;&#125;\n判断枚举常量的名字，要始终使用name()方法，绝不能调用toString()！\n在switch语句中使用switch()语句支持的类型有：byte char short int及其包装类、以及枚举类和String\n有关switch这方面推荐博客CSDN博主 由零开始Leon\nWeekday day = Weekday.SUN;switch(day) &#123;case MON:case TUE:case WED:case THU:case FRI:    System.out.println(&quot;Today is &quot; + day + &quot;. Work at office!&quot;);    break;case SAT:case SUN:    System.out.println(&quot;Today is &quot; + day + &quot;. Work at home!&quot;);    break;default:    throw new RuntimeException(&quot;cannot process &quot; + day);\n\n枚举的values()方法枚举类都有一个values方法，但注意，这个方法并不来自父类Enum，而是编译器增加的一个方法\n\nThe compiler automatically adds some special methods when it creates an enum. For example, they have a static values method that returns an array containing all of the values of the enum in the order they are declared. （Oracle官方文档）\n翻译：编译器在创建enum时，会自动添加一些方法。比如values静态方法，会返回一个该枚举类型的数组\n\n工作中经常会遇到一个枚举类，需要通过Int获取他的String（或是相反）的情况，这里给出一个模板：\npublic enum EnumTemplate &#123;    CREATE(0,&quot;create&quot;),    TOUCH(1,&quot;touch&quot;),    SUBMIT(2, &quot;submit&quot;);        private String tag;    private Integer id;    EnumTemplate(Integer id, String tag) &#123;        this.tag = tag;        this.id = id;    &#125;    /**     * 通过int获取String（普通写法）     */    public static String getNameById(Integer id)&#123;        for (EnumTemplate value : values()) &#123;            if(value.id.equals(id))&#123;                return value.tag;            &#125;        &#125;        return &quot;&quot;;    &#125;    /**     * 通过String获取int（流式写法）     */    public static Integer getIdByName(String name)&#123;        return Arrays.stream(values())                .collect(Collectors.toList())                .stream()                .filter(x -&gt; name.equals(x.tag))                .map(EnumTemplate::getId)                .findFirst().orElse(0);    &#125;    public String getTag() &#123;        return tag;    &#125;    public Integer getId() &#123;        return id;    &#125;&#125;\n\n注意：工作强烈建议使用普通方法而不是流式写法，效率差太多了（差距一百多倍）。\n枚举的更多写法接口的内部枚举有时候我们会遇到这种情况，枚举有了分类，比如：腾讯有QQ与微信，QQ有QQ登录的和平精英、王者荣耀，微信同样也有，但是我们想用枚举标识这两种不同的账号，我们可以如此创建这个枚举类。\n同一个接口Tencent下，实现了两个枚举类：\npublic interface Tencent &#123;    enum WX&#123;        WX_WZRY(0, &quot;王者荣耀&quot;),        WX_HPJY(1, &quot;和平精英&quot;);        private Integer id;        private String name;        WX(Integer id, String name) &#123;            this.id = id;            this.name = name;        &#125;        public Integer getId() &#123;            return id;        &#125;        public String getName() &#123;            return name;        &#125;    &#125;    enum QQ&#123;        QQ_WZRY(0, &quot;王者荣耀&quot;),        QQ_HPJY(1, &quot;和平精英&quot;);        private Integer id;        private String name;        QQ(Integer id, String name) &#123;            this.id = id;            this.name = name;        &#125;        public Integer getId() &#123;            return id;        &#125;        public String getName() &#123;            return name;        &#125;    &#125;&#125;\n\n在调用时，我们需要通过接口名调用，才能拿到想要的数据：\nTencentEnum.WX.WX_HPJY.getName();\n\n接口实现抽象方法枚举类可以有抽象方法，并且需要在实例中实现。\n假设现在需要给和平精英的玩家发红包，但是发的个数不同，就可以这么写：\n（但这种写法具体有什么好处，有待考究）\npublic enum TencentEnum2 &#123;    WX_HPJY(0, &quot;和平精英&quot;)&#123;        private final Integer num = 100;        @Override        public int sendHongBao() &#123;            return num;        &#125;    &#125;,    QQ_HPJY(1, &quot;和平精英&quot;)&#123;        private final Integer num = 1;        @Override        public int sendHongBao() &#123;            return num;        &#125;    &#125;,    WX_WZRY(2, &quot;王者荣耀&quot;)&#123;        @Override        public int sendHongBao() &#123;            return 0;        &#125;    &#125;;    private Integer id;    private String name;    abstract public int sendHongBao();    TencentEnum2(Integer id, String name) &#123;        this.id = id;        this.name = name;    &#125;&#125;\n\n\n参考材料： 廖雪峰官方网站官方APICSDN博主 由零开始Leon\n\n","categories":["Java","Enum"],"tags":["Enum"]},{"title":"字符编码","url":"/2020/02/20/%E5%BA%8F%E5%88%97%E5%8C%96/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/","content":"\n    引言： 字符编码\n\n\n\n\n字符编码在早期的计算机系统中，为了给字符编码，美国国家标准学会（American National Standard Institute：ANSI）制定了一套英文字母、数字和常用符号的编码，它占用一个字节，编码范围从0到127，最高位始终为0，称为ASCII编码。\n例如，字符A的编码是0x41，字符1的编码是0x31。\nASCII是能表示英文了，但是中文、日文、韩文怎么办？\n\n但是，如果要把汉字也纳入计算机编码，很显然一个字节是不够的。各个国家都有了自己的标准。\nGB2312标准使用两个字节表示一个汉字，其中第一个字节的最高位始终为1，以便和ASCII编码区分开。例如，汉字中的GB2312编码是0xd6d0。\n类似的，日文有Shift_JIS编码，韩文有EUC-KR编码，这些编码因为标准不统一，同时使用，就会产生冲突。\n那各个国家交流不就乱套了吗\n\n为了统一全球所有语言的编码，全球统一码联盟发布了Unicode编码，它把世界上主要语言都纳入同一个编码，这样，中文、日文、韩文和其他语言就不会冲突。\nUnicode编码需要两个或者更多字节表示，我们可以比较中英文字符在ASCII、GB2312和Unicode的编码：\n英文字符’A’的ASCII编码和Unicode编码：\n         ┌────┐ASCII:   │ 41 │         └────┘         ┌────┬────┐Unicode: │  00│ 41 |         └────┴────┘\n英文字符的Unicode编码就是简单地在前面添加一个00字节。\n中文字符’中’的GB2312编码和Unicode编码：\n         ┌────┬────┐GB2312:  │ d6 │ d0 │         └────┴────┘         ┌────┬────┐Unicode: │ 4e │ 2d │         └────┴────┘\n\n那我们经常使用的UTF-8又是什么编码呢？\n因为英文字符的Unicode编码高字节总是00，包含大量英文的文本会浪费空间，所以，出现了UTF-8编码，\n它是一种变长编码，用来把固定长度的Unicode编码变成1～4字节的变长编码。\n通过UTF-8编码，英文字符A的UTF-8编码变为0x41，正好和ASCII码一致，而中文’中’的UTF-8编码为3字节0xe4b8ad。\nUTF-8编码的另一个好处是容错能力强。如果传输过程中某些字符出错，不会影响后续字符，因为UTF-8编码依靠高字节位来确定一个字符究竟是几个字节，它经常用来作为传输编码。\nJava和编码在Java中，char类型实际上就是两个字节的Unicode编码。如果我们要手动把字符串转换成其他编码，可以这样做：\nbyte[] b1 = &quot;Hello中&quot;.getBytes(); // 按系统默认编码转换，不推荐/* 查看系统默认的编码    System.out.println(Charset.defaultCharset());*/byte[] b2 = &quot;Hello中&quot;.getBytes(&quot;UTF-8&quot;); // 按UTF-8编码转换byte[] b3 = &quot;Hello中&quot;.getBytes(&quot;GBK&quot;); // 按GBK编码转换byte[] b4 = &quot;Hello中&quot;.getBytes(StandardCharsets.UTF_8); // 按UTF-8编码转换System.out.println(Arrays.toString(b1));// 按系统默认编码而定System.out.println(Arrays.toString(b2));//[72, 101, 108, 108, 111, -28, -72, -83]System.out.println(Arrays.toString(b3));//[72, 101, 108, 108, 111, -42, -48]System.out.println(Arrays.toString(b4));//[72, 101, 108, 108, 111, -28, -72, -83]\n如果要把已知编码的byte[]转换为String，可以这样做：\nString s1 = new String(arr, &quot;GBK&quot;); // 按GBK转换String s2 = new String(arr, StandardCharsets.UTF_8); // 按UTF-8转换\n始终牢记：Java的String和char在内存中总是以Unicode编码表示。\nString类的演变对于不同版本的JDK，String类在内存中有不同的优化方式。\n具体来说，早期JDK版本的String总是以char[]存储，它的定义如下：\npublic final class String &#123;    private final char[] value;    private final int offset;    private final int count;&#125;\n而较新的JDK版本的String则以byte[]存储：如果String仅包含ASCII字符，则每个byte存储一个字符，否则，每两个byte存储一个字符，这样做的目的是为了节省内存，因为大量的长度较短的String通常仅包含ASCII字符：\npublic final class String &#123;    private final byte[] value;    private final byte coder; // 0 = LATIN1, 1 = UTF16&#125;\n\n对于使用者来说，String内部的优化不影响任何已有代码，因为它的public方法签名是不变的。\n小结\nJava内存中使用Unicode表示char和String\n转换编码就是将String和byte[]转换，需要指定编码\n转换为byte[]时，始终优先考虑UTF-8编码。\n\n改编自廖雪峰的官方网站，原文链接\n","tags":["字符编码"]},{"title":"IO多路复用","url":"/2024/04/26/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","content":"\n    引言：select、poll、epoll模型\n\n\n\n\nIO多路复用这篇文章再复习一下select、poll、epoll，三种最经典的IO多路复用模型，是NIO实现的基础。\n他们模型共同点都是轮训文件描述符，区别在于具体的一些实现的细节。下面给出具体的区别：\nselectselect模型的实现主要如下：\nint select(    int maxfdp1,    fd_set *readset,    fd_set *writeset,    fd_set *exceptset,    const struct timeval *timeout)\n\n主要是两个结构：\n\nmaxfdp1：待轮训的文件描述符的个数。\nfd_set：分别表示读事件、写事件、异常事件；一个bitmap，长度只有1024位。\n\n缺点：\n\nfd数量有限制，最多只有1024个\n每次轮训，都需要copy 3个fd到内核，存在频繁的用户态和内核态的copy\nfd_set不能重用\n每次遍历都得遍历所有的fd\n\npollstruct pollfd &#123;　　int    fd; // 要轮询的文件描述符fd　　short  events; // 关心的fd事件：普通数据可读、优先级带数据可读等等　　short  revents;// fd上发生的事件&#125;;\n\npoll主要改进了两点：\n\n引入了pollfd结构体，不再局限于1024个\npollfd可以重用\n\n缺点：\n\n依然需要频繁的用户态和内核态的copy\n需要遍历所有的pollfd\n\nepollepoll模型由三个函数构成：\n\nepoll_create：创建epollfd对象\nepollfd对象主要由两个结构组成\n红黑树：存储关心的fd\n双向链表：存储发生相关事件的fd（关心事件触发，就会自动填入这个双向链表）\n\n\n\n\nepoll_ctl：将epollfdcopy到内核，并注册关心的事件\n将copy过程提前到此阶段，而且在整个轮训过程中，只需要copy这一次！\n关心事件的触发方式有两种\n水平触发LT（默认）：事件可处理可不处理\n边缘触发 ET：事件必须处理\n\n\n\n\nepoll_wait：调用系统调用，陷入内核等待\n\n因此，前面select、poll的缺点就全被搞定了：\n\n1024上限？不再有了，我们有epollfd对象\n每次轮训所有？不轮训所有，只轮训事件触发的对象\n每次都需要用户态与内核态的copy？只需要在epoll_ctl时copy一次即可\n\n\n问题一：水平触发和边缘触发的区别是什么？\n\n水平触发情况下，如果事件没有处理，那么下次epoll_wait依然会返回这个事件的fd；\n边缘触发情况下，如果没有立即处理，那么下一次的返回不一定会有该事件，只能等到该事件再次触发。\n因此：\n\n水平触发适用于处理长时间处于可读或科协的socket\n边缘触发更适合于要求效率更高的前提下\n\n\n问题二：select、poll 与 epoll的区别是什么？\n\n\nselect、poll：都是主动轮训\nepoll：被动轮训，所谓被动轮训指的是当数据准备好之后，就会把就绪的fd加入双向链表中（存在一个回调函数，触发就会加入到双向队列）\n\n","categories":["操作系统"],"tags":["操作系统"]},{"title":"cache高速缓存","url":"/2021/10/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/cache%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/","content":"\n    引言：进一步理解CPU缓存，理解CPU与缓存的协作\n\n\n\n\nCache高速缓存\n这一节的内容主要介绍Cache，涉及到的相关知识可以看此篇，比如：\n\n局部性原理\nSRAM的结构\n\n\n几个问题，引入今天的Cache\n为什么引入了Cache？\n引入Cache带来了什么问题？\n如何解决Cache带来的问题？\n\n第一个问题应该很好回答，此篇的目的是记录后两个问题。\nCacheCache的设计结构Cache由三部分组成：\n\n高速静态储存器\nSRAM，一种十分稳定的存储结构（使用6个晶体管，访问速度是DRAM的十倍，常用在cache）\n\n地址转换模块\n\nCache行替换模块\nCache中有一些标志位（脏位、回写位、访问位），Cache行替换模块的目的就是根据这些标志位进行相关操作\n\n\n\nCache与内存之间的交流\n\nCache与内存交换数据的最小单位是一行（一行通常为32字节或是64字节）\n而且，Cache的很多行形成一组\n工作流程CPU发来的地址，到达Cache会经过以下步骤：\n\n地址转换模块将CPU发来的地址转换为三部分：组号、行号、行内偏移\n\nCache根据组号、行号查找cache中对应的行\n\n读操作\n\n命中：根据行内偏移，返回数据即可\n没有命中：分配一个新行，并访问内存，把从内存访问到的数据家载入Cache返回给内存\n\n\n写操作（分为两种）\n\n回写：写入Cache行就结束\n直通写：写入Cache行并且写入内存\n\n\n\n\n如果没有新行了，那么执行相关替换算法\n\n\n上述流程对程序员透明，全部由硬件实现\n注意：从结构中我们可以发现，Cache的流程与内存的工作流程，甚至是到Mysql、redis这些应用的缓存流程，基本一致（这也是缓存思想的广泛应用）\n三级缓存冯诺依曼结构与哈佛结构\n进入正题之前，先介绍两种计算机的设计理念\n\n两者的区别：\n\n冯诺依曼结构：讲求数据与指令混装\n哈佛结构：数据与指令分开装\n\n基于冯诺依曼结构的计算机，设计简单，而且对硬件的要求也简单；\n基于哈佛结构的计算机，运行速度快，主要有两个优点：\n\n可以并发的读取指令与数据（冯需要分时执行）\n由于指令通常情况下不会动态修改，而数据则需要频繁的修改，因此可以进一步优化指令Cache的设计（冯需要全部重新载入）\n\n\n为什么我要引入两种计算机的结构设计思想？\n\n​        因为平常我们用到的计算机，其实大体都是基于冯诺依曼的设计理念，对于嵌入式的设备来说，哈佛结构更受欢迎\n​        而在Cache的设计中，L1 cache就使用了哈佛结构这种设计思想，整体上来看cache其实还是冯诺依曼的设计思想\n三级缓存的结构现代CPU将Cache分为三级，如图：\n\n这是一个双核心的CPU，三级缓存等级不同：\n\n一级缓存：指令与数据分开（如图：指令Cache与数据Cache）\n指令进入指令Cache，指令涉及到的数据进入数据Cache\n\n\n二级缓存：CPU核心独占\n三级缓存：核心之间共享\n\n\n三级缓存带来的问题：\n\n​        使用缓存，就会带来缓存一致性问题，CPU设计了三级缓存，就涉及到了三种缓存一致性问题\n（CPU 的 L3 Cache 与设备内存，如 DMA、网卡帧储存，显存之间的一致性问题此处不进行讨论）\n指令Cache与数据Cache的缓存一致性问题一级缓存：将指令与数据分开存储，就涉及到了缓存一致性问题\n\n怎么样会出现？\n\n可能存在这么一种情况：\nCPU执行指令1 + 地址A ，去执行地址A所在的指令2，但是某些自修改程序（可以修改运行中代码指令数据）就改为了新的指令（即将地址A的代码修改为指令3）\n但是修改指令也需要CPU，因此CPU会将修改后的新的指令(指令3)放在数据缓存（注意，此时指令缓存还是旧的指令（指令2））\n此时如果执行，那么有可能运行的还是旧的指令\n因此存在指令Cache与数据Cache缓存一致性问题\n\n如何解决？\n\n对于这种情况，需要先将数据Cache的数据写回内存，并让指令Cache无效，重新去加载内存中的数据\n核心与L2 Cache的缓存一致性问题L2 Cache是一个CPU核心独占的，L3是核心之前共享的；\n但是读取相同的数据，是不需要走一遍L3-&gt;L2-&gt;l1的流程的\n硬件上实现了：对于核心1已经读取的数据可以直接复制到核心2的L2、L1中\n\n怎么出现缓存一致性问题？\n\n​        核心1修改了指令，但是核心2拷贝的是旧的指令\n\n如何解决？\n\n​        通过缓存一致性协议，比如MESI\n缓存一致性协议——MESI\nMESI：定义了四种基本状态\n\n\nM（Modified）已修改\nE（Exclusive）独占\nS（Shared）共享\nI（Invalid）无效\n\n举个栗子：\n\n最开始只有一个核读取了A数据，此时状态为E独占，数据是干净的；\n\n后来另一个核又读取了A数据，此时状态为S共享，数据还是干净的；\n\n接着其中一个核修改了数据A，数据变脏，此时会向其他核广播数据已被修改，让其他核的数据状态变为I失效\n\n而本核的数据还没回写内存，状态则变为M已修改\n\n等待后续刷新缓存后，数据变回E独占，其他核由于数据已失效，读数据A时需要重新从内存读到高速缓存，此时数据又共享了\n\n\n缓存实战开启缓存x86 CPU 上默认是关闭 Cache 的，需要在 CPU 初始化时将其开启\n开启的方式：只需要将CR0寄存器的CD、NW位同时清理即可\n\nCD=1表示Cache关闭\nNW=1表示CPU不维护内存数据一致性\n\nmov eax, cr0;开启 CACHE    btr eax,29 ;CR0.NW=0btr eax,30  ;CR0.CD=0mov cr0, eax\n\n获取可以读写的内存对于程序员来说，最主要的目的，就是想知道哪块内存还可以使用\n我们可以直接调用BIOS实模式下的中断服务即可\n中断服务是int 15h，但是它需要一些参数\n_getmemmap:  xor ebx,ebx ;ebx设为0  mov edi,E80MAP_ADR ;edi设为存放输出结果的1MB内的物理内存地址loop:  mov eax,0e820h ;eax必须为0e820h  mov ecx,20 ;输出结果数据项的大小为20字节：8字节内存基地址，8字节内存长度，4字节内存类型  mov edx,0534d4150h ;edx必须为0534d4150h  int 15h ;执行中断  jc error ;如果flags寄存器的C位置1，则表示出错  add edi,20;更新下一次输出结果的地址  cmp ebx,0 ;如ebx为0，则表示循环迭代结束  jne loop  ;还有结果项，继续迭代    reterror:;出错处理\n\n每次中断都输出一个 20 字节大小数据项，最后会形成一个该数据项（结构体）的数组\n#define RAM_USABLE 1 //可用内存#define RAM_RESERV 2 //保留内存不可使用#define RAM_ACPIREC 3 //ACPI表相关的#define RAM_ACPINVS 4 //ACPI NVS空间#define RAM_AREACON 5 //包含坏内存typedef struct s_e820&#123;    u64_t saddr;    /* 内存开始地址 */    u64_t lsize;    /* 内存大小 */    u32_t type;    /* 内存类型 */&#125;e820map_t;\n\n\n\n\n\n\n\n\n\n\n\n\n\n","categories":["操作系统"],"tags":["操作系统","CPU","cache"]},{"title":"Java的面向对象","url":"/2019/08/09/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%9E%84/Java%E7%9A%84%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":"\n引言：Java如何面向对象？\n\n\n\n\n\n面向对象从C到Java，认识面向过程 到 面向对象的转变\n不再注重所有功能从小到大的完善开发\n四大特性面向对象四大特性：封装、继承、多态、抽象\n（也有版本说三大特性，将抽象去掉）\n\n抽象性：将实体的一些共同特性抽取出来，封装在一个新的概念类中\n\n类，就是一种抽象\n\n\n封装性：可以理解为一个黑箱，我们只需要知道他能干什么，而不需要知道他怎么去干的，这样编程思想就是封装\n\n方法就是一种封装\nprivate也是一种封装\n\n\n继承性：子可以遗传一些父的特性，能减小代码和数据的冗余度，大大增加程序的重用性\n\n是多态性的前提\n子类拥有父亲的非私有成员\n子类可以拥有自己的方法\nJava的继承是单继承，直接的父类只可以有一个\n\n\n多态性：多态就是通过传递给父类对象引用不同的子类对象从而表现出不同的行为\n\nimplements实现接口，就是多态的一种体现\n重载、重写都是多态性思想的体现\n\n\n\n类创建一个类的对象NewClass x = new NewClass();//对象名 变量名 = new关键字 对象名();\n调用子类的变量或者方法：\nNewClass x = new NewClass();//创建一个对象int temp = x.y;//通过对象名调用子类的变量x.alert();//通过对象名调用子类的方法\n\n一个标准的类(Java Bean):\n所有成员变量都用private修饰\n每一个变量都有set/get方法\n一个无参构造\n一个有参构造\n\n成员变量和局部变量的区别\n定义的位置不同：局部变量在方法内部，成员变量在方法的外部，直接在类中\n作用范围不同：局部变量只能在方法内部使用，出了方法则不能使用，整个类内都可以使用\n默认值不同：局部变量没有默认值，而成员变量默认会有初始值\n位置不同：局部变量在栈中，成员变量在堆内存\n生命周期不同：局部变量入栈建立，出栈消失；成员变量随对象的建立而建立，随其消失而消失\n\nthis指针当方法的局部变量和成员变量重名时，根据就近原则，优先使用局部变量；如果要访问成员变量，要用this.XXX;\n\nthis 其实就是调用者自己本身\n\n作用：\n\n重名的情况下起到区分的效果\n访问本类的内容\n还可以调用自己的构造方法\n\n构造方法特点：\n\n名称和类名一样\n无函数类型，无返回值\n有默认的构造函数（编写了构造函数则无默认的构造函数）\n可以重载\n\n\n继承关系中的构造方法：\n\n子类构造方法当中，有一个默认隐含的super()调用，所以一定是先调用父类构造，再调用子类构造\n可以通过super关键字来调用父类重载构造\nsuper的父类构造调用，必须是子类构造方法的第一个调用\n只有子类的构造方法才能调用父类构造方法\n\n匿名对象NewClass x = new NewClass();//普通的创建对象new NewClass()//创建匿名对象\n注意： 匿名对象只能使用唯一的一次\n使用建议：如果确定有一个对象只需要使用唯一的一次，情况如下\n\n当需要记录一次数据的时候\nint sum1 = new Scanner(System.in).nextInt();\n使用匿名对象传递参数\npublic static void main(String[] args) &#123;    Method(new Scanner(System.in));&#125;public static void Method(Scanner sc) &#123;&#125;\n返回匿名参数\n public static Scanner Method(Scanner sc) &#123;    return new Scanner(System.in);&#125;\n合理使用匿名参数，大大简洁代码\n\n\n","categories":["Java"],"tags":["Java"]},{"title":"XV6操作系统","url":"/2022/02/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/XV6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","content":"\n    引言：MIT-S081课程——XV6操作系统（更新ing）；包括管道、重定向的实现原理；文件描述符的作用\n\n\n\nXV6操作系统接口系统调用\n什么是系统调用？\n\n系统调用就是内核的一组API（比如open write fork），他们封装了更底层的与硬件交互的逻辑\n因此系统调用是应用程序访问内核的一种方式\n（即APP如果需要使用内核函数，就必须走内核提供的接口，也就是系统调用）\nfork因为会copy父进程内存所有的数据，因此如果你没用到与父进程内存一样的数据，在某种意义上，这是一种浪费，因此提出了写入时复制（COW ），消除fork 中几乎所有明显的延迟\nI/O与文件描述符要点\n每个进程都有专属的一套文件描述符（0、1、2、3….）：其中0、1、2分别为标准输入、标准输出、标准错误\n文件描述符这层抽象，屏蔽了文件、管道、或是设备，将他们统一看成IO来处理（这是Linux一切皆文件的原因）\nfork会copy父进程的fd表；exec虽然会替换调用者的内存，但是fd表会保留\nclose关闭fd，会返还fd资源；新分配的fd将是最小的数字\n\n重定向实现的原理重定向依托于：fork、exec、文件描述符\n比如这样的一个命令：cat &lt; input.txt（将input.txt文件的内容，作为cat命令的参数执行）\n它会这样去执行：\nchar *argv[2];argv[0] = &quot;cat&quot;;argv[1] = 0;if(fork() == 0) &#123;    close(0);    open(&quot;input.txt&quot;, O_RDONLY);    exec(&quot;cat&quot;, argv);&#125;\n\n\n创建一个参数数组：[&quot;cat&quot;, 0]（此时的0代表着标准输入）\nfork创建了一个子进程，这个子进程会copy父进程的内存，即子进程也会拥有argv这个指针以及0、1、2的文件描述符\n当fork()函数返回0，代表if的执行体让子进程去执行\n关闭了0号文件描述符，将会回收0（标准输入）的资源；之后open打开文件，这个文件描述符就是当前最小的一个数字，也就是刚刚回收的0（此时的0代表着input.txt文件的fd，注意父进程的fd表不会被改变）\nexec执行cat命令，会占用当前的内存，即会替换子进程的内存，去执行cat命令\n\n如此就完成了重定向，fork+exec是一种很常见的执行命令的手段，不会影响原有的进程，且执行完命令，子进程会自动销毁\n注意：\n\nexec会调用其他程序，替换当前的内存（会把自己替换掉），没有返回值，除非出现了一些错误\n\n因此，exec执行完成后就会消失了\n所以经常使用一个fork去执行exec的程序\n\n\n文件是共享资源，因此如果有两个进程同时读一个文件，那么有一个进程会阻塞\n\n因为文件是共享资源，所以每个基础文件的偏移量在父级和子级之间共享\nint main()&#123;    if(fork() == 0)&#123;        write(1, &quot;hello&quot;, 6);    &#125;else&#123;        write(1, &quot; world\\n&quot;,7);    &#125;    // 因为父子进程共享偏移量，因此不会出现父子进程打印的值被对方覆盖的情况    printf(&quot;\\n&quot;);    return 0;&#125;\ndup系统调用也可以复制一份fd（但是偏移量还是共享的），利用这个系统调用，可以实现这样的命令：\nls a.out b.out &gt; tmp1 2&gt;&amp;1# 2&gt;&amp;1 表示用描述符2复制一份1(即 标准错误将是标准输出的一个复制)# 此时a.out 与b.out文件的错误信息，都会输出到tmp1文件中\n\n管道PIPE管道管道我的另一篇博客介绍很详细，此处做一些补充\n实现原理\n管道的实现原理\n\npipe(int p[2])：传入一个2个size的数组，调用后会分别存放管道的读端（下标0）与写端（下标1）\nint p[2];char*argv[2];argv[0] = &quot;wc&quot;;argv[1] = 0;pipe(p);// 此时的fd：0、1、2、3、4if(fork() == 0) &#123;    // 子进程此时的fd：0、1、2、3、4    close(0);// 1、2、3、4    dup(p[0]);// 0、1、2、3、4 (此后的0表示管道的读端)    close(p[0]);//0、1、2、4    close(p[1]);//0、1、2    exec(&quot;/bin/wc&quot;, argv);&#125; else &#123;    // 父进程此时的fd：0、1、2、3、4    close(p[0]); // 0、1、2、4    write(p[1], &quot;hello world\\n&quot;, 12); // 由写端写入数据 hello world    close(p[1]); // 0、1、2&#125;\n\n管道的Highlight其实就是通过dup + fork命令，改写文件描述符\n\n使用管道vs使用临时文件:\necho hello world | wc # 管道echo hello world &gt; tmp.txt; wc &lt; tmp.txt # 使用临时文件+重定向\n\n\n管道可以自动清理自己；重定向需要自己进行删除临时文件\n管道可以传输任意长的数据；而重定向需要有足够的磁盘存储临时文件\n管道可以在pipeline stage并行执行；而临时文件重定向，只能等一个执行完再去执行另一个\n如果要实现进程间通信，管道read阻塞要比文件阻塞更有意义\n\n\n名词解释 pipeline 与stage：\n一条指令的执行是被分成多个stage的，每个stage使用一个cycle，一条指令从第一个stage依次执行到结束，这个过程叫做pipeline\n\n文件系统Xv6创建文件或目录的方式创建文件有这么几种方式：\n\n以CREATE的方式OPEN文件\nmkdir创建目录\nmknod创建设备文件\n\n要点\n设备文件是一种特殊的文件mknod(char *file, int 主设备号,int 次设备号)，在进程打开一个设备文件时，内核会将read与write系统调用转移到内核设备实现，而不是递交给文件系统\n文件名与文件的含义不同。同一个底层文件称为inode；可以有多个名称，称为links\n每个link由文件名+inode的引用组成\ninode包含了文件的元数据（文件类型、长度、磁盘上的位置、link的数目）\n\n\n\nfstat系统调用可以从inode检索信息：\n#define T_DIR     1   // Directory#define T_FILE    2   // File#define T_DEVICE  3   // Devicestruct stat &#123;  int dev;     // File system&#x27;s disk device  uint ino;    // Inode number  short type;  // Type of file  short nlink; // Number of links to file  uint64 size; // Size of file in bytes&#125;;\n\nlink系统调用可以给文件一个新名称链接到这个文件上\nopen(&quot;a&quot;, O_CREATE|O_WRONLY);link(&quot;a&quot;, &quot;b&quot;);\n\nQuestion\n文件什么时候会被回收？\n\n需要同时满足两个条件:\n\n链接数为0\n没有fd被使用\n\n\n创建一个没有名称的临时inode的方法（该inode将在进程关闭时自动被清除）\n\nfd = open(&quot;/tmp/xyz&quot;, O_CREATE|O_RDWR);unlink(&quot;/tmp/xyz&quot;);\n\nXV6操作系统组成操作系统需要满足的能力\n前一章提供了很多接口函数，为什么我们需要使用操作系统呢？直接让应用程序调用硬件资源不可以吗?\n\n直接让APP调用硬件资源是可以的：在嵌入式系统及一些实时系统很常见\n\n优点：高性能（直接利用硬件资源，可以保证很高的性能）\n缺点：当APP多于硬件资源时，无法维护\n\n比如现在有五个打印机，但是只有一个CPU：\n​        你可能会说，那不能在APP级别实现共享CPU吗（时分复用）？\n​        但是APP可能会存在BUG，及时你能保证一个APP完美无缺，但是很多的APP一同运行，是无法避免BUG的，BUG的出现可能会导致资源被恶意利用。\n​        解决这个问题的一个好的办法就是，APP之间相互隔离，使用内核来控制进程之间的调度，使他们与CPU之间保持透明。\n​        但是某些程序之间需要合作来完成任务，我们就得提供他们交互的能力（管道）\n\n操作系统需要满足的能力：\n\n操作系统必须满足三个要求：\n\n多路复用：进程之间共享计算机资源（进程都可以获取到CPU、内存、磁盘资源，得到执行）\n隔离：进程之间互不影响\n交互：进程之间可以通信\n\n机器模式、监管模式、用户模式前面说了，操作系统需要保证进程之间的隔离，这个隔离必须很强（不然会被恶意利用，导致系统不安全）：\n\n一个进程的运行失败不能影响其他进程\n一个进程不能访问其他进程的地址\n进程不能改变操作系统的数据结构\n\n因此操作系统给出以下的方案：\n软件方面：（解决1与2）进程虚拟地址（此篇博客详细介绍进程空间）\n硬件方面：（解决3）硬件方面解决，比如RSIC-V指令架构给出三种模式：machine mode,supervisor mode, user mode\n\n机器模式(machine mode)：机器模式拥有全部权限（机器模式会用来装在计算机所需要的硬件，装载完成就会切换到监管模式）\n监管模式(supervisor mode)：可以运行特权指令（常说的内核态）\n用户模式(user mode)：只能运行普通指令（常说的用户态）\n\n如果一个APP需要执行系统调用，必须切换到内核态，CPU提供了特殊的指令，可以切换CPU到监管模式，进而执行内核函数（比如说RSIC-V提供的切换指令为ecall）\n一旦切换到监管模式，就可以检验参数（比如检验地址是否越界），再去判断是否要执行该命令\n内核设计\n内核设计：哪些操作应该放在监管模式下？\n\n单内核monolithic kernel：将整个操作系统全放在内核中\n好处：\n\n设计简单\n程序交互方便（可以共享缓存实现交互）\n\n缺点：\n\n如果有bug，那么整个OS都会瘫痪（致命的缺点）\n\n微内核为了降低内核出错的风险，所以设计了微内核micro kernel（最小化监管模式的代码）\n\n但这样进程之间的交互将会变得麻烦，所以提出了IPC进程间通信，如图shell如果想读写文件，需要给File Server发送消息并且等待\nLinux的实现两种设计理念都存在于Linux中。\nlinux是一个单内核（但是有些程序是运行在用户级别的，比如窗口程序），但吸取了微内核的优点——模块化\n","categories":["操作系统"],"tags":["操作系统"]},{"title":"异常控制流","url":"/2021/10/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%81/","content":"\n    引言：异常控制流，之前对异常的理解还是肤浅了\n\n\n\n\n异常控制流控制流与异常控制流\nCPU读取PC的地址运行程序，PC会存储一系列地址的值，如果这一串序列排成一串，那么这就是控制流\n\n比如：a0,a1,a2,a3...an-1\n\n从ak -&gt; ak+1的过程就称为控制转移（平滑的变化过程）\n从am -&gt; an的过程（m，n不相邻），这就称为突变（这种情况有可能是执行了程序的跳转、调用等等指令，也有可能是出现了异常）\n\n\n为什么要进行异常处理？\n\n程序要继续执行，系统就必须能对出现的任何状况进行响应：\n\n对于正常的状况，直接执行即可；\n对于正常的突变，也可以正常执行；\n但是如果出现与程序执行无关的一些突变，也需要做出响应（比如）\n一个硬件定时器定期产生信号\n包传到网卡后，必须放入内存\n\n\n\n\n这样的突变（与程序执行无关的一些突变）就称为异常控制流（Exceptional Control Flow，ECF）\n\n异常注意：本节所讲述的都是硬件级别的异常（不是Java中那种catch到的应用级别异常）\n异常的处理\n异常：是异常控制流ECF的突变，一部分由硬件实现，一部分由OS实现\n\n硬件和OS内核（软件）一同实现了这个功能，所以不同的处理器，它的异常处理过程也是不同的，但是原理基本一致\n异常处理的关键结构\n异常号：每种异常都有一个非负整数的异常号，异常号分为两部分\n\n一部分是CPU的设计者分配的（比如除零、缺页、内存访问违例、断点以及算数运算溢出）\n一部分是OS内核的设计者分配的（比如系统调用、外部的I/O信号）\n\n\n异常表：计算机启动时，OS就会分配和初始化一张称为异常表的跳转表\n\n这个表的结构如下，序号其实就是异常号，异常号就是遍历这个表的索引值\n0 |-----------------|  |处理异常程序0的代码 |1 |-----------------|  |处理异常程序1的代码 |2 |-----------------|  |处理异常程序2的代码 |   ....n |------------------|\n\n\n异常处理程序：可以看到异常表内有处理对应异常的代码，他们就是异常处理程序\n\n异常表基址寄存器：此寄存器存放了异常表的基址，通过基址寄存器+异常号，就能快速的找到处理异常的代码\n\n\n\n异常处理流程\n如何检测到异常？\n\nCPU有很多状态，这些状态表现为不同的位和信号\n如果状态发生了变化，就称为事件，CPU可以检测到这些事件的发生\n这些事件的发生后，如果其有对应的异常号，那么就是一个异常\n\n硬件与OS是如何协同处理一个异常的？\n\n\n运行时，如果发生了一个事件（引起了CPU状态（有些位或信号）的改变），就会去查是否有对应的异常号\n如果存在对应的异常号，处理器就会触发异常\n通过异常表基址寄存器+异常号，就可以锁定到对应处理该异常的代码位置，处理对应的异常\n\n异常处理的特点异常的处理类似于过程调用，但是有些区别：\n（PS：过程调用是相对于系统调用而言的，过程调用不需要切换到内核态，过程调用有可能涉及到磁盘的一些操作等等）\n\n过程调用会将返回地址压入栈中；而异常会根据不同的类型压入当前指令的返回地址或是下一个指令的返回地址\n处理器会把额外的一些状态也压入栈（可能重新开始执行后会需要这些状态）\n异常处理程序运行在内核模式下（意味着，他们对所有的系统资源都有完全的访问权限）\n\n异常的分类异常主要分为四大类（对于OS而言，不讨论应用级别的异常）\n\n\n\n类别\n原因\n异步/同步\n返回行为\n\n\n\n中断\n来自IO设备\n异步\n总是返回下一条指令\n\n\n陷阱\n有意的异常\n同步\n总是返回下一条指令\n\n\n故障\n潜在的可恢复的错误\n同步\n返回当前指令/不返回(终止)\n\n\n终止\n不可恢复的错误\n同步\n不会返回\n\n\n下面会详细介绍这些异常\n中断\n中断：来自I/O设备的信号引起的异常\n\n（IO设备：并不单独指磁盘，像是网卡、定时器、鼠标、键盘都属于IO设备）\n注意：不同的书籍，对于中断的解释不一样，这点要注意区别，这里列一下具体的区别\n\n中断的特点中断最大的特点就是异步\n\n中断是异步的，具体怎么理解？\n\n指信号是由IO设备发出的，并不是CPU处理指令造成的；其他的三种异常，都是CPU执行的过程中出现的问题，所以称为同步的异常\n中断的处理流程\n如何判断发生了中断？\n\nCPU有很多引脚，如果发生中断，CPU可以感知到中断引脚的电压升高\n\n处理流程\n\n然后会进行一系列的步骤对中断进行处理：\n\n感知到中断后，从系统总线读取异常号\n通过异常表基址寄存器+异常号，调用对应的中断处理程序\n当处理程序返回时，它就将控制返回给下一条指令\n\n陷阱陷阱：陷阱的唯一作用就是在用户态与内核态之间提供一个像过程一样的接口（即系统调用）\n\n为什么需要有陷阱（系统调用）？\n\n内核提供了很多服务：读文件、创建进程、终止进程等，都属于内核态的功能，用户态没有也不能有这些权限（很危险，如果用户进程都可以随意的操作你的OS服务的话，难以想象，你的电脑还是你的电脑吗）\n\n如何执行系统调用\n\n处理器提供了syscall n指令，用户程序如果需要服务n，那么就可以执行这条指令来使用系统调用\n\n陷入的过程\n\n（与其他异常的过程大同小异）\n\n用户程序需要系统调用，执行syscall n指令\n通过异常表基址寄存器+异常号，调用对应的异常处理程序（此处为陷阱）\n当处理程序返回时，它就将控制返回给下一条指令\n\n陷阱的特点陷阱需要与其他异常区别的就是目的不一样，陷阱的目的是切换用户态与内核态的，是为了进行系统调用的\n故障\n故障：由错误情况引起，可能被修复，可能修复不了\n\n如果故障可以修复，那么在执行完处理程序后，就会返回本条指令，继续执行（比如说缺页异常）\n如果故障不能修复，那么就调用abort历程，终止引起故障的应用程序\n常见的故障\n除法错误：比如除零错误、或是除的结果对于目标操作数来说太大\n一般保护故障：试图修改一个只读的文本段（Linux为段错误，也叫吐核）\n缺页\n\n终止终止一般代表不能回复的错误，一般为硬件的错误，比如DRAM或是SRAM位损坏发生奇偶错误，将不会返回控制给应用进程，调用abort历程，终止引起故障的应用程序\n常见的终止有：机器检查（硬件异常）\n内核态与用户态（未完成）内核态\n为什么有内核态与用户态？\n\n​        为了保证安全，内核必须无懈可击，防止用户程序恶意破坏，所以处理器提供了一种机制，限制一个应用可以执行的指令（特权指令）以及它可以访问的地址空间范围\n\nOS是如何实现的内核态？\n\nCPU某个控制寄存器中有一位作为模式位，此位为1就运行在内核态，为0就运行在用户态\n内核态的特点\n可以访问内存的任何位置\n可以执行特权指令\n\n用户程序只能通过系统调用来间接的访问内核的代码和数据\n参考资料\n《CSAPP》\n《汇编语言》王爽著\n\n","categories":["操作系统"],"tags":["操作系统","异常"]},{"title":"进程通信IPC","url":"/2021/09/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1/","content":"\n    引言：进程通信！！\n\n\n\n进程通信IPC\nIPC（Inner-Process Communication 进程间通信）\n\n进程之间协作完成任务，必然涉及到其进程间的通信\n\n为什么要进程间通信？\n\n​        多进程之间的空间是独立的，如果需要操作共享数据，就涉及到了通信；进程通信就是为了协作操作共享数据的（和进程同步的目的也差不多）\n\n下面我们先从为什么需要通信开始讲起\n进程的空间是完全独立的先引入一个问题\n\nOS为什么要将进程设计为独立的？\n\n进程空间\n1、虚拟内存\n\n就是程序运行时提供的内存空间，进程运行的空间都是虚拟内存空间（此虚拟内存空间指，OS在物理内存上营造出来的空间）\n\n2、虚拟地址\n\n虚拟空间有自己的虚拟地址，并不和真实的物理地址一一对应\n注意：CPU从PC取指令运行，PC存放的地址为虚拟地址，而不是真实地址\n（之后会进行虚拟地址与真实地址的转换，将数据从真实地址中取出）\n\n3、 进程空间中虚拟地址的编码范围\n\n注意：每个进程空间中的虚拟地址范围都是一样的！\n对于32位OS来说，虚拟内存的虚拟地址的编码范围为：\n4G-1: 1111 1111...1111 11114G-2: 1111 1111...1111 1110\t\t...1: 0000 0000 ... 0000 00010: 0000 0000 ... 0000 0000\n\n注意：虚拟地址范围如此大，但是对应到物理内存，只有几M而已！\n实际上，OS对进程的虚拟地址做了限制，只使用了其中一部分\n\n4、虚拟内存都一样，进程间会不会相互干扰？\n\n不会，类似于一楼编号1-20、二楼编号1-20,，1楼对1楼的操作，不会影响到二楼（这也是虚拟内存的意义）\n\n5、进程间相互独立空间的好处与坏处\n\n好处：\n​        可以保证安全，防止病毒的侵入（病毒也是一个进程，他和我的其他进程不共享数据，也就无法入侵）\n缺点：\n​        增加了共享信息的难度，所以提出了IPC\n\n6、广义与狭义\n\n广义上来说，只要能够实现进程间通信的交换方式就是进程间通信\n比如：A进程 -&gt; 文件 -&gt; B进程AB进程通过文件来交换数据、再比如AB进程通过数据库来进行数据交换\n但是我们研究的都是OS来实现的狭义上的进程通信\n管道管道分为两种：无名管道、有名管道\n无名管道内核会开辟一个“管道”，通信的进程可以共享这个管道，从而实现通信    \n\n什么是管道？\n\n其实管道就是OS内核在自己的物理内存空间开辟的一段缓存空间，并且提供对这块缓存区域对应的API，方便进程进行读写\n\n如何操作管道？\n\n通过文件描述符及相关write、read等IO函数对文件进行操作\n（这里我们也能知道，其实管道也是一个文件，因为有文件描述符）\n\n为什么要叫无名管道？\n\n管道其实也是一个文件，但是这个文件比较特殊，因为它没有文件名，所以叫无名管道\n\n\n无名管道的实现原理\n\n函数原型：\n#include &lt;unistd.h&gt;int pipe(int pipe[2]); // 等同于 int pipe(int *pipe)// 只不过这样写可以让你知道要传几个参数\n\n功能就是创建一个用于有亲缘关系的进程通信的管道\n（注意：管道只能满足亲缘关系进程通信，例如父子、父孙进程之间的通信！）\n有两个参数：\n\n元素[0]：放读管道的读文件描述符\n元素[1]：放写管道的写文件描述符\n\n（这里的读写文件描述符是独立的，即并不是open函数得到的，创建无名管道时就会有它的读写文件描述符）\n\n为什么无名管道只能用于亲缘进程间通信？\n\n因为无名管道没有文件名，因此没有办法通过open打开文件，得到文件描述符，所以只有一种办法：\n\n就是父进程先调用pipe函数创建出管道，得到无名管道的文件描述符\n然后fork出子进程，让子进程通过继承父进程打开文件描述符，从而父子间操作同一个管道，进行通信\n\n\n注意：\n\n管道创建失败返回 -1，成功返回一个大于0的数\n读管道时，如果管道没有数据，那么读操作会休眠（即阻塞）\n\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt; // 使用pipe()#include &lt;strings.h&gt; // 使用了bzero()void print_error(char *str)&#123;    perror(str);    exit(-1);&#125;int main()&#123;    int ret = 0;    int pipefd[2] = &#123;0&#125;;// 用来存放无名管道的文件描述符    // 赋值为0，是为了清除一下以前的数据        ret = pipe(pipefd);    printf(&quot;%d, %d \\n&quot;, pipefd[0], pipefd[1]);\t// 显示一下文件描述符是多少    // 其实猜也能猜到，是3, 4（因为0,1,2已经被占用了）    if(ret == -1)&#123;// 返回-1 代表管道创建失败        print_error(&quot;pipe_create_fail&quot;);    &#125;       ret = fork();// 创建一个进程    if(ret &gt; 0)&#123;// 父进程        while(1)&#123;            write(pipefd[1], &quot;hello&quot;, 5);            // 三个参数，写端的文件描述符，写的内容，内容的长度            sleep(2);            // 每两秒写一次        &#125;    &#125;else if(ret == 0)&#123;// 子进程        while(1)&#123;            char buf[30] = &#123;0&#125;;            bzero(buf, sizeof(buf));// 将缓存区清空            read(pipefd[0], buf, sizeof(buf));            printf(&quot;child process read: %s \\n&quot;,buf);        &#125;    &#125;   &#125;\n\n运行结果如下：\n[root@master learnIPC]# ./a.out 3, 4 child process read: hello child process read: hello child process read: hello...\n\n\n无名管道是单向还是双向通信？\n\n是单向通信的，只有一个写段，一个读端；\n如果你用两个线程分别去读写，那么写线程会立即读到自己的写的内容\n\n如何实现双向通信？\n\n可以使用两个无名管道\n\n无名管道的缺点\n\n\n无法用于无亲缘关系的进程\n不适合用于网状通信（因为会导致文件描述符变的异常复杂）（只适合单向双方通信）\n\n有名管道\n什么是有名管道\n\n对比无名管道就是有了名字，即有了文件名的管道文件\n这意味着我们可以通过名字open来打开这个文件，得到其文件描述符\n\n有名管道的特点\n\n\n能够用于非亲缘进程之间的通信\n读管道时，管道无数据，读操作会阻塞\n当进程写一个所有读端都被关闭的管道，进程会被返回SIGPIPE信号（如果不想管道被该信号终止，要忽略这个信号）\n\n\n有名管道的创建步骤\n\n\n使用mkfifo创建有名管道\nopen打开有名管道\nread/write读写管道进行通信\n\n\n函数原型\n\n#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;int mkfifo(const char *pathname, mode_t mode);\n\n传入两个参数：\n\npathname：文件路径\nmode：被创建的原始权限（一般为0664）必须包含读写权限\n\n\n注意！有名管道也是单向通信，如果要实现双向通信，也需要使用两个有名管道\n\nSystem V IPC提供了新的通信方式\n什么是System V IPC？\n\n管道是Unix提供的很原始的一种进程间通信方式，后来升级到版本5后，引入了新的进程通信方式：\n\n消息队列\n信号量\n共享内存\n\n所以System V IPC指的就是这三种通信方式\n\nSystem V 的通信原理\n\n与管道的通信方式不同（管道的通信方式类似于文件操作）\nSystem V IPC不再以文件的形式存在，而是通过一个标识符（完全可以认为这个标识符就是文件描述符的替代品）\n消息队列\n消息队列是什么？\n\n消息队列就是一个用于存放消息的双向链表\n通信的进程通过共享操作同一个消息队列，就能实现通信\n\n消息是如何存放在消息队列中？\n\n链表的每一个结点就是一个消息，结点应该有两部分内容：\n\n消息编号\n消息正文\n\nstruct msgbuf&#123;    long mtype; // 消息编号    char mtext[msgsz]; //消息内容&#125;\n\n\n消息队列的作用\n\n消息队列很好的实现了网状通信！\n（具体的创建过程等内容，过于硬件，不再介绍）\n共享内存\n什么是共享内存？\n\n共享内存就是OS在内存区域开辟的一大段内存空间\n\n适合于什么场景？\n\n适合于传输大量的数据（如果用管道或者消息队列，将会很慢）是最快的IPC方式\n如果要让很多个进程共享同一个空间，要加保护措施\n\n实现方式\n\n\n调用API，让OS内核在物理内存开辟出一大段空间\n让进程与开辟的缓存建立映射关系\n\n\n共享内存与管道的区别：\n\n\n管道小，共享内存大\n管道慢（管道每次调用都要进行系统调用），共享内存快\n管道不需要自己管理，其会自己阻塞；而共享内存需要我们自己管理\n\n信号量\n信号量是一个锁机制，为什么会归类到IPC内？\n\n因为其进行锁的原理，就是通知各个进程什么时候该做什么，所以也算是一种通信方式（只不过其通信的内容仅仅只是事情发生了没有，而不是事情是什么）\nSocketsocket也可以实现进程间通信（Socket另外单独来讲）\n信号\n什么是信号？\n\n​        信号是一条小的消息，由内核或者其它进程生成并发送至目标进程，目标进程可以根据该信号来做出响应。\n​        信号可以由进程或者内核发出，例如：\n\n用户在Bash界面通过键盘对正在执行的进程输入Ctrl+C、Ctrl+\\等信号命令，或者执行kill命令发送信号。\n进程执行出错，例如访问了一个非法的地址、除0运算，或者硬件发生故障，就会由内核向进程发送一个信号。\n进程执行kill命令向目标进程发送信号。\n\n\n信号的传递步骤：\n\n传送一个信号到目的进程主要有两个步骤：\n\n发送信号：内核通过更新目标进程上下文的某个状态，传递一个信号给目标进程\n接收信号：目标进程会被内核强制以某种方式对信号的发送做出反应，它就会接收到信号。（如果程序没有针对这种信号指定其处理方式，就会采用默认的处理策略，例如中止进程、忽略）\n\n一个发出但没有接收的信号称之为待处理信号，在任何时刻，同一种类型的信号最多只会有一个待处理的信号\n\n发送信号的方式\n\n\n通过操作系统的bin/kill程序，向程序发送信号\n\n例如：kill -9 pid向进程发送信号值为9的信号\n\n用键盘发出信号\n\n在命令行界面中，能有一个前台任务和多个后台任务\n\nkill函数发送信号\n\nkill函数的定义位于头文件signal.h中：\nint kill(pid_t pid, int sig);/*如果pid &gt; 0，该函数会向PID为pid的进程发送信号值为sig的信号。如果pid = 0，该函数会向当前进程隶属的进程组下所有的进程发出信号值为sig的信号，包括这个进程自己。如果pid &lt; 0，该函数会向进程组ID为-pid下所有的进程发出信号值为sig的信号*/\n\n\nalarm函数发送SIGALRM信号\n\n进程可以通过alarm函数向自己发送一个SIGALRM信号，该函数定义于头文件unistd.h中：\nunsigned int alarm(unsigned int secs);// 传入一个时间参数secs，单位为秒，// 表示在secs秒后发送一个SIGALRM信号给当前线程\n\n\n\n\n\n\n\n","categories":["操作系统"],"tags":["操作系统","IPC"]},{"title":"操作系统死锁","url":"/2020/12/20/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%AD%BB%E9%94%81/","content":"\n    引言：操作系统死锁\n\n\n\n\n操作系统死锁死锁的基本概念产生死锁的原因：多个进程之间竞争共享的资源\n在进程一节讨论过原因\n假设：有两个临界资源为Q与W，我们使用记录型信号量处理以下两个进程的任务\nA进程：\t\t\t\tB进程：\tP(Q)\t\t\t\t\tP(W)\tP(W)\t\t\t\t\tP(Q)\tV(Q)\t\t\t\t\tV(W)\tV(W)\t\t\t\t\tV(Q)\n\n\n进程A抢到了资源Q\n进程B抢到了资源W\n进程A想要资源W，没有，进入阻塞状态\n进程B想要资源Q，没有，进入阻塞状态\n\n我们发现两个进程都进入了阻塞状态，并且都不会释放他们已有的资源，这种情况叫做死锁状态\n死锁的一些结论由于死锁是进程间竞争共享资源产生的，所以由如下结论\n\n死锁的进程至少是两个\n死锁的进程至少有两个已经占有了资源\n死锁的所有进程都在等待资源\n死锁的进程是当前进程中所有进程的子集\n\n永久性资源和临时性资源永久性资源（可再用资源）：可以被多个进程多次使用，使用模式为“申请—分配—使用—释放模式”\n\n可抢占资源(可剥夺)；如：主存、CPU（不会引起死锁）\n不可抢占资源（不可剥夺）；如：打印机\n\n临时性资源（可消耗性资源）：只可使用一次的资源；\n\n如信号量，中断信号，同步信号\n\n产生死锁的根本原因死锁起因是并发进程的资源竞争，但资源竞争并不一定产生死锁\n所以，死锁产生的原因是：\n系统能够提供的资源数少于需要该资源的进程数\n\n竞争不可抢占资源\n竞争可消耗资源\n进程推进顺序不当\n\n其中1与2可以归为一点——竞争系统资源（非可剥夺）\n产生死锁的必要条件必须同时具备以下条件，否则不会成立：\n\n互斥条件：进程对其所要求的资源进行排它性控制，即一次只有一个进程可以使用一个资源。\n请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求。\n不可剥夺条件：进程所获得的资源在未被释放之前，不能被其它进程强行剥夺。\n环路条件：在发生死锁时，必然存在一个进程资源的循环等待链， \n\n死锁的处理\n预防死锁\n避免死锁\n检测死锁\n解除死锁\n\n预防死锁只需要破坏四个条件之一，即可避免死锁\n优点：直观、简单\n缺点：导致系统资源利用率和系统吞吐量降低\n\n破坏互斥条件：做不到，对于抢占式资源来说，不能共享操作\n破坏请求和保持条件：\n第一种策略：保证资源的一次性分配（AND型信号量）\n但是会导致资源的浪费、饥饿现象的产生\n\n\n第二种策略：只获得初期所需资源后，开始运行。运行过程逐步释放已分配、已用完的全部资源，再请求新的所需资源\n\n\n破坏不可剥夺条件：申请未果，则放弃\n难度大、可能会使资源出现错误\n\n\n破坏环路等待条件：资源有序分配\n做法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反\n编号的原则：较为紧缺的资源给以一个较大的序号\n优点：较前两种策略，资源利用率和系统吞吐量，都有显著的改善。\n问题：\n限制了新设备类型的增加\n发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费，如：某进程先用磁带机，后用打印机，但按系统规定，它应先申请打印机，后申请磁带机，致使打印机长期闲置\n限制了用户简单、自由的编程。      \n\n\n\n\n\n避免死锁允许动态的申请资源，提高了系统的资源利用率\n​        系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统可能发生死锁，则不予分配，否则予以分配。\n首先要明确两个概念：安全状态和不安全状态\n\n安全状态指系统能按某种进程顺序来为每个进程分配其所需资源，直至最大需求，使每个进程都可顺序完成。若系统不存在这样一个序列，则称系统处于不安全状态。\n\n注意：\n\n安全状态一定没有死锁发生\n并非所有的不安全状态都会转化为死锁状态\n避免死锁的实质：系统在进行资源分配时，使系统不进入不安全状态\n\n例如：\n​        假定系统中有三个进程P1、P2和P3，共有12台磁带机。进程P1总共要求10台磁带机，P2和P3分别要求4台和9台。假设在T0时刻，进程P1、P2和P3已分别获得5台、2台和2台磁带机，尚有3台空闲未分配。\n\n\n\n进程\n最大需求\n已分配\n可用\n\n\n\nP1\n10\n5\n3\n\n\nP2\n4\n2\n\n\n\nP3\n9\n2\n\n\n\n​        此时可以先给P2分配，等P2运行完毕后，就有5个磁带机了，此时满足了P1的要求，等P1结束后，也满足了P3的要求，三个进程都可以完成，此时就可以找到安全序列：P2 -&gt; P1 -&gt; P3\n​        \n​        假如T0时刻P3要求3台磁带机\n\n\n\n进程\n最大需求\n已分配\n可用\n\n\n\nP1\n10\n5\n2\n\n\nP2\n4\n2\n\n\n\nP3\n9\n3\n\n\n\n​        此时不管如何寻找，都找不到一个安全序列，所以此时不可以进行分配\n代表算法：\n\n银行家算法\n安全性算法\n\n银行家算法\nDijkstra设计的给银行发放贷款使用的算法，由此得名\n\n数据结构：\n\n可利用资源向量Available：含有m个元素的数组\n如：Available[j]=K，表示系统中现有Rj类资源K个\n初始值是系统中所配置的该类全部可用资源的数目。\n\n\n最大需求矩阵Max：一个n*m的矩阵，表示系统中n个进程中的每一个进程对m类资源的最大需求\n如：Max[i,j]=K，表示进程i需要Rj类资源的最大数目为K。 \n\n\n分配矩阵Allocation：一个n*m的矩阵，\n如:Allocation[i,j]=K，则表示进程i当前已分得Rj类资源的数目为K。\n\n\n需求矩阵need：一个n×m的矩阵\nNeed[i,j]=K，则表示进程i还需要R j类资源K个，才能完成其任务。\n\n\n\n上述三个矩阵存在以下关系：\nNeed[i, j] = Max[i, j]-Allocation[i, j] \n\n\n\n算法过程：\n设Requesti是进程Pi的请求向量，如果Requesti[j]=K表示进程pi的请求向量\n\n安全性算法\n安全性算法：对银行家算法改进后的更通用的算法\n\n作用：判断状态是否安全，关键是寻找一个进程安全推进序列\n另外设置：\n\n工作向量Work：表示系统可提供给进程继续运行所需的各类资源数目，它含有m个元素，在执行安全算法开始时，Work:=Available\nFinish：它表示系统是否有足够的资源分配给进程，使之运行完成。开始时先做Finish[i]:=false;当有足够资源分配给进程时，再令Finish[i]:=true\n\n\n例1：​        假定系统中有五个进程&#123;P0，P1，P2，P3，P4&#125;和三类资源&#123;A，B，C&#125;，各种资源的数量分别为10、5、7，在T0时刻的资源分配情况如下：\n\n\n\n\nMax\nAllocation\nNeed\nAvailable\n\n\n\nP0\n7 5 3\n0 1 0\n7 4 3\n3 3 2\n\n\nP1\n3 2 2\n2 0 0\n1 2 2\n\n\n\nP2\n9 0 2\n3 0 2\n6 0 0\n\n\n\nP3\n2 2 2\n2 1 1\n0 1 1\n\n\n\nP4\n4 3 3\n0 0 2\n4 3 1\n\n\n\n     可以找安全的进程推进序列：`P1-&gt;P3-&gt;P4-&gt;P2-&gt;P0`\n\n\n\n\n\nwork\nNeed\nAllocation\nwork+Allocation\nFinish\n\n\n\nP1\n3 3 2\n1 2 2\n2 0 0\n5 3 2\ntrue\n\n\nP3\n5 3 2\n0 1 1\n2 1 1\n7 4 3\ntrue\n\n\nP4\n7 4 3\n4 3 1\n0 0 2\n7 4 5\ntrue\n\n\nP2\n7 4 5\n6 0 0\n3 0 2\n10 4 7\ntrue\n\n\nP0\n10 4 7\n7 4 3\n0 1 0\n10 5 7\ntrue\n\n\n​        work就是当前的available值         \n此时系统处于安全状态\n例2：\n某系统有同类资源m个，可并发执行且共享该类资源的进程最多n个，而每个进程申请该类资源的最大量为x(1≤x≤m)，只要不等式n(x-1)+1≤m成立，则系统一定不会发生死锁。\n\n​        例题: 某系统中有11台打印机，N个进程共享打印机资源，每个进程要求3台。但N的取值不超过____时，系统不会发生死锁。\n​    计算：m = 11，N，x=3，代入公式n(x-1)+1&lt;=m即可算出n&lt;=5\n死锁检测当系统为进程分配资源时，若未采取任何限制性措施来保证不进入死锁状态，则系统必须提供检测和解除死锁的手段。\n系统检测要求系统做到：  \n\n保存有关资源的请求和分配信息\n提供一种算法，以利用这些信息来检测系统是否已进入死锁状态\n\n发现死锁：根据死锁状态的定义，利用死锁描述中介绍的资源分配图来考察某一时刻系统状态是否合理，即是否能使所有进程都得到它们所申请的资源而运行结束。 \n死锁解除解除死锁：与检测死锁相配套的一种措施。\n方法：剥夺资源、撤消进程 ；死锁的检测和解除措施有可能使系统获得较好的资源利用率和吞吐量，但在实现上难度也最大。\n","categories":["操作系统"],"tags":["操作系统","死锁"]},{"title":"RSA非对称加密","url":"/2023/06/15/%E5%AF%86%E7%A0%81%E5%AD%A6/RSA%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/","content":"\n引言：RSA算法及RSA在代理重加密中的应用\n\n\n\n\nRSA算法\nRSA算法：由Ron Rivest、Adi Shamir和Leonard Adleman于1977年共同提出。这个算法基于数论中的数学问题，利用了大素数分解的困难性来提供安全性。\n\nRSA如何生成公钥与私钥？1、首先我们需要两个大素数，比如p与q\np = new BigInteger(&quot;851322...19074969&quot;);// 154个charq = new BigInteger(&quot;836458...86991233&quot;);// 154个char\n\n2、计算其乘积，设为n（n与加密解密有关）\nn = p * q\n\n3、计算欧拉函数φ(n) = (p-1) * (q-1)，这里使用PhiN\nPhiN = p.subtract(BigInteger.valueOf(1));PhiN = PhiN.multiply(q.subtract(BigInteger.valueOf(1)));\n\n4、找一个小于φ(n)且与φ(n)互质的整数e，作为公钥的指数\ndo &#123;    e = new BigInteger(2 * SIZE, new Random());&#125;// 前面的条件表示 e&gt;PhiN，后面的条件表示e与PhiN的最大公约数不为1，即表示不互质// 当e&gt;PhiN或e与PhiN不互质时就不断循环，直到两个条件都满足，即找到了一个小于φ(n)且与φ(n)互质的整数ewhile ((e.compareTo(PhiN) != 1) || (e.gcd(PhiN).compareTo(BigInteger.valueOf(1)) != 0));\n\n5、计算与e关于模φ(n)的乘法逆元d，作为私钥的指数。\nd = e.modInverse(PhiN);\n\n即找到一个满足(d*e)%PhiN==1的d\n这样我们就找到了公钥的指数e与私钥的指数d\ne和d并不是公钥和私钥本身，公钥与私钥本身指的是一个指数与一个模数，在这里公钥的指数是e，模数是n；私钥的指数是d，模数也是n。\nRSA如何进行加密解密？\n加密：使用公钥(e, n)，将明文数据m加密为密文c。加密操作为c = m^e mod n。\n解密：使用私钥(d, n)，将密文c解密为明文数据m。解密操作为m = c^d mod n。\n\n代理重加密中使用RSA在代理重加密的过程中，我们常用一个代理Proxy，代理使用重加密秘钥对已加密的数据进行第二次加密。\n一种常见的重加密秘钥生成方式是：使用发送者的私钥与接受者的公钥做乘积\n为什么使用乘积作为新的公钥去加密数据，接受者依然可以解密呢？\n下面来证明一下其正确性：\n首先我们需要知道基本的模运算法则和幂运算法则\n\n举个例子：\n\n完整代码public class RSA &#123;    public BigInteger p, q;    public BigInteger n;    public BigInteger PhiN;    public BigInteger e, d;    public RSA() &#123;        Initialize();    &#125;    //Generate e and d    //e:- Public Key    //d:- Private Key    /**     * 密钥生成：     * 1 选择两个大素数p和q，并计算它们的乘积n，即n = p * q。     * 2 计算欧拉函数φ(n)，即φ(n) = (p-1) * (q-1)。     * 3 选择一个小于φ(n)且与φ(n)互质的整数e，作为公钥的指数。     * 4 计算与e关于模φ(n)的乘法逆元d，作为私钥的指数。     */    public void Initialize() &#123;        int SIZE = 512;        // p and q are 2 154 digit Prime Numbers which are used in the generation of RSA Keys        p = new BigInteger(&quot;8513222065247162701695105220665738877312063308356937563625345485856710133446374665834898192825484459951443770023314504441479244278247980992441766519074969&quot;);        q = new BigInteger(&quot;8364581280641288933593527550533091363060086128207408134848028170130641974184553465641962883238792572920670310338579332490687347012348067644317739328586993&quot;);        n = p.multiply(q);        PhiN = p.subtract(BigInteger.valueOf(1));        PhiN = PhiN.multiply(q.subtract(BigInteger.valueOf(1)));        do &#123;            e = new BigInteger(2 * SIZE, new Random());        &#125;        // 前面的条件表示 e&gt;PhiN，后面的条件表示e与PhiN的最大公约数不为1，即表示不互质        // 当e&gt;PhiN或e与PhiN不互质时就不断循环，直到两个条件都满足        while ((e.compareTo(PhiN) != 1) || (e.gcd(PhiN).compareTo(BigInteger.valueOf(1)) != 0));        d = e.modInverse(PhiN);    &#125;    /**     * 加密：使用接收者的公钥(e, n)，将明文数据m加密为密文c。加密操作为c = m^e mod n。     * 解密：使用接收者的私钥(d, n)，将密文c解密为明文数据m。解密操作为m = c^d mod n。     */    public BigInteger encrypt(BigInteger plaintext) &#123;        return plaintext.modPow(e, n);    &#125;    public BigInteger decrypt(BigInteger ciphertext) &#123;        return ciphertext.modPow(d, n);    &#125;&#125;\n\n","categories":["密码学","非对称加密"],"tags":["密码学","非对称加密"]},{"title":"HashMap哈希表","url":"/2021/06/08/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/HashTable/","content":"\n    引言：哈希表——一个链表数组\n\n\n\n\n哈希表哈希表基础哈希表数据结构，主要是为了使用空间换取查找时间，如果我们有一个无限大的空间，理论上我们查找任何数据都可在O(1)的时间内完成\n我们可以使用哈希来实现集合、映射等等数据结构\n哈希函数映射关系就被称作哈希函数\n比如说将26个小写字母映射到26个数字上，在Java中\npublic int hashFunc(char chr)&#123;    return chr - &#x27;a&#x27;;&#125;\n\n这就是一个哈希函数，但是在实际中，我们使用的都是一个一个对象，将对象转换为一个索引是比较复杂的\n哈希冲突实际中对象转换成一个索引，通常是不可能做到每一次都转换为不同的索引的，所以当有两个对象经过哈希函数转换后，发现有着相同的索引，此时就发生了哈希冲突。\n而在基于哈希表实现的数据结构中，如何解决哈希冲突就是一个重中之重！\n哈希函数的设计存储整数与浮点数假如要存储一堆大的整数，我们要把它转换为一个索引，最简单的哈希函数，就是让这个整数对一个精心设计的整数取模\n为什么要说是精心设计的整数呢？\n\n保证索引分布均匀：开辟一个空间，得保证大量的数据存入之后，是均匀的\n\n试想我们使用2、4、6、8这种偶数来作为被取模的数，那么当大量的数据来存放时，会发现他们的倍数都存放到了一起，引起了大量的哈希冲突\n如果选择3,、5、9这种奇数，效果和偶数其实差不多，许多数学家研究后，发现选择一个素数的效果是最好的，可以让索引分布均匀，最大程度减少哈希冲突\n而且不同数量级选择的最好的数也不一样，例如在2^5~2^6这个数量级之间，选择53是最好的选择，但是在上一个量级2^6~2^7选择97是最好的选择，其他量级我们可以去搜索\n假如要存储一堆浮点数，尽管和整数不一样，但是底层存储还是差不多的，都是存放在32位或是64位的内存中，大小是固定的\n存储字符串假如要存储一堆字符串（简单考虑其全由小写字母组成），那么可以将其转换为一个整型处理，如何转换呢？一共有26个小写字母，我们就可以使用26进制来实现，例如dac =d*26^2+ a*26^1 + c*26^0。如果包括大小写字母，那么用52进制就行，如果有更多更多，我们也可以解决，类似这样\n# B代表进制，对M求余，防止这个数太大hash(&quot;字符串&quot;) = (&quot;字&quot;*B^2 + &quot;符&quot;*B^1 + &quot;串&quot;*B^0) % M# 上面的式子等同于下面的式子hash(&quot;字符串&quot;) = ((((&quot;字&quot;*B)+ &quot;符&quot;)*B + &quot;串&quot;)*B) % M# 为了防止在运算的过程中出现整型溢出，最终可以写成这个样子hash(&quot;字符串&quot;) = (((&quot;字&quot; % M)*B+ &quot;符&quot;)%M*B + &quot;串&quot;)%M \n\n存储对象更一般的，假如要存储一堆学生对象（有姓名、学号、年龄、性别等等属性），仍然可以转换为整型，\n借鉴字符串的思想，就是这样\nhash(s1) = (((s1.name % M)*B+ s1.id)%M*B + s1.age)%M \n\n设计原则总之有着这样几个设计原则：\n\n分布均匀\n一致性：如果a==b那么a的hash值应该和b的哈希值相同\n高效性：哈希运算可以很快完成\n\nJava中的哈希函数——hashcode\nhashcode：将对象转换为一个整型值\n\n在Java中，对于整型来说，它的hashcode就是它本身，而且有正有负\nInteger a1 = 123;System.out.println(a1.hashCode()); // 123Integer a2 = 1233192123;System.out.println(a2.hashCode()); // 1233192123Integer a3 = -1233192123;System.out.println(a3.hashCode()); // -1233192123\n\n对于自定义的类，没重写hashcode方法前，会自动调用继承自Obejct类的hashcode方法，而这个方法是对存储的地址进行一下转换，转换为一个整型值\n我们可以重写hashcode方法，例如：\n public class Student &#123;    private String name;    private String sex;    private Integer age;    public Student(String name, String sex, Integer age) &#123;        this.name = name;        this.sex = sex;        this.age = age;    &#125;    @Override    public int hashCode() &#123;        int result = name != null ? name.hashCode() : 0;        result = 31 * result + (sex != null ? sex.hashCode() : 0);        result = 31 * result + (age != null ? age.hashCode() : 0);        return result;    &#125;&#125;\n\n\n\n哈希冲突的解决解决哈希冲突，有很多种方法，这里只介绍最出名也是Java8目前所使用的方法——链地址法\n即如果出现哈希冲突，就把冲突的元素放在一个链表里（虽然叫链地址法，但不一定是链表，也可以使用tree等结构）\n（Java8之前，每一个位置对应一个链表、Java8开始，当哈希冲突达到一定程度时，会将链表转换成红黑树）\nJava实现哈希表哈希表的实质：一个TreeMap数组或者是一个链表数组\npackage hash;import java.util.TreeMap;/** * @author 董文浩 * @Date 2021/6/8 17:45 * 哈希表 */public class HashTable&lt;K, V&gt; &#123;    /**     * 底层使用TreeMap实现（TreeMap是用红黑树实现的）     */    private TreeMap&lt;K, V&gt;[] hashtable;    /**     * 此M即被模的数     */    private int M;    /**     * 容量     */    private int size;    /**     * 指定上下界，当N / M超过upperTol扩容，小于lowerTol时缩容     * （N是size大小）     * initCapacity初始化大小     */    private static final int upperTol = 10;    private static final int lowerTol = 2;    private static final int initCapacity = 7;    public HashTable() &#123;        this(97);    &#125;    public HashTable(int M) &#123;        this.M = M;        this.size = 0;        hashtable = new TreeMap[M];        for (int i = 0; i &lt; M; i++) &#123;            hashtable[i] = new TreeMap&lt;&gt;();        &#125;    &#125;    public int hash(K key) &#123;        /**         * 因为hashcode值肯能为负数，例如-84的hash值还是-84         * 所以与0x7fffffff求与运算就相当于求绝对值         */        return (key.hashCode() &amp; 0x7fffffff) % M;    &#125;    public int getSize() &#123;        return size;    &#125;    /**     * 添加元素     *     * @param key     * @param value     */    public void add(K key, V value) &#123;        // 先进行哈希函数转换，然后放在数组指定位置即可        TreeMap&lt;K, V&gt; map = hashtable[hash(key)];        if (map.containsKey(key)) &#123;            // 如果包含了key，那么就更新一下值            map.put(key, value);        &#125; else &#123;            // 添加逻辑            map.put(key, value);            size++;            // N / M &gt; upperTol扩容            if (size &gt;= upperTol * M) &#123;                resize(2 * M);            &#125;        &#125;    &#125;    /**     * 删除方法     *     * @param key     * @return     */    public V remove(K key) &#123;        TreeMap&lt;K, V&gt; map = hashtable[hash(key)];        if (map.containsKey(key)) &#123;            size--;            // 缩容            if (size &lt; lowerTol * M &amp;&amp; M / 2 &gt; initCapacity) &#123;                resize(M / 2);            &#125;            return map.remove(key);        &#125;        return null;    &#125;    public void set(K key, V value) &#123;        TreeMap&lt;K, V&gt; map = hashtable[hash(key)];        if (!map.containsKey(key)) &#123;            throw new IllegalArgumentException(&quot;键值不存在&quot;);        &#125;        map.put(key, value);    &#125;    public boolean contains(K key) &#123;        return hashtable[hash(key)].containsKey(key);    &#125;    public V get(K key) &#123;        return hashtable[hash(key)].get(key);    &#125;    /**     * 自动扩容     * @param newM     */    private void resize(int newM) &#123;        TreeMap&lt;K,V&gt;[] newHashTable = new TreeMap[newM];        for (int i = 0; i &lt; newHashTable.length; i++) &#123;            newHashTable[i] = new TreeMap&lt;&gt;();        &#125;        int oldM = M;        this.M = newM;        for (int i = 0; i &lt; oldM; i++) &#123;            TreeMap&lt;K, V &gt; map = hashtable[i];            for (K key:map.keySet())&#123;                newHashTable[hash(key)].put(key, map.get(key));            &#125;        &#125;    &#125;&#125;\n\n","categories":["数据结构","HashTable"],"tags":["数据结构","HashTable","Hash"]},{"title":"Java数组_手写一个Array","url":"/2020/03/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Java%E6%95%B0%E7%BB%84-%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AAArray/","content":"\n    引言：数据结构——数组\n\n\n\n\n\n写在前面：这个系列来重新学习数据结构，并且使用Java来实现他们\n手写简单的Array重要的地方都有注释\n代码如下：\npackage array;/** * @author BlackKnight * @apiNote 自己写一个Array数组 */public class Array&lt;E&gt;&#123;    /*        如果你是先从容易的int数组来思考，进而转换为泛型时：        注意要改的地方：        1. 把数组的类型换为泛型        2. 把泛型之间比较的方法换为equals    */    private E[] data;    private int size;    private final static int initialCapacity = 10;    /**     * 构造一个函数，初始化一个数组     *     * @param capacity 数组大小     */    public Array(int capacity) &#123;        //使用泛型时，我们并不能直接new一个泛型对象，但是可以new一个超类再强转为泛型        data = (E[])new Object[capacity];        size = 0;    &#125;    /**     * 用户如果也不知道需要多大，就先创建一个吧     */    public Array() &#123;        this(initialCapacity);    &#125;    /**     * 返回数组已存储的长度     *     * @return     */    public int getSize() &#123;        return size;    &#125;    /**     * 返回数组的容量     *     * @return     */    public int getCapacity() &#123;        return data.length;    &#125;    /**     * 数组是否为空     *     * @return     */    public boolean isEmpty() &#123;        return size == 0;    &#125;    //-------------------------------------------------------    /**     * 在指定位置插入元素     *     * @param index     * @param e     */    public void add(int index, E e) &#123;        //排除非法index        if (index &lt; 0 || index &gt; size) &#123;            throw new IllegalArgumentException(&quot;需要index&lt;0 || index &gt; size&quot;);        &#125;        /*  size表示存储大小，data.length代表数组的大小        假如我们的存了3个数，数组的大小是10        那么 size == 3  &amp;&amp; data.length ==10        随着我们不断的添加元素 size慢慢增加，会出现一个问题        size 大小范围应该在 [0,data.length-1]        当size == data.length 时， 就会出现数组越界异常        此时我们需要扩容        */        if (size == data.length) &#123;            /*为了提高效率，如果固定提高第一个常数的话            当数组越大我们需要扩容的次数越多，这显然不是我们想要的            所以每次扩容两倍            */            resize(2 * data.length);        &#125;        /*  主要的难点在于插入的同时要移动元素                 index：0 1 2 3 4 5 6            比如我现在有 1 2 3 4 6 7 8            现在我要插入5到4的位置，我就需要移动 4 ~ size个元素        */        for (int i = size - 1; i &gt;= index; i--) &#123;            data[i + 1] = data[i];        &#125;        data[index] = e;        size ++;    &#125;    /**     * 改变容器大小，这个方法是不需要被用户知道的，所以private     * @param newCapacity     */    private void resize(int newCapacity)&#123;        E[] newData = (E[]) new Object[newCapacity];        for(int i = 0; i &lt; size ; i++)&#123;            newData[i] = data[i];        &#125;        data = newData;    &#125;    /**     * 向数组的末尾添加内添加     * @param e 元素值     */    public void addLast(E e) &#123;        /*        if (size == data.length) &#123;            throw new IllegalArgumentException(&quot;数组越界&quot;);        &#125;        data[size] = e;        size++;        //我也可以写成 data[size++] = e;        */        //-------------------------------------        // 但其实，我们完全可以复用add()        add(size,e);    &#125;    /**     * 向数组头添加     * @param e     */    public void addFirst(E e) &#123;        add(0,e);    &#125;    //-------------------------------------------------------    @Override    public String toString()&#123;        StringBuilder res = new StringBuilder();        res.append(String.format(&quot;Array: size = %d , capacity =%d\\n&quot;,size,data.length));        res.append(&quot;[&quot;);        for (int i = 0; i &lt; size; i++) &#123;            res.append(data[i]);            if(i!=size-1)&#123;                res.append(&quot;, &quot;);            &#125;        &#125;        res.append(&quot;]&quot;);        return res.toString();    &#125;    /**     * 获取元素     * @param index     * @return     */    public E get(int index)&#123;        /*        设计get方法的优点：        1. 可以判断用户输入的index是否合法        2. 防止用户可以查询我们未曾使用的数组空间         */        if(index&lt;0||index&gt;=size)&#123;            throw new IllegalArgumentException(&quot;非法index&quot;);        &#125;        return data[index];    &#125;    /**     * 更新指定位置的元素     * @param index     * @param e     */    public void set(int index, E e)&#123;        if(index&lt;0||index&gt;=size)&#123;            throw new IllegalArgumentException(&quot;非法index&quot;);        &#125;        data[index] = e;    &#125;    //-------------------------------------------------------    /**     * 是否包含某个数     * @param e     * @return     */    public boolean contains(E e)&#123;        for (int i = 0; i &lt; size; i++) &#123;            if (data[i].equals(e))&#123;                return true;            &#125;        &#125;        return false;    &#125;    /**     * 查找某个数并返回下标     * @param e     * @return 返回-1代表没有找到这个数     */    public int find(E e)&#123;        for (int i = 0; i &lt; size; i++) &#123;            if (data[i].equals(e))&#123;                return i;            &#125;        &#125;        return -1;    &#125;    /**     * 删除指定位置的元素     * @return 返回被删除元素     */    public E remove(int index)&#123;        if(index&lt;0||index&gt;=size)&#123;            throw new IllegalArgumentException(&quot;非法index&quot;);        &#125;        E ret = data[index];        for(int i = index + 1 ; i &lt; size; i++)&#123;            data[i-1]=(data[i]);        &#125;        size--;        /* data[size] = null 说明：        原本int[]数组的时候，删除一个元素的最后        size依然指向了data[size]这个单元，但是用户是访问不到的，所以我们并没有处理        但是使用泛型之后，每个单元都会存储对象的引用        如果我们不将data[size]清空，虽然用户依然访问不到        但是因为data[size]中存有引用，这样就不会被自动的垃圾回收掉        这样的对象专业术语叫 loitering objects （游荡对象）        所以我们需要自己处理        */        data[size] = null;        /*        删除元素到一定程度时。缩减容量         */            /*            这里判断 size == data.length / 2也可以            但是判断 size == data.length / 4会更好一点            可以先思考一下，末尾解答            */        if(size == data.length / 4 &amp;&amp; data.length / 2 != 0)&#123;            resize(data.length/2) ;        &#125;        return ret;    &#125;    /**     * 删除末尾元素     * @return     */    public E removeLast()&#123;        return remove(size-1);    &#125;    /**     * 删除第一个元素     * @return     */    public E removeFirst()&#123;        return remove(0);    &#125;    /**     * 删除与值相同的第一个元素     * @param e     */    public void removeElement(E e)&#123;        int index = find(e);        if(index!=-1)&#123;            remove(index);        &#125;    &#125;&#125;\n\n复杂度分析回看我们所写的方法，我们来分析他们的时间复杂度\n增方法名                 |  最坏 | 最好 | 平均   |------------------------------------------------addLast(E e)           |  O(1) | O(1) | O(1)   |addFirst(E e)          |  O(n) | O(n) | O(n)   |add(int index, E e)    |  O(n) | O(1) | O(n/2) |resize(int newCapacity)|  O(n) | O(n) | O(n)   |------------------------------------------------注意：O(n/2) = O(n)\n\n通常我们认为的时间复杂度其实是最坏情况下的复杂度，所以由上表分析，增方法的全部方法的时间复杂度都是为的O(n)（addLast()方法由于有resize()方法的存在，所以它的复杂度也是O(n)）\n但是这样会有一些问题，因为resize方法只有当超出容量了我们才会调用一次，此时我们可以进行均摊复杂度(amortized time complexity)分析\n假设capacity为n我们向其中添加的方法是addLast，这个方法时间复杂度为O(1)当满出时，需要进行resize方法，这个方法时间复杂度为O(n)当我们执行到第 n+1 次addLast()方法时，我们才会调用resize()方法所以我们共操作 2n+1 次用 2n+1 / n 差不多为2所以这时的时间复杂度为O(1)\n这样分析，其实addLast()方法平均下来的时间复杂度和n没有关系，它一直是O(n)\n删方法名                  |  最坏 | 最好 | 平均   |-------------------------------------------------removeLast()            |  O(1) | O(1) | O(1)   |removeFirst()           |  O(n) | O(n) | O(n)   |remove(int index)       |  O(n) | O(1) | O(n/2) |resize(int newCapacity) |  O(n) | O(n) | O(n)   |-------------------------------------------------注意：O(n/2) = O(n)\n同理，removeLast()是O(1)，其他方法依然为O(n)\n查方法名                  |  最坏 | 最好 | 平均   |-------------------------------------------------get(int index)          |  O(1) | O(1) | O(1)   |contains(E e)           |  O(1) | O(n) | O(n/2) |find(E e)               |  O(n) | O(1) | O(n/2) |-------------------------------------------------注意：O(n/2) = O(n)\n\n改方法名                  |  最坏 | 最好 | 平均   |-------------------------------------------------set(int index)          |  O(1) | O(1) | O(1)   |\n\n复杂度震荡在代码中我们遗留了一个问题\n/*删除元素到一定程度时。缩减容量 */    /*    这里判断 size == data.length / 2也可以    但是判断 size == data.length / 4会更好一点    可以先思考一下，末尾解答    */if(size == data.length / 4 &amp;&amp; data.length / 2 != 0)&#123;    resize(data.length/2) ;&#125;return ret;\n为什么下方的代码会更好一些呢？我们来思考一个问题\n假设我们使用上方的代码size == data.length / 2，假设Capacity设置为10，现在我们已经有了十个数字，将这个数组已经撑满\n现在我们来执行以下操作\n\n调用一次addLast()方法，它内部会执行resize()方法，capacity会变为20\n再调用一次removeLast()方法，它内部会执行resize()方法，capacity又会变为10\n再调用一次addLast()方法，它内部会执行resize()方法，capacity会变为20\n依次下去….\n\n我们发现，我们原先论证的O(1)的复杂度，现在却变成了O(n)，这就叫做复杂度震荡\n原因在于：判断size == data.length / 2过于着急(Eager)\n解决：我们需要懒一点(Lazy)，换成下方的代码size == data.length / 4 ;，就解决了这个问题。\n参考资料\n参考资料：来自慕课liuyubobobo的教程\n\n","categories":["数据结构"],"tags":["Java","数据结构","数组"]},{"title":"Java栈_手写一个ArrayStack","url":"/2020/03/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Java%E6%A0%88-%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AAArrayStack/","content":"\n    引言：数据结构——队列\n\n\n\n\nArrayStack实现栈有两种方法，但这次我们使用Array来实现栈\n由于有两个不同的实现，我们可以把Stack作为一个接口，两种方法分别实现它\n/** * @author BlackKnight */public interface Stack&lt;E&gt; &#123;    /**     * 获取大小     * @return     */    int getSize();    /**     * 判空     * @return     */    boolean isEmpty();    /**     * 入栈     * @param e     */    void push(E e);    /**     * 出栈/弹栈     * @return     */    E pop();    /**     * 查看栈顶元素     * @return     */    E peak();&#125;\n\n想一下有什么功能?\n\n现在来实现ArrayList\nimport array.Array;import java.util.StringJoiner;/** * @author BlackKnight * 这个栈是基于Array来构建的 */public class ArrayStack&lt;E&gt; implements Stack &#123;    Array&lt;E&gt; array;    /**     * 使用     * @param capacity     */    public ArrayStack(int capacity) &#123;        array = new Array&lt;&gt;(capacity);    &#125;    /**     * 用户不知道用多少大小，先创建一个再说     */    public ArrayStack() &#123;        array = new Array&lt;&gt;();    &#125;    /**     * 因为使用Array来实现栈，所以特有了一个getCapacity的方法     * @return     */    public int getCapacity()&#123;        return array.getCapacity();    &#125;    @Override    public int getSize() &#123;        return array.getSize();    &#125;    @Override    public boolean isEmpty() &#123;        return array.isEmpty();    &#125;    @Override    public void push(Object o) &#123;        array.addLast((E)o);    &#125;    @Override    public E pop() &#123;        return array.removeLast();    &#125;    @Override    public E peak() &#123;        return array.get(array.getSize());    &#125;    @Override    public String toString() &#123;        StringJoiner sj = new StringJoiner(&quot;,&quot;,&quot;Stack: [&quot;,&quot;] top&quot;);        for(int i = 0 ; i &lt; array.getSize() - 1 ; i++)&#123;            sj.add(array.get(i)+&quot;&quot;);        &#125;        return sj.toString();    &#125;&#125;\n\n\n复杂度分析方法名                  | 时间复杂度 |-------------------------------------------------push(E e)               |     O(1)   | （均摊复杂度）pop()                   |     O(1)   | （均摊复杂度）peek()                  |     O(1)   |getSize()               |     O(1)   |isEmpty()               |     O(1)   |\n\n\n\n参考资料\n参考资料：来自慕课liuyubobobo的教程\n\n","categories":["数据结构"],"tags":["Java","数据结构","栈"]},{"title":"Java队列_手写一个LinkedListQueue","url":"/2020/03/05/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Java%E9%98%9F%E5%88%97-%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AALinkedListQueue/","content":"\n    引言：数据结构——链表队列\n\n\n\n\n\nLinkedListQueue如果我们直接使用之前我们编写的LinkedList的话，为了实现队列的FIFO的特性，我们必须选一端入，一端出，但是这就有了一个问题\n我们的LinkedList有头结点，向头添加或者删除都是O(1)，很方便，但是如果是对尾部的操作的话，就都是O(n)了\n这其实和使用Array来实现的一样，在数组中，操作尾部是简单的，但是操作头是困难的\n所以为了提高链表队列的性能，我们需要改进一下现有的LinkedList，即再增添一个尾节点\n又因为实现队列，只需要FIFO，即只需要对头和尾来进行操作，所以我们不需要设置一个虚拟头结点\n\n/** * 改进LinkedList实现队列 * @author BlackKnight */public class LinkedListQueue&lt;E&gt; implements Queue&#123;    /**     * 我们依然需要结点     */    private class Node&#123;        public E e;        public Node next;        /**         * 方便我的LinkedListQueue类来访问结点         * 有多个重载方法         * @param e         * @param next         */        public Node(E e, Node next) &#123;            this.e = e;            this.next = next;        &#125;        public Node(E e) &#123;            this(e,null);        &#125;        public Node() &#123;            this(null,null);        &#125;        @Override        public String toString() &#123;            return &quot;Node&#123;&quot; +                    &quot;e=&quot; + e +                    &quot;, next=&quot; + next +                    &#x27;&#125;&#x27;;        &#125;    &#125;    private Node head;    private Node tail;    private int size;    public LinkedListQueue() &#123;        this.head = null;        this.tail = null;        this.size = 0;    &#125;    @Override    public int getSize() &#123;        return size;    &#125;    @Override    public boolean isEmpty() &#123;        return size==0;    &#125;    /**     * 入队     * 我们需要对链表的尾部进行操作     * @param o     */    @Override    public void enqueue(Object o) &#123;        //如果尾节点是空，说明队列中没有元素        if(tail == null)&#123;            tail = new Node((E)o);            head = tail;        &#125;else &#123;            tail.next =  new Node((E)o);            tail = tail.next;        &#125;        size++;    &#125;    @Override    public E dequeue() &#123;        if(isEmpty())&#123;            throw new IllegalArgumentException(&quot;队列为空，出队错误&quot;);        &#125;        Node delNode = head;        head = head.next;        delNode.next = null;        //假如只有一个元素，我们删掉他之后，head指向空，但是tail还指向那个被删除的元素，所以置空tail        if(head == null)&#123;            tail = null;        &#125;        size--;        return delNode.e;    &#125;    @Override    public E getFront() &#123;        if(isEmpty())&#123;            throw new IllegalArgumentException(&quot;队列为空，出队错误&quot;);        &#125;        return head.e;    &#125;    @Override    public String toString() &#123;        StringJoiner sj = new StringJoiner(&quot;-&gt;&quot;,&quot;Queue: Head [&quot;,&quot;] tail&quot;);        Node cur = head;        while (cur!=null)&#123;            sj.add(cur.e+&quot;&quot;);            cur = cur.next;        &#125;        return sj.toString();    &#125;&#125;\n\n复杂度分析方法名                  | 时间复杂度 |-------------------------------------------------enqueue()               |     O(1)   |dequeue()               |     O(1)   |front()                 |     O(1)   |getSize()               |     O(1)   |isEmpty()               |     O(1)   |\n\n\nLinkedListQueue 对比 LoopQueueQueue现在我们有三种\n\nArrayQueue\nLoopQueue\nLinkedListQueue\n\nArrayQueue速度慢于LoopQueue很多，那么LinkedListQueue和LoopQueue相比会怎么样呢\npublic class SpeedTest &#123;    public static void main(String[] args) &#123;        int loopTurn = 10_000_000;        Queue&lt;Integer&gt; loopQueue = new LoopQueue&lt;&gt;();        Queue&lt;Integer&gt; linkedListQueue = new LinkedListQueue&lt;&gt;();        System.out.println(&quot;loopQueue运行时间：&quot;+testSpeed(loopTurn,loopQueue)+&quot;s&quot;);        System.out.println(&quot;linkedListQueue运行时间：&quot;+testSpeed(loopTurn,linkedListQueue)+&quot;s&quot;);    &#125;    private static double testSpeed(int loopTurn, Queue&lt;Integer&gt; q) &#123;        long startTime = System.nanoTime();        for(int i=0;i&lt;loopTurn;i++) &#123;            Random r = new Random();            q.enqueue(r.nextInt(Integer.MAX_VALUE));        &#125;        for(int i=0;i&lt;loopTurn;i++) &#123;            q.dequeue();        &#125;        long endTime = System.nanoTime();        return (endTime - startTime) / 1000000000.0;    &#125;&#125;\n执行一百万次代码\nloopQueue运行时间：2.8736317slinkedListQueue运行时间：4.035901s\n对比结果，LinkedListQueue慢了几秒，这是由于不断的new结点造成的速度下降\n","categories":["数据结构"],"tags":["Java","数据结构","队列"]},{"title":"Java队列_手写一个ArrayQueue","url":"/2020/03/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Java%E9%98%9F%E5%88%97-%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AAArrayQueue/","content":"\n    引言：数据结构——队列\n\n\n\n\nArrayQueue实现队列同样有两种方式，这里我们使用Array来实现\n用户不需要知道底层的实现方式，所以我们先写一个Queue的接口吧\n/** * @author BlackKnight */public interface Queue&lt;E&gt; &#123;    int getSize();    boolean isEmpty();    /**     *入队列     * @param e     */    void enqueue(E e);    /**     * 出队列     * @return     */    E dequeue();    /**     * 得到队头元素     * @return     */    E getFront();&#125;\n\n然后我们想一想，我们需要什么方法？\n\nimport array.Array;import java.util.StringJoiner;/** * @author BlackKnight */public class ArrayQueue&lt;E&gt; implements Queue&#123;    Array&lt;E&gt; array;    public ArrayQueue(int capacity) &#123;        this.array = new Array&lt;&gt;(capacity);    &#125;    public ArrayQueue() &#123;        array = new Array&lt;&gt;();    &#125;    @Override    public int getSize() &#123;        return array.getSize();    &#125;    @Override    public boolean isEmpty() &#123;        return array.isEmpty();    &#125;    /**     * 添加从尾添加     * @param o     */    @Override    public void enqueue(Object o) &#123;        array.addLast((E)o);    &#125;    /**     * 出从队头出     * @return     */    @Override    public E dequeue() &#123;        return array.removeFirst();    &#125;    @Override    public E getFront() &#123;        return array.get(0);    &#125;    public int getCapacity()&#123;        return array.getCapacity();    &#125;    @Override    public String toString() &#123;        StringJoiner sj = new StringJoiner(&quot;,&quot;,&quot;Queue: front [&quot;,&quot;] tail&quot;);        for(int i =0;i&lt;array.getSize();i++)&#123;            sj.add(array.get(i)+&quot;&quot;);        &#125;        return sj.toString();    &#125;&#125;\n\n\n\n\n复杂度分析方法名                  | 时间复杂度 |-------------------------------------------------enqueue(E e)            |     O(1)   | （均摊复杂度）dequeue()               |     O(n)   |front()                 |     O(1)   |getSize()               |     O(1)   |isEmpty()               |     O(1)   |\n这里我们可以注意到，在使用Array来实现队列，它的出队时间复杂度需要O(n)，在数据量很大的情况下，出队一次就需要浪费我们很长时间\n那么我们怎么解决这个问题呢？\n使用循环队列\n参考资料\n参考资料：来自慕课liuyubobobo的教程\n\n","categories":["数据结构"],"tags":["Java","数据结构","队列"]},{"title":"Java栈_手写一个LinkedListStack","url":"/2020/03/05/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Java%E6%A0%88-%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AALinkedListStack/","content":"\n    引言：链表栈\n\n\n\n\nLinkedListStack之前我们说过，实现栈有两种方式，这次就来通过链表来实现栈\n由于底层不需要用户知道，我们还是继续实现栈的接口：\n/** * @author BlackKnight */public interface Stack&lt;E&gt; &#123;    /**     * 获取大小     * @return     */    int getSize();    /**     * 判空     * @return     */    boolean isEmpty();    /**     * 入栈     * @param e     */    void push(E e);    /**     * 出栈/弹栈     * @return     */    E pop();    /**     * 查看栈顶元素     * @return     */    E peak();&#125;\n\n实现的功能:\n\n代码如下：\npackage stack;import linkedList.LinkedList;/** * 使用链表来实现栈 * @author BlackKnight */public class LinkedListStack&lt;E&gt; implements Stack&#123;    private LinkedList&lt;E&gt; list;    public LinkedListStack() &#123;        list = new LinkedList&lt;E&gt;();    &#125;    @Override    public int getSize() &#123;        return list.getSize();    &#125;    @Override    public boolean isEmpty() &#123;        return list.isEmpty();    &#125;    @Override    public void push(Object o) &#123;        list.addFirst((E)o);    &#125;    @Override    public Object pop() &#123;        return list.removeFirst();    &#125;    @Override    public Object peak() &#123;        return list.getFirst();    &#125;    @Override    public String toString() &#123;        StringBuilder sb = new StringBuilder();        sb.append(&quot;Stack: top&quot;);        sb.append(list);        return sb.toString();    &#125;&#125;\n\n复杂度分析方法名                  | 时间复杂度 |-------------------------------------------------push(E e)               |     O(1)   |pop()                   |     O(1)   |peek()                  |     O(1)   |getSize()               |     O(1)   |isEmpty()               |     O(1)   |\n由于push pop方法底层是addFirst removeFirst，所以他们的时间复杂度其实也是O(1)\n这和ArrayList是一致的\nArrayStack 与 LinkedListStack 比较分别使用两个不同的数据结构实现的栈，他们速度有什么不同呢\npublic class SpeedTest &#123;    public static void main(String[] args) &#123;        int loopTurn = 10_000_000;        Stack&lt;Integer&gt; arrayStack = new ArrayStack&lt;&gt;();        Stack&lt;Integer&gt; linkedListStack = new LinkedListStack&lt;&gt;();        System.out.println(&quot;arrayStack运行时间：&quot;+testSpeed(loopTurn,arrayStack)+&quot;s&quot;);        System.out.println(&quot;linkedListStack运行时间：&quot;+testSpeed(loopTurn,linkedListStack)+&quot;s&quot;);    &#125;    private static double testSpeed(int loopTurn, Stack&lt;Integer&gt; q) &#123;        long startTime = System.nanoTime();        for(int i=0;i&lt;loopTurn;i++) &#123;            Random r = new Random();            q.push(r.nextInt(Integer.MAX_VALUE));        &#125;        for(int i=0;i&lt;loopTurn;i++) &#123;            q.pop();        &#125;        long endTime = System.nanoTime();        return (endTime - startTime) / 1000000000.0;    &#125;&#125;\n运行的结果如下\narrayStack运行时间：2.4849806slinkedListStack运行时间：4.1543247s\n看起来LinkedListStack好像要比ArrayStack慢，\n但其实我们分析他们的时间复杂度是一样的\n在JVM中，LinkedListStack慢的原因是因为，运行如此大的数据，它的事件浪费在了new结点上，而不是操作上\n参考资料\n参考资料：来自慕课liuyubobobo的教程\n\n","categories":["数据结构"],"tags":["Java","数据结构","队列"]},{"title":"Java链表_手写一个LinkedList","url":"/2020/03/05/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Java%E9%93%BE%E8%A1%A8-%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AALinkedList/","content":"\n    引言：数据结构——链表\n\n\n\n\nLinkedList在线性表家族中，\n对于数组、栈、队列来说，他们虽然实现了动态，但底层却还是静态的\n但是对于链表来说，它是真正的动态，但失去了随机读取的功能\n方法如下\n代码如下：\n/** * 手写一个链表 * @author BlackKnight */public class LinkedList&lt;E&gt;&#123;    /**     * 链表的核心——结点     * 私有内部类     */    private class Node&#123;        public E e;        public Node next;        /**         * 方便我的LinkedList类来访问结点         * 有多个重载方法         * @param e         * @param next         */        public Node(E e, Node next) &#123;            this.e = e;            this.next = next;        &#125;        public Node(E e) &#123;            this(e,null);        &#125;        public Node() &#123;            this(null,null);        &#125;        @Override        public String toString() &#123;            return &quot;Node&#123;&quot; +                    &quot;e=&quot; + e +                    &quot;, next=&quot; + next +                    &#x27;&#125;&#x27;;        &#125;    &#125;    private Node head;    private int size;    public LinkedList() &#123;        this.head = null;        this.size = 0;    &#125;    public int getSize()&#123;        return size;    &#125;    public boolean isEmpty()&#123;        return size==0;    &#125;    /**     * 向链表头添加结点     * @param e     */    public void addFirst(E e)&#123;        /*不同于数组在末尾添加元素，链表更容易在头head添加元素          将一个元素添加到一个链表的头部，其实只需要两步就能完成            1. 将要插入的结点的next指向当前链表的head            2. 再把head重新指向被插入结点         */        //Node node = new Node(e);        //node.next = head;        //head = node;        //上述三行代码可以更 优雅 ，一行就可以完成        head = new Node(e,head);        size++;    &#125;    /**     * 向链表中间添加结点     * @param index     * @param e     */    public void add(int index, E e)&#123;        if(index&lt;0||index&gt;size)&#123;            throw new IllegalArgumentException(&quot;无效的index&quot;);        &#125;        //如果要放在第0个位置上，就需要判断一下，因为没有第-1个结点        //但是我们可以单独设置一个 虚拟头结点 来避免这种判断        if(index==0)&#123;            addFirst(e);        &#125;else &#123;            Node prev = head;            //插入的核心：找到所要插入位置的前一个结点！            //这里的循环条件注意要理解，不理解可以画画图，举举例子            for(int i=0; i &lt; index - 1 ;i++)&#123;                prev = prev.next;            &#125;            //Node node = new Node(e);            //node.next = prev.next;            //prev.next = node;            //同样，可以更加的优雅            prev.next = new Node(e,prev.next);            size++;        &#125;    &#125;    public void addLast(E e)&#123;        add(size,e);    &#125;&#125;\n上述的代码并没有写完，因为在使用过程中，带有虚拟头结点的链表是非常多的，所以我们下面来写使用带有虚拟头结点的链表\n真正的代码如下：\npackage linkedList;import java.util.StringJoiner;/** * 手写一个链表 * @author BlackKnight */public class LinkedList&lt;E&gt;&#123;    /**     * 链表的核心——结点     * 私有内部类     */    private class Node&#123;        public E e;        public Node next;        /**         * 方便我的LinkedList类来访问结点         * 有多个重载方法         * @param e         * @param next         */        public Node(E e, Node next) &#123;            this.e = e;            this.next = next;        &#125;        public Node(E e) &#123;            this(e,null);        &#125;        public Node() &#123;            this(null,null);        &#125;        @Override        public String toString() &#123;            return &quot;Node&#123;&quot; +                    &quot;e=&quot; + e +                    &quot;, next=&quot; + next +                    &#x27;&#125;&#x27;;        &#125;    &#125;    private Node dummyHead;    private int size;    public LinkedList() &#123;        //虚拟头结点        this.dummyHead = new Node(null,null);        this.size = 0;    &#125;    public int getSize()&#123;        return size;    &#125;    public boolean isEmpty()&#123;        return size==0;    &#125;    /**     * 向链表中间添加结点     * @param index     * @param e     */    public void add(int index, E e)&#123;        if(index&lt;0||index&gt;size)&#123;            throw new IllegalArgumentException(&quot;无效的index&quot;);        &#125;        //设置一个了虚拟头结点 避免判断是不是要插在0的位置上        Node prev = dummyHead;        //插入的核心：找到所要插入位置的前一个结点！        //这里的循环条件注意要理解，不理解可以画画图，举举例子        for(int i=0; i &lt; index ;i++)&#123;            //因为我们从虚拟头结点开始遍历，条件就不再是 index-1 了            prev = prev.next;        &#125;        //Node node = new Node(e);        //node.next = prev.next;        //prev.next = node;        //同样，可以更加的优雅        prev.next = new Node(e,prev.next);        size++;    &#125;    /**     * 向链表头添加结点     * @param e     */    public void addFirst(E e)&#123;        /*        因为使用了虚拟头结点，所以直接可以复用add方法了         */        add(0,e);        size++;    &#125;    /**     * 向链表位添加结点     * @param e     */    public void addLast(E e)&#123;        add(size,e);    &#125;    /**     * 获得链表第index个元素     * 并不常用     * @param index     * @return     */    public E get(int index)&#123;        if(index&lt;0||index&gt;size)&#123;            throw new IllegalArgumentException(&quot;无效的index&quot;);        &#125;        /*        不同于插入时的遍历，这里的遍历需要遍历到index，而不是index的前一个         */        Node cur = dummyHead.next;        //这里直接赋值到了第0个结点        for(int i=0 ;i&lt;index;i++)&#123;            cur = cur.next;        &#125;        return cur.e;    &#125;    public E getFirst()&#123;        return get(0);    &#125;    public E getLast()&#123;        return get(size);    &#125;    /**     * 修改的方法     * @param index     * @param e     */    public void set(int index , E e)&#123;        if(index&lt;0||index&gt;size)&#123;            throw new IllegalArgumentException(&quot;无效的index&quot;);        &#125;        Node cur = dummyHead.next;        for(int i=0 ;i&lt;index;i++)&#123;            cur = cur.next;        &#125;        cur.e = e;    &#125;    /**     * 查找     * @param e     * @return     */    public boolean contains(E e)&#123;        Node cur = dummyHead.next;        while (cur!=null)&#123;            if(cur.e.equals(e))&#123;                return true;            &#125;            cur = cur.next;        &#125;        return false;    &#125;    @Override    public String toString() &#123;        StringJoiner sj = new StringJoiner(&quot;-&gt;&quot;,&quot;LinkedList: dummyHead-&gt;[&quot;,&quot;]-&gt;null&quot;);        Node cur = dummyHead.next;        while (cur!=null)&#123;            sj.add(cur.e+&quot;&quot;);            cur = cur.next;        &#125;        return sj.toString();    &#125;    /**     * 删除一个结点     * @param index     * @return     */    public E remove(int index)&#123;        if(index&lt;0||index&gt;size)&#123;            throw new IllegalArgumentException(&quot;无效的index&quot;);        &#125;        Node prev = dummyHead;        /*        删除一个结点，也是要找要删除结点的前一个结点         */        for(int i = 0;i &lt; index;i++)&#123;            prev = prev.next;        &#125;        Node ret = prev.next;        prev.next = prev.next.next;        //将被删除结点从链表中分离出来        ret.next = null;        size--;        return ret.e;    &#125;    public E removeFirst()&#123;        return remove(0);    &#125;    public E removeLast()&#123;        return remove(size-1);    &#125;&#125;\n\n复杂度分析方法名                  | 时间复杂度 |--------------------------------------add()                   |     O(n)   |addFirst()              |     O(1)   | addLast()               |     O(n)   |--------------------------------------      remove()                |     O(n)   |removeFirst()           |     O(1)   |removeLast()            |     O(n)   |--------------------------------------get()                   |     O(n)   |isEmpty()               |     O(1)   |contains()              |     O(n)   |--------------------------------------set()                   |     O(n)   |注意：O(n/2) = O(n)\n由此可见，除了少数对头操作的方法外，几乎所有的方法，时间复杂度都是O(n)\n剖析虚拟头结点的作用LeetCode中有一道题\n删除链表中等于给定值 val 的所有节点。\n/** * Definition for singly-linked list. * public class ListNode &#123; *     int val; *     ListNode next; *     ListNode(int x) &#123; val = x; &#125; * &#125; */示例:输入: 1-&gt;2-&gt;6-&gt;3-&gt;4-&gt;5-&gt;6, val = 6输出: 1-&gt;2-&gt;3-&gt;4-&gt;5\n\n这里有两种不同的解决办法\n不用虚拟头结点class Solution &#123;    public ListNode removeElements(ListNode head, int val) &#123;        //假如一开始就出现了val        //注意，当删除完一个结点后，不用再移动结点了        while(head!=null &amp;&amp; head.val==val)&#123;            ListNode del = head;            head = head.next;            del.next = null;        &#125;        if(head==null)&#123;            return null;        &#125;        ListNode prev = head;        //这里删除中间出现的val        while(prev.next!=null)&#123;            if(prev.next.val == val)&#123;                ListNode delNode = prev.next;                prev.next = prev.next.next;                delNode.next = null;            &#125;            else prev = prev.next;        &#125;        return head;    &#125;&#125;\n使用虚拟头结点class Solution &#123;    public ListNode removeElements(ListNode head, int val) &#123;                ListNode dummyHead = new ListNode(0);        dummyHead.next = head;        ListNode prev = dummyHead;        //这里删除中间出现的val        while(prev.next!=null)&#123;            if(prev.next.val == val)&#123;                ListNode delNode = prev.next;                prev.next = prev.next.next;                delNode.next = null;            &#125;            else prev = prev.next;        &#125;        return dummyHead.next;    &#125;&#125;\n区别使用虚拟头结点，可以不用再讨论head的特殊性，因为此时所有的结点都有一个前置的结点\n返回的时候返回虚拟头结点的next即可\n所以我们可以有如下总结\n\n如果只是操作头结点，则我们可以不使用虚拟头结点\n如果要对中间的结点进行操作，使用虚拟头结点可以避免分类讨论\n两者可以互换，但要注意条件\n\n参考资料\n参考资料：来自慕课liuyubobobo的教程\n\n","categories":["数据结构"],"tags":["Java","数据结构","队列"]},{"title":"堆和优先队列","url":"/2020/09/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%A0%86%E5%92%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97-Java%E5%AE%9E%E7%8E%B0/","content":"\n    引言：数据结构——优先队列和堆\n\n\n\n\n堆和优先队列优先队列\n普通队列：先进先出FIFO\n\n优先队列：出队顺序和入队顺序无关，和优先级相关\n\n\n优先队列应用很广，比如操作系统的任务调度，就需要动态选择优先级最高的任务执行；还有一个游戏的AI，当敌人来了之后会默认的攻击威胁程度最大的敌人等等，都使用了优先队列\n\n优先队列需要实现的接口依然还是\n/** * @author BlackKnight */public interface Queue&lt;E&gt; &#123;    int getSize();    boolean isEmpty();    /**     *入队列     * @param e     */    void enqueue(E e);    /**     * 出队列     * @return     */    E dequeue();    /**     * 得到队头元素     * @return     */    E getFront();&#125;\n\n\n\n但是我们可以使用不用的数据结构实现相同的功能，比如说普通的线性结构（数组，链表），比如说顺序的线性结构（保持着排序）等等，但是最好的方式是使用堆来实现，比较如下\n\n\n\n\n二叉堆二叉堆是一棵完全二叉树（缺失的叶子节点都在右下方）\n\n\n堆的特性：\n\n一棵完全二叉树\n一颗平衡二叉树\n堆的某个节点的值总是不大于其父节点的值（最大堆）\n同上也有最小堆\n\n可以使用树的结构来实现堆，但是由于堆是一棵完全二叉树，所以可以使用数组来实现完全二叉树（可以完美的对应数组的下标）\n\n\n如图，有三条性质，这三条性质就是数组下标和二叉堆结点的对应关系，而且为了防止0号空间无使用，我们略微改变了一下，就有\n\nparent(i) = ( i - 1 ) / 2\nleftChild (i) = 2*i +1\nrightChild (i) = 2*i + 2\n\n使用数组实现二叉堆，代码如下：（数组使用我们之前实现的数组）\nimport array.Array;/** * @Date 2020/9/23 20:35 * 最大堆 */public class MaxHeap&lt;E extends Comparable&lt;E&gt;&gt; &#123;    /**     * 使用数组实现堆     */    private Array&lt;E&gt; data;    public MaxHeap(int capacity) &#123;        data = new Array&lt;&gt;(capacity);    &#125;    public MaxHeap() &#123;        data = new Array&lt;&gt;();    &#125;    /**     * 返回堆中的元素个数     *     * @return     */    public int size() &#123;        return data.getSize();    &#125;    /**     * 返回一个布尔值，表示堆是否为空     *     * @return     */    public boolean isEmpty() &#123;        return data.isEmpty();    &#125;    /**     * 三个辅助方法：     * 1. 返回完全二叉树的数组表示中，一个索引所表示的元素的父亲节点的索引     */    private int parent(int index) &#123;        if (index == 0) &#123;            throw new IllegalArgumentException(&quot;索引0：没有父亲节点&quot;);        &#125;        return (index - 1) / 2;    &#125;    /**     * 三个辅助方法：     * 2. 返回完全二叉树的数组表示中，一个索引所表示的元素的左孩子节点的索引     */    private int leftChild(int index) &#123;        return 2 * index + 1;    &#125;    /**     * 三个辅助方法：     * 3. 返回完全二叉树的数组表示中，一个索引所表示的元素的右孩子节点的索引     */    private int rightChild(int index) &#123;        return 2 * index + 2;    &#125;    /**     * 向堆中添加元素     */    public void add(E e) &#123;        data.addLast(e);        siftUp(data.getSize() - 1);    &#125;    /**     * 调整最大堆的结构     *     * @param k 传入索引     */    private void siftUp(int k) &#123;        while (k &gt; 0 &amp;&amp; data.get(parent(k)).compareTo(data.get(k)) &lt; 0) &#123;            // 交换两个元素            swap(k, parent(k));            k = parent(k);        &#125;    &#125;    private void swap(int i, int j) &#123;        E temp = data.get(i);        data.set(i, data.get(j));        data.set(j, temp);    &#125;    public E findMax() &#123;        if (isEmpty()) &#123;            throw new IllegalArgumentException(&quot;堆是空的&quot;);        &#125;        return data.get(0);    &#125;    public E extractMax() &#123;        E e = findMax();        // 先将最大和最小交换位置        swap(0, data.getSize() - 1);        // 删除最后一个元素        data.removeLast();        siftDown(0);        return e;    &#125;    private void siftDown(int k) &#123;        // 如果左孩子都越界了，那么肯定要停止了        while (leftChild(k) &lt; data.getSize()) &#123;            int j = leftChild(k);            // 判断有没有右孩子，且 右孩子比左孩子大            if (j + 1 &lt; data.getSize()                    &amp;&amp; data.get(j + 1).compareTo(data.get(j)) &gt; 0) &#123;                j++;                // data.get(j) 是左右孩子中的最大值            &#125;            // 如果 k位置的值比他的两个孩子内更大的孩子大，说明已经完成调度            if (data.get(k).compareTo(data.get(j)) &gt;= 0) &#123;                break;            &#125;            swap(k, j);            k = j;        &#125;    &#125;&#125;\n\n\n\n关于增添方法和删除方法增添方法思想：\n将要添加的元素放在完全二叉树的最后一个节点，然后逐级与根节点比较，放置在一个合适的位置上\n删除方法思想：\n交换堆顶和最后一个节点，将新的头结点放置在一个合适的位置\n优先队列有了二叉堆，实现优先队列就特别简单了\npackage queue;import heap.MaxHeap;/** * @Date 2020/9/23 19:31 * 优先队列 */public class PriorityQueue&lt;E extends Comparable&lt;E&gt;&gt; implements Queue&lt;E&gt;&#123;    private MaxHeap&lt;E&gt; maxHeap;    @Override    public int getSize() &#123;        return maxHeap.size();    &#125;    @Override    public boolean isEmpty() &#123;        return maxHeap.isEmpty();    &#125;    @Override    public void enqueue(E e) &#123;        maxHeap.add(e);    &#125;    @Override    public E dequeue() &#123;        return maxHeap.extractMax();    &#125;    @Override    public E getFront() &#123;        return maxHeap.findMax();    &#125;&#125;\n\n\n\n","categories":["数据结构","优先队列","堆"],"tags":["数据结构","优先队列","heap堆"]},{"title":"Java二叉搜索树_手写一个BST","url":"/2020/09/13/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-Java%E5%AE%9E%E7%8E%B0/","content":"\n    引言：数据结构——二叉搜索树\n\n\n\n\n二叉搜索树二叉树树的基本结构，不过多叙述：\n\n\n具有天然的递归结构\n\n每个结点的左、右子树都是二叉树\n\n\n满二叉树：除了叶子结点外，每个结点都有两个孩子\n例如这一棵就不是满二叉树：\n\n\n空也是二叉树\n\n\n二分搜索树(Binary Search Tree)\n首先是一棵二叉树\n独有的特点：每一个节点的值\n大于左子树所有结点的值\n小于右子树所有结点的值\n\n\n每一棵子树也是二分搜索树\n注意：存储的元素必须具有可比较性，存储一个int类的数据，当然可以比较大小，但是存储一个学生类、车类等实体类，我们必须规定它的比较方式，比如学生可以按年龄比较等等\n\n二分搜索树代码package BinaryTree;import java.util.LinkedList;import java.util.Queue;import java.util.Stack;/** * @author 董文浩 * @Date 2020/9/7 11:46 * 二分搜索数 *///泛型必须满足可比较性，所以继承了Comparable接口public class BinarySearchTree&lt;E extends Comparable&lt;E&gt;&gt; &#123;    /**     * 内部节点类     */    private class Node &#123;        public E e;        public Node left, right;        public Node(E e) &#123;            this.e = e;            left = null;            right = null;        &#125;    &#125;    /**     * 根     */    private Node root;    /**     * 存储元素个数     */    private int size;    /**     * 初始化构造方法     */    public BinarySearchTree() &#123;        root = null;        size = 0;    &#125;    /**     * 返回当前大小     *     * @return     */    public int size() &#123;        return size;    &#125;    /**     * 是否为空     *     * @return     */    public boolean isEmpty() &#123;        return size == 0;    &#125;    public void add(E e) &#123;        root = add(root, e);    &#125;    /**     * 递归插入     *     * @param node     * @param e     */    private void add1(Node node, E e) &#123;        //********* 终止条件 *************        if (e.equals(node.e)) &#123;            return;        &#125; else if (e.compareTo(node.e) &lt; 0 &amp;&amp; node.left == null) &#123;            node.left = new Node(e);            size++;            return;        &#125; else if (e.compareTo(node.e) &gt; 0 &amp;&amp; node.right == null) &#123;            node.right = new Node(e);            size++;            return;        &#125;        //*********  终止条件end ************        //*********  递归 *************        if (e.compareTo(node.e) &gt; 0) &#123;            add1(node.right, e);        &#125; else &#123;            // 一定是 &lt; 的 ，因为等于在最一开始就判断了            add1(node.left, e);        &#125;        //*********  递归end *************    &#125;    /**     * 递归插入：优化     *     * @param node     * @param e     * @return 返回插入新节点后二分搜索数的根节点     */    private Node add(Node node, E e) &#123;        //********* 终止条件 *************        if (node == null) &#123;            size++;            return new Node(e);        &#125;        //*********  终止条件end ************        //*********  递归 *************        if (e.compareTo(node.e) &gt; 0) &#123;            node.right = add(node.right, e);        &#125; else if (e.compareTo(node.e) &lt; 0) &#123;            node.left = add(node.left, e);        &#125;        return node;        //*********  递归end *************    &#125;    /**     * 二分搜索数的查询操作     *     * @param e     * @return     */    public boolean contains(E e) &#123;        return contains(root, e);    &#125;    /**     * 二分搜索树查询的递归操作     *     * @param node     * @param e     * @return     */    public boolean contains(Node node, E e) &#123;        if (node == null) &#123;            return false;        &#125;        if (node.e.compareTo(e) == 0) &#123;            return true;        &#125; else if (node.e.compareTo(e) &gt; 0) &#123;            return contains(node.left, e);        &#125; else &#123;            return contains(node.right, e);        &#125;    &#125;    /**     * 前序遍历二叉搜索树：根 -&gt; 左 -&gt; 右     */    public void preOrder() &#123;        preOrder(root);    &#125;    private void preOrder(Node node) &#123;        if (node == null) &#123;            return;        &#125;        System.out.println(node.e);        preOrder(node.left);        preOrder(node.right);    &#125;    /**     * 前序遍历二叉搜索树：非递归（深度优先遍历）     * 使用栈来辅助存储     * 要点：先将右孩子压入栈，然后将左孩子压入栈，因为出栈时是先进后出，所以前序遍历要先压入右孩子     */    public void preOrderNR() &#123;        Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;();        stack.push(root);        while (!stack.isEmpty())&#123;            Node cur = stack.pop();            System.out.println(cur.e);            if(cur.right!=null) &#123;                // 先压入右孩子                stack.push(cur.right);            &#125;            if(cur.left!=null)&#123;                stack.push(cur.left);            &#125;        &#125;    &#125;    /**     * 中序遍历二叉搜索树：左 -&gt; 根 -&gt; 右     */    public void inOrder() &#123;        inOrder(root);    &#125;    private void inOrder(Node node) &#123;        if (node == null) &#123;            return;        &#125;        inOrder(node.left);        System.out.println(node.e);        inOrder(node.right);    &#125;    /**     * 二叉搜索树的后序遍历：左 -&gt; 右 -&gt; 根     */    public void postOrder() &#123;        postOrder(root);    &#125;    private void postOrder(Node node) &#123;        if (node == null) &#123;            return;        &#125;        postOrder(node.left);        postOrder(node.right);        System.out.println(node.e);    &#125;    /**     * 二叉搜索树的层序遍历（广度优先遍历）     * 使用队列来辅助记录孩子节点     */    public void levelOrder()&#123;        Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;();        queue.add(root);        while (!queue.isEmpty())&#123;            Node cur = queue.remove();            System.out.println(cur.e);            if(cur.left!=null)&#123;                queue.add(cur.left);            &#125;            if(cur.right!=null)&#123;                queue.add(cur.right);            &#125;        &#125;    &#125;    /**     * 返回以node为根的二分搜索树的最小值所在的节点     * @return     */    private Node minimum(Node node)&#123;        if(node.left == null)&#123;            return node;        &#125;        return minimum(node.left);    &#125;    /**     * 返回以node为根的二分搜索树的最大值所在的节点     * @return     */    private Node maximum(Node node)&#123;        if(node.right == null)&#123;            return node;        &#125;        return minimum(node.right);    &#125;    /**     * 寻找最小值     * @return     */    public E minimum()&#123;        if(size==0)&#123;            throw new IllegalArgumentException(&quot;BST is empty!&quot;);        &#125;        return minimum(root).e;    &#125;    /**     * 寻找最大值     * @return     */    public E maximum()&#123;        if(size==0)&#123;            throw new IllegalArgumentException(&quot;BST is empty!&quot;);        &#125;        return maximum(root).e;    &#125;    /**     * 删除最小值     * @return     */    public E removeMin()&#123;        E ret = minimum();        root = removeMin(root);        return ret;    &#125;    /**     * 删除以node为根的最小结点     * @param node     * @return 删除节点后新的二分搜索树的根     */    private Node removeMin(Node node) &#123;        if(node.left ==null)&#123;            Node rightNode = node.right;            node.right = null;            size--;            return rightNode;        &#125;        node.left = removeMin(node.left);        return node;    &#125;    /**     * 删除最大值     * @return     */    public E removeMax()&#123;        E ret = maximum();        root = removeMax(root);        return ret;    &#125;    private Node removeMax(Node node) &#123;        if(node.right ==null)&#123;            Node leftNode = node.left;            node.left = null;            size--;            return leftNode;        &#125;        node.right = removeMax(node.right);        return node;    &#125;    /**     * 删除任意结点：1962年Hibbard提出的-Hibbard Deletion     * @param e     * @return     */    public void remove(E e)&#123;        root = remove(root, e);    &#125;    /**     * 删除以node为根的二分搜索树中值为 e 的结点     * @param node     * @param e     * @return     */    private Node remove(Node node, E e)&#123;        if(node == null)&#123;            return null;        &#125;        if(e.compareTo(node.e) &lt; 0)&#123;            node.left = remove(node.left, e);            return node;        &#125;else if(e.compareTo(node.e) &gt; 0)&#123;            node.right = remove(node.right, e);            return node;        &#125;else&#123; // e 等于 node.e            if(node.left == null)&#123;                Node rightNode = node.right;                node.right = null;                size --;                return rightNode;            &#125;            if(node.left == null)&#123;                Node leftNode = node.left;                node.left = null;                size --;                return leftNode;            &#125;            // 左右结点的左右子树均不为空            // 找 “最近” 的结点，这里找了被删除结点的后驱结点，其实也可以选择前驱            Node successor = minimum(node.right);            successor.right = removeMin(node.right);            successor.left = node.left;            // 与不再有关系，将node左右结点置为空            node.left = node.right = null;            return successor;        &#125;    &#125;    /**     * 重写toString方法     *     * @return     */    @Override    public String toString() &#123;        StringBuilder res = new StringBuilder();        generateBSTString(root, 0, res);        return res.toString();    &#125;    /**     * 生成以node为根节点，深度为depth的描述二叉树的字符串     *     * @param node     * @param depth     * @param res     */    private void generateBSTString(Node node, int depth, StringBuilder res) &#123;        if (node == null) &#123;            res.append(generateDepthString(depth) + &quot;null\\n&quot;);            return;        &#125;        res.append(generateDepthString(depth) + node.e + &quot;\\n&quot;);        generateBSTString(node.left, depth + 1, res);        generateBSTString(node.right, depth + 1, res);    &#125;    /**     * 打印深度，不同深度用不同的 “-” 来表示     *     * @param depth     * @return     */    private String generateDepthString(int depth) &#123;        StringBuilder res = new StringBuilder();        for (int i = 0; i &lt; depth; i++) &#123;            res.append(&quot;--&quot;);        &#125;        return res.toString();    &#125;&#125;\n\n\n\n删除操作\n1962年Hibbard提出的-Hibbard Deletion\n\n删除任意结点操作中，删除一个任意结点的值，关键在于要糅合被删除结点的孩子结点，关键是要找到被删除结点的“最近”的节点，如图，绿色的结点就是被删除结点的最近的结点\n\n所以我们要做的事情就是用这个绿色的结点替换掉蓝色的结点，就可以了\n(你可能发现了，其实也可以找53这个结点)\n实际使用中：\n前序遍历使用最广，因为前序遍历得到的是一个有序的串\n后序遍历的思想可以使用在内存的释放过程中\n前序遍历其实也叫作深度优先遍历\n层序遍历也叫作广度优先遍历\n\n注意：当存入的数据是一个有序的数据时，我们的二叉搜索树会变成一个链表\n为了解决这个问题，我们就要实现平衡二叉树（以后我们会说到平衡二叉树）\n","categories":["数据结构","树"],"tags":["Java","数据结构","二叉搜索树","树"]},{"title":"Java队列_手写一个LoopQueue","url":"/2020/03/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Java%E9%98%9F%E5%88%97-%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AALoopQueue/","content":"\n    引言：数据结构——循环队列\n\n\n\n\n\nLoopQueue在实现完ArrayQueue之后，发现ArrayQueue有一个致命的缺点，就是出队列需要O(n)的时间复杂度，因为每次出队时，后面的元素都要向前移动一个空间，所以造成了时间复杂度上升\n怎么解决这个问题呢？在出队之后，我们可以不移动，使用一个front和tail来标记队头和队尾，再把队头队尾连起来，实现一个循环队列\n这样当出队时，只需要front++，入队只需要tail++，时间复杂度都是O(1)，解决了上述的问题\n循环队列需要什么方法\n\n这里我们会继续实现Queue这个接口，Queue接口的代码如下，和\n/** * @author BlackKnight */public interface Queue&lt;E&gt; &#123;    int getSize();    boolean isEmpty();    /**     *入队列     * @param e     */    void enqueue(E e);    /**     * 出队列     * @return     */    E dequeue();    /**     * 得到队头元素     * @return     */    E getFront();&#125;\n\n\n\n\n代码如下：package queue;import java.util.StringJoiner;/** * @author BlackKnight * 实现循环队列 */public class LoopQueue&lt;E&gt; implements Queue &#123;    private E[] data;    private int front , tail;    private int size;    private final static int initialCapacity = 10;    /**     * 构造方法     * @param capacity     */    public LoopQueue(int capacity) &#123;        data = (E[]) new Object[capacity+1];        //这里为什么要+1呢？        /*我们在判断循环队列满或空的时候，需要使用一个空间来分辨          * 假如我们不+1            空的条件为：front == tail;            满的条件为：front == tail;          * 假如我们+1            空的条件为：front == tail;            满的条件为：front == tail + 1;            （考虑到tail指向最后一个空间的时候，              判断满正确来说应该是：              (tail + 1) % capacity = front;）        */        front = 0;        tail = 0;        size = 0;    &#125;    public LoopQueue() &#123;        this(initialCapacity);    &#125;    public int getCapacity()&#123;        //有一个空间浪费掉，所以-1        return data.length - 1;    &#125;    @Override    public int getSize() &#123;        return size;    &#125;    @Override    public boolean isEmpty() &#123;        //判断空的条件        return front == tail;    &#125;    /**     * 入队     * @param o     */    @Override    public void enqueue(Object o) &#123;        //判断是否需要扩容        if((tail +1 )% data.length == front)&#123;            resize(getCapacity() * 2);        &#125;        data[tail] = (E) o;        tail = (tail +1)% data.length;        size++;    &#125;    /**     * 扩容     * @param newCapacity     */    private void resize(int newCapacity) &#123;        E[] newData = (E[]) new Object[newCapacity];        /*        我们扩容的时候可以直接往0~size赋值         */        for (int i = 0; i &lt; size; i++) &#123;            //这里data的下标需要注意！！！            newData[i] = data[(front + i) % data.length];        &#125;        data = newData;        front = 0;        tail = size;    &#125;    /**     * 出队     * @return     */    @Override    public E dequeue() &#123;        if(size == 0)&#123;            throw new IllegalArgumentException(&quot;队列为空，不能删除&quot;);        &#125;        E ret = data[front];        /*同样为了防止出现游荡对象loitering objects，这里手动的置空*/        data[front] = null;        /*循环队列，注意不能简单的++*/        front = (front+1)%data.length;        size--;        /*            防止复杂度震荡，所以判断size == getCapacity()/4            且防止当队列capacity为2时，出现2/2==0，重新分配0个内存的情况，所以判断getCapacity()/2!=0        */        if(size == getCapacity()/4 &amp;&amp; getCapacity()/2!=0)&#123;            resize(getCapacity()/2);        &#125;        return ret;    &#125;    @Override    public E getFront() &#123;        if (isEmpty())&#123;            throw new IllegalArgumentException(&quot;队列为空&quot;);        &#125;        return data[front];    &#125;    @Override    public String toString() &#123;        StringJoiner sj = new StringJoiner(&quot;,&quot;,&quot;LoopQueue: front [&quot;,&quot;] tail &quot;);        /*        注意这里循环的方式！！        循环数组，我们的i也必须循环起来         */        for(int i =front; i!=tail ;i= (i+1)%data.length)&#123;            sj.add(data[i]+&quot;&quot;);        &#125;        return sj.toString();    &#125;&#125;\n\n\n复杂度分析方法名                  | 时间复杂度 |-------------------------------------------------enqueue(E e)            |     O(1)   | （均摊复杂度）dequeue()               |     O(1)   | （均摊复杂度）front()                 |     O(1)   |getSize()               |     O(1)   |isEmpty()               |     O(1)   |\n\nArrayQueue 对比 LoopQueue数组队列和循环队列，他们之间的差距只在dequeue()这个方法上，一个是O(n),一个是O(1)\n这样的差距是天翻地覆的，下面的测试代码\npublic class Main &#123;    public static void main(String[] args) &#123;        int loopTurn = 500_000;        Queue&lt;Integer&gt; arrayQueue = new ArrayQueue&lt;&gt;();        Queue&lt;Integer&gt; loopQueue = new LoopQueue&lt;&gt;();        System.out.println(&quot;arrayQueue运行时间：&quot;+testQueue(loopTurn,arrayQueue)+&quot;s&quot;);        System.out.println(&quot;loopQueue运行时间：&quot;+testQueue(loopTurn,loopQueue)+&quot;s&quot;);    &#125;    private static double testQueue(int loopTurn, Queue&lt;Integer&gt; q) &#123;        long startTime = System.nanoTime();        for(int i=0;i&lt;loopTurn;i++) &#123;            Random r = new Random();            q.enqueue(r.nextInt(Integer.MAX_VALUE));        &#125;        for(int i=0;i&lt;loopTurn;i++) &#123;            q.dequeue();        &#125;        long endTime = System.nanoTime();        return (endTime - startTime) / 1000000000.0;    &#125;&#125;\n让他们各自分别执行五十万次，（原本想测试一百万次的，但是觉得太慢了）\n在我的电脑上得到如下成绩\narrayQueue运行时间：70.0025624sloopQueue运行时间：0.0590492s\n嘶！倒吸一口凉气，要不是我的音乐还在播放，我会以为我电脑卡了的。\n参考资料\n参考资料：来自慕课liuyubobobo的教程\n\n","categories":["数据结构"],"tags":["Java","数据结构","队列"]},{"title":"平衡二叉树-红黑树","url":"/2020/10/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E2%80%94%E2%80%94%E7%BA%A2%E9%BB%91%E6%A0%91/","content":"\n    引言：数据结构——平衡二叉树红黑树\n\n\n\n\n\n平衡二叉树——红黑树2-3树在了解红黑树之前，要先学习一下2-3树\n\n2-3树：\n满足二分搜索树的性质，但不是二叉树。\n2-3树就是每个节点有2个或者3个孩子的树\n\n\n\n 例如这就是一棵2-3树：\n\n\n重要的性质：2-3树是一棵绝对平衡（从根节点到任意节点的路径一定是相同的）的树\n绝对平衡如图：2-3树是一棵可以保持绝对平衡的树\n\n红黑树2-3树与红黑树的等价在理解2-3树是什么之后，理解红黑树就不会太难了。\n2-3树与红黑树之间的关系如图：\n\n\n\n\n由此我们再来看红黑树的性质：\n\n红黑树就是这样的树：\n\n每个节点是红色或者黑色\n根节点是黑色\n叶子节点是黑色\n如果一个节点是红色的，那么他的孩子节点都是黑色的\n如果一个红节点的孩子有一个是红色的，就出现四节点了，就不是我们所说的2-3树了\n\n\n从任意一个节点到叶子节点，经过的黑色节点是一样的（黑平衡）\n如同2-3树，是一棵绝对平衡的树\n\n\n\n\n红黑树添加元素红黑树只会添加红节点，以这个为前提，我们来看\n\n\n整体来看，处理的过程有三种情况\n\n代码package BinaryTree.RBTree;import BinaryTree.AVLTree.FileOperation;import java.util.ArrayList;/** * @author 董文浩 * @Date 2020/10/10 10:44 * 红黑树 */public class RBTree&lt;K extends Comparable&lt;K&gt;, V&gt; &#123;    // * 表示红色与黑色    private static final boolean RED = true;    private static final boolean BLACK = false;    private class Node&#123;        public K key;        public V value;        public Node left, right;        public boolean color;        public Node(K key, V value)&#123;            this.key = key;            this.value = value;            left = null;            right = null;            color = RED;    //* 只插入黑色节点        &#125;    &#125;    private Node root;    private int size;    public RBTree()&#123;        root = null;        size = 0;    &#125;    public int getSize()&#123;        return size;    &#125;    public boolean isEmpty()&#123;        return size == 0;    &#125;    // * 判断节点node的颜色    private boolean isRed(Node node)&#123;        // * 为null代表叶子结点，叶子节点都是黑色        if(node == null) &#123;            return BLACK;        &#125;        return node.color;    &#125;    //   node                     x    //  /   \\     左旋转         /  \\    // T1   x   ---------&gt;   node   T3    //     / \\              /   \\    //    T2 T3            T1   T2    private Node leftRotate(Node node)&#123;        Node x = node.right;        // 左旋转        node.right = x.left;        x.left = node;        // 改变颜色        x.color = node.color;   // 新的根节点继承原本根节点的颜色        node.color = RED;       // 左孩子变为红色        return x;    &#125;    //   node                     x    //  /   \\     右旋转         /  \\    //  x   T2   ---------&gt;     y   node    // / \\                           / \\    //y   T1                       T1   T2    private Node rightRotate(Node node)&#123;        Node x = node.left;        // 右旋转        node.left = x.right;        x.right = node;        // 维持节点颜色        x.color = node.color;        node.color = RED;        return x;    &#125;    // * 颜色翻转    private void filpColors(Node node)&#123;        node.color = RED;        node.left.color = BLACK;        node.right.color = BLACK;    &#125;    // 向红黑树中添加新的元素(key, value)    public void add(K key, V value)&#123;        root = add(root, key, value);        root.color = BLACK; // 完成后的根节点必须为黑色节点    &#125;    // 向以node为根的红黑树中插入元素(key, value)，递归算法    // 返回插入新节点后红黑树的根    private Node add(Node node, K key, V value)&#123;        if(node == null)&#123;            size ++;            return new Node(key, value); // 默认插入红色节点        &#125;        if(key.compareTo(node.key) &lt; 0) &#123;            node.left = add(node.left, key, value);        &#125; else if(key.compareTo(node.key) &gt; 0) &#123;            node.right = add(node.right, key, value);        &#125; else // key.compareTo(node.key) == 0        &#123;            node.value = value;        &#125;        // 左黑右红 -&gt; 左旋        if(isRed(node.right) &amp;&amp; !isRed(node.left))&#123;            node =leftRotate(node);        &#125;        // LL都为红        if(isRed(node.left) &amp;&amp; isRed(node.left.left))&#123;            node = rightRotate(node);        &#125;        // 左右为红        if(isRed(node.left) &amp;&amp; isRed(node.right))&#123;            filpColors(node);        &#125;        return node;    &#125;    // 返回以node为根节点的二分搜索树中，key所在的节点    private Node getNode(Node node, K key)&#123;        if(node == null) &#123;            return null;        &#125;        if(key.equals(node.key)) &#123;            return node;        &#125; else if(key.compareTo(node.key) &lt; 0) &#123;            return getNode(node.left, key);        &#125; else // if(key.compareTo(node.key) &gt; 0)        &#123;            return getNode(node.right, key);        &#125;    &#125;    public boolean contains(K key)&#123;        return getNode(root, key) != null;    &#125;    public V get(K key)&#123;        Node node = getNode(root, key);        return node == null ? null : node.value;    &#125;    public void set(K key, V newValue)&#123;        Node node = getNode(root, key);        if(node == null) &#123;            throw new IllegalArgumentException(key + &quot; doesn&#x27;t exist!&quot;);        &#125;        node.value = newValue;    &#125;    // 返回以node为根的二分搜索树的最小值所在的节点    private Node minimum(Node node)&#123;        if(node.left == null) &#123;            return node;        &#125;        return minimum(node.left);    &#125;    // 删除掉以node为根的二分搜索树中的最小节点    // 返回删除节点后新的二分搜索树的根    private Node removeMin(Node node)&#123;        if(node.left == null)&#123;            Node rightNode = node.right;            node.right = null;            size --;            return rightNode;        &#125;        node.left = removeMin(node.left);        return node;    &#125;&#125;\n\n\n\n\n\n对比普通平衡二叉树、AVL树、红黑树\n对于完全随机的数据来说，普通平衡二叉树足够使用了，因为完全随机的数据不会有太大的偏斜，而且普通平衡二叉树没有复杂的操作逻辑\n对于查询较多的情况，AVL树较好（红黑树牺牲了平衡性，达到了2logn）的高度\n红黑树的统计性能更好（综合增删查改所有操作）\n\n","categories":["数据结构","平衡二叉树","红黑树"],"tags":["数据结构","平衡二叉树","红黑树"]},{"title":"平衡二叉树-AVL树","url":"/2020/10/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91-AVL%E6%A0%91/","content":"\n    引言：数据结构——平衡二叉树AVL树\n\n\n\n\n\n平衡二叉树——AVL树\n平衡二叉树：任意节点的左子树和右子树的高度差不能超过1\n\n通过什么判断一棵树不再平衡呢？当然是它的左右子树差超过1的时候，我们把这个差值叫做平衡因子\n如图：\n\n\n树上黑色的数字代表该节点的高度：\n​    例如2那个叶子节点，它的高度是1\n​    例如8那个节点，它的左子树高度是3，右子树高度是1，那么他的高度就是较大的那个树的高度再加1，就是4\n树上的蓝色数字代表这个结点的平衡因子：\n​    例如2那个叶子结点，它的左右孩子都是null，所以它的平衡因子是0 - 0 = 0\n​    例如8那个叶子结点，它的左子树高度为3，右子树高度为1，所以它的平衡因子是3 - 1 = 2，超过了1，所以该树从这个结点开始不再平衡\n维护平衡的时机是什么时候呢？当我们从一个根节点开始不断插入值的时候，这棵树会不断的生长，如果在插入一个值的时候，平衡被破坏了，那么不管如何，将这颗树改为平衡状态一定是在这个叶子节点的父节点路径上\n\nAVL树一种最早的也是最经典的平衡二叉树，由G.M.Adelson-Velsky和E.M.Landis两位俄罗斯的科学家找出了 左旋和右旋 两种操作来实现树的平衡。\n对于平衡二叉树，有两种不平衡的状况（如图）：\n\n以上的两种状况是：\n\nLL 与 RR\nLR 与 RL\n\nLL与RR我们先来看右旋（同理可以得到左旋的代码）如图：\n\n在右旋完成后，我们需要去更新height（平衡因子）两个值，但是留心观察我们会发现，其实只需要更新x和y，而且要先更新y再更新x（因为对于T3来说根本没有发生变化，先更新y的原因是因为更新x需要y的值，所以要先更新y）\n右旋代码如下：\n// 对节点y进行向右旋转操作，返回旋转后新的根节点x//        y                              x//       / \\                           /   \\//      x   T4     向右旋转 (y)        z     y//     / \\       - - - - - - - -&gt;    / \\   / \\//    z   T3                       T1  T2 T3 T4//   / \\// T1   T2private Node rightRotate(Node y) &#123;    Node x = y.left;    Node T3 = x.right;    // 向右旋转过程    x.right = y;    y.left = T3;    // 更新height    y.height = Math.max(getHeight(y.left), getHeight(y.right)) + 1;    x.height = Math.max(getHeight(x.left), getHeight(x.right)) + 1;    return x;&#125;\n\n我们可以站在x的角度，理解“右旋”\n对于这种情况，只需先转换为LL与RR情况，在做改变即可：\n\n完整代码package BinaryTree.AVLTree;import java.util.ArrayList;/** * @author 董文浩 * @Date 2020/10/7 21:10 */public class AVLTree&lt;K extends Comparable&lt;K&gt;,V&gt; &#123;    private class Node &#123;        public K key;        public V value;        public Node left, right;        public int height; // 当前所处高度值        public Node(K key, V value) &#123;            this.key = key;            this.value = value;            left = null;            right = null;            height = 1; //默认高度为1        &#125;    &#125;    private Node root;    private int size;    public AVLTree() &#123;        root = null;        size = 0;    &#125;    // * 获得结点的高度    private int getHeight(Node node)&#123;        if(node==null) &#123;            return 0;        &#125;        return node.height;    &#125;    // * 计算结点的平衡因子    private int getBalanceFactor(Node node)&#123;        if(node == null) &#123;            return 0;        &#125;        return getHeight(node.left) - getHeight(node.right);    &#125;    public void add(K key, V value) &#123;        root = add(root, key, value);    &#125;    // * 判断该二叉树是否是一棵二分搜索树    public boolean isBST()&#123;        ArrayList&lt;K&gt; keys = new ArrayList&lt;&gt;();        inOrder(root,keys);        // 中序遍历后的二分搜索树应该是一个有序的数列        for (int i = 1; i &lt; keys.size(); i++) &#123;            if(keys.get(i-1).compareTo(keys.get(i))&gt;0)&#123;                return false;            &#125;        &#125;        return true;    &#125;    // * 中序遍历这棵树    private void inOrder(Node node, ArrayList&lt;K&gt; keys) &#123;        if(node == null)&#123;            return;        &#125;        inOrder(node.left,keys);        keys.add(node.key);        inOrder(node.right,keys);    &#125;    // * 判断该二叉树是否是一个平衡二叉树    public boolean isBalanced()&#123;        return isBalanced(root);    &#125;    // * 递归判断是否是平衡二叉树    public boolean isBalanced(Node node)&#123;        if(node == null) &#123;            return true;        &#125;        int balanceFactor = getBalanceFactor(node);        if(Math.abs(balanceFactor) &gt; 1)            return false;        return isBalanced(node.left) &amp;&amp; isBalanced(node.right);    &#125;    // * 每次增加结点改变高度值    private Node add(Node node, K key, V value) &#123;        //********* 终止条件 *************        if (node == null) &#123;            size++;            return new Node(key, value);        &#125;        //*********  终止条件end ************        //*********  递归 *************        if(key.compareTo(node.key) &lt; 0) &#123;            node.left = add(node.left, key, value);        &#125; else if(key.compareTo(node.key) &gt; 0) &#123;            node.right = add(node.right, key, value);        &#125; else // key.compareTo(node.key) == 0        &#123;            node.value = value;        &#125;        // * 对当前的node值更新它的height：它的高度是左右子树更高那个加1        node.height = 1 + Math.max(getHeight(node.left),getHeight(node.right));        // * 计算结点的平衡因子        int balanceFactor = getBalanceFactor(node);        // * 如果平衡因子(有可能为负数)超过了1 ，那么我们就需要进行自平衡了        // * 如果不平衡，那么判断这个结点的两个孩子：如果左孩子平衡值大于等于0，那么需要右旋；如果右孩子平衡值大于等于0，那么需要左旋        // LL        if (balanceFactor &gt; 1 &amp;&amp; getBalanceFactor(node.left) &gt;= 0) &#123;            return rightRotate(node);        &#125;        // RR        if (balanceFactor &lt; -1 &amp;&amp; getBalanceFactor(node.right) &lt;= 0) &#123;            return leftRotate(node);        &#125;        // LR        if (balanceFactor &gt; 1 &amp;&amp; getBalanceFactor(node.left) &lt; 0) &#123;            node.left = leftRotate(node.left);            return rightRotate(node);        &#125;        // RL        if (balanceFactor &lt; -1 &amp;&amp; getBalanceFactor(node.right) &gt; 0) &#123;            node.right = rightRotate(node.right);            return leftRotate(node);        &#125;        return node;        //*********  递归end *************    &#125;    // 对节点y进行向右旋转操作，返回旋转后新的根节点x    //        y                              x    //       / \\                           /   \\    //      x   T4     向右旋转 (y)        z     y    //     / \\       - - - - - - - -&gt;    / \\   / \\    //    z   T3                       T1  T2 T3 T4    //   / \\    // T1   T2    private Node rightRotate(Node y) &#123;        Node x = y.left;        Node T3 = x.right;        // 向右旋转过程        x.right = y;        y.left = T3;        // 更新height        y.height = Math.max(getHeight(y.left), getHeight(y.right)) + 1;        x.height = Math.max(getHeight(x.left), getHeight(x.right)) + 1;        return x;    &#125;    // 对节点y进行向左旋转操作，返回旋转后新的根节点x    //    y                             x    //  /  \\                          /   \\    // T1   x      向左旋转 (y)       y     z    //     / \\   - - - - - - - -&gt;   / \\   / \\    //   T2  z                     T1 T2 T3 T4    //      / \\    //     T3 T4    private Node leftRotate(Node y) &#123;        Node x = y.right;        Node T2 = x.left;        // 向左旋转过程        x.left = y;        y.right = T2;        // 更新height        y.height = Math.max(getHeight(y.left), getHeight(y.right)) + 1;        x.height = Math.max(getHeight(x.left), getHeight(x.right)) + 1;        return x;    &#125;    private Node removeMin(Node node) &#123;        if (node.left == null) &#123;            Node rightNode = node.right;            node.right = null;            size--;            return rightNode;        &#125;        node.left = removeMin(node.left);        return node;    &#125;    /**     * 寻找最小值     *     * @return     */    public V minimum() &#123;        if (size == 0) &#123;            throw new IllegalArgumentException(&quot;BST is empty!&quot;);        &#125;        return minimum(root).value;    &#125;    /**     * 返回以node为根的二分搜索树的最小值所在的节点     *     * @return     */    private Node minimum(Node node) &#123;        if (node.left == null) &#123;            return node;        &#125;        return minimum(node.left);    &#125;    public V remove(K key) &#123;        Node node = getNode(root, key);        if (node != null) &#123;            root = remove(root, key);        &#125;        return null;    &#125;    private Node remove(Node node, K key)&#123;        if( node == null ) &#123;            return null;        &#125;        Node retNode;        if( key.compareTo(node.key) &lt; 0 )&#123;            node.left = remove(node.left , key);            // return node;            retNode = node;        &#125;        else if(key.compareTo(node.key) &gt; 0 )&#123;            node.right = remove(node.right, key);            // return node;            retNode = node;        &#125;        else&#123;   // key.compareTo(node.key) == 0            // 待删除节点左子树为空的情况            if(node.left == null)&#123;                Node rightNode = node.right;                node.right = null;                size --;                // return rightNode;                retNode = rightNode;            &#125;            // 待删除节点右子树为空的情况            else if(node.right == null)&#123;                Node leftNode = node.left;                node.left = null;                size --;                // return leftNode;                retNode = leftNode;            &#125;            // 待删除节点左右子树均不为空的情况            else&#123;                // 找到比待删除节点大的最小节点, 即待删除节点右子树的最小节点                // 用这个节点顶替待删除节点的位置                Node successor = minimum(node.right);                //successor.right = removeMin(node.right);                successor.right = remove(node.right, successor.key);                successor.left = node.left;                node.left = node.right = null;                // return successor;                retNode = successor;            &#125;        &#125;        if(retNode == null) &#123;            return null;        &#125;        // 更新height        retNode.height = 1 + Math.max(getHeight(retNode.left), getHeight(retNode.right));        // 计算平衡因子        int balanceFactor = getBalanceFactor(retNode);        // 平衡维护        // LL        if (balanceFactor &gt; 1 &amp;&amp; getBalanceFactor(retNode.left) &gt;= 0)            return rightRotate(retNode);        // RR        if (balanceFactor &lt; -1 &amp;&amp; getBalanceFactor(retNode.right) &lt;= 0)            return leftRotate(retNode);        // LR        if (balanceFactor &gt; 1 &amp;&amp; getBalanceFactor(retNode.left) &lt; 0) &#123;            retNode.left = leftRotate(retNode.left);            return rightRotate(retNode);        &#125;        // RL        if (balanceFactor &lt; -1 &amp;&amp; getBalanceFactor(retNode.right) &gt; 0) &#123;            retNode.right = rightRotate(retNode.right);            return leftRotate(retNode);        &#125;        return retNode;    &#125;    // 返回以node为根节点的二分搜索树中，key所在的节点    private Node getNode(Node node, K key)&#123;        if(node == null) &#123;            return null;        &#125;        if(key.equals(node.key)) &#123;            return node;        &#125; else if(key.compareTo(node.key) &lt; 0) &#123;            return getNode(node.left, key);        &#125; else // if(key.compareTo(node.key) &gt; 0)        &#123;            return getNode(node.right, key);        &#125;    &#125;    public boolean contains(K key) &#123;        return getNode(root, key) != null;    &#125;    public V get(K key) &#123;        Node node = getNode(root, key);        return node == null ? null : node.value;    &#125;    public void set(K key, V newValue)&#123;        Node node = getNode(root, key);        if(node == null) &#123;            throw new IllegalArgumentException(key + &quot; doesn&#x27;t exist!&quot;);        &#125;        node.value = newValue;    &#125;    public int getSize() &#123;        return size;    &#125;    public boolean isEmpty() &#123;        return size == 0;    &#125;&#125;\n\n","categories":["数据结构","平衡二叉树","AVL树"],"tags":["数据结构","平衡二叉树","AVL树"]},{"title":"Tire字典树","url":"/2020/09/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Trie%20%E5%AD%97%E5%85%B8%E6%A0%91/","content":"\n    引言：数据结构——Tire字典树\n\n\n\n\nTrie 字典树Trie\n一个便于搜索的多叉树。\n我们学习了树结构实现映射，它的时间复杂度是O(log n)，如果有两百万个条目，大约会花费20\n但是Tire查询每个条目的时间复杂度和字典中一共有多少条目无关，取决于查询单词的长度O(w)\n\n一棵Trie就像是这样\n\n\n那么这样的一棵树，它的节点是如何定义的？\nclass Node&#123;    char c;    Node next[];    public Node(char c) &#123;        this.c = c;        this.next = new Node[26];    &#125;&#125;\n\n假如我们的业务是实现单词的存储，那么应该就是这样，每一个结点可以存储26个字母。\n但是假如我们的业务是存储网址信息等等，我们会扩展到更多更多，所以我们可以使用一个Map集合来充当这里的数据\nclass Node&#123;    Map&lt;Character, Node&gt; next;&#125;\n\n但是，如果要存储单词的话，我们会遇到一个问题，就是假设存储cat和category，两个词前面都是cat，那么我们如何存储呢？\n我们可以再给Node加一个字段，就是isWord\nclass Node&#123;    boolean isWord;    Map&lt;Character, Node&gt; next;&#125;\n\n\n\n\n\n全部代码如下：\npackage Trie;import java.util.Map;import java.util.TreeMap;/** * @author 董文浩 * @Date 2020/9/26 9:37 * 字典树Trie */public class Trie&#123;    private class Node&#123;        boolean isWord;        Map&lt;Character, Node&gt; next;        public Node(boolean isWord) &#123;            this.isWord = isWord;            this.next = new TreeMap&lt;&gt;();        &#125;        public Node()&#123;            this(false);        &#125;    &#125;    private Node root;    private int size;    public Trie()&#123;        root = new Node();        size =0;    &#125;    public int getSize()&#123;        return size;    &#125;    public void add(String word)&#123;        Node cur = root;        char[] chars = word.toCharArray();        for (int i = 0; i &lt; chars.length; i++) &#123;            if(cur.next.get(chars[i]) == null)&#123;                cur.next.put(chars[i], new Node());            &#125;            cur = cur.next.get(chars[i]);        &#125;        // 如果之前这不是一个单词        if(!cur.isWord)&#123;            cur.isWord = true;            size ++;        &#125;    &#125;    /** 查询是否有一个单词     * @param word     * @return     */    public boolean contains(String word)&#123;        Node cur = root;        char[] chars = word.toCharArray();        for (int i = 0; i &lt; chars.length; i++) &#123;            if(cur.next.get(chars[i]) == null)&#123;                return false;            &#125;            cur = cur.next.get(chars[i]);        &#125;        return cur.isWord;    &#125;    /** 查询是否在Tire中以prefix为前缀的单词     * @param prefix     * @return     */    public boolean isPrefix(String prefix)&#123;        Node cur = root;        char[] chars = prefix.toCharArray();        for (int i = 0; i &lt; chars.length; i++) &#123;            if(cur.next.get(chars[i]) == null)&#123;                return false;            &#125;            cur = cur.next.get(chars[i]);        &#125;        return true;    &#125;&#125;\n\n\n\n\n\n\n\n","categories":["数据结构","Tire字典树"],"tags":["数据结构","Tire字典树"]},{"title":"映射-Java实现","url":"/2020/09/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%98%A0%E5%B0%84-Java%E5%AE%9E%E7%8E%B0/","content":"\n    引言：数据结构——映射Map\n\n\n\n\n\n映射Map\n\n在Java语言中，映射就是一一映射，类似于函数，一个x对应一个y，一个y可以对应多个x\n\n使用 键key 来快速的找到 值value\n\n这里使用二叉搜索树与链表实现映射\n/** * @Date 2020/9/8 18:00 * Map映射 */public interface Map&lt;K, V&gt; &#123;    void add(K key, V value);    V remove(K key);    boolean contains(K key);        V get(K key);    void set(K key, V newValue);    int getSize();    boolean isEmpty();&#125;\n\n\n\n链表映射LinkedListMap链表实现Map\n/** * @Date 2020/9/8 18:00 * 链表实现映射map */public class LinkedListMap&lt;K, V&gt; implements Map&lt;K, V&gt; &#123;    private class Node &#123;        public K key;        public V value;        public Node next;        public Node(K key, V value, Node next) &#123;            this.key = key;            this.value = value;            this.next = next;        &#125;        public Node(K key, V value) &#123;            this(key, value, null);        &#125;        public Node() &#123;            this(null, null, null);        &#125;        @Override        public String toString() &#123;            return &quot;Node&#123;&quot; +                    &quot;key=&quot; + key +                    &quot;, value=&quot; + value +                    &quot;, next=&quot; + next +                    &#x27;&#125;&#x27;;        &#125;    &#125;    private Node dummyHead;    private int size;    public LinkedListMap() &#123;        dummyHead = new Node();        size = 0;    &#125;    /**     * 辅助方法     * 通过key获得对应的node     *     * @param key     * @return     */    private Node getNode(K key) &#123;        Node cur = dummyHead.next;        while (cur != null) &#123;            if (cur.key.equals(key)) &#123;                return cur;            &#125;            cur = cur.next;        &#125;        return null;    &#125;    @Override    public void add(K key, V value) &#123;        Node node = getNode(key);        if (node == null) &#123;            dummyHead.next = new Node(key, value, dummyHead.next);            size++;        &#125; else &#123;            node.value = value;        &#125;    &#125;    @Override    public V remove(K key) &#123;        Node prev = dummyHead;        while (prev.next != null)&#123;            if (prev.next.key.equals(key))&#123;                break;            &#125;            prev = prev.next;        &#125;        if(prev.next!=null)&#123;            Node delNode = prev.next;            prev.next = delNode.next;            delNode.next = null;            size --;            return delNode.value;        &#125;        return null;    &#125;    @Override    public boolean contains(K key) &#123;        return getNode(key) != null;    &#125;    @Override    public V get(K key) &#123;        Node node = getNode(key);        if(node == null)&#123;            throw new IllegalArgumentException(key + &quot;doesn&#x27;t exist!&quot;);        &#125;        return node.value;    &#125;    @Override    public void set(K key, V newValue) &#123;        Node node = getNode(key);        if(node==null)&#123;            throw new IllegalArgumentException(key + &quot;doesn&#x27;t exist!&quot;);        &#125;        node.value = newValue;    &#125;    @Override    public int getSize() &#123;        return size;    &#125;    @Override    public boolean isEmpty() &#123;        return size == 0;    &#125;&#125;\n\n\n\n二叉搜索树映射BstMap二叉搜索树实现Map\npackage map;/** * @author 董文浩 * @Date 2020/9/8 18:00 */public class BstMap&lt;K extends Comparable&lt;K&gt;, V&gt; implements Map&lt;K, V&gt; &#123;    private class Node &#123;        public K key;        public V value;        public Node left, right;        public Node(K key, V value) &#123;            this.key = key;            this.value = value;            left = null;            right = null;        &#125;    &#125;    private Node root;    private int size;    public BstMap() &#123;        root = null;        size = 0;    &#125;    @Override    public void add(K key, V value) &#123;        root = add(root, key, value);    &#125;    private Node add(Node node, K key, V value) &#123;        //********* 终止条件 *************        if (node == null) &#123;            size++;            return new Node(key, value);        &#125;        //*********  终止条件end ************        //*********  递归 *************        if (key.compareTo(node.key) &gt; 0) &#123;            node.right = add(node.right, key, value);        &#125; else if (key.compareTo(node.key) &lt; 0) &#123;            node.left = add(node.left, key, value);        &#125; else &#123;            node.value = value;        &#125;        return node;        //*********  递归end *************    &#125;    private Node removeMin(Node node) &#123;        if (node.left == null) &#123;            Node rightNode = node.right;            node.right = null;            size--;            return rightNode;        &#125;        node.left = removeMin(node.left);        return node;    &#125;    /**     * 寻找最小值     *     * @return     */    public V minimum() &#123;        if (size == 0) &#123;            throw new IllegalArgumentException(&quot;BST is empty!&quot;);        &#125;        return minimum(root).value;    &#125;    /**     * 返回以node为根的二分搜索树的最小值所在的节点     *     * @return     */    private Node minimum(Node node) &#123;        if (node.left == null) &#123;            return node;        &#125;        return minimum(node.left);    &#125;    @Override    public V remove(K key) &#123;        Node node = getNode(root, key);        if (node != null) &#123;            root = remove(root, key);        &#125;        return null;    &#125;    private Node remove(Node node, K k) &#123;        if (node == null) &#123;            return null;        &#125;        if (k.compareTo(node.key) &lt; 0) &#123;            node.left = remove(node.left, k);            return node;        &#125; else if (k.compareTo(node.key) &gt; 0) &#123;            node.right = remove(node.right, k);            return node;        &#125; else &#123; // e 等于 node.e            if (node.left == null) &#123;                Node rightNode = node.right;                node.right = null;                size--;                return rightNode;            &#125;            if (node.left == null) &#123;                Node leftNode = node.left;                node.left = null;                size--;                return leftNode;            &#125;            // 左右结点的左右子树均不为空            // 找 “最近” 的结点，这里找了被删除结点的后驱结点，其实也可以选择前驱            Node successor = minimum(node.right);            successor.right = removeMin(node.right);            successor.left = node.left;            // 与不再有关系，将node左右结点置为空            node.left = node.right = null;            return successor;        &#125;    &#125;    // 返回以node为根的二分搜索树中，key所在的节点    private Node getNode(Node node, K key) &#123;        if (node == null) &#123;            return null;        &#125;        if (key.compareTo(node.key) == 0) &#123;            return node;        &#125; else if (key.compareTo(node.key) &lt; 0) &#123;            return getNode(node.left, key);        &#125; else &#123;            return getNode(node.right, key);        &#125;    &#125;    @Override    public boolean contains(K key) &#123;        return getNode(root, key) != null;    &#125;    @Override    public V get(K key) &#123;        return getNode(root, key) == null ? null : getNode(root, key).value;    &#125;    @Override    public void set(K key, V newValue) &#123;        Node node = getNode(root, key);        if (node == null) &#123;            throw new IllegalArgumentException(key + &quot;doesn&#x27;t exist&quot;);        &#125;        node.value = newValue;    &#125;    @Override    public int getSize() &#123;        return size;    &#125;    @Override    public boolean isEmpty() &#123;        return size == 0;    &#125;&#125;\n\n","categories":["数据结构","Map"],"tags":["数据结构","Map","映射"]},{"title":"线段树","url":"/2020/09/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%BA%BF%E6%AE%B5%E6%A0%91/","content":"\n    引言：数据结构——线段树\n\n\n\n\n线段树线段树也叫区间树(Segment Tree)\n有些问题我们关注的是一个区间\n例如区间染色问题\n\n区间染色问题：有一个数组区间[0~N]区间，每次操作，我们将其一段染为一种颜色（颜色可以覆盖）\n\n经过m次操作后，我们能看到多少种颜色？\nm次操作后，我们能在[i , j]区间内看到多少种颜色？\n\n\n审题我们可以知道主要有两种操作：\n\n染色操作\n查询操作\n\n自然而然我们会选择遍历数组，但是这样的话，染色操作和查询操作都需要O(N)的复杂度\n再比如计算机经常会有的区间查询操作，我们可能也要统计一个区间的最大值，最小值，区间和等等信息。\n再比如，你想统计一下2020年你们项目中消费最高的用户，消费最少的用户，学习时间最长的用户。\n如果我们使用线段树，我们进行这种的操作都可以实现在O(log N)之内\n\n那么什么是线段树？\n和普通的树唯一的区别，就是每个节点存放的数据是一个区间\n\n\n\n\n线段树特点：\n\n是一棵平衡二叉树（任意节点的最大深度和最小深度的差最大为1）\n可以使用数组来表示（虽然叶子结点不会分布在同一层，但是我们可以把不存在的叶子结点当做空来处理）\n一个n个节点的线段树需要开辟4n个空间\n\n为什么一个n个节点的线段树需要4n个空间？对于一颗平衡二叉树来说，第一层有2^0个节点，一直到第h层，有2^h个节点。整棵树总共有着2^(h+1）-1个节点，对比最后一层和全部节点数我们会有这样的感觉，几乎最后一层的节点数就和整棵树的大小是一样的，而线段树基本就是使用最后一层来存储元素。\n有了上述的观念，我们再来看这个问题。因为我们要以满二叉树的标准来存储元素，假设有n个节点，而n=2^h，我们只需要使用2n个存储空间即可。，但是如果再多一个节点，我们就需要再开辟一行空间，也就是再来一行，需要使用4n个空间\n线段树代码（无增添操作，线段树的优势在于实现更新和查询操作）\n这里我们使用一个接口，来表示两个元素之间的相互操作。例如相加操作、相减操作等等一系列甚至是复杂的业务操作\n/** * @Date 2020/9/24 21:19 * 线段树业务 */public interface Merger&lt;E&gt; &#123;    E merge(E a, E b);&#125;\n\n\n\nimport java.util.Arrays;/** * @Date 2020/9/24 20:54 * 线段树 */public class SegmentTree&lt;E&gt; &#123;    private E[] data;    private E[] tree;    // 根据具体业务决定    private Merger&lt;E&gt; merger;    public SegmentTree(E[] arr, Merger&lt;E&gt; merger) &#123;        this.merger = merger;        data = (E[]) new Object[arr.length];        for (int i = 0; i &lt; arr.length; i++) &#123;            data[i] = arr[i];        &#125;        tree = (E[]) new Object[4 * arr.length];        buildSegmentTree(0, 0, arr.length - 1);    &#125;    /**     * 递归创建线段树     *     * @param treeIndex     * @param l         左端下标     * @param r         右端下标     */    private void buildSegmentTree(int treeIndex, int l, int r) &#123;        // 如果只有一个元素        if (l == r) &#123;            tree[treeIndex] = data[l];            return;        &#125;        // 注意这里的范围，可以写为 (r+l)/2，但是r+l可能会出现整型溢出的问题        // 所以我们这样写 l+(r-l)/2        int mid = l + (r - l) / 2;        buildSegmentTree(leftChild(treeIndex), l, mid);        buildSegmentTree(rightChild(treeIndex), mid + 1, r);        //tree[treeIndex] = tree[rightChild(treeIndex)] + tree[leftChild(treeIndex)];        //假如我们的业务需要求分段的和，我们就可以写为+的形式        //所以这里我们使用一个新的接口来进行两个泛型的运算        tree[treeIndex] = merger.merge(tree[leftChild(treeIndex)], tree[rightChild(treeIndex)]);    &#125;    /**     * 返回区间[queryL, queryR]的值     *     * @param queryL     * @param queryR     * @return     */    public E query(int queryL, int queryR) &#123;        if (queryL &lt; 0 ||                queryL &gt;= data.length ||                queryR &lt; 0 ||                queryR &gt;= data.length ||                queryL &gt; queryR) &#123;            throw new IllegalArgumentException(&quot;索引不正确&quot;);        &#125;        return query(0, 0, data.length - 1, queryL, queryR);    &#125;    /**     * 在以treeID为根的线段树中[l...r]的范围内，搜索区间[queryL...queryR]的值     */    private E query(int treeIndex, int l, int r, int queryL, int queryR) &#123;        if (l == queryL &amp;&amp; r == queryR) &#123;            return tree[treeIndex];        &#125;        int mid = l + (r - l) / 2;        int leftTreeIndex = leftChild(treeIndex);        int rightTreeIndex = rightChild(treeIndex);        //要查询的部分在右子树        if (queryL &gt;= mid + 1) &#123;            return query(rightTreeIndex, mid + 1, r, queryL, queryR);        &#125; else if (queryR &lt;= mid) &#123;            return query(leftTreeIndex, l, mid, queryL, queryR);        &#125; else &#123;            E leftResult = query(leftTreeIndex, l, mid, queryL, mid);            E rightResult = query(rightTreeIndex, mid + 1, r, mid + 1, queryR);            return merger.merge(leftResult, rightResult);        &#125;    &#125;    /**     * 将index位置的值更新为e     *     * @param index     * @param e     */    public void set(int index, E e) &#123;        if (index &lt; 0 || index &gt;= data.length) &#123;            throw new IllegalArgumentException(&quot;索引不正确&quot;);        &#125;        data[index] = e;        set(0, 0, data.length - 1, index, e);    &#125;    /**     * @param treeIndex     * @param l     * @param r     * @param index     * @param e     */    private void set(int treeIndex, int l, int r, int index, E e) &#123;        if (l == r) &#123;            tree[treeIndex] = e;            return;        &#125;        int mid = l + (r - l) / 2;        int leftTreeIndex = leftChild(treeIndex);        int rightTreeIndex = rightChild(treeIndex);        if (index &gt;= mid + 1) &#123;            set(rightTreeIndex, mid + 1, r, index, e);        &#125; else &#123;            set(leftTreeIndex,l,mid,index,e);        &#125;        // 更新每一级的范围        tree[treeIndex] = merger.merge(tree[leftTreeIndex],tree[rightTreeIndex]);    &#125;    public E get(int index) &#123;        if (index &lt; 0 || index &gt;= data.length) &#123;            throw new IllegalArgumentException(&quot;索引不正确&quot;);        &#125;        return data[index];    &#125;    /**     * 当做满二叉树来存储，那么肯定符合完全二叉树的性质     *     * @return     */    private int leftChild(int index) &#123;        return 2 * index + 1;    &#125;    private int rightChild(int index) &#123;        return 2 * index + 2;    &#125;    @Override    public String toString() &#123;        return &quot;SegmentTree&#123;&quot; +                &quot;tree=&quot; + Arrays.toString(tree) +                &#x27;&#125;&#x27;;    &#125;&#125;\n\n","categories":["数据结构","SegmentTree线段树"],"tags":["数据结构","SegmentTree线段树"]},{"title":"集合-java实现","url":"/2020/09/13/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%9B%86%E5%90%88-Java%E5%AE%9E%E7%8E%B0/","content":"\n    引言：数据结构——集合Set\n\n\n\n集合Set\n集合：\n一个无序的，不会存放相同元素的特殊的数据结构。\n\n需要实现如下方法：\npublic interface Set&lt;E&gt; &#123;    void add(E e);    void remove(E e);    boolean contains(E e);    int getSize();    boolean isEmpty();&#125;\n\n特点：\n\n不含重复元素\n没有顺序\n\n 分别使用二叉搜索树和链表来实现集合\nLinkedListSetpublic class LinkedListSet&lt;E&gt; implements Set&lt;E&gt; &#123;    private LinkedList&lt;E&gt; linkedList;    public LinkedListSet() &#123;        linkedList = new LinkedList&lt;&gt;();    &#125;    @Override    public void add(E e)&#123;        if(!linkedList.contains(e))&#123;            linkedList.addFirst(e);        &#125;    &#125;    @Override    public void remove(E e) &#123;        linkedList.removeElement(e);    &#125;    @Override    public boolean contains(E e) &#123;        return linkedList.contains(e);    &#125;    @Override    public int getSize() &#123;        return linkedList.getSize();    &#125;    @Override    public boolean isEmpty() &#123;        return linkedList.isEmpty();    &#125;&#125;\n\nBstSet二分搜索树来实现集合\npublic class BstSet&lt;E extends Comparable&lt;E&gt;&gt; implements Set&lt;E&gt; &#123;    private BinarySearchTree&lt;E&gt; bst;    public BstSet() &#123;        bst = new BinarySearchTree&lt;&gt;();    &#125;    @Override    public void add(E e) &#123;        // 实现的二叉搜索树就是不会重复的        bst.add(e);    &#125;    @Override    public void remove(E e) &#123;        bst.remove(e);    &#125;    @Override    public boolean contains(E e) &#123;        return bst.contains(e);    &#125;    @Override    public int getSize() &#123;        return bst.size();    &#125;    @Override    public boolean isEmpty() &#123;        return bst.isEmpty();    &#125;&#125;\n\n复杂度分析LinkedListSet\n增 add：O(n)\n查 contains：O(n)\n删 remove: O(n)\n\nBstSet最多访问树的高度 h\n\n\n\n增 add ：O(log n) \n查 contains：O(log n)\n删 remove: O(log n)\n\n结论二叉搜索树实现的集合要比链表实现的集合性能高的多。\n但是当存储的数据为顺序的话，二叉搜索树有可能是这个样子的\n\n\n这个时候二叉搜索树的性能将会和链表一样（AVL树可以解决这种问题）。\n","categories":["数据结构","集合"],"tags":["数据结构","集合"]},{"title":"朴素贝叶斯","url":"/2022/09/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/","content":"\n引言：朴素贝叶斯就是很天真的贝叶斯~ Naive Bayes\n\n\n\n\n朴素贝叶斯今天是2022年9月10日，中秋节哇！中秋节快乐\n基本概念及注意点\n朴素贝叶斯原理\n\nscikit-learn的朴素贝叶斯类库如何使用？\n这里直接贴大佬的博客\n\n类库有三个关于朴素贝叶斯的实现，他们关于，分别基于不同的分布：\n\n高斯分布（正态分布）：GaussianNB\n\n多项式分布：MultinomialNB\n\n伯努利分布：BernoulliNB\n\n\n","categories":["机器学习"],"tags":["机器学习"]},{"title":"决策树","url":"/2022/09/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/","content":"\n引言：决策树既是一种分类算法、也是一种回归算法\n\n\n\n决策树\n祥见大佬的博客内容，质量很高：\n\n决策树算法原理（上）\n决策树算法原理（下）\n决策树类库使用\n\n\n信息熵在开始决策树之前，我们需要了解几个东西：\n\n熵：度量了事物的不确定性，越不确定其值越大。\n\n熵的计算公式如图：\n\n\nH(x)表示随机事件x的熵\n\n举个例子：\n\n\n推广到多个变量就有联合熵：\n\n\n\n条件熵：x在知道y后的不确定性\n\n\n\n互信息或称为信息增益：x在知道y后的不确定性的减少程度\nI(X, Y) = H(X) - H(X|Y)\n\n\n如图所示：\n\n两个椭圆的并就是联合熵；\n重合部分就是信息增益；\n排除重合部分就是他们分别的条件熵；\n\n决策树是什么首先，我们有一个多个输入属性和一个输出属性的数据集：例如下面这个表格\n\n\n\n有没有乌云\n有没有打雷\n会不会下雨\n\n\n\n有\n有\n下雨\n\n\n有\n没有\n下雨\n\n\n然后我们需要对这个数据进行处理，从中选择一个最能区别实例的属性（比如这个例子，有没有乌云更加决定了是否下雨）\n然后根据这个属性创建了树的根节点，同时创建这个节点的分支\n使用这些分支，将数据集中的数据进行分类，然后重复这个过程，直至完成一棵决策树\n\n总结一句话就是：每次选择最能区别实例的属性，重复此过程构建树\n\n决策树的三种实现那么如何判断一个属性是不是最能区别一个实例呢？\n有三种判断方法：\n\nID3：基于信息增益\nC4.5：基于信息增益率\nCART：基于Gini指数\n\n\n为什么C4.5不叫ID4？\n那是因为决策树太火爆，他的 ID3一出来，别人二次创新，很快 就占了 ID4， ID5，所以他另辟蹊径，取名 C4.0 算法，后来的进化版为 C4.5 算法\n\nID3ID3细节1970年，昆兰提出了ID3，是最早出现的决策树的实现，它基于信息增益\n根据这个表，使用C4.5算法来构建决策树：\n\n\n\n序号\n学历\n婚姻\n车\n收入\n贷款\n\n\n\n1\n专科\n未婚\n无\n中\n否\n\n\n2\n专科\n未婚\n无\n高\n否\n\n\n3\n专科\n已婚\n无\n高\n是\n\n\n4\n专科\n已婚\n有\n中\n是\n\n\n5\n专科\n未婚\n无\n中\n否\n\n\n6\n本科\n未婚\n无\n中\n否\n\n\n7\n本科\n未婚\n无\n高\n否\n\n\n8\n本科\n已婚\n有\n高\n是\n\n\n9\n本科\n未婚\n有\n很高\n是\n\n\n10\n本科\n未婚\n有\n很高\n是\n\n\n11\n硕士\n未婚\n有\n很高\n是\n\n\n12\n硕士\n未婚\n有\n高\n是\n\n\n13\n硕士\n已婚\n无\n高\n是\n\n\n14\n硕士\n已婚\n无\n很高\n是\n\n\n15\n硕士\n未婚\n无\n中\n否\n\n\n\n首先计算输出属性熵：观察输出属性“贷款”，共有是、否两种值，是占有9/15，否占有6/15\n\nH(是否贷款)= -(9/15*log(9/15) + 6/15*log(6/15))\n\n然后分别计算每个属性的条件熵：这里以属性“学历”为例\n\n观察到学历有三个值：专科、本科、硕士，因此各占5/15\n其中：\n\n专科：2/5可以贷款\n本科：3/5可以贷款\n硕士：4/5可以贷款\n\n于是就如此计算H(是否贷款|学历)\nH(是否贷款|学历) = 5/15*H(专科) + 5/15*H(本科) + 5/15*H(硕士)\n其中分别计算每个取值的熵：\nH(专科) = -(2/5*log(2/5) + 3/5*log(3/5))\nH(本科) = -(3/5*log(3/5) + 2/5*log(2/5))\nH(硕士) = -(4/5*log(4/5) + 1/5*log(1/5))\n\n计算信息增益I(是否贷款，学历)\n\nI(是否贷款，学历) = H(是否贷款) - H(是否贷款|学历)\n\n计算其他属性的信息增益\n比较不同的信息增益，建立树\n\nID3存在的问题ID3算法的过程就是这样，简单方便，这里我们值得去思考这几个问题：\n\nID3没有考虑连续特征，比如长度、密度\n在相同条件下，取值比较多的特征比取值少的特征信息增益大\n缺少对缺失值情况的\n没有考虑过拟合的问题\n\nC4.5C4.5的优化昆兰改进了ID3算法：\n\nID3没有考虑连续特征\n\nC4.5中将连续变量离散化\n假设有属性为长度有四个值10、11、12、13，C4.5把连续变量求其两两相邻的平均数得到三个值10.5、11.5、12.5，然后计算三个值对于的信息增益\n最后选择最大的信息增益值作为分离点，大于此值的为1，小于的为0\n\n在相同条件下，取值比较多的特征比取值少的特征信息增益大\n\nC4.5改用信息增益率代替信息增益\n\n其中分母为\n\n\n缺少对缺失值的处理\n\n第三个缺失值处理的问题，主要需要解决的是两个问题：一是在样本某些特征缺失的情况下选择划分的属性；二是选定了划分属性，对于在该属性上缺失特征的样本的处理\n翻译一下就是：\n\n选择特征属性时：在有缺失情况下，如何选择最优属性进行子树划分。\n缺失样本的处理：选择好属性后，属性缺失样本划入哪个子节点。\n\n可以看这两篇blog：\n\n缺失值处理\n实例\n\n\n没有考虑过拟合的问题\n\nC4.5引入了正则化和剪枝。\n我们还是用上一节的那个例题：\n\n在计算出信息增益I(是否贷款，学历)后\n分母为H(学历) = -(5/15*log(5/15)+ 5/15*log(5/15) + 5/15*log(5/15))\n使用1与2做除法，就得到了信息增益率，之后的步骤与ID3一样\n\nC4.5存在的问题\n生成的是多叉树，对于计算机来说二叉树效率会更高\n只能用于分类\n有大量的耗时的对数运算, 如果是连续值还有大量的排序运算\n\nCARTCART细节CART 分类树算法使用基尼系数来代替信息增益比，基尼系数代表了模型的不纯度，基尼系数越小，则不纯度越低，特征越好。这和信息增益 (比) 是相反的。\n\n\npk代表第k个概率\n\n当这是一个二类分类的时候（即p0 + p1 = 1）：\n\n基于基尼系数有这么几点弥补了C4.5的缺点：\n\n基尼系数会生成二叉树而不是多叉树\n基尼系数运算比求对数运算简单很多\n可以分类，也可以回归\n\n\n对于连续值，CART与C4.5处理的步骤一样\n\n但是有一个区别：如果当前节点为连续属性，则该属性后面还可以参与子节点的产生选择过程\n CART 分类树使用的方法不同，他采用的是不停的二分\n假如一个特征A有A1、A2、A3三个特征值。如果是C4.5的话，那么就会出现三个岔；如果是基尼系数的话，他会分为{A1}与{A2、A3}、{A2}与{A1、A3}、{A3}与{A1、A2}三种情况，这样还是一颗二叉树\nCART的回归树与分类树\n回归树和分类树的区别：\n\n区别在于样本输出，如果样本输出是离散值，那么这是一颗分类树。如果果样本输出是连续值，那么那么这是一颗回归树\n在CART中，分类树与回归树唯一的区别就是在对于连续值的处理有些不同（这部分可以去看刘建平大佬的博客）\n对于连续值，回归树使用均方差，而回归树使用基尼系数。\nCART剪枝策略这是为了解决决策树一直都存在的一个问题——容易过拟合\nCART使用后剪枝法\n\n后剪枝法：先生成决策树，然后产生所有可能的剪枝后的CART树，然后使用交叉验证剪枝效果，选择最好的剪枝策略\n\n可以分为两步：\n\n从原始决策树生成剪枝后的CART树\n交叉验证效果，选择最好的剪枝后的CART树\n\n（关于CART剪枝详见大佬的博客）\nCART存在的问题\n有些时候，最优选择不是由一个特征决定的（三种算法都存在这个问题）\n如果样本发生一点点改动就会影响整个树的结构\n\n对比ID3、C4.5、CART\n\n\n算法\n支持模型\n树结构\n特征选择\n连续值处理\n缺失值处理\n剪枝\n\n\n\nID3\n分类\n多叉树\n信息增益\n不支持\n不支持\n不支持\n\n\nC4.5\n分类\n多叉树\n信息增益率\n支持\n支持\n支持\n\n\nCART\n分类、回归\n二叉树\n基尼系数、均方差\n支持\n支持\n支持\n\n\n","categories":["机器学习"],"tags":["机器学习"]},{"title":"机器学习概述","url":"/2022/08/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0/","content":"\n引言：对机器学习的过程梳理、名词扫盲\n\n\n\n\n机器学习概述\n赫尔伯特·西蒙：如果一个系统能够通过执行某个过程改进它的性能，这就是学习\n\n机器学习的步骤大致分为六个步骤，其中某些专有名词我们之后专门解释：\n\n得到一个有限的训练数据集合\n确定假设空间\n确定学习策略\n实现求解最优模型的算法\n选择最优模型\n对新数据进行预测或分析\n\n机器学习分类分为监督学习、无监督学习、强化学习三种，有时包括半监督学习、主动学习\n本文只介绍监督学习\n监督学习监督学习的基本过程串一下专有名词（专有名词具体解释在基础概念内解释），以便于清晰的理解监督学习的过程\n\n首先，我们需要一个数据集，这个数据集应该被分为三类：训练集、验证集、测试集\n其次我们需要确定我们的假设空间，这是一个概率问题？还是一个非概率问题？\n假设空间确定后，我们需要选择其中一个合适的模型，如何进行选择是一个很重要的问题，这也是我们需要决定的策略\n一般有经验风险最小化和结构风险最小化两种策略，他们通过不同的方式尽量使经验风险趋近于期望风险\n选择经验风险最小化是很简单，但是很容易出现过拟合现象，因此给经验风险加上了正则化项\n这样在选择了具体的模型后，我们就可以使用训练数据训练模型了，同样为了防止过拟合，我们可以进行交叉检验，选择验证数据误差最小的一个作为最优解\n基础概念监督学习的专有名词有很多，这里做一个罗列，在阅读文章时遇到新名词可以来这里Search一下\n输入空间、输出空间其实就是输入与输出的集合\n特征空间关于这部分可以参考：线性代数——特征值与特征向量\n\nAx=λx# λ表示特征值，x表示特征向量，A是给定的矩阵\n\n当只有尺度变化，而没有方向变化时（或者说这个矩阵只有伸缩，没有旋转），这类特殊的向量就是矩阵的特征向量 eigenvector，特征向量的尺度变化系数就是特征值 eigenvalue。\n\n对于具体数据来说，特征就是属性（比如一个人的数据，它的特征就是它的年龄，特征向量就是(年龄，性别等)特征组成的向量）\n对于一个数据集合，每一个具体的输入都是一个实例 Instance或称为特征向量 feature vector\n\n实例完全可以理解为就是特征向量\n\n\n特征空间（eigenspace）是具有相同特征值的特征向量与一个同维数的零向量的集合\n\n联合概率分布\n联合概率就是P(AB)：即AB事件同时发生的概率\n\n机器学习的前提就是随机变量X与Y服从联合概率分布（这句话的意思就是我们假设输入与输出存在一定的统计规律，否则我们的研究将没有任何意义）\n模型与假设空间\n假设空间 hypothesis space：即模型的集合\n\n\n模型：输入空间到输出空间的映射（机器学习中，模型可以是概率模型或是非概率模型，分别用P(y|x)与y=f(x)表示）\n\n可能不是很好理解，这里举一个例子：\n假设我们已知一个问题是线性关系，那么此时的模型就是一个线性函数，假设空间就是所有的线性函数\n样本与样本点样本就是样本点\n\n样本：输入与输出对（注意，一个成对的输入和输出才是一个样本）\n\n比如这样的一个训练数据集合：T=&#123;(x1,y1),(x2,y2)...(xn,yn)&#125;\n(x1,y1)就是一个样本，x是输入，y是输出\n决策函数与条件概率分布机器学习的模型有这两种：决策函数y=f(x)，条件概率分布为P(y|x)\n欧式空间\nR表示实数域\nR^n表示一个n维的向量空间，每一个向量都由R中的实数组成\n\n欧式空间，别名也叫参数空间\n损失函数（代价函数）损失函数 loss function或称为代价函数 cost function：是一个用f(X)和Y表示的非负值函数，用L(Y, f(X))表示\n常见的损失函数有四种：\n\n0-1损失函数\n\nL(Y, f(X)) = 1, Y!=f(X)L(Y, f(X)) = 0, Y==f(X)\n\n\n平方损失函数：L(Y, f(X)) = (Y-f(X))^2\n绝对损失函数：L(Y, f(X)) = |Y-f(X)|\n对数损失函数（对数似然损失函数）L(Y, P(Y|X)) = -logP(Y|X) \n\n损失函数值越小，模型越好\n风险函数（期望损失）风险函数就是期望损失，用Rexp表示\n\n期望损失：损失函数的期望\n期望损失是无法具体得到的，我们只能通过经验损失来模拟期望损失\n\n期望损失最小的模型就是我们要选择的模型\n经验损失\n经验损失：模型f(X)关于训练集的平均损失，用Remp表示\n\n\n根据大数定律，当N趋近于无穷时，经验损失趋近于期望损失\n策略\n如何选择最优模型？\n\n通过经验损失吗？但是由于我们的训练数据有限，因此经验风险并不理想（也就是N不趋近于无穷，经验损失也就不趋近于期望损失）\n\n因此监督学习有两个基本策略：\n\n\n经验风险最小化 ERM\n结构风险最小化 SRM\n\n经验风险最小化经验风险最小化ERM策略认为：经验风险最小的模型就是最优模型\n\n\n那个类似于F的字符表示假设空间\n比如极大似然估计就是经验风险最小的一个例子，这也是频率派的主张\n\n缺点：\n由于我们的训练数据有限，因此经验风险并不理想（也就是N不趋近于无穷，经验损失也就不趋近于期望损失）\n由于样本容量小，因此这种判断方式很有可能出现过拟合现象\n结构风险最小化结构风险最小化策略认为，结构风险最小的模型为最优模型\n什么是结构风险？\n\n\n在经验损失的基础上加了一项模型的复杂度\nJ(f)表示模型的复杂度，模型越复杂越大，反之越小\nλ系数用来权衡经验风险和模型复杂度\n最大后验概率估计就是一个结构风险最小化的一个体现，是贝叶斯学派的主张\n\n\n算法学习模型具体的计算方法\n过拟合现象\n过拟合 over-fitting：模型出现对训练数据（已知数据）预测的很好，但是对测试数据（未知数据）预测的很差的现象\n\n训练误差与测试误差\n训练误差 training error：模型关于训练数据的经验损失\n测试误差 test error：模型关于测试数据的经验损失\n\n泛化能力即模型预测新数据的能力\n正则化\n正则化等价于结构风险最小化\n\n\n\nλJ(f)也称为正则化项 regularizer或罚项 penalty term，模型越复杂越大\n正则化项可以取不同的形式，比如L1范数、L2范数\n\n关于范数可以看此篇\n\n正则化符合奥卡姆剃刀原则\n正则化项对应与模型的先验概率\n\n\n奥卡姆剃刀原则：能够很好解释数据并简单的才是最好的模型\n\n交叉验证为了防止过拟合现象，我们也可以把样本数据分为三类：训练数据、验证数据、测试数据\n验证数据是为了用于模型选择，我们应该选择验证数据最小误差的模型\n验证的方法通常使用交叉验证cross validation：\n\n简单交叉验证：即随机将数据分为两部分，一部分为训练集、一部分为验证集\nS折交叉验证：均分为S份，每次利用S-1个训练，用余下的一份进行验证（比如我们分为10份，第一次我们使用2-10号训练，1验证，第二次使用1,3-10训练，2验证，以此类推）\n留一交叉验证：S=数据集容量的特殊情况\n\n泛化误差上界泛化误差就是期望风险\n泛化误差上界用来比较两个模型的优劣（类似于比较两个算法的时间复杂度以确定哪个好）\n生成模型与判别模型监督学习方法可以分为生成方法和判别方法，对应的模型就是生成模型与判别模型\n\n生成方法：根据输入数据和输出数据之间的联合概率分布确定条件概率分布P(Y∣X)\n判别方法：则直接学习条件概率分布 P(Y∣X) 或决策函数 f(X)\n\n\n简而言之：生成方法需要研究数据集的分布，而判别方法直接使用条件概率公式或是决策函数\n\n生成方法具有更快的收敛速度和更广的应用范围，判别方法则具有更高的准确率和更简单的使用方式。\n","categories":["机器学习"],"tags":["机器学习"]},{"title":"概率论概念深入理解","url":"/2022/08/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%A6%82%E5%BF%B5/","content":"\n引言：概率论是另一种用数学看待真实世界的工具\n\n\n\n\n概率论概念深入理解在历史长河中，对概率的认知是有一个过程的，对概率的认知不同，分为了两个派系：频率学派与贝叶斯学派\n频率学派古典概率模型频率学派的依赖的基础是古典概率模型，这种模型的特点是：\n\n包含有限个基本事件\n每个基本事件发生的概率相同\n\n比如投骰子、比如投硬币，这些都是古典概率模型的体现\n投硬币一次是否能出现正面，我们并不确定，但是随着不断的投掷，我们会发现，正反面出现的次数几乎相同，这就是频率学派眼中的概率——其实是一个可独立重复实验出现单个结果频率的极限\n古典概率中，事件A的概率计算公式为：\n\n\nn表示所有基本事件的数量\nk表示发生A事件的基本事件数目\n\n比如，投一个骰子，点数小于3的概率为P(A) = 2 / 6\n条件概率古典概率针对的是单个事件，这种事件之间相互独立，互不影响，为了处理这种互相影响的情况，引入了条件概率conditional probability\n\n\nP(A|B)表示在B事件发生的条件下，A事件发生的概率\nP(AB)表示A和B共同发生的概率，也叫联合概率 joint probability\n如果联合概率P(AB) = P(A) * P(B)，那么说明A与B相互独立\n对于相互独立的事件P(A|B) = P(A)\n\n基于条件概率，可以得出全概率公式 law of total probability：\n\n全概率公式的意义在于：将复杂事件的概率求解  转化为  在不同情况下发生的简单事件的概率求和\n\n这也是频率学派的核心观点，即：先做出假设，再在这些假设的前提下讨论随机事件的概率\n\n贝叶斯学派\n而贝叶斯学派则是：在事件结果已经确定下，推断假设发生的可能性\n（或者说，事后诸葛亮，结果发生后推断其可能的原因，我们需要事先拟定一些假设）\n\n贝叶斯定理对全概率公式稍作整理就可以得出逆概率理论，因为首先由英国牧师托马斯·贝叶斯提出，所以叫贝叶斯公式：\n\n推到过程很简单，只需要套入全概率公式和条件概率公式就可以得到，建议手推一下\n进一步抽象，就可以得到贝叶斯定理 Bayes’ theorem（两步条件概率公式推导即可）\n\n\nH表示我们的假设，D表示数据\nP(H)表示先验概率（prior probability）：即假设成立的概率\nP(D|H)表示似然概率（likelihood function）：在假设H成立的条件下，可以观测到结果D的概率\nP(H|D)表示后验概率（posterior probability）：在观测到结果的前提下，假设成立的概率\n\n\n贝叶斯派关注的核心是后验概率，而且贝叶斯学派认为概率描述的是随机事件的可信程度\n比如预测今天85%的概率下雨，这就不能理解为频率了，而是得理解为明天下雨的可信度是85%\n\n贝叶斯定理应用的经典问题：\n\n有一种病在人群中的患病率是1%，其检查结果的可靠程度是95%，也就是得病的人95%会得到阳性结果，没得病的人95%会得到阴性结果。如果一个人检查的结果是阳性，那他得病的概率是多少？\n\n解：\n\n套用到公式，此题的B1事件就是有病，B2事件就是没病，N就为2；A事件是结果为阳性的概率\nP(B1|A) =  P(A|B1) * P(B1) /( P(A|B1)*P(B1) + P(A|B2)*P(B2) )由题意知：得病的概率 P(B1) = 0.01没病的概率 P(B2) = 0.99本身有病检测为阳性的概率 P(A|B1) = 0.95本身无病检测为阳性的概率 P(A|B2) = 1-0.95 = 0.05全部代入得：P(B1 | A) = 16.1%\n\n结果大吃一惊，检测为阳性有病的概率竟然这么低\n学院派和贝叶斯派的区别参考知乎，他们最大的区别在于认为参数空间不同\n频率学派认为：数据都是在某个参数条件下产生的，一个模型中的参数是“固定”的，而数据是在分布中随机采样的。\n（即：我们相信这个分布的参数不管你怎么采样，根据参数对其的估计都应该是不会变的。如果根据数据估计出来的参数和真实模型不符合，只可能是引入了噪声而已）\n贝叶斯派认为：观察到的数据才是“固定”的，而我们的模型的参数才是在一直变化的。\n\n具体到人工智能这一应用领域，基于贝叶斯定理的各种方法与人类的认知机制吻合度更高，在机器学习等领域中也扮演着更加重要的角色\n\n估计的方法概率估计有两种方法：最大似然估计法（maximum likelihood estimation）和最大后验概率法（maximum a posteriori estimation）\n最大似然估计体现了频率派的思想观点。\n\n最大似然估计：使训练数据出现的概率最大化，依此确定概率分布中的未知参数，估计出的概率分布也就最符合训练数据的分布\n\n此方法只需要使用训练数据\n最大后验概率体现了贝叶斯派的思想观念\n\n根据训练数据和已知的其他条件，使未知参数出现的可能性最大化，并选取最可能的未知参数取值作为估计值\n\n此方法除了训练数据外还需要先验概率\n举一个例子：\n一个优等生和一个差生打架，老师肯定想当然认为是差生的错，因为差生爱惹事，这就是最大似然估计；\n可如果老师知道优生和差生之间原本就有过节（先验信息），把这个因素考虑进来，就不会简单地认为是差生挑衅，这就是最大后验估计。\n随机变量概率论的一个重要的应用就是描述随机变量，随机变量有两种：\n\n离散型随机变量（discrete random variable）\n连续型随机变量（continuous random variable）\n\n\n离散变量的每个可能的取值都有大于0的概率\n\n为了描述取值和概率之间的对应关系，对于离散型我们称为概率质量函数 probability mass function；对于连续型我们称为概率密度函数 probability density function\n\n注意：对于连续型随机变量的概率密度函数来说，并非其真实概率，而是不同取值之间的相对关系\n因为连续函数有无穷个取值，将1分配到每一个取值上面，约为0，概率密度函数的意义在于，虽然他们都为零但是也有相对关系\n比如1/x与2/x，虽然x-&gt;∞均为0，但后者永远是前者的两倍\n如果我们想求它的具体概率，需要在一个区间内内对其进行积分\n\n重要的分布及他们对应的概率质量/密度函数离散分布\n两点分布：用于随机试验的结果是二进制的情形\n事件发生 / 不发生的概率分别为 p/(1−p)\n\n比如抛硬币就是典型的两点分布\n\n二项分布：将满足参数为 p 的两点分布的随机试验独立重复 n 次\n\n\n\nX表示事件，k表示第几次，共n次\n（国外Cnk 与国内Ckn书写相反，理解意思即可）\nC表示排列组合，在n个中拿出k个的种类数\n\n比如多次抛掷硬币，如果抛掷两次，那么就有正正、反反、正反、反正四种情况，因此公式中有排列组合C\n\n泊松分布：放射性物质在规定时间内释放出的粒子数所满足的分布\n通常被使用在估算在一段特定时间/空间内发生成功事件的数量的概率\n\n\n\nλ表示在一段空间/时间内事件发生的平均值\nk表示事件发生的次数\ne为自然常量\n当二项分布中的n很大且p很小时，其概率值可以由参数为 λ=np 的泊松分布的概率值近似\n\n在Java中，HashMap的结构由链表变为红黑树的负载因子为0.75就是根据泊松分布找一个尽量使链表的长度小于8的概率\n连续分布（连续分布的概率密度函数要记得我们上一节提到的，他们只是代表相对关系，求概率需要对其积分）\n\n均匀分布：在区间 (a, b) 上满足均匀分布的连续型随机变量，其概率密度函数为 1/(b-a)\n\n均匀分布中，等长度概率相同\n\n指数分布：通常用于解决表示独立随机事件发生的时间间隔（或者说，发生某事件需要多长时间）\n\n\n\n指数分布的一个重要特征是无记忆性：即 P(X &gt; s + t | X &gt; s) = P(X &gt; t)（这个式子就可以看出与s其实没有关系，t秒之前的概率与t秒之后的概率无关）\n比如客服接电话，假设5秒能接一个客户，那么他半个小时后，或是一个小时后还是需要等5s才能接一个客户，也就是说，过去的实验不影响未来事件发生的概率\n\n\n正态分布：自然界最常见的一种分布\n\n\n\n当μ=0, σ=1为标准正态分布\n\n数学期望、方差、协方差描述随机变量除了函数外，还有刻画他们某些特性的常数：\n\n数学期望 expected value：即均值\n方差 variance：表示不同变量与期望的偏离程度。越小表示随机变量越趋近于期望，反之亦然。\n协方差 covariance：期望和方差都是描述单个随机变量，而协方差描述两个变量之间的关系\n\n\n协方差度量了两个随机变量之间的线性相关性，即变量 Y 能否表示成以另一个变量 X 为自变量的 aX+b 的形式\n\n协方差可以求出相关系数\n\n相关系数是一个绝对值不大于 1 的常数：\n\n =1 意味着两个随机变量满足完全正相关\n=-1 意味着两者满足完全负相关\n=0 意味着两者不相关\n\n\n注意：协方差和相关系数只能刻画线性相关的关系，对于Y=X^2这种非线性关系无法表达\n","categories":["概率论"],"tags":["概率论"]},{"title":"线性代数概念深入理解","url":"/2022/08/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%A6%82%E5%BF%B5/","content":"\n引言：线性代数是用虚拟数字表示真实物理世界的工具\n\n\n\n\n线性代数概念深入理解标量、向量、矩阵、张量在AI中最最基础的概念。\n在线性代数中，他们的概念如下\n\n标量 Scalar：单独的数，如a\n向量 Vector：多个数按一定序列排列，如(a1,a2,a3)\n矩阵 Matrix：将向量中的每一个标量都变为一个向量，如[(a1,a2,a3),(a4,a5,a6),(a7,a8,a9)]\n张量 Tensor：将矩阵中的每一个标量都变为一个矩阵，即一个多维矩阵\n\n从标量到张量的过程，就是一个升高维度的过程，标量是0维，向量是一维，矩阵是二维，张量就是n维\n（可以类比为点、线、面、三维立体）\n在计算机存储中，标量占据的是零维数组；向量占据的是一维数组，例如语音信号；矩阵占据的是二维数组，例如灰度图像；张量占据的是三维乃至更高维度的数组，例如 RGB 图像和视频。\n范数与内积向量是虚构的概念，为了描述这些向量，提出了特定的数学语言范数和内积来描述向量的一些性质。\n范数 norm\n可以将一个向量映射为一个非负的数值\n范数用来度量单个向量\n\n通常用L^p来表示，公式为：\n\n可以推得：\n\np=1：范数为向量的绝对值之和\np=2：范数为向量的平方和再开根，通常意义上这为向量的长度（比如在二维直角坐标系中，求一个点到原点的距离就是平方求和再开根）\np=∞：范数为求向量的最大的绝对值（当p无限趋近于无穷时，可以推到得其为最大的绝对值）\np=-∞：范数为最小的绝对值\n\n\n为什么无穷范数是最大或最小的绝对值？\n\n看这篇文章，推导的很详细，自己复刻一遍，加深印象\n内积 inner product\n内积用来表示两个向量之间的关系\n\n两个相同维数向量内积的表达式为：对应元素乘积的求和\n⟨x,y⟩=∑ xi⋅yi\n当内积为0时是一种特殊情况，在二维空间下，表示两个向量垂直，如(1,0)与(0,1)，他们的内积是0，在二维直角坐标系下，他们也是垂直的。在更高维度下，内积为零代表正交\n而且如果两个向量正交，说明他们线性无关，相互独立，互不影响。\n线性空间线性空间linear space是这样的一个集合：\n\n所有向量的维度相同\n定义了数乘、加法等结构化运算\n如果还定义了内积运算，那么就叫内积空间 inner product space\n\n\n在线性空间中：\n​        任意一个向量代表的都是 n 维空间中的一个点；反过来， 空间中的任意点也都可以唯一地用一个向量表示。两者相互等效。\n\n正交基\n为什么要有正交基？\n\n在现实生活中，只要给定经度、纬度和海拔高度，就可以唯一地确定地球上的任何一个位置；\n但是在直觉无法感受的高维空间中，坐标系的定义可就没有这么直观了。\n\n在内积空间中，一组两两正交的向量构成这个空间的正交基（orthogonal basis）\n\n并且如果他们的L2范数都是单位长度1，那么这两个向量就是标准正交基\n正交基就相当于给我们无法直观感受到的空间，加了一个经纬度，便于我们感受\n线性空间会发生变化一个人可以从美国去到中国，亦或反之。\n在线性空间中，当确定标准正交基后，空间中的点就可以使用向量表示\n当这个点从一个位置移动到另一个位置，描述他的向量也会发生变化，矩阵就是为了描述这种变化\n（by the way，现在是2022年8月27日23:58:20，这直接拓宽了我的视野，这很令人兴奋）\n变化可以理解为有两种：\n\n点本身的变化\n参考系的变化\n\n因此，对于理解下面这个常见的线代式子，我们有了另一种角度\nAx = y# A是一个矩阵，x、y是一个向量\n\n既可以理解为，向量x经过矩阵A变换为了y；也可以理解为，一个对象在坐标系为矩阵A时，结果为x，而在标准坐标系（单位矩阵：一个对角线为1，其余为0的矩阵）下为y\n表达式Ax就相当于对向量x 做了一个环境声明，用于度量它的参考系是A。如果想用其他的参考系做度量的话，就要重新声明。\n\n而对坐标系施加变换的方法，就是让表示原始坐标系的矩阵与表示变换的矩阵相乘。\n\n特征值与特征向量如上面我们提到的：让一个坐标发生变化，就是让表示原始坐标系的矩阵与表示变换的矩阵相乘。\nAx=λx# λ表示特征值，x表示特征向量，A是给定的矩阵\n\n如前面所述，矩阵代表了向量的变换，其效果通常是对原始向量同时施加方向变化和尺度变化\n\n当只有尺度变化，而没有方向变化时（或者说这个矩阵只有伸缩，没有旋转），这类特殊的向量就是矩阵的特征向量 eigenvector，特征向量的尺度变化系数就是特征值eigenvalue。\n\n如果把矩阵所代表的变化看作奔跑的人，那么矩阵的特征值就代表了他奔跑的速度，特征向量代表了他奔跑的方向。\n但矩阵可不是普通人，它是三头六臂的哪吒，他的不同分身以不同速度（特征值）在不同方向（特征向量）上奔跑，所有分身的运动叠加在⼀起才是矩阵的效果。\n\n求解给定矩阵的特征值和特征向量的过程叫做特征值分解，但能够进行特征值分解的矩阵必须是 n 维方阵。\n将特征值分解算法推广到所有矩阵之上，就是更加通用的奇异值分解。\n\n总结容易理解错误的点，这里再次强调一下：\n\n向量是线性空间中的一个静止点\n向量的变化（线性变换）可以看做是点的变换，也可以看做是参考系的变化，可以用矩阵表示\n矩阵的特征值和特征向量描述了变化的速度与方向\n\n","categories":["线性代数"],"tags":["线性代数"]},{"title":"正则表达式","url":"/2019/10/17/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","content":"\n引言:\n\n正则表达式\n\n\n\n\n\n正则表达式正则表达式\nRegular expression 正则表达式，一组由字母数字符号组成的特殊文本\n\n功能： 从文本中找出让你满意的句子\n1. 基本匹配正则表达式可以理解为 正在执行搜索的格式\n例如：在 The fat cat sat on the mat.搜索the\n我们就可以输入”the”来查找到the，大小写敏感，不会匹配到The\n2. 元字符注：以下所有的元字符都使用这句来举例\nThe fat cat sat on the mat\n\n\n. \n\n句号匹配任意的单个字符，换行符除外\n例如输入.at，会匹配fat，cat，sat，mat\n\n [] \n\n匹配方括号内的任意内容，\n例如[the]此时匹配所有的单个字母，匹配The内的he，匹配fat内的t等等\n再如，输入[Tthe]会匹配the和The\n输入[.]就代表句号\n\n[^]\n\n匹配除了方括号内的任意字符，即上个例子的补集\n例如输入[^f]at会匹配cat,sat,mat\n\n*\n\n匹配&gt;=0个重复在*之前的字符\n输入[a-z]*会匹配所有的小写字母\n输入\\s*cat\\s*，\\s代表空格，会匹配所有零个或多个空格开头结尾的cat\n\n+\n\n匹配&gt;=1个重复的+号前的字符\n输入c.+t会匹配cat sat on the mat,以c开头以t结尾中间至少有一个字符的字符串\n\n?\n\n标记?之前的字符为可选，\n例如f?at会匹配fat和所有的at\n\n&#123;n,m&#125;\n\n匹配num个大括号之前的字符，其中num&gt;=n&amp;&amp;num&lt;=m\n例如，输入表达式[0-9]&#123;2,3&#125;匹配最少两位最多三位的数字\n第二个可以不必输入[0-9]&#123;2,&#125;代表至少两位数字\n如果逗号都省略，则表示固定重复的次数，[0-9]&#123;3&#125;代表三位数字\n\n(xyz) 特征标群\n\n字符集，匹配与xyz完全相等的字符串\n输入(at)*匹配连续出现0个或多个的ab\n\n|\n\n或运算符，匹配符号前或后的字符\n例如输入a|t，a和t都会被匹配\n我们还可以在()中用字符|表示或\n例如(f|c)at只能匹配，fat，cat\n\n\\\n\n反斜杠，转义字符，用来匹配保留字符\n例如，输入 \\. 匹配语句最后的句号\n\n^\n\n从开始行开始匹配\n例如, 在 abc 中使用表达式 ^a 会得到结果 a. 但如果使用 ^b 将匹配不到任何结果. 因为在字符串 abc 中并不是以 b 开头.\n\n$\n\n从末端开始匹配\n例如, (at\\.)$ 匹配以 at. 结尾的字符串\n3.简写字符集\n. 匹配除换行符外的所有字符\n\n\n\\w 匹配所有数字字母，等同于[0-9a-zA-Z_]\n\n\n\\W 匹配所有符号,即非字母数字，即[^\\w]\n\n\n\\d 匹配数字\n\n\n\\D 匹配非数字，等同于[^\\d]\n\n\n\\s 匹配所有空格字符，等同于[\\t\\n\\f\\r\\p&#123;z&#125;]\n\n\n\\S 匹配所有非空格字符,[^\\s]\n\n\n\\f 匹配换页符\n\n\n\\n 匹配换行符\n\n\n\\r 匹配回车符\n\n\n\\t 匹配制表符\n\n\n\\v 匹配一个垂直制表符\n\n\n\\p 匹配CR/LF,等同于(\\r\\n)，用来匹配DOS行终止符\n\n4. 零宽度断言(前后预查)例句：The fat cat sat on the mat.\n?=正先行断言表示第一部分表达式之后必须跟着?=..定义的表达式\n定义一个正先行断言要使用 (),在括号内部使用一个问号和等号: (?=…)\n例如：表达式(T|t)he(?=\\sfat),只会匹配第一个The，因为只有第一个The后跟着(空格)fat\n?!负先行断言表达式其后不跟随着断言中定义的格式\n例如：表达式(T|t)he(?!\\sfat),只会匹配第二个the，因为第一个The后跟着(空格)fat\n?&lt;=正后发断言其前跟随着断言中定义的格式\n(?&lt;=(T|t)he\\s)(fat|mat)会找出fat和mat\n?&lt;!负后发断言其前不跟随着断言中定义的格式\n(?&lt;!(T|t)he\\s)(cat)只会匹配cat\n5. 标志标志也叫模式修正符, 因为它可以用来修改表达式的搜索结果. 这些标志可以任意的组合使用, 它也是整个正则表达式的一部分.\ni忽略大小写修饰语 i 用于忽略大小写. \n例如, 表达式 /The/gi 表示在全局搜索 The, \n在后面的 i 将其条件修改为忽略大小写, 则变成搜索 the 和 The, g 表示全局搜索.\ng全局搜索修饰符 g 常用于执行一个全局搜索匹配\n即(不仅仅返回第一个匹配的, 而是返回全部). \n例如, 表达式 /.(at)/g 表示搜索 任意字符(除了换行) + at, 并返回全部结果\nm多行修饰符多行修饰符 m 常用于执行一个多行匹配.\n像之前介绍的 (^,$) 用于检查格式是否是在待检测字符串的开头或结尾. 但我们如果想要它在每行的开头和结尾生效, 我们需要用到多行修饰符 m.\n例如, 表达式 /at(.)?$/gm 表示小写字符 a 后跟小写字符 t , 末尾可选除换行符外任意字符. 根据 m 修饰符, 现在表达式匹配每行的结尾.\n&quot;/.at(.)?$/gm&quot; =&gt; The fat                  cat sat                  on the mat.// 匹配到fat sat mat\n\n贪婪匹配与惰性匹配正则表达式默认采用贪婪匹配模式，\n在该模式下意味着会匹配尽可能长的子串。\n我们可以使用 ? 将贪婪匹配模式转化为惰性匹配模式。\n&quot;/(.*at)/&quot; =&gt; The fat cat sat on the mat. // 匹配所有\n&quot;/(.*?at)/&quot; =&gt; The fat cat sat on the mat. // 匹配The fat","categories":["正则表达式"],"tags":["正则表达式"]},{"title":"计算机视觉CV","url":"/2022/10/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89CV/","content":"\n引言：CV 计算机视觉\n\n\n\nCV参考的内容：\n\nCS231N 计算机视觉课程\n李永乐 卷积神经网络\n\nComputer Vision图像识别的难点：**Semantic gap **语义间隙、语义鸿沟（即我们看一张图片和计算机看一张图片之间存在一些区别）\n\n视角区别 Viewpoint Variation：稍微切换一个视角，存储的图片将会发生巨大的变化\n照明 Illumination： 光线昏暗明亮\n变形 Deformation：猫咪可能会有不同的姿势\n隐藏 Occlusion： 猫咪可能只露出一个小尾巴\n背景干扰 Background Clutter：雪地里面有一只白色猫咪\n类内差异Innerclass Variation：猫咪有黑、白，大、小的区别\n\n在最一开始，科学家使用一些硬编码的方式，比如对一只猫先找边界，然后找出它的眼睛、鼻子、嘴巴，然后再去判断这是否是一只猫\n但是这种方法很不优雅，不是一个通用的方法，换一个研究对象就得重新进行编码，因此提出了：数据驱动方法 Data-Driven Approach\n数据驱动方法类似于监督学习的方法\n1、 首先要有一些已经加了标签的图片集\n2、 使用机器学习的方式去训练一个分类器\n3、 对新的图片进行预测\nK近邻算法\nK近邻算法通过计算两张图片像素点之间的L1或是L2范数，去求两者之间的关系\n\n使用KNN并不是一个好的办法，它存在以下缺点：\n\n训练的时间短，但是测试的时间很长（我们通常都会希望训练的时间长点，但是测试的很快）\n\n训练是O(1)，但是测试是O(N)\n\n2范数不太适合表示图像之间的视觉感受差异（一个图片经过平移、略微着色、去掉几个块后求出的值与原图相同，但是我们感受上却是不同的）\n\nsuch as这个图：\n\n\n维度灾难：为了达到好的效果，我们需要将数据密集的分布在空间中，但是这样计算量会指数式的上升（意思是：不利于处理高维问题）\n\n线性分类\n线性分类企图去构造一条线，去判别是否是此类别的图片\n\n使用线性分类也存在一些问题：\n\n可能存在不能使用一条线去划分的情况：比如我们人工构造这样的一种数据集是大于零的奇数、大于零的偶数，不存在一条线可以划分这两个类别\n范围问题：比如一个类别只在一个范围内\n多分类问题：比如一张图片分给多种类别\n\n反向传播正向传播与反向传播反向传播是相对于前向传播而言的，如图所示，这是一个f(x) = (X+Y)*Z的例子：\n\n正向传播如图左：给XYZ分别初始值，会影响之后的结果。\n反向传播如图右：从结果开始，初始化为1，分别对Z求偏导、对(X+Y)求偏导，对X和Y再分别求偏导（这也就是所谓的梯度），用来对前面的参数做一个优化，进而影响整个函数的走向\n\nPS：为什么不直接对整个函数的积分？\n这个函数是一个简单的函数，如果遇到一个比较复杂的函数，我们直接求微分是很复杂的，因此分布进行偏导，然后对每一部分求其偏导，然后不断的向前乘积，会更为简单（这样的过程称为 链式法则 Chain Rules）\n\n不同运算的反向传播例如这样几个运算：+ * max，我们分析一下他们的梯度其实很容易理解\n\n\n对于加法：它的梯度会给上一级分发，比如这一级是5，传到上一级的两个分别都是5\n对于乘法：它的梯度会给上一级按比例转换，比如这一级是5，上一级的a=3 b=4，那么梯度传播到上一层就是a的梯度=3*b b的梯度=3*a\n对于max：它的梯度会分别传1与0，对于大的值回1、小的值为0，假设a&gt;b，那么会给上一级a传1、b传0\n\n本地梯度对于常用的梯度传播，比如sigmoid函数，直接作为一个工具类，下一次直接复用，不需要再进行求解（常用的梯度还有很多，类库里面提供的很全）\n这样的梯度称为本地梯度（local gradient）\n反向传播的意义反向传播应用在神经网络中，是一种较为容易的为了得到神经网络梯度的方法\n神经网络 Neural Networks类比于生物脑细胞的轴突、树突传递电信号，神经网络\n最简单的神经网络类似于这一的函数f = A*max(0, Bx) 就是一个两层的神经网络，它的内层就是Bx、外层是一个A*x；甚至我们可以进一步嵌套，构造三层、四层甚至更深的神经网络\n这里的max就是一个激活函数（Activation function），在生物中，他决定了此轴突向下传播的放电率，在神经网络内，他决定了是否将这一层的数据向下传播、传播多少\n一点历史\n1957 Frank Rosen blatt：感知机\n1960 Adaline/Madaline：多层的感知机\n1986 Rumelhart：反向传播算法\n1979 福岛邦彦：神经认知，图像会沿着皮层传递信号，边缘-&gt;轮廓-&gt;细节\n1981 David Hunter Hubel, Torsten Nils Wiesel：观察猫对图片的反应\n杨立昆：提出了卷积神经网络\n2006 Hinton and Salakhutdinov：更高效的训练NN\n2010 Abdek-rahman Mohamed, George Dahl, Geoffrey Hinton：语音识别 \n2012 Alex Krizhevsky, llya Sutskever, Geoffrey E Hinton：卷积图像分类\n\n卷积神经网络 Convolutional NN组合拳：卷积、池化、激活、全连接\n\n\n卷积：一种数学方法，使用卷积核可以提取出图像的特征\n\n 图片的存储是一张N*N的矩阵，这个矩阵的每个元素都代表了这个位置的像素点的RGB，一张图片由这么一个矩阵来组成\n卷积核通常是3*3或是5*5的一个核，它会在图片上面滑动（类似于滑动窗口），每滑动一次，都会和对应的图像位置进行点积运算（对应位置相乘，然后对结果求和），新产生的这个矩阵就是该卷积核提取的关于该图片的特征矩阵\n卷积核通常不止一个，常见有3个或是更多，每一个卷积核代表一个方向（可以这么理解：如果有两个卷积核，代表有x轴y轴，如果有三个卷积核，那么就代表还有一个z轴），卷积核的数量也代表了最后的结果有几个\n\n池化：从特征矩阵中拿出最有价值的矩阵\n\n在卷积后，池化会进一步提取有价值的数据。\n比如会对特征矩阵进行一个2*2的池化，它会从各个2*2的小矩阵里，找最大的值，填充到小矩阵内\n\n激活：决定数据是否向下传播，传播多少\n\n池化后的小矩阵会交给下一层的激活函数，得到一个0.99,0.93,0.77...类似的矩阵，**越接近于1，说明该部分越满足卷积核的特征\n卷积、池化、激活的过程可能不止一次，这是一个反复的过程\n\n全连接：当经历过前面的完整过程后，你就是一只成功找到面包的小蚂蚁了，但是如果你想知道，是不是还有其他面包，你得去和你得兄弟们（蚂蚁大军）开个会，这个会议就是全连接，它会帮我们得到输出\n知乎link\n\n关于卷积\n1、如果卷积时步长和矩阵长度不合适怎么办？\n\n比如：一个矩阵7*7，要求步长是3，如图所示，当滑动到最后的时候，会有超出去的部分。\n\n我们可以给这个矩阵填充0，来保证我们可以进行拟合，如下图\n\n\n2、如何计算卷积后的大小？\n\n这里有这么一个公式：\n假设原有矩阵：W1*H1*D1，有K个卷积核大小为F*F，步长为S，填充为P\n那么输出的结果为W2*H2*D2，其中\n\nW2 = (W1 - F + 2*P)/S +1\nH2 = (H1 - F + 2*P)/S +1\nD2 = K\n\n发现，如果这是一个方阵的话，那么输出也会是一个方阵\n每一个卷积核有F * F * D1个参数，总共有(F*F*D1 + bias)*K（bias是偏置）\n\n3、 eg：现在对32*32*3的矩阵进行卷积，卷积核为5*5*10，步长为1，填充为2,卷积后的矩阵大小是多少？\n\n很容易的求出(32 - 5 + 2*2)/1 + 1 = 32，因此结果为32*32*10\n关于池化池化就是为了尽可能的使表小一点，增快训练速度，它会提取所有有价值的数据 （池化是降采样的一种方法）\n最常用的方法就是最大池化 Max Pooling，当然也有均值池化等等方法\n\n注意：一般不会在池化过程中填充0，因此一般池化的步长都会和大小相适应（池化的目的是为了降采样，而填充0就偏离了这个目的）\n关于全连接在这张图中，我们省略了关于全连接后面的步骤，这里来介绍一下\n\n在得到3*3*N的数据后，全连接的第一步，就是将这N个矩阵拉平，拉成一个一维的序列，汇集所有的信息，得到结果\n常用的参数配置现有卷积核F*F*K，步长S，填充P\n\nK通常为2的幂数：32、64、128、256等\n常用1：F=3 S=1 P=1\n常用2：F=5 S=1 P=1\n常用3：F=5 S=2 P=?（？代表任意）\n常用4：F=1 S=1 P=0\n\n对于池化来说常用的配置为：\n\n常用1：F=2 S=2\n常用2：F=3 S=2\n\n训练NN的细节选择激活函数激活函数的种类有很多，如图所示\n\nSigmoid\nSigmoid 是一类函数的统称：\n\n有极限\n饱和\n\n所以最出名的这种逻辑斯谛回归和tanh都是Sigmoid函数\n\n逻辑斯谛回归的函数\n\n介于[0,1]之间\n类似于生物中神经元的放电率\n\n关于Sigmoid有三个问题：\n\n1、饱和的神经元会让梯度消失\n\n所谓饱和神经元，就是当传入的X过大或者过小的时候，Sigmoid函数的两侧的导数（可以看Sigmoid图像两侧的斜率）会慢慢趋近于0\n这就意味着，当数值偏高或偏低的时候，Sigmoid函数将导致无法更新梯度\n\n2、Sigmoid不是零均值的（或者叫不是以0为中心的）\n\nSigmoid这一特点会导致其收敛速度较慢\n关于为什么非零中心的函数会使收敛速度变慢，可以看这篇博客，非常Nice！\n简单来说就是：假设输入数据全为正或是负，会导致所有的参数都向一个方向变化，假设我们有两个参数W1 W2，现在期望W1小一点，W2大一点，Sigmoid在输入数据全为正或负的情况下不可能做到让两个参数一个大一个小\n\n3、指数运算非常耗时\n\ntanh\n介于[-1, 1]\n以零为中心\n\n和Sigmoid相比：tanh是以0为中心的，有利于收敛，但是仍然有在饱和情况下Kill梯度的问题\nReLU及其变种ReLU优点：\n\n介于[0, +无穷]，负数返回零，正数返回本身\n运算简单，因此卷积会很快，大约是tanh/Sigmoid的6倍\n正数域不会有饱和的问题\n也有证据表明它比sigmoid要更有生物上的合理性\n\n也存在这么几个问题：\n\n不是以0为中心的\n负半轴还是会饱和（出现这种现象的时候称为 dead ReLU）\n\nLeaky ReLU其实就是把原本的0，换成了0.01，这个参数可以避免在负数域饱和（加了参数的ReLU称为 PReLU Parametric ReLU）\n特点：\n\n不会饱和\n运算快（类似于ReLU）\n\nELU在负数域换成了指数，避免负数域不饱和：\n\n有LU的优点\n基本不会饱和\n对噪声有更强的鲁棒性\n\n缺点就是添加了指数，增加了运算难度\nMaxout取最大，有这几个特点：\n\n泛化了ReLU和LeakyReLU\n不会饱和\n\n缺点就是将每个神经元参数数量翻倍了\n激活函数小结\n尽量使用ReLu（小心调整学习率，防止dead ReLU）\n可以尝试用一下Leaky ReLU、Maxout、ELU\n可以试一下tanh（效果可能不会比上面的好）\n不要使用Sigmoid\n\n数据预处理拿到数据后的第一步：\n\n零均值化\n归一化\n\n一般一开始只对数据做零均值化\n零均值化激活函数那里我们提到，如果数据全为正或是负，会导致收敛变慢，在一开始我们就对数据进行零均值化可以尽量避免这个问题\n\n零均值化：将每个像素的值减去训练集上所有像素值的平均值\n\n注意：在后续的不断的卷积过程中，还会遇到非零均值的数据，这里只能保证在第一层避免了均值化，所以还是不要使用Sigmoid\n初始化权重初始化神经网络的权值：（权值就是x前面的那个W）\n\n【想法一】可以初始化权值为一个小的随机数，比如0.00x\n\n使用小的随机数初始化在比较深的层次中可能会出现问题：即使一开始是标准的正态分布（高斯分布），在一层一层的卷积后，所有的激活值都会趋近于0，会让我们高斯分布小时\n（在不断的W*X，最终会让结果趋近于0也很正常）\n\n如图所示，一开始还是一个优雅的正态分布，到后面全变成0了\n不仅如此，在反向传播的时候，由于数据非常小，也会导致我们的梯度几乎不会发生变化\n\n【想法二】权重值给很大，比如说W=1或者W=-1\n\n这种情况下，所有的神经元都会饱和，导致梯度不会再发生变化\n\n【想法三】Xavier初始化：一种根据方差缩放的参数初始化\n\n但是这种方法和ReLU效果不好（ReLU会把负数域干掉，因此方差也会干掉一半）\n一个优化的办法是将输入值除以2\n批量归一化如果一个激活函数能给出近似于高斯分布，那将是极好的。通常使用批量归一化 Batch Normalization这种方法来让数据保持高斯分布\n优点：\n\n这样可以提高整个网络的梯度流，允许更广范围的学习率和不同初始值下工作\n\n超参数调优learning rate的调优：使用cross validation，先选择部分数据、执行少量迭代；观察loss function是否下降，变化情况如何，以确定learning rate 的大致范围。\n（过大则loss fucntion可能出现NaN，过小则loss function 无变化）\n对超参数的采样使用随机抽样，而不是等间隔抽样，这样更容易找到更好的组合\n","categories":["深度学习"],"tags":["神经网络"]},{"title":"机器学习入门","url":"/2022/07/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/","content":"\n引言：机器学习入门。入坑机器学习\n\n\n\n\n\n机器学习入门吴恩达老师的机器学习入门课，本文的目的是入门，了解基本的概念，梳理整个结构，对具体的算法内容不求甚解。\n什么是机器学习\n机器学习 Machine Learning：\n在没有具体的编程的情况下（without being explicitly programmed）使计算机有学习能力的研究领域\n\n机器学习分类机器学习有以下几种：\n\nSupervised Learning 监督学习：所谓监督，就是会给出一个集合，并且会给出这个集合内的部分元素（right answers）\nUnsupervised Learning 非监督学习：数据没有任何标签，我们需要找数据可能存在的结构\nReinforcement Learning 强化学习： 有奖惩（rewards and penalties）机制的交互式学习\n\n监督学习监督学习算法有两种形式：\n\n回归问题 Regression：设法预测连续值的属性（比如预测房子的价格）\n分类问题 Classification：设法对其划分种类（比如预测癌症的恶性与良性、预测是否下雨）\nMulticlass classification 多类分类：比如分为热狗、披萨、面条\nBinary classification 二元分类，总共只有两种分类\n热狗 &amp; 不是热狗\n积极的 &amp; 消极的（比如评论）\n\n\n\n\n\n非监督学习非监督学习算法的类别大致有以下几种\n聚类（Clustering Algorithm）：\n\n社交网络的应用：判断一个人的社交圈子，判断他们哪些人相互认识\n管理大型的计算机集群：可能存在将部分计算机放在一起，可以减少内部传输消耗，增加效率\n给用户画像，将用户细分到不同的市场中去\n\n鸡尾酒会算法（Cocktail party algorithm）：从源数据中分离出不同的数据\n\n分离音频\n\n特征 Features特征有两种：\n\n定性特征\n定量特征\n连续的\n离散的\n\n\n\n监督学习Demo吴老师以一个房子的大小与价格的demo为例，串了一下监督学习的整个过程\n1、数据：有一个 房子大小、价格的数据表（这也是监督学习的基础）\n2、假设函数：假设模拟为 h=a + bx（模拟为了简单的线性函数）\n3、确定一个代价函数（通常选用平方误差函数 Square Error Function，对于线性回归问题，平方误差函数是一个很常用的手段）\n4、优化目标：尽量使代价函数小，选择不同的参数，尽可能的使代价函数小，代价函数越小说明我们拟合的越好（吴老师用到了等高线图）\n如何优化目标，我们可以使用梯度下降算法\n梯度下降算法为了方便的找到使代价函数最小的参数值，我们可以用梯度下降算法（Gradient descent）\n\n梯度下降算法的大致策略是：\n1、 给定参数的初始值（初始值是多少并不重要）\n2、不断的改变参数值，减小代价函数，直到我们找到最小\n\n\n相当于这两座山峰，我们需要从山坡上（初始值），找到最快下山的一条路（最小值）；然后我们再改变一开始的位置，然后再次寻找最快的路；\n不同的路可能会找到不同的最低点（可能会找到不同的局部最优解）\n\n梯度算法的特点是：不同的初始值可能会找到不同的局部最优解\n\n数学原理就是：\n\n（α表示学习率、J表示代价函数，j表示不同的参数代号、:=表示赋值，此式的意思是不断的修正θj的值，括号的内容表示要同步更新参数）\n\n（不同步更新的话，可能会用新的θ0值去算新的θ1值，如图右侧所示）\n如图梯度下降算法示，α代表学习率 Learning Rate，它的大小表示我们是以大步子下山还是小步子下山。\nα越小，下山就会慢（趋近最小值的速度就会变慢）\nα越大，可能会错过最低点（但是速度很快）\n\n有意思的是，我们并不需要频繁修改学习率α，因为当趋近于局部最低点的时候，我们的斜率，会变的很小很小（趋近于0，因为一条横线的斜率就是0），因此我们的步子就会自动的变小\n\n这样的梯度下降算法，也叫Batch 梯度下降算法，它意味着：每次我们下降梯度，都会遍历所有的训练集\n当然也有其他的梯度下降算法没有遍历所有的训练集，因此他们也不叫这个名字。\n","categories":["机器学习"],"tags":["机器学习"]},{"title":"hadoop基本运行与源码编译","url":"/2020/07/04/%E7%BC%96%E8%AF%91/hadoop%E5%9F%BA%E6%9C%AC%E8%BF%90%E8%A1%8C%E4%B8%8E%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/","content":"\n引言： \n\nhadoop的基本使用与源码编译\n\n\n\n\nHadoop启动及其基本操作前置需求\nJDK（官方要求不同版本使用不同的JDK，由于我们使用2.10.0版本hadoop，必须使用JDK7及以上，JDK太高又会有warning，使用JDK8是最好的选择）\nssh及pdsh管理ssh资源\n\nrpm -qa|grep -E &quot;openssh&quot;# 检查是否安装sshecho $JAVA_HOME# 查看javahome路径\n\n\n下载Hadoop。官网链接，千万注意，下hadoop-2.10.0-src.tar.gz，别下成原码了！！\n\n安装Hadoop及实现伪分布式配置\n官网链接：详细配置及参考\n\n将下载的Hadoop压缩包随意的解压在一个包内\n这就是解压后的文件\n\n进入etc目录下，配置hadoop-env.sh\n# The java implementation to use.export JAVA_HOME=[配置到JAVA_HOME]# 使用 echo $JAVA_HOME 查看JAVA_HOME路径\n配置core-site.xml及hdfs-site.xml\n# core-site.xml&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;--------------------------------# hdfs-site.xml&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\n官网配置了这些就可以启动了，下面是百度到的其他配置，便于学习\n&lt;!--core-site.xml--&gt;&lt;configuration&gt;        &lt;!-- 指定HDFS的nameservice --&gt;        &lt;property&gt;                &lt;name&gt;fs.defaultFS&lt;/name&gt;                &lt;value&gt;hdfs://zachary-pc:9000&lt;/value&gt;        &lt;/property&gt;\t\t&lt;!-- 缓冲区大小 --&gt;        &lt;property&gt;                &lt;name&gt;io.file.buffer.size&lt;/name&gt;                &lt;value&gt;131072&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 指定临时文件目录 --&gt;        &lt;property&gt;                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                &lt;value&gt;/home/zachary/hadoop-2.10.0/tmp&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;-------------------&lt;!--hdfs-site.xml--&gt;&lt;configuration&gt;&lt;!-- configuration for NameNode:--&gt;        &lt;property&gt;                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;                &lt;value&gt;/home/zachary/hadoop-2.10.0/name&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 块大小 --&gt;        &lt;property&gt;                &lt;name&gt;dfs.blocksize&lt;/name&gt;                &lt;value&gt;268435456&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;                &lt;value&gt;100&lt;/value&gt;        &lt;/property&gt;&lt;!-- configuration for DateNode:--&gt;        &lt;property&gt;                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;                &lt;value&gt;/home/zachary/hadoop-2.10.0/data&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 指定HDFS副本的数量 --&gt;        &lt;property&gt;                &lt;name&gt;dfs.replication&lt;/name&gt;                &lt;value&gt;1&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;------------&lt;!--mapred-site.xml--&gt;&lt;configuration&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;                &lt;value&gt;yarn&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;------------&lt;!--mapred-site.xml--&gt;&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;        &lt;!-- configuration for ResourceManger: --&gt;        &lt;property&gt;                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;                &lt;value&gt;zahcary-pc&lt;/value&gt;        &lt;/property&gt;        &lt;!-- configuration of NodeManager: reducer获取数据方式 --&gt;        &lt;property&gt;                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;        &lt;/property&gt;      &lt;!-- 配置外网只需要替换外网ip为真实ip，否则默认为 localhost:8088 --&gt;\t  &lt;!-- &lt;property&gt;\t          &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;\t          &lt;value&gt;外网ip:8088&lt;/value&gt;\t  &lt;/property&gt; --&gt;&lt;/configuration&gt;\n配置SSH免密登录\n在hadoop根目录下，输入\n# 生成公钥和秘钥，他们生成后是家目录(~)下的id_rsa和id_rsa.pub前者为私钥，后者为公钥ssh-keygen -t rsa -P &#x27;&#x27; -f ~/.ssh/id_rsacat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keyschmod 0600 ~/.ssh/authorized_keys\n格式化namenode\nbin/hdfs namenode -format\n启动守护程序\nsbin/start-dfs.sh\n启动hadoop，在sbin目录下\n./start-all.sh# 启动./stop-all.sh# 关闭\n输入jsp，如果有6个进程出现，说明启动成功\n\n访问端口50070就是HDFS管理界面\n\n查看端口8088，结点管理页面\n\n\n\nHadoop命令行基本的操作bin/hdfs dfs -mkdir /user/t# 创建指定目录hadoop fs –rmr /user/t# 删除指定的文件夹hadoop fs -touchz /user/new.txt# 在hadoop指定目录下新建空文件hadoop dfs –ls [文件目录]# 查看hadoop fs –put [本地地址] [hadoop目录]hadoop fs –put /home/t/file.txt  /user/t   # 上传本地文件hadoop fs –put [本地目录] [hadoop目录] hadoop fs –put /home/t/dir_name /user/t# 上传本地文件夹(dir_name是文件夹名)hadoop fs -get [文件目录] [本地目录]hadoop fs –get /user/t/ok.txt /home/t# 将hadoop上某个文件down至本地已有目录下hadoop fs –rm [文件地址]hadoop fs –rm /user/t/ok.txt# 删除hadoop上指定文件hadoop fs –rm [目录地址]hadoop fs –rmr /user/t# 删除hadoop上指定文件夹（包含子目录等）hadoop fs –mv /user/test.txt /user/ok.txt# 将hadoop上某个文件重命名（将test.txt重命名为ok.txt）hadoop job –kill  [job-id]# 将正在运行的hadoop作业kill掉\n\nHadoop 源码编译环境要求\n要求apache-ant\n要求jdk1.7（亲自尝试，jdk1.8在最后会报出一大片红色Error）\n要求maven（maven要求在3.3.0以上，最好选择最新版本的maven）\n要求剩余磁盘大于两个G（df -h查看剩余磁盘容量）\n编译hadoop-2.10.0-src.tar.gz\n\n编译过程Maven配置\n解压软件到一个位置。\n在/etc/profile中配置环境路径\n使用mvn -version查看版本信息\n\nTips：如果下载太慢的话，可以中断后，执行mvn -clean然后换成阿里的镜像，重新下载\nANT配置\n同Maven的安装的配置，解压缩\n在/etc/profile中配置环境路径\n使用ant -version查看版本信息\n\n安装glibc-headers和g++sudo yum install glibc-headers# 安装glibc-headerssudo yum install gcc-c++# 安装g++sudo yum install make# 安装makesudo yum install cmake# 安装cmake\n\n\n\n安装配置protobuf\n解压文件\n进入到protobuf-2.5.0目录下\n./configure命令\nmake命令\nmake check命令\nmake install命令\nldconfig命令\n配置环境变量\n\n环境变量配置如图\n注意！！protobuf没有bin，不需要配置到bin下\n如果配置环境后，查看版本没有成功，就输入source /etc/profile重编一下path\n安装其他环境sudo yum install openssl-devel# 安装openssl-devel库sudo yum install ncurses-devel# 安装ncurces-devel库\n\n开始编译\n解压hadoop源码包到指定目录\n\n进入该目录，使用mvn执行编译（这个过程十分漫长，请耐心等待）\n\ndf -h查看磁盘\n\n# 注意！！！查看磁盘是否足够，是否有2g以上，然后再执行命令（在漫长的等待后，我因为磁盘不足，failed一次，血的教训）mvn package -Pdist,native -DskipTests -Dtar\n如果你的版本和我要求的版本都一样的话（要求jdk1.7、Maven3.3.0+、ant无要求，protobuf2.5）是可以成功的\n\n\n\n\n成功\n\n","categories":["编译"],"tags":["hadoop"]},{"title":"Linux内核编译","url":"/2020/07/07/%E7%BC%96%E8%AF%91/Linux%20%E5%86%85%E6%A0%B8-%E8%91%A3%E6%96%87%E6%B5%A9/","content":"\n引言： \n\n编译linux内核\n\n\n\n\n\nLinux内核编译前置要求官网下载压缩文件\n新建一个文件夹存放这个压缩文件，这里新建的文件夹为/usr/kernel，将文件解压到此tar -xf xxxx.gx.xz\n开始配置安装\n进入到linux内核路径下\n如果是不是第一次执行，则要清理一下之前残留的配置文件\nmake mrproper# 如果不是第一次配置，运行此命令后会显示删除xxx.conf文件等等make clean\n拷贝系统原有的操作模板\ncp /boot/config-xxx-xx [我们解压后的linux路径/.config]\n\n定义编译内核时功能的特性\n\n安装需要的组包\nyum groupinstall &quot;development tools&quot; \n配置内核选项，这里有多种配置\nmake defconfig# 默认配置（据说是linus的配置）make allnoconfig# 只安装必须安装的选项（适用嵌入式系统）make menuconfig# 图形化界面安装方式（需要ncurses-devel，记得先yum install）\n这里选择了make menuconfig方式（如果报错display不够什么的错误，就调大一点你的窗口，就ok了）\n\n进入General setup\n我们改一下Local version -append to kernel release\n加上自己的名字吧-1.0-wenhaoLinux，点击OK\n一步一步exit，选择YES保存退出即可\n\n使用grep -i ntfs .config查询一下我们刚刚所做的配置\n\n开始编译，make -j 4，需要很长的一段时间，如果报错说缺少什么，直接yum即可\n\n开始安装模块make modules_install，安装后ls /lib/modules查看咱们自己编译的内核\n\nmake install安装内核相关的文件，安装后使用ls /boot查看，会有三个我们自己产生的文件initramfs、System.map、vmlinuz\n\n查询grub菜单，cat /boot/grub2/grub.cfg查看，会有对应我们新装的内核的菜单\n\nreboot，重新启动，在启动页可以看到我们自己安装内核的Linux\n\n\n\n\n进入后，使用uname -a查看，发现确实是我们的版本\n\n\n\n","categories":["Linux"],"tags":["Linux"]},{"title":"Mysql8编译安装","url":"/2020/07/07/%E7%BC%96%E8%AF%91/Mysql8%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"\n引言： \n\ncentOs 编译运行mysql\n\n\n\n\nMySql8.0.20编译安装前置要求：更新cmake\ncmake要求3.0及以上\n\nyum -y remove cmake# 如果你曾yum安装过cmake，就卸载一下吧wget https://github.com/Kitware/CMake/releases/download/v3.15.3/cmake-3.15.3-Linux-x86_64.tar.gz# 下载压缩包tar -zxvf cmake-3.15.3-Linux-x86_64.tar.gz# 设置环境变量vim /etc/profileexport CMAKE_PATH=/usr/local/cmakeexport PATH=$CMAKE_PATH/bin:$PATH# 更新pathsource /etc/profile# 查看cmake信息cmake -v\n\n\n\n更新gcc\n gcc 要求5.4及以上\n\nsudo yum install centos-release-sclsudo yum install devtoolset-7-gcc*scl enable devtoolset-7 bashgcc --version\n\n更新完成后，我们需要改动/usr/bin/下的文件\n# 先删除这个文件夹下的 cc 和 c++两个文件# 建立链接sudo ln -s [gcc-c++路径] /usr/bin/c++# 建立链接sudo ln -s [gcc路径] /usr/bin/cc# 可以使用以下命令查看路径which gcc\n\n\n\nboost文件boost文件我们可以直接下载，也可以在命令行直接下载。这里我们直接在后面命令行中下载即可\n安装Mysql\n解压mysql文件后，进入文件目录\n\n为了避免每次失败后，得删除整个mysql文件重新解压，我们建一个build文件夹\nmkdir buildcd buildcmake .. -DDOWNLOAD_BOOST=1 -DWITH_BOOST=[配置一个下载的目的路径]  -DFORCE_INSOURCE_BUILD=1\n\n以下是百度到的更多的配置，记录一下：\nsudo cmake .. \\-DDEFAULT_CHARSET=utf8mb4 \\-DDEFAULT_COLLATION=utf8mb4_unicode_ci \\ #-DENABLED_LOCAL_INFILE=ON \\-DWITH_SSL=system \\-DCMAKE_INSTALL_PREFIX=/usr/local/mysql/server \\-DMYSQL_DATADIR=/usr/local/mysql/data \\-DMYSQL_TCP_PORT=3306 \\-DDOWNLOAD_BOOST=0 \\-DWITH_BOOST=/usr/mysql-boost/boost_1_70_0.tar.gz\n\n\nDDEFAULT_CHARSET：指定默认字符集为utf8mb4，因为历史遗留问题，MySQL中的utf8不是真正的utf8，而是阉割版的，最长只有三个字节，当遇到四个字节的utf8编码时，会导致存储异常。从5.5.3开始，使用utf8mb4实现完整的utf8。\nDDEFAULT_COLLATION：排序规则，默认为utf8mb4_0900_ai_ci，属于utf8mb4_unicode_ci的一种。0900指的是Unicode校对算法版本，ai是指口音不敏感（as表示敏感），ci指不区分大小写（cs表示区分）。utf8mb4_unicode_ci表示基于标准的的Unicode来排序和比较，能够在各种语言之间精确排序，而utf8mb4_general_ci遇到某些特殊的字符集时排序结果可能不一致，准确性较差，但是性能较好，比较和排序时候更快。\nDENABLED_LOCAL_INFILE表示能否使用load data命令。\nDWITH_SSL表示使用系统的SSL库，若不使用系统的请自定义路径。\nDCMAKE_INSTALL_PREFIX：MySQL安装目录。\nDMYSQL_DATADIR：MySQL数据目录，初始时为空。\nDMYSQL_TCP_PORT：端口，默认3306。\nDDOWNLOAD_BOOST：取值0或1，是否下载Boost库。\nDWITH_BOOST：若不下载Boost库的话，是本地Boost库的位置，若下载Boost表示下载位置\n\n\n然后在mysql根目录下就可以make了\n然后make install\n\n配置mysql这才是真正的难处啊！！！\n摸爬滚打，一个坑一个坑菜，试出来：\n\n```shell\n添加用户组groupadd mysqluseradd -g mysql mysqlchown -R mysql:mysql /usr/local/mysql\n 2. ```shell   # 初始化mysql   cd /usr/local/mysql/bin   ./mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data\n```shellecho “export PATH=$PATH:/usr/local/mysql/bin” &gt;&gt; /etc/profilesource /etc/profile\n4. ```shell   # 配置my.cnf文件   [mysqld]   skip-grant-tables   # 跳过密码   basedir = /usr/local/mysql   datadir = /usr/local/mysql/data   socket = /usr/local/mysql/mysql.sock   user = mysql   symbolic-links=0   [mysqld_safe]   log-error = /usr/local/mysql/log-error/mariadb.log   pid-file = /usr/local/mysql/mariadb.pid\n```\n创建日志授予权限mkdir -p /usr/local/mysql/log-error/touch /usr/local/mysql/log-error/mariadb.logchown -R mysql:mysql /usr/local/mysql/log-error/mariadb.log\n6.    ```shell   # 启动服务   /usr/local/mysql/support-files/mysql.server start\n```shell\nbin下登录mysql./mysql -u root \n 这里会报一个错误，![image-20200705113857303](http://qcrt74khz.bkt.clouddn.com/image-20200705113857303.png)这里需要建立一个软链接查看`/etc/my.cnf`文件下的`socket`路径，建立它和`tmp/mysql.sock`的软链接```shellln -s /usr/local/mysql/mysql.sock tmp/mysql.sock\n重新启动\n./mysql restart\n\n太难了！！启动六个小时没启动成功。最后成功了\n\n\n启动成功\n","categories":["编译"],"tags":["mysql"]},{"title":"openjdk编译","url":"/2020/07/01/%E7%BC%96%E8%AF%91/openjdk%E7%BC%96%E8%AF%91/","content":"\n引言： \n\n使用linux编译jdk源码！！\n\n\n\n\n\nCentOS7 编译 OpenJDK前述 ：​       最开始是想编译JDK8的，但是无奈折腾了一下午都没有找见门路。决定曲线救国，先编译JDK12.\n​       果然越新的JDK越容易构建，终于成功的编译。\n步骤：编译JDK12，需要如下准备：\n\n准备openjdk12的压缩文件，解压\na) 官方网址 下载 jdk 12\nb)  完成后XFTP丢入虚拟机，这里放在了/usr/openjdk12下\nc)  解压文件：tar -zxvf xxx.tar.gz  或者 unzip xxx.zip\nd) 在DOC目录下，会有Building.html文件，这里有详细的配置需求，可以参考。\n\n准备jdk10或者jdk11，并且配置环境变量\na)  亲爱的甲骨文公司下载jdk10或者11，这里使用了jdk11，解压到一个地方，这里解压到了 /usr/local/java/ 目录下\nb)  配置/etc/profiles\nc)  在最底下加两行\nexport PATH=$JAVA_HOME/bin:$PATHexport JAVA_HOME=/usr/local/install/jdk-11\n\nd)  更新配置 source /etc/profile\ne)  用java -version检查一下，是不是11（不是11，试着检查配置是否正确，路径是否正确，再更新一下）\n\n配置\n打开openjdk下的doc目录，会发现有一个 building.html 文件，这个文件中的 Build jdk requirements，要用yum装了这里所有的配置：\n\n\nsudo yum install autoconfsudo yum install freetype-develsudo yum install cups-develsudo yum install libXtst-devel libXt-devel libXrender-devel libXrandr-devel libXi-develsudo yum install alsa-lib-develsudo yum install libffi-develsudo yum install -y gcc gcc-c++sudo yum install fontconfig-devel\n\n还有其他的一些配置，在下一步的时候会报错，提示安装。\n​    执行配置：\nbash configure --with-debug-level=slowdebug --with-boot-jdk=[这里放引导jdk的路径] --disable-warnings-as-errors —with-version-string=12-internal+0-wenhaodong\n\n​    重要配置参数详细设置：可以使用bash configure --help查看\n--with-version-string=&lt;string&gt; - Specify the version string this build will be identified with.# 可以配置自己的名字 —with-version-string=12-internal+0-wenhaodong--with-boot-jdk=&lt;path&gt; - Set the path to the Boot JDK# 配置boot-jdk路径（boot-jdk即引导jdk）\n\n\n\n​    显示类似这样，就成功了！！\n\n\n编译\n\n​        终于到了这一步，别紧张，先去看看虚拟机处理器和内存数，别太低，太低会很慢，会让你感觉是卡了，真的很难受，这里配置了 2 处理器 4G内存\n输入 \nmake images \n\nmake的详细参数：\nmake images # 构建jdk映像make docs # 构建jdk文档make all # 构建全部生成映像make clean # 删除make生成的文件，但不会删除configure的文件make dist-clean # 删除所有文件\n\n然后去打水喝水，深呼吸祷告。\n出现这样，就代表你成功了！！\n\n\n成功！！\n在build目录下中有一个jdk文件，那就是我们编译出来的文件。\n自己编一个.java文件，用jdk/bin下的命令编译、运行 最后成功了\n令人感动\n\n\n\n成功！！激动。\n","categories":["编译"],"tags":["openjdk"]},{"title":"编译运行nginx","url":"/2020/07/02/%E7%BC%96%E8%AF%91/%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Cnginx/","content":"\n引言： \n\n使用linux编译运行nginx！！\n\n\n\n\n编译运行nginx安装环境CentOS7安装编译nginx1.19.0\n步骤：1. Nginx官网\n在Nginx官网下载安装包 nginx-1.19.0\n官网有详细的安装部署说明\n\n2. CentOS7中解压\ntar -zxvf nginx-1.19.0.tar.gz\n\n进入解压后的文件，会看到\n有多个文件，我们主要会用到的有conf configure\n\n3. configure\n切换到nginx目录内，执行\n./configure --prefix=/usr/local/demo\n\n其他参数官网十分详细，这里列举几个重要的配置\n--prefix=path# 定义保存服务器文件的目录，默认为 /usr/local/nginx--with-http_ssl_module# 将支持https协议\n\n4. make\n依然在原目录下执行\nmake\n\n编译安装\n5. make install\n执行安装，安装后--prefix指定的安装目录下会出现\n\n如此的目录。\nconf下就是配置文件，我们待会儿需要对其目录下的nginx.conf进行配置\nsbin下是执行命令的目录\n6. 找一个博客作为检验\n我把博客放在了/usr/nginx/blog内\n\n博客目录下有html文件以及静态图片文件夹还有css文件\n\n7. 配置conf\n在--prefix后的路径下，进入conf目录，配置nginx.conf文件，将\nhttp&#123;server&#123;\tlisten 80;\t# 监听的端口地址\tserver_name localhost;\t\tlocation /&#123;\t\troot html;\t\tindex index.html index.htm\t&#125;\t# 把这里的root 配置到blog的目录&#125;&#125;\n\n\n8. 启动配置\n这里先学习一下nginx的命令\n\nnginx -s signal\n\nWhere signal may be one of the following:\nstop — fast shutdownquit — graceful shutdownreload — reloading the configuration filereopen — reopening the log files\n\n优雅的杀死nginx\nkill -s QUIT [nginx的pid]\n\n学会了这些，进入sbin目录执行\n./nginx\n\n就启动了，打开浏览器，输入localhost，发现已经能愉快的访问了\n\n\n遇到的小bug可能会出现这种情况\n\n有可能是你执行了两遍./nginx，80端口被占用，就会报错\n解决方法：\nnetstat -ntlp# 查看端口为80的哪一个进程kill -s QUIT [nginx的pid]# 使用官方手法，优雅的杀死nginx\n\nENDING\n","categories":["编译"],"tags":["nginx"]},{"title":"2的整数幂","url":"/2020/07/10/%E7%AE%97%E6%B3%95/2%E7%9A%84%E6%95%B4%E6%95%B0%E5%B9%82/","content":"\n引言： \n\n判断一个数是否为2的整数次幂\n\n\n\n\n\n2的整数幂\n判断一个数是否为2的整数次幂\n\n第一眼看完这个题，会想到的办法：\n\n先判断奇偶，是奇数直接false\n如果是偶数，就从2开始平方2,4,16,32,32*32…\n\n但其实，我们如果知道巧妙的运用位运算：\n\n代码只有一行，就可以搞定\n/** * @author 董文浩 * @Date 2020/7/10 20:57 * 2的整数幂： * 判断一个数，是否为2的整数次幂 */public class IntegralPowerOf2 &#123;    //如果使用位运算，这道题会非常的简单，如下    public static boolean isIntegralPowerOf2(int num)&#123;        return (num &amp; num-1) == 0;    &#125;    public static void main(String[] args) &#123;        System.out.println(isIntegralPowerOf2(1024));        System.out.println(isIntegralPowerOf2(65536));        System.out.println(isIntegralPowerOf2(60000));        //输出结果：true true false    &#125;&#125;\n\n","categories":["算法"],"tags":["Java","算法"]},{"title":"字符串KMP算法","url":"/2022/08/01/%E7%AE%97%E6%B3%95/KMP%E7%AE%97%E6%B3%95/","content":"\n引言： \n\n\nK、M、P是三位科学家，他们以自己的首字母命名了这种字符串查找法\n\n\n\n\n字符串KMP算法适用情况假设有字符串S，想要在其中查找字符串P，如果使用双指针去遍历，那么他的时间复杂度为O(m*n)，其中m和n为各自的字符串长度。\n但是使用KMP算法，就可以压缩到O(m+n)\nKMP算法\nKMP算法的核心，是一个被称为部分匹配表(PMT Partial Match Table)的数组\nPMT中的值是字符串的前缀集合与后缀集合的交集中最长元素的长度。\n\n什么是PMT数组？首先我们需要知道什么是字符串的前缀和后缀？\n比如对于字符串hello来说：\n\n前缀集合：&#123;h, he, hel, hell&#125;\n后缀集合：&#123;o, lo, llo, ello&#125;\n\n又比如对于字符串ababa来说：\n\n前缀集合：&#123;a, ab, aba, abab&#125;\n\n后缀集合：baba, aba, ba ,a&#125;\n\n\n前缀集合与后缀集合的交集为&#123;aba, a&#125;，最长的长度就是3了，因此我们可以对字符串ababa构造出一个数组PMT\nstr = &quot;ababa&quot;;pmt = &#123;0, 0, 1, 2, 3&#125;;// pmt[0]代表字符串&quot;a&quot;的前后缀交集的最长的长度// pmt[1]代表字符串&quot;ab&quot;// pmt[2]代表&quot;aba&quot; // pmt[3]代表&quot;abab&quot;// pmt[4]代表&quot;ababa&quot;\n\nKMP算法如何提高查询速度？现在假设我们要在主字符串&quot;ababababca&quot;中查找模式字符串&quot;abababca&quot;\nS = &quot;ababababca&quot;;P = &quot;abababca&quot;;\n\n可以根据字符串P求出PMT数组为\npmt = &#123;0, 0, 1, 2, 3, 4, 0, 1&#125;;\n\n现在我们开始从S中找P，设i,j分别是S和P的指针，从0开始相互匹配，那么当出现如图(a)所示的情况时，会匹配失败，此时i,j为6\nPMT[j-1]的值4，那么说明字符串S的后缀abab与字符串P的前缀abab相同\n因此下一次循环，i指针无需动，j=pmt[j-1]即可，如图(b)\n\nNext数组为了编程的方便，将PMT数组向前挪动1位，最开始的位置补一个-1（这个值为多少都可以，无所谓），如图所示：\n\nCode部分KMP的代码可以背下来，可以作为我们的一个API进行调用！！\n（注意这里的next数组其实是pmt数组，并没有移动一位）\npublic int strStr(String s, String p) &#123;    int n = s.length(), m = p.length();    if (m == 0) return 0;    // 使用p字符串构造Next数组    int[] next = new int[m];    for (int i = 1, j = 0; i &lt; m; i++) &#123; // i为next指针，因此初始值为1        while (j &gt; 0 &amp;&amp; p.charAt(i) != p.charAt(j)) j = next[j - 1];        if (p.charAt(i) == p.charAt(j)) j++;        next[i] = j;    &#125;    // 快速匹配    for (int i = 0, j = 0; i &lt; n; i++) &#123;        while (j &gt; 0 &amp;&amp; s.charAt(i) != p.charAt(j)) j = next[j - 1];        if (s.charAt(i) == p.charAt(j)) j++;        if (j == m) return i - m + 1;    &#125;    return -1;&#125;\n\n记忆点：\n\n两个循环，一个构造next，一个快速匹配\n第一个循环初始值i=1,j=0，是字符串p和自身比较，最后需要赋值next[i]=j\n第二个循环初始值i=0, j=0，是字符串s和p比较，当j==m就可以返回值了\n\n参考资料\n知乎文章\n\n力扣28.实现strStr()\n\n\n","categories":["算法"],"tags":["Java","算法"]},{"title":"并查集","url":"/2020/09/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%B9%B6%E6%9F%A5%E9%9B%86/","content":"\n    引言：数据结构——并查集\n\n\n\n并查集并查集一种由孩子节点指向父亲节点的特殊的数据结构，可以用来很方便的解决连接问题（判断是否相互连接，如网络（社交网络）中节点间的连接状态，例如一个人是否可以通过朋友的朋友认识另一个人）\n并查集主要支持两个操作：\n\nunion(p,q)将p和q联系起来\nisConnected(p,q)判断p与q是否有联系\n\n并查集接口如下：\npublic interface UnionFind &#123;    void union(int p, int q);    boolean isConnected(int p, int q);    int getSize();&#125;\n\n\n\n实现这里准备了6种实现方式，有着不同的机制或者是对方法的优化\nquick find这种实现方式使得我们isConnected方法更快（O(1)级别），但是union方法会比较慢\n/** * @Date 2020/9/26 10:52 * quick find */public class UnionFind1 implements UnionFind &#123;    // 表示数据的下标，可以理解为一个指针    private int[] id;        public UnionFind1(int size) &#123;        this.id = new int[size];        // 给每一个数据一个不同的下标        for (int i = 0; i &lt; id.length; i++) &#123;            id[i] = i;        &#125;    &#125;    /**     * 合并元素p和元素q所属的集合     * @param p     * @param q     */    @Override    public void union(int p, int q) &#123;        int pId = find(p);        int qId = find(q);        if(pId == qId) &#123;            return;        &#125; else &#123;            for (int i = 0; i &lt; id.length; i++) &#123;                if(id[i] == pId) &#123;                    id[i] = qId;                &#125;            &#125;        &#125;    &#125;    /**     * 查看元素p和q是否在一个集合     * @param p     * @param q     * @return     */    @Override    public boolean isConnected(int p, int q) &#123;        return find(p) == find(q);    &#125;    /**     * 查找元素p所对应的集合编号     * @param p     * @return     */    private int find(int p)&#123;        if(p&lt;0&amp;&amp;p&gt;=id.length) &#123;            throw new IllegalArgumentException(&quot;不正确的下标&quot;);        &#125;        return id[p];    &#125;    @Override    public int getSize() &#123;        return id.length;    &#125;&#125;\n\n\n\nquick union主流的并查集的实现方式，将两个操作的时间复杂度都为O(h)，h为树的高度\n/** * @Date 2020/9/26 11:06 * quick union */public class UnionFind2 implements UnionFind &#123;    private int[] parent;    public UnionFind2(int size)&#123;        parent = new int[size];        for (int i = 0; i &lt; parent.length; i++) &#123;            parent[i] = i;        &#125;    &#125;    @Override    public void union(int p, int q) &#123;        int pRoot = find(p);        int qRoot = find(q);        if(pRoot == qRoot)&#123;            return;        &#125;        parent[pRoot] = qRoot;    &#125;    @Override    public boolean isConnected(int p, int q)&#123;        return find(p) == find(q);    &#125;    /**     * 找到对应的根节点     * @param p     * @return     */    private int find(int p)&#123;        if(p&lt;0&amp;&amp;p&gt;=parent.length) &#123;            throw new IllegalArgumentException(&quot;不正确的下标&quot;);        &#125;        while (p!=parent[p])&#123;            p = parent[p];        &#125;        return p;    &#125;    @Override    public int getSize() &#123;        return parent.length;    &#125;&#125;\n\n\n\n优化Union增加了一个字段sz，存储以i为根的集合中元素的个数，在Union操作的时候，我们可以将元素个数少的指向元素个数多的\n/** * @Date 2020/9/26 15:04 */public class UnionFind3 implements UnionFind&#123;    private int[] parent;    private int[] sz;   // 以i为根的集合中元素的个数    public UnionFind3(int size)&#123;        parent = new int[size];        sz = new int[size];        for (int i = 0; i &lt; parent.length; i++) &#123;            parent[i] = i;            sz[i] = 1;        &#125;    &#125;    @Override    public void union(int p, int q) &#123;        int pRoot = find(p);        int qRoot = find(q);        if(pRoot == qRoot)&#123;            return;        &#125;        // -----------------这里-----------------------        // 将元素少的合并到元素多的元素上        if(sz[pRoot] &gt; sz[qRoot])&#123;            parent[pRoot] = qRoot;            sz[qRoot]+= sz[pRoot];        &#125;else &#123;            parent[qRoot] = pRoot;            sz[pRoot] += sz[qRoot];        &#125;    &#125;    @Override    public boolean isConnected(int p, int q)&#123;        return find(p) == find(q);    &#125;    /**     * 找到对应的根节点     * @param p     * @return     */    private int find(int p)&#123;        if(p&lt;0&amp;&amp;p&gt;=parent.length) &#123;            throw new IllegalArgumentException(&quot;不正确的下标&quot;);        &#125;        while (p!=parent[p])&#123;            p = parent[p];        &#125;        return p;    &#125;    @Override    public int getSize() &#123;        return parent.length;    &#125;&#125;\n\n优化为rank其实我们可以直接存储树的高度，而不是元素的个数，如图\n\n\n/** * @Date 2020/9/26 15:14 * rank优化 */public class UnionFind4 implements UnionFind &#123;    private int[] parent;    private int[] rank;   // 以i为根的集合所表示的树的高度    public UnionFind4(int size) &#123;        parent = new int[size];        rank = new int[size];        for (int i = 0; i &lt; parent.length; i++) &#123;            parent[i] = i;            rank[i] = 1;        &#125;    &#125;    @Override    public void union(int p, int q) &#123;        int pRoot = find(p);        int qRoot = find(q);        if (pRoot == qRoot) &#123;            return;        &#125;        // 将树高更低的集合合并到高的集合上        if (rank[pRoot] &lt; rank[qRoot]) &#123;            parent[pRoot] = qRoot;        &#125; else if (rank[pRoot] &gt; rank[qRoot])&#123;            parent[qRoot] = pRoot;        &#125;else &#123;// 相等情况            parent[qRoot] = pRoot;            rank[qRoot]++;        &#125;    &#125;    @Override    public boolean isConnected(int p, int q) &#123;        return find(p) == find(q);    &#125;    /**     * 找到对应的根节点     *     * @param p     * @return     */    private int find(int p) &#123;        if (p &lt; 0 &amp;&amp; p &gt;= parent.length) &#123;            throw new IllegalArgumentException(&quot;不正确的下标&quot;);        &#125;        while (p != parent[p]) &#123;            p = parent[p];        &#125;        return p;    &#125;    @Override    public int getSize() &#123;        return parent.length;    &#125;&#125;\n\n\n\n路径压缩一个并查集，我们主要实现的操作就是两个，但是在极端情况下，我们发现还是会出现树很高的现象，但其实\n\n\n只需要优化一下find方法，我们就可以在每次find时，更改树的结构\n/** * 找到对应的根节点 * * @param p * @return */private int find(int p) &#123;    if (p &lt; 0 &amp;&amp; p &gt;= parent.length) &#123;        throw new IllegalArgumentException(&quot;不正确的下标&quot;);    &#125;    while (p != parent[p]) &#123;        // 就是这一行代码        parent[p] = parent[parent[p]];        p = parent[p];    &#125;    return p;&#125;\n\n这一行代码：parent[p] = parent[parent[p]];看上去很复杂，其实就是在遍历到这里时，把该节点的父节点 换成父节点的父节点\n\n\n每一次find，我们都可以优化一遍，最后所有的子节点都会指向一个根，这样我们的树高大大的降低，这种路径压缩的操作，最后会\n递归优化经过路径优化后，你可能在想，为什么不直接在第一次find的时候，就将子节点连接到根节点呢？\n所以我们可以这样优化\n/** * 找到对应的根节点 * * @param p * @return */private int find(int p) &#123;    if (p &lt; 0 &amp;&amp; p &gt;= parent.length) &#123;        throw new IllegalArgumentException(&quot;不正确的下标&quot;);    &#125;    if (p != parent[p]) &#123;        parent[p] = find(parent[p]);    &#125;    return parent[p];&#125;\n\n\n\n\n\n时间复杂度分析经过优化后，并查集的时间复杂度为*O(logn)**（推导十分复杂）\n\n\n","categories":["数据结构","UnionFind并查集"],"tags":["数据结构","UnionFind并查集"]},{"title":"Morris中序遍历","url":"/2023/01/13/%E7%AE%97%E6%B3%95/Morris%E9%81%8D%E5%8E%86/","content":"\n引言： 新年的第一篇blog，学一下Morris算法吧\n\n\n\n\nMorris中序遍历Morris基本了解提出：Morris原本是用来解决，当树的深度很深的时候，遍历树需要一个很大的栈，Morris可以省去这一部分空间\n原理：假设cur代表当前节点，如果cur没有左孩子，那么就直接转到右孩子；如果cur有左孩子，那么让cur的前驱节点（前驱节点就是其左孩子的最右孩子）的right指针指向当前的cur，这样做的好处是我们无需再挨个出栈，而是一步到位，省去了栈空间\nMorris算法假设我们有这样一颗树，\n/** *               6*             /   \\*            2     8*           / \\    / \\*          1   4   7  9*             /\\*            3  5*/\n\nMorris基本是中序遍历（左根右顺序），区别在于，遍历到1时，会将1的right指针指向2，然后返回2；同理2-&gt;6，3-&gt;4、5-&gt;6、7-&gt;8\n在第二次遍历到1、3、5、7的位置上时，会将right再置为null，让树保持原状\n下面给出Morris中序遍历的Java实现：\n// Morris 中序遍历public static void morrisInOrderTraverse(TreeNode root) &#123;    TreeNode cur = root;    for (; cur != null; ) &#123;        // 如果该节点没有左孩子，那么就将该节点直接指向右孩子        if (cur.left == null) &#123;            System.out.println(cur.val);            cur = cur.right;        &#125; else &#123;            // 寻找前驱节点            TreeNode pre = cur.left;            for (; pre.right != null &amp;&amp; pre.right != cur; pre = pre.right) ;            // 判断是否已经设置过线索            if (pre.right == cur) &#123;                // 说明设置过线索，开始处理右子树                pre.right = null; // 将原本的线索擦去                System.out.println(cur.val + &quot;线索回归&quot;);                cur = cur.right;            &#125; else &#123;                // 将前驱节点的right指向cur                pre.right = cur;                System.out.println(&quot;设置&quot;+ cur.val +&quot;线索，其前驱为&quot;+ pre.val);                cur = cur.left;            &#125;        &#125;    &#125;&#125;\n\n遍历结果为：\n/** *               6*             /   \\*            2     8*           / \\    / \\*          1   4   7  9*             /\\*            3  5*/12线索回归设置4线索，其前驱为334线索回归56线索回归设置8线索，其前驱为778线索回归9\n\nLeetCode-501. 二叉搜索树中的众数501.二叉搜索树中的众数\n\n首先因为一棵二叉搜索树的中序遍历序列是一个非递减的有序序列，所以相同的数字一定是连续出现的；\n\n其次为了避免使用Map，保证O1的空间；\n\n\n以上两个原因保证此题可以是Morris中序遍历来解决\nclass Solution &#123;    int base, count, maxCount;    List&lt;Integer&gt; answer = new ArrayList&lt;Integer&gt;();     // answer列表：众数可能不止一个，存放多个众数    public int[] findMode(TreeNode root) &#123;        TreeNode cur = root, pre = null;        while (cur != null) &#123;            if (cur.left == null) &#123;                update(cur.val);                cur = cur.right;                continue;            &#125;            pre = cur.left;            while (pre.right != null &amp;&amp; pre.right != cur) pre = pre.right;                        if (pre.right == null) &#123;                pre.right = cur;                cur = cur.left;            &#125; else &#123;                pre.right = null;                update(cur.val);                cur = cur.right;            &#125;        &#125;        int[] mode = new int[answer.size()];        for (int i = 0; i &lt; answer.size(); ++i) mode[i] = answer.get(i);        return mode;    &#125;    // eg：1,2,2,2,3,4,5,6,6,7 相同就计数，不同就更新    public void update(int x) &#123;        if (x == base) &#123;            count ++;        &#125; else &#123;            count = 1;            base = x;        &#125;        if (count == maxCount) answer.add(base); // 众数可能不止一个        if (count &gt; maxCount) &#123;            maxCount = count;            answer.clear();            answer.add(base);        &#125;    &#125;&#125;\n\n\n\nLeetCode-99. 恢复二叉搜索树99. 恢复二叉搜索树\n多使用一个额外的指针preNode\npublic void recoverTree(TreeNode root) &#123;    TreeNode cur = root, pre = null, preNode = null;    TreeNode a = null, b = null;    while (cur != null) &#123;        if (cur.left == null) &#123;            // 新增code开始            if(preNode != null &amp;&amp; cur.val &lt; preNode.val)&#123;                b = cur;                if(a == null) a = preNode;            &#125;            preNode = cur;            // 新增code结束            cur = cur.right;            continue;        &#125;        pre = cur.left;        while (pre.right != null &amp;&amp; pre.right != cur) pre = pre.right;        if (pre.right == null) &#123;            pre.right = cur;            cur = cur.left;        &#125; else &#123;            // 新增code开始            if(preNode != null &amp;&amp; cur.val &lt; preNode.val)&#123;                b = cur;                if(a == null) a = preNode;            &#125;            preNode = cur;            // 新增code结束            pre.right = null;            cur = cur.right;        &#125;    &#125;    change(a, b);&#125;// 交换两个元素public void change(TreeNode pre,TreeNode cur)&#123;    int temp = pre.val;    pre.val = cur.val;    cur.val = temp;&#125;\n\n\n\n\n\n\n\n\n\n","categories":["算法"],"tags":["Java","算法"]},{"title":"二分查找","url":"/2024/04/10/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E6%A8%A1%E6%9D%BF/","content":"\n引言： 二分查找模板\n\n\n\n\n两个二分查找模板二分查找是比较重要的一个算法思想，这里使用两个二分法的模板来解释二分查找的细节问题。\n目标：对于数组nums，要找到target的下标位置\n模板一：边界外\n看这个更清楚\n\n二分模板如下：\n// 1、初始条件需要卡在0和nums.length-1之外int l = -1;int r = nums.length;whle(l + 1 != r)&#123; // 2、循环条件    int m = (l + r) / 2;    if(condition) l = m; // 3-1、设置值别 l = m - 1 ，这样容易弄错    else r = m; // 3-2、设置值别 l = m - 1 ，这样容易弄错&#125;return r or l; // 4、按照条件与题意选择 l或是r返回\n\n\n问题1：为什么边界条件要设置在数组的外边？\n\n因为如果整个数组都&lt;或&gt;预期值target，我们的l与r边界就会出现问题\n\n问题2：循环条件为什么是 l + 1 != r，我用l &lt; r不行吗？\n\n假设有三种情况：\n... L R ... // 情况1：: L + 1 == R 成立，不会进入循环... L X R ... // 情况2： L + 2 == R，进入循环，他的下一步就是情况1... L X X R ... // 情况3：可以归类到情况2...\n\n如果我们的循环条件是l &lt; r，对于情况1会进入循环，这是两种条件的区别。\n现在我们求这道题：对于数组nums，要找到target的下标位置\n由此我们可以快速的得出：\nint l = -1;int r = nums.length;for(;l+1 != r;)&#123;    int m = (l + r) / 2;    if(nums[m] &lt; target) l = m;    else r = m;&#125;return r;\n\n此处我们的条件是nums[m] &lt; target，我们的结果就会变成：\n....lr....\n\nl及其左边都是&lt;target的数值；r及其右边都是&gt;= target的数值，因此我们要求target的位置就应该选择返回r\n同理，如果你的条件是&lt;= target，那么就应该返回l\n在思考到底要返回l还是r时，我们可以脑海构建一个 类似...lr...的图，结合条件，就可以立马反应我们该返回哪一个值了。\nExec：\n35. 搜索插入位置\n74. 搜索二维矩阵\n34. 在排序数组中查找元素的第一个和最后一个位置\n模板二：边界上适合解决旋转有序数组的问题。\n// 1、初始条件卡在边界int l = 0;int h = nums.length - 1;for (; l &lt;= h;) &#123; // 2、循环条件就是 l &lt;= r    int mid = (h + l) / 2; // 3、找中间值    if (nums[mid] == target) return mid; // 4、找到值就返回    if (nums[mid] &lt; target) l = mid + 1;    else h = mid - 1;&#125;return l;\n\nExec：\n35. 搜索插入位置\n33. 搜索旋转排序数组\n153. 寻找旋转排序数组中的最小值\n","categories":["算法"],"tags":["Java","算法"]},{"title":"冒泡排序","url":"/2020/07/09/%E7%AE%97%E6%B3%95/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/","content":"\n    冒泡排序及其优化\n\n\n\n\n冒泡排序\nbubble sort 经典的排序算法以及冒泡排序的优化\n\n经典的冒泡排序两次循环遍历所有的数字，相邻进行交换。是一种稳定的算法，算法的时间复杂度为O(n^2)\n优化\n第一次优化第一次优化：优化有序数列排序\n对于有序数列，经典的冒泡排序发现不了已经是有序数列，还是会傻傻的一轮一轮进行比较，会浪费很多时间和资源\n第二次优化第二次优化：优化部分有序数列排序\n对于部分有序数列，我们可以记录它最后一次交换的位置，从这个位置到数列的末尾，这个区间都是有序的\nimport java.util.Arrays;/** * @Date 2020/7/12 10:17 * 冒泡排序： * 经典的冒泡排序以及冒泡排序的三种优化 */public class BubbleSort &#123;    /**     * 经典的冒泡排序     * @param arr     */    private static void sort1(int[] arr) &#123;        int  cycle = 0 ,swap = 0;        //记录排序次数        for (int i = 0; i &lt; arr.length - 1; i++) &#123;            for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123;                int temp;                if(arr[j] &gt; arr[j+1])&#123;                    temp = arr[j];                    arr[j] = arr[j+1];                    arr[j+1] = temp;                    swap++;                &#125;                cycle ++;            &#125;        &#125;        System.out.println( &quot;循环：&quot;+cycle + &quot;,交换：&quot; +swap);    &#125;    /**     * 加了判断优化的冒泡排序     * @param arr     */    private static void sort2(int[] arr)&#123;        //对于已经排序好的数组，经典的冒泡排序还是要从头开始，遍历n次，这样很慢        int  cycle = 0,swap = 0;        boolean isSorted;        for (int i = 0; i &lt; arr.length - 1; i++) &#123;            isSorted = true;            //每次重置为true            for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123;                int temp;                if(arr[j] &gt; arr[j+1])&#123;                    //如果进入这个分支，证明不是有序的队列                    isSorted = false;                    temp = arr[j];                    arr[j] = arr[j+1];                    arr[j+1] = temp;                    swap++;                &#125;                cycle ++;            &#125;            //如果已经是排序好的数组，立马退出循环            if(isSorted)&#123;                break;            &#125;        &#125;        System.out.println( &quot;循环：&quot;+cycle + &quot;,交换：&quot; +swap);    &#125;    /**     * 对于[3,2,1,4,5,6,7,8]这样的数组，我们会发现，前半部分是无序的，后半部分是有序的     * 会有很多无意义的判断     * 我们需要对 数列有序区 进行判断：     *    记录最后一次元素交换的位置，这个位置就是有序数列的边界，从这到数组末尾，都是有序的     * @param arr     */    private static void sort3(int[] arr)&#123;        int  cycle = 0 , swap = 0;        int lastEchangeIndex = 0;        // 记录最后一次交换位置的下标        boolean isSorted;        int sortBorder = arr.length - 1;        //排序的边界        for (int i = 0; i &lt; arr.length - 1; i++) &#123;            isSorted = true;            //每次重置为true            for (int j = 0; j &lt; sortBorder; j++) &#123;                int temp;                if(arr[j] &gt; arr[j+1])&#123;                    //如果进入这个分支，证明不是有序的队列                    isSorted = false;                    temp = arr[j];                    arr[j] = arr[j+1];                    arr[j+1] = temp;                    //记录最后一次排序位置                    lastEchangeIndex = j;                    swap++;                &#125;                cycle ++;            &#125;            sortBorder = lastEchangeIndex;            //如果已经是排序好的数组，立马退出循环            if(isSorted)&#123;                break;            &#125;        &#125;        System.out.println( &quot;循环：&quot;+cycle + &quot;,交换：&quot; +swap);    &#125;    public static void main(String[] args) &#123;        // 给出四种数组情况 ： 无序、有序、逆序、部分有序        System.out.println(&quot;------无序数组三种排序对比-------&quot;);        arr1 = new int[]&#123;5, 8, 6, 3, 9, 2, 1, 7&#125;;        sort1(arr1);        arr1 = new int[]&#123;5, 8, 6, 3, 9, 2, 1, 7&#125;;        sort2(arr1);        arr1 = new int[]&#123;5, 8, 6, 3, 9, 2, 1, 7&#125;;        sort3(arr1);        System.out.println(&quot;------有序数组三种排序对比-------&quot;);        arr2 = new int[]&#123;1,2,3,4,5,6,7,8&#125;;        sort1(arr2);        arr2 = new int[]&#123;1,2,3,4,5,6,7,8&#125;;        sort2(arr2);        arr2 = new int[]&#123;1,2,3,4,5,6,7,8&#125;;        sort3(arr2);        System.out.println(&quot;------逆序数组三种排序对比-------&quot;);        arr3 = new int[]&#123;9,8,7,6,5,4,3,2&#125;;        sort1(arr3);        arr3 = new int[]&#123;9,8,7,6,5,4,3,2&#125;;        sort2(arr3);        arr3 = new int[]&#123;9,8,7,6,5,4,3,2&#125;;        sort3(arr3);        System.out.println(&quot;------部分有序数组三种排序对比-------&quot;);        arr4 = new int[]&#123;3,2,1,4,5,6,7,8&#125;;        sort1(arr4);        arr4 = new int[]&#123;3,2,1,4,5,6,7,8&#125;;        sort2(arr4);        arr4 = new int[]&#123;3,2,1,4,5,6,7,8&#125;;        sort3(arr4);    &#125;&#125;\n\n运行结果：\n\n","categories":["算法"],"tags":["Java","算法"]},{"title":"最大公约数","url":"/2020/07/10/%E7%AE%97%E6%B3%95/%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0/","content":"\n引言： \n\n求两个数的最大公约数\n\n\n\n\n最大公约数经典的问题，这里我们直接给出三种算法\n\n辗转相除法（欧几里得算法）：两个正整数a和b(a&gt;b)，他们的最大公约数等于 a 除以 b 的余数 c 和 b（小的那个数） 之间的最大公约数。递归出口是（a%b==0）\n\n\n 更相减损术：两个正整数a和b(a&gt;b)，他们的最大公约数等于a-b的插值c和较小数b的最大公约数。递归出口是(a == b)\n\n\n综合方法：\n\n如果a,b均为偶数  gcd(a,b) = 2*gcd(a/2,b/2) = gcd(a&gt;&gt;1,b&gt;&gt;1)&lt;&lt;1\n如果a,b一个奇数一个偶数 gcd(a,b) = gcd(偶数/2,奇数) = gcd(偶数&gt;&gt;1, 奇数)\n如果a,b均为奇数 (a&gt;b) gcd(a,b) = gcd(a-b,b) 此时 a-b 为偶数\n\n递归出口是（a==b）\n\n思考如图：\n\n/** * @author 董文浩 * @Date 2020/7/10 19:57 * 求两个数的最大公约数 */public class GreatestCommonDivisor &#123;    /**     * 求一个数的最大公约数，是很经典的问题了     * 我们主要列出以下几种方法：     * 1. 辗转相除法（欧几里得算法）     * 2. 更相减损术     * 3. 融合两种方法特点的最佳方法     */    /**     * 欧几里得算法：两个正整数a和b(a&gt;b)，他们的最大公约数等于 a 除以 b 的余数 c 和 b（小的那个数） 之间的最大公约数     */    public static int euclidean(int a, int b)&#123;        int bigger = a &gt; b ? a : b;        int smaller = a &gt; b ? b : a;        if(bigger % smaller == 0)&#123;            return smaller;        &#125;        return euclidean( bigger%smaller ,smaller);    &#125;    /**     * 更相减损术：两个正整数a和b(a&gt;b)，他们的最大公约数等于a-b的插值c和较小数b的最大公约数     */    public static int morePhaseLoss(int a , int b)&#123;        if(a == b)&#123;            return a;        &#125;        int smaller = a &gt; b ? b : a;        int bigger = a &gt; b ? a : b;        return morePhaseLoss(bigger - smaller , smaller);    &#125;    /**     * 综合方法：     *          1. 如果a,b均为偶数  gcd(a,b) = 2*gcd(a/2,b/2) = gcd(a&gt;&gt;1,b&gt;&gt;1)&lt;&lt;1     *          2. 如果a,b一个奇数一个偶数 gcd(a,b) = gcd(偶数/2,奇数) = gcd(偶数&gt;&gt;1, 奇数)     *          3. 如果a,b均为奇数 (a&gt;b) gcd(a,b) = gcd(a-b,b) 此时 a-b 为偶数     */    public static int gcd(int a , int b)&#123;        if( a==b)&#123;            return a;        &#125;        if((a&amp;1)==0 &amp;&amp; (b&amp;1) == 0)&#123;            //全是偶数            return gcd(a&gt;&gt;1,b&gt;&gt;1)&lt;&lt;1;        &#125;else if((a&amp;1)!=0 &amp;&amp; (b&amp;1) == 0)&#123;            //a为奇数，b为偶数            return gcd(a,b&gt;&gt;1);        &#125;else if((a&amp;1)==0 &amp;&amp; (b&amp;1) != 0)&#123;            //a为偶数，b为奇数            return gcd(a&gt;&gt;1,b);        &#125;else &#123;            int smaller = a &gt; b ? b : a;            int bigger = a &gt; b ? a : b;            return gcd(bigger-smaller,smaller);        &#125;    &#125;    public static void main(String[] args) &#123;        // 辗转相除法测试        System.out.println(euclidean(25,10));        System.out.println(euclidean(100,80));        System.out.println(euclidean(27,14));        // 更相减速术测试        System.out.println(morePhaseLoss(25,10));        System.out.println(morePhaseLoss(100,80));        System.out.println(morePhaseLoss(27,14));        // 综合方法        System.out.println(gcd(25,10));        System.out.println(gcd(100,80));        System.out.println(gcd(27,14));        //输出均为 5 、20 、 1    &#125;&#125;\n\n快速判断是奇数还是偶数，与1（&amp;1）\n例如\t7 -&gt; 二进制\n\n","categories":["算法"],"tags":["Java","算法"]},{"title":"快速排序","url":"/2020/07/14/%E7%AE%97%E6%B3%95/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","content":"\n引言： \n\n速记快速排序\n\n\n\n快速排序优雅的快速排序更新后的快排，发现之前的快排存在点问题，而且不利于记忆（常见的算法应该很快就能写出来）\npublic int[] sortArray(int[] nums) &#123;    sort(nums, 0, nums.length - 1);    // 直接传入0和最后一个索引即可    return nums;&#125;\n\n快排code：\npublic void sort(int[] nums, int i, int j) &#123;    if (i &gt;= j) return;    int left = i - 1;    int right = j + 1;    int pivot = nums[(i + j + 1) / 2];    for (; left &lt; right; ) &#123;        for (; nums[--right] &gt; pivot;);        for (; nums[++left] &lt; pivot;);        if(left &lt; right)&#123;            int temp = nums[left];            nums[left] = nums[right];            nums[right] = temp;        &#125;    &#125;    // 下面这个部分，选择边界要注意：看下文    sort(nums, i, left - 1);    sort(nums, left, j);&#125;\n\n我们知道，快排的pivot选择，一般有三种选法，第一个数字、最后一个数字、中间任意一个数字\n上面的代码就选择了中间任意一个数字，如果要选择第一个数字或是最后一个数字，那么他们有如下对应规则：\n注意边界问题：pivot选择要注意，其实选择left和right都可以，但是要和初始值对应\n\npivot选择nums[j]：可以选(i, left-1) (left , j)区间\npivot选择nums[i]：可以选(i, right), (right + 1, j) 区间\n\n","categories":["算法"],"tags":["Java","算法"]},{"title":"出现超过数组一半的数","url":"/2020/08/16/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87Offer39%EF%BC%9A%E6%95%B0%E7%BB%84%E4%B8%AD%E5%87%BA%E7%8E%B0%E6%AC%A1%E6%95%B0%E8%B6%85%E8%BF%87%E4%B8%80%E5%8D%8A%E7%9A%84%E6%95%B0%E5%AD%97/","content":"\n引言： \n\n摩尔投票法\n\n\n\n\n\n剑指Offer39：数组中出现次数超过一半的数字\n题意：\n数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。\n你可以假设数组是非空的，并且给定的数组总是存在多数元素。\n示例 1:\n输入: [1, 2, 3, 2, 2, 2, 5, 4, 2]输出: 2\n\n解法1：HashMap很容易想到HashMap很容易来解决这种问题，只需要出现一次+1即可\n// 法一：憨憨HashMap法 可以是肯定可以，就是慢 public static int majorityElement1(int[] nums) &#123;     HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();     int x = nums[0];     int turn = 1;     for (int num : nums) &#123;         if(map.get(num)==null)&#123;             map.put(num,1);         &#125;else &#123;             Integer a = map.get(num);             map.put(num,++a);             if(a &gt; turn)&#123;                 x = num;                 turn = a;             &#125;         &#125;     &#125;     return x; &#125;\n\n\n\n解法2：摩尔投票法这个方法也是为了写这篇blog的原因。\n可以结合官网的解析LeetCode\n\n摩尔投票法：\n记投票数： 众数会 +1，非众数会 -1\n\n最开始，我们记第一个数字就是众数。\n\n遍历数组，如果投票数为0，则说明之前数中，众数与非众数个数相同，所以在剩下的数字中，众数依然没有变化\n\n投票数为0后，记紧接着的下一个数就是众数\n\n遍历到最后，我们只需要返回最后一个使投票数+1的数即可。\n\n\n\n\n// 法二：摩尔投票法！！！public static int majorityElement2(int[] nums) &#123;     // 初始化投票数和众数    int votes = 0;    int res = nums[0];    // 开始遍历数组    for (int num : nums) &#123;        if(votes==0) &#123;            // 如果票数为0，就记紧挨着的数字为众数            res= num;        &#125;        // 众数就+1 非众数就-1        votes += res==num ? 1: -1;    &#125;    return res;&#125;\n如果题目没有明确说明这个数组内必然有众数，我们可以在求出最后的结果，再遍历一遍数组，记录该结果出现的次数，如果超过数组的一半就是众数。\n复杂度分析空间复杂度：O(1)，只使用了一个votes来记录投票个数\n时间复杂度：O(N)，遍历一遍数组，需要O(n)的时间\n","categories":["算法"],"tags":["Java","算法"]},{"title":"最小栈问题","url":"/2020/07/10/%E7%AE%97%E6%B3%95/%E6%9C%80%E5%B0%8F%E6%A0%88%E9%97%AE%E9%A2%98/","content":"\n引言： \n\n实现一个栈，带有出栈、入栈、取最小值三个方法，并要求这三个方法的时间复杂度都为O(1)\n\n\n\n\n最小栈问题\n实现一个栈，带有出栈、入栈、取最小值三个方法，并要求这三个方法的时间复杂度都为O(1)\n\n出栈入栈都可以用O(1)实现，最重要的是实现取最小值，最小值我们必须存起来，存在另一个栈中。\n如下图，先入栈4、9、7、3、8、5\n再出栈三次\n\nimport java.util.Stack;/** * @author 董文浩 * @Date 2020/7/9 21:23 * 最小栈问题： * 实现一个栈，带有出栈、入栈、取最小值三个方法，并要求这三个方法的时间复杂度都为O(1) */public class MinimumStack &#123;    /**     * 主栈mainStack，完成正常的栈的使用     */    private Stack&lt;Integer&gt; mainStack = new Stack();    /**     * 副栈minStack，存储最小的数     */    private Stack&lt;Integer&gt; minStack = new Stack();    /**     * 入栈     *     * @return     */    public void push(int e) &#123;        //如果最小栈为空，或者存入的数值小，那么就将它存入        if (minStack.isEmpty() || e &lt;= minStack.peek()) &#123;            minStack.push(e);        &#125;        mainStack.push(e);    &#125;    /**     * 出栈     *     * @return     */    public int pop() &#123;        //如果出栈的是最小栈内的，就让它也出栈        if (mainStack.peek().equals(minStack.peek())) &#123;            minStack.pop();        &#125;        return mainStack.pop();    &#125;    public int getMin()&#123;        return minStack.peek();    &#125;    public static void main(String[] args) &#123;        MinimumStack stack = new MinimumStack();        stack.push(4);        stack.push(9);        stack.push(7);        stack.push(3);        stack.push(8);        stack.push(5);        System.out.println(stack.getMin()); //输出 3        stack.pop();        stack.pop();        stack.pop();        System.out.println(stack.getMin());// 输出 4    &#125;&#125;\n\n","categories":["算法"],"tags":["Java","数据结构","栈","算法"]},{"title":"链表环问题","url":"/2020/07/09/%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8%E7%8E%AF%E9%97%AE%E9%A2%98/","content":"\n    解决一个链表是否有环的问题\n\n\n\n\n\n链表环问题需求\n问题一：如何判断一个链表是否有环\n问题二：求环的长度\n问题三：求入环节点\n\n分析如下：\n实现如下public class Main &#123;    private static class Node&#123;        int data;        Node next;        Node(int data)&#123;            this.data = data;        &#125;    &#125;    /**     * 双指针判断是否有环     * @param node     * @return     */    private static boolean isCycle1(Node node) &#123;        Node p1 = node;        Node p2 = node;        while (p2!=null &amp;&amp; p2.next!=null)&#123;            p1 = p1.next;            p2 = p2.next.next;            // 利用追及问题的思想，如果有环，那么速度快的节点一定会超越速度慢的节点            if(p1 == p2)&#123;                //相遇在这一点，即可证明有环                return true;            &#125;        &#125;        return false;    &#125;    /**     * 求是否有环，并且求出长度     * @param node     * @return     */    private static boolean isCycle2(Node node) &#123;        Node p1 = node;        Node p2 = node;        while (p2!=null &amp;&amp; p2.next!=null)&#123;            p1 = p1.next;            p2 = p2.next.next;            if(p1 == p2)&#123;                //有环，由于p2速度是p1的两倍，所以 环长 = (速度差)*前进次数 = 前进次数                int count = 0;                while ( count==0 || p1 != p2)&#123;                    p1 = p1.next;                    p2 = p2.next.next;                    count++;                &#125;                System.out.println(&quot;环长度为：&quot;+count);                return true;            &#125;        &#125;        return false;    &#125;    /**     * 求是否有环、以及入环点     * @param node     * @return     */    private static boolean isCycle3(Node node) &#123;        Node head = node;        Node p1 = node;        Node p2 = node;        while (p2!=null &amp;&amp; p2.next!=null)&#123;            p1 = p1.next;            p2 = p2.next.next;            if(p1 == p2)&#123;                p1 = head;                int count = 0;                while (count==0 || p1!=p2)&#123;                    p1 = p1.next;                    p2 = p2.next;                    count++;                &#125;                System.out.println(&quot;入环点在&quot;+p1.data);                System.out.println(&quot;头到入环点的距离有&quot;+count+1);                return true;            &#125;        &#125;        return false;    &#125;        /**           8 &lt;- 2     *            ↓    ↑     *  3 -&gt; 9 -&gt; 6 -&gt; 7     * @param args     */    public static void main(String[] args) &#123;        Node node1 = new Node(3);        Node node2 = new Node(9);        Node node3 = new Node(6);        Node node4 = new Node(7);        Node node5 = new Node(2);        Node node6 = new Node(8);        node1.next = node2;        node2.next = node3;        node3.next = node4;        node4.next = node5;        node5.next = node6;        node6.next = node3;        System.out.println(isCycle3(node1));    &#125;&#125;\n\n在LeetCode也刷到了这个题，发现算法逻辑有点问题，具体看代码\n/** * Definition for singly-linked list. * class ListNode &#123; *     int val; *     ListNode next; *     ListNode(int x) &#123; *         val = x; *         next = null; *     &#125; * &#125; */public class Solution &#123;    public ListNode detectCycle(ListNode head) &#123;        // 这里防止Head发来null或者只有一个结点的情况        if(head==null||head.next==null)&#123;            return null;        &#125;        ListNode fast = head;        ListNode slow = head;        boolean isCycle = false;        while(fast!=null &amp;&amp; slow!=null)&#123;            slow = slow.next;            if(fast.next==null)&#123;                // 进入循环前只判断了fast是否为空，在这里判断fast.next，以防使用fast.next.next报错， 如果fast.next为空则说明肯定没有环                return null;            &#125;            fast = fast.next.next;            if(fast == slow)&#123;                // 相遇                isCycle = true;                slow = head;                while(fast!=slow)&#123;                    slow = slow.next;                    fast = fast.next;                &#125;                break;            &#125;        &#125;        if(!isCycle)&#123;            // 无环返回null值            return null;        &#125;else&#123;            return slow;        &#125;    &#125;&#125;\n\n","categories":["算法"],"tags":["Java","数据结构","算法","链表"]},{"title":"单精度与双精度浮点数与十进制 之间的转换","url":"/2020/08/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/%E6%A0%B9%E6%8D%AEIEEE-754%E6%A0%87%E5%87%86%EF%BC%9A%E5%8D%95%E7%B2%BE%E5%BA%A6%E4%B8%8E%E5%8F%8C%E7%B2%BE%E5%BA%A6%E6%B5%AE%E7%82%B9%E6%95%B0%E4%B8%8E%E5%8D%81%E8%BF%9B%E5%88%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/","content":"\n引言： \n\n根据IEEE 754标准：单精度与双精度浮点数 与  十进制 之间的转换\n\n\n\n\n根据IEEE 754标准：单精度与双精度浮点数 与  十进制 之间的转换单精度与双精度\n根据IEEE 754 标准，单双精度有如下区别：\n\n单精度：符号(1 bit) + 阶码(8 bit) + 尾数(23 bit)   ； 偏置常量 = 127  非规格化为 126\n双精度：符号(1 bit) + 阶码(11 bit) + 尾数(52 bit) ； 偏置常量 = 1023 非规格化为 1022\n\n单精度转换为十进制数例1：0x FF80 0000 转换为 十进制ff80 0000 转换为二进制1111 1111 1000 0000 0000 0000 0000 0000其中分别为符号位、阶码、还有尾数1  | 111  1111 1 | 000 0000 0000 0000 0000 0000由此可以看出，这个数是负数，阶码全1，尾数全0所以这个数比较特殊，答案是：负无穷\n\n无穷大（尾数全0，阶码全1，根据符号位又区分出无穷大和无穷小）\n例2：0x 7FE0 0000 转换为 十进制7fe0 0000转换为二进制0111 1111 1110 0000 0000 0000 0000 0000分开0 | 111 1111 1 | 110 0000 0000 0000 0000 0000这是一个正数，而且阶码全1 ， 尾数非0这又是一种特殊情况，非数\n\n非数 NaN（阶码全1 ， 尾数非0）\n例3： 0x C1C9 0000 转换为十进制C1C9 0000转换为二进制1100 0001 1100 1001 0000 0000 0000 0000分开1 | 100 0001 1 | 100 1001 0000 0000 0000 0000发现这个数是一个负数，阶码与尾数都没有什么特殊点由于是单精度浮点型，所以将阶码减去127\t1000 0011-    0111 1111——————————————————得   0000 0100  为 4在看尾数，转换为小数为1 + 2^-1 + 2^-4 + 2^-7 （由于是规格化非0数，1是隐含的）= 1.5703125此时将 2^4 * 1.5703125 = 25.125在看符号位，所以最后的结果为-25.125\n\n\n\n双精度转换为十进制例1: 0x 8008 0000 0000 0000 转换为十进制同样的道理 ，转换1000 0000 0000 1000 0000 ... 0000分开，注意双进度阶码有11位1 | 000 0000 0000 | 1000 0000 ... 0000阶码全0，尾数非0，所以这是一个 非规格化非0数（所以不能减1023，要减去1022）所以结果为 -0.5 * 2^-1022 （由于是非规格化，所以是隐含是0，而不是1）\n\n例2: 0x 7065 0200 0000 0000 转换为十进制7065 0200 0000 0000 转换为二进制0111 0000 0110 0101 0000 0010 0000 ... 0000分开0 | 111 0000 0110 | 0101 0000 0010 0000 ... 0000可以看出是一个正数，而且阶码和尾数都没有什么特殊点，为规格化非0数\t111 0000 0110- \t011 1111 1111 （1023）——————————————————\t011 0000 0111 （775）尾数化为小数 1 + 2^-2 + 2^-4 + 2^-11 = 1.31298828125结果为 1.31298828125 * 2^775\n\n\n\n\n十进制转换为单精度例1: 0 转换为单精度在IEEE 754 标准中尾数全0 阶码全0 代表0根据符号不同，有+0和-0的区别\n\n\n\n例2: 116.25转换为单精度116.25 我们先来想，2的幂次中，小于116而且最近的一个数字128太大，只能为6464 为 2^6 所以阶码为 6 + 127 转换为二进制 1000 0101现在用 116.25 / 64 = 1.81640625 其中1隐含掉，求0.81640625的二进制0.11010001所以结果的二进制码为0 | 100 0010 1 | 110 1000 1000 ... 0000也就是0100 0010 1110 1000 1000 0000 ... 0000所以化为16进制为0x 42E8 0000\n\n\n\n例3： -4.375 转化为单精度同理，寻找与4最近的，即2^2，所以阶码就是2+127 为 1000 0001再用4.375 / 4 = 1.09375用二进制表示0.09375 为 0.00011所以结果为1 | 100 0000 1 | 000 1100 0000 ... 0000即1100 0000 1000 1100 0000 ... 0000转换为16进制C08C 0000\n\n\n\n十进制转换为双精度例1：116.25 转换为双精度同理，寻找到64 也就是66+1023 转换为二进制 100 0000 0101 ，这就是阶码现在用 116.25 / 64 = 1.81640625 转换为二进制 0.11010001所以结果为0 | 100 0000 0101 | 1101 0001 0000... 0000结果就是405D 1000 0000 ... 0000\n\n例2：-2049.5转换为双精度寻找一个距离2049最近的，也就是2048，即2的11次方11 + 1023 转换为二进制100 0000 10102049.5 / 2048 = 1.000732421875尾数转换为二进制0.000000000011所以结果为1 | 100 0000 1010 | 0000 0000 0011 0000 ... 0000转换为16进制C0A0 0030 0000 0000 ... 0000\n\n\n\n总结\n注意是否为非数（NaN）或者是无穷大\n\n非数：阶码全1 尾数非0\n\n无穷大：阶码全1 尾数全0\n\n\n\n注意是否是规格化非0数\n\n规格化非0数（阶码非全1非全0），此时隐藏的尾数为1，偏置常量为127或是1023\n非规格化非0数（阶码全0，尾数非0），此时隐藏的尾数为0，偏置常量为126或是1022\n\n\n\n以上就是全部啦\n:wq\n","categories":["计算机体系结构"],"tags":["计算机体系结构","IEEE754"]},{"title":"CDN内容分发网络","url":"/2023/07/19/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/CDN/","content":"\n引言：CDN不是一个单独的应用层协议，而是一种基于网络架构和技术的内容分发解决方案\n\n\n\n\nCDNCDN本质\nCDN（Content Delivery Networks，或CDNs）内容分发网络：本质是一个网络层面的分布式缓存架构\n\n目的：在全球范围内部署分布式缓存节点，将内容存储在离用户更近的位置，从而减少传输延迟，提高内容的访问速度和性能\n\n问题1：所谓的内容分发，其中的“内容”具体指网页的什么内容？\n\n一个网页通常有：\n\n静态数据：HTML、CSS、JavaScript、图像、字体、文件、视频和流媒体\n动态数据：用户的个人数据、视频的点赞量、收藏量\n\n静态数据通常不会发生变化，CDN可以将这些数据缓存起来，当用户访问时就无需将请求发送到源服务器，加快响应速度。\n（注意：CDN并不是只能缓存静态数据，有些情况下也缓存了动态数据）\nCDN内容分发的流程CDN的网络布局有三种角色构成：客户端、服务器、CDN服务器\n如图所示：\n\n假设现在有客户端A、B：\n\n服务器会将静态资源主动push到CDN服务器\n客户端A发送请求\nCDN缓存命中，直接响应\n客户端B发送请求\nCDN缓存未命中，执行pull操作，请求源服务器\n关于未命中的原因有很多，需要根据具体的缓存策略来考虑\n\n\n响应给客户端的同时缓存在本地CDN缓存中\n\n\n问题2：为什么会出现缓存未命中呢？CDN如何判断资源是否过期？\n\n缓存未命中的原因有很多：比如资源过期、或是其中含有动态数据\n判断资源过期由不同的缓存策略决定：\n\n时间戳过期：根据文件的时间戳判断是否过期，当时间戳发生变化时，CDN服务器会重新请求最新的内容。\nHTTP头部控制：通过HTTP头部中的Cache-Control、Expires等字段来控制缓存过期时间。\n内容分片：将内容分成多个小块进行缓存，可以更灵活地更新和替换内容。（比如HLS（HTTP Live Streaming）将视频和音频源文件编码并切割成小的.ts分段）\n\n\n问题3：CDN与Nginx的关系\n\nCDN服务器的具体实现和使用的软件可以有多种选择，其中Nginx是一个常见且广泛应用于CDN架构中的服务器软件之一\nNginx是一个web服务器软件，提供高性能的静态资源服务、反向代理等功能，他与Java服务端软件Tomcat经常配合使用，可以将Nginx作为反向代理服务器，将静态资源交给Nginx处理，动态请求转发给Tomcat。这种结合使用的方式可以充分利用Nginx的高性能和Tomcat的动态内容处理能力\nCDN内容分发的原理：任播\n任播（Anycast）是一种网络技术，并不是某个特定的应用或协议。\n用户无论位于世界的哪个地方，都可以通过最近的缓存节点获取内容，减少了数据传输的延迟和网络拥塞，任播广泛应用于负载均衡、内容分发网络（CDN）、域名系统（DNS）等\n\n任播的主要特点是它不依赖于特定的源节点和目标节点之间的一对一连接，而是将数据包传输到最近的可用节点，使得数据能够快速到达用户或目标地点。\nCDN使用任播来实现内容的分发和路由\n\n问题4：任播如何判断距离远近？\n\n任播的实现依赖于网络路由协议和底层网络设备的支持：\n\n\nIP地址共享：在任播中规定，多个不同位置的节点共享同一个IP地址。\n这意味着在网络中的不同位置都存在具有相同IP地址的节点。当有数据包发送到该IP地址时，路由器会根据一定的规则选择距离最近的节点来处理数据包。\n\n\n路由选择：路由器在选择处理数据包的节点时，会根据网络拓扑和距离等因素进行选择。它可能使用基于距离向量的路由协议（如RIP、BGP）或链路状态协议（如OSPF）来获取网络拓扑信息并做出路由决策。\n\n\n问题5：任播与组播的区别\n\n\n工作方式：\n组播：数据包从一个发送者传输给一组IP地址（多个节点，不同IP）\n任播：数据包从一个发送者传输给一个IP地址（多个节点，相同IP）\n\n\n数据包：\n组播：只需被发送一次，但可以被多个接收者共享\n任播：一个数据包被发送到多个服务器，但只有最近的服务器会处理该数据包\n\n\n应用场景：\n组播：实时视频、在线会议\n任播：负载均衡、CDN\n\n\n\n补充：HTTP头部关于缓存的字段Cache-Control是HTTP/1.1引入的缓存控制机制，而Expires与Last-Modified是HTTP/1.0中的一种旧有的缓存机制，在HTTP/1.1中被Cache-Control所取代，但由于向下兼容的原因，依然保留这两个字段：\n\nCache-Control字段：\nCache-Control是一个通用的头部字段，用于控制缓存行为。它可以包含多个指令，指定缓存的行为方式。\n常见的Cache-Control指令包括：\npublic：响应可以被任何缓存（包括公共缓存）缓存。\nprivate：响应只能被单个用户缓存，不可被共享缓存存储。\nno-cache：需要进行重新验证，缓存必须向服务器发送请求进行确认。\nmax-age=&lt;seconds&gt;：指定响应的有效时间，单位为秒。\n\n\nCache-Control的值可以是单个指令，也可以是多个指令通过逗号分隔。例如：Cache-Control: max-age=3600, private\n\n\nExpires字段：\nExpires是一个HTTP响应头部字段，用于指定响应的过期时间。\n它的值是一个GMT（格林尼治标准时间）格式的日期时间字符串，指定了响应在该日期时间之后将被认为是过期的。\n如果Expires字段的日期时间已经过去，那么客户端会发送一个新的请求来获取最新的内容，而不是使用缓存中的过期内容。\n注意，Expires字段的缺点是它使用的是服务器的时间，而客户端和服务器的时间可能不完全同步。\n\n\nLast-Modified字段：\nLast-Modified是一个表示资源最后修改时间的头部字段，由服务器在响应中返回。\n客户端可以通过发送If-Modified-Since头部字段，携带先前获取的Last-Modified值，来验证资源是否发生了修改。\n\n\n\n","categories":["计算机网络"],"tags":["计算机网络","CDN"]},{"title":"鸡尾酒排序","url":"/2020/07/13/%E7%AE%97%E6%B3%95/%E9%B8%A1%E5%B0%BE%E9%85%92%E6%8E%92%E5%BA%8F/","content":"\n引言： \n\n什么是鸡尾酒排序？\n\n\n\n\n鸡尾酒排序\n鸡尾酒排序：也是对冒泡排序的一种优化，例如对于这样的数组2,3,4,5,6,7,1,8\n如果使用普通的冒泡排序，需要七轮才能将1排到第一\n而鸡尾酒排序，解决了这样的问题\n\n通过：奇数轮正向遍历，偶数轮逆向遍历 ，这样第二轮就可以将1排到左边了\nimport java.util.Arrays;/** * @author 董文浩 * @Date 2020/7/12 14:13 * 鸡尾酒排序 */public class Cocktail &#123;    /**     * 所谓鸡尾酒排序，就是一种对于冒泡排序的优化     * 对于这样的数组[2,3,4,5,6,7,1,8]     * 我们发现只有1的位置顺序不对，但是却要进行死板的排序，七轮才能将1排到第一位     * 所以我们改进一下排序方法     */    public static void sort(int[] arr) &#123;        int change = 0 , cycle = 0;        int temp ;        for (int i = 0; i &lt; arr.length / 2; i++) &#123;            boolean isSorted = true;            for (int j = i; j &lt; arr.length - i - 1; j++) &#123;                if (arr[j] &gt; arr[j + 1]) &#123;                    temp = arr[j];                    arr[j] = arr[j + 1];                    arr[j + 1] = temp;                    isSorted = false;                    change++;                &#125;                cycle++;            &#125;            if (isSorted) &#123;                break;            &#125;            isSorted = true;            //重置一下排序标志            for (int j = arr.length - i - 1; j &gt; i ; j--) &#123;                if (arr[j] &lt; arr[j - 1]) &#123;                    temp = arr[j];                    arr[j] = arr[j - 1];                    arr[j - 1] = temp;                    isSorted = false;                    change++;                &#125;                cycle++;            &#125;            if (isSorted) &#123;                break;            &#125;        &#125;        System.out.println(&quot;循环：&quot;+cycle + &quot;，交换：&quot;+change);    &#125;    public static void main(String[] args) &#123;        int[] arr = new int[]&#123;2, 3, 4, 5, 6, 7, 1, 8&#125;;        sort(arr);        System.out.println(Arrays.toString(arr));    &#125;&#125;\n\n优点：\n​    对于类似示例的数组，排序很方便，很快速\n缺点：\n​    代码量翻倍\n","categories":["算法"],"tags":["Java","算法"]},{"title":"DNS解析过程","url":"/2021/08/21/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/DNS/","content":"\n引言：DNS解析过程；更新：补充了DNS的一个搜索环节\n\n\n\n\n\n\n\n\n\nDNS解析过程前置概念\n1、 什么是DNS？\n\nDNS，全称为Domain Name Server，作用就是将域名解析为IP地址\nDNS依赖的传输层是UDP协议，无需建立连接，十分快速。\n默认端口号为53\n\n2、域名的组成\n\n比如：www.yesmylord.cn\n\nwww是三级域名，像本网站的图片域名就是img.yesmylord.cn\nyesmylord是二级域名，在域名网站购买的多是二级域名\ncn是顶级域名，代表中国，常见的还有com、en、us等等\ncn后面其实还有一个.代表根域名，不需要输入\n\n\n3、 域名服务器都有哪些？\n\n\n本地域名服务器：最先接收我们主机的DNS查询，是当地的域名服务器\n\n比如说一个大学就有一个域名服务器、一个ISP也有一个本地域名服务器\n\n\n根域名服务器：最高层次的域名服务器\n\n上面的例子的xxx.cn.，最后面的点就是根域名，一般不需要写\n根域名服务器管理所有的顶级域名\n\n\n顶级域名服务器：顶级域名服务器管理在该服务器注册的所有二级域名\n\n即.cn\n顶级域名服务器管理注册在此的二级域名\n\n\n权限域名服务器：负责管理一个区（区的范围小于等于域，是DNS服务器的管理单位）\n\n当一个权威域名服务器还不能够给出最后的额查询回答时，就会告知发出查询请求的DNS客户，下一步应当找哪一个权威域名服务器\n\n\n\n\n4、DNS的递归查询与迭代查询\n\n如图所示：\n\n\n递归查询：图中的1和10\n\n主机访问本地DNS服务器并且没有查到IP时，本地服务器就会代替我们访问其他域名服务器。\n递归查询的特点是：本地DNS服务器代替我们查询，直到找到答案或确定答案不存在\n\n\n迭代查询：图中2~9\n\n本地DNS服务器向较高级别的DNS服务器（如根DNS服务器、顶级域DNS服务器、权威DNS服务器等）发起查询时，它执行的是迭代查询。\n迭代查询的特点是：DNS服务器之间相互协作，每个DNS服务器都只提供有限的信息，而不负责完成整个查询过程\n\n\n\n\n5、DNS域名服务器只使用UDP协议吗？\n\n在域名查询时使用UDP协议，但在区域传送（即主域名服务器向辅助域名服务器同步数据时）会使用TCP\n\n6、访问一个HTTPs网址有几个大过程？\n\n\n首先会进行DNS查询\n得到IP后，才能进行TCP三次握手\n握手成功后，进行TLS握手，才能建立安全通信\n\n一个域名的解析之路\n当我们输入一个网址，比如www.yesmylord.cn（我的博客），DNS都做了什么？\n\n你在浏览器地址栏输入了www.yesmylord.cn：\n\n查询浏览器缓存（浏览器缓存会缓存最近浏览过的网页的域名与IP地址）\n如果没有，查询系统缓存（即hosts文件）\n如果没有，去路由器缓存查找\n如果没有，去本地DNS服务器查\n本地DNS服务器会代替我们，向根域名服务器发送请求（这里叫递归查询：因为DNS是代替我们进行的查询，而不是我们主机发起的查询）\n本地DNS服务器访问根域名服务器，根域名服务器返回顶级域名服务器IP地址（解析出顶级域名.cn的地址）\n本地DNS服务器访问.cn的顶级域名服务器的地址，返回其管理的权威域名服务器IP地址（解析出.yesmylord）\n权威域名服务器A不知道IP是什么，他告诉我们访问权威域名服务器B\n权限域名服务器B返回真正的IP地址（解析出www）\n\n\n本地DNS服务器查到结果后，得到了www.yesmylord.cn的地址，告知我们\n得到IP就可以进行TCP握手了\nTCP建立连接后，如果是HTTPS协议，还需要TLS握手\n此后就可以进行HTTP通信了\n\n\n值得注意的是，DNS查到的可能是CDN服务器的地址\n\nCDN服务器可以缓存一个网站的静态资源，达到快速响应的目的\n注意：\n\n缓存的是静态资源，动态资源不能缓存\n\n总结查询过程：\n\n浏览器缓存\n系统hosts文件\n路由器缓存\n本地DNS服务器缓存\n根域名服务器\n顶级域名服务器\n权限域名服务器（有的也叫权威域名服务器）\n\n","categories":["计算机网络","应用层","DNS"],"tags":["计算机网络","应用层","DNS"]},{"title":"跨域","url":"/2020/08/22/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/HTTP%20%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/","content":"\n引言：HTTP访问控制，CORS跨域资源分享；什么是跨域，以及预检请求等\n\n\n\nHTTP访问控制发现在web开发中，会配置拦截器，在拦截器中，有这么一个配置：\nif (request.getMethod().equalsIgnoreCase(&quot;options&quot;)) &#123;    return true;&#125;\n\nOPTIONS请求，这个OPTIONS请求到底是什么？\n还有跨域到底是什么？\n跨域是什么？首先我们需要了解一些网络这方面的专业术语\nOrigin 同源\nWeb内容的源由用于访问它的URL 的方案(协议)，主机(域名)和端口定义。\n只有当方案，主机和端口都匹配时，两个对象具有相同的起源。\n\n\n方案（scheme）：就是协议，例如HTTP、HTTPS、FTP等等协议\n\n主机（host）：也就是主机的IP地址，如果有域名代表域名\n\n端口（port）：端口，共有65536个，0-65535，0-1023是周知端口，端口详细链接\n\n\n同源的例子：\nhttp://example.com/app1/index.htmlhttp://example.com/app2/index.html-------------------------------------------http://Example.com:80http://example.com\n\n他们有相同的协议和主机，端口都是默认的80端口\n不同源的例子：\nhttp://example.com/app1https://example.com/app2\tdifferent schemes-------------------------------------------------------http://example.comhttp://www.example.comhttp://myapp.example.com\tdifferent hosts-------------------------------------------------------http://example.comhttp://example.com:8080\n\n他们都是不同源的\n同源不同源有什么作用？同源概念来自同源策略\n\n同源策略的作用：同源策略控制不同源之间的交互\n\n某些操作，仅只限于同源内容才能操作，这种操作就叫跨源网络访问\n跨源网络访问相关链接：CORS\n\nCORS （Cross-Origin Resource Sharing，跨域资源共享）是一个系统，它由一系列传输的HTTP头组成，这些HTTP头决定浏览器是否阻止前端 JavaScript 代码获取跨域请求的响应。\n同源安全策略 默认阻止“跨域”获取资源。但是 CORS 给了web服务器这样的权限，即服务器可以选择，允许跨域请求访问到它们的资源。\n\n分为三类：\n\n跨域写操作（Cross-origin writes）一般是被允许的。例如链接（links），重定向以及表单提交。特定少数的HTTP请求需要添加 preflight。\n跨域资源嵌入（Cross-origin embedding）一般是被允许（后面会举例说明）。\n跨域读操作（Cross-origin reads）一般是不被允许的，但常可以通过内嵌资源来巧妙的进行读取访问。例如，你可以读取嵌入图片的高度和宽度，调用内嵌脚本的方法\n\n以下是可能嵌入跨源的资源的一些示例：\n\n&lt;script src=&quot;...&quot;&gt;&lt;/script&gt; 标签嵌入跨域脚本。语法错误信息只能被同源脚本中捕捉到。\n&lt;link rel=&quot;stylesheet&quot; href=&quot;...&quot;&gt; 标签嵌入CSS。由于CSS的松散的语法规则，CSS的跨域需要一个设置正确的 HTTP 头部 Content-Type 。不同浏览器有不同的限制： IE, Firefox, Chrome, Safari (跳至CVE-2010-0051)部分 和 Opera。\n通过 &lt;img&gt;展示的图片。支持的图片格式包括PNG,JPEG,GIF,BMP,SVG,…\n通过 &lt;video&gt; 和 &lt;/video&gt;播放的多媒体资源。\n通过 &lt;object&gt;、 `` 和 &lt;applet&gt; 嵌入的插件。\n通过 @font-face 引入的字体。一些浏览器允许跨域字体（ cross-origin fonts），一些需要同源字体（same-origin fonts）。\n通过 &lt;iframe&gt; 载入的任何资源。站点可以使用 X-Frame-Options 消息头来阻止这种形式的跨域交互。\n\n预检请求跨域资源共享标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站通过浏览器有权限访问哪些资源\nCORS的头有下面这些：\nAccess-Control-Allow-Origin# 指示请求的资源能共享给哪些域。Access-Control-Allow-Credentials# 指示当请求的凭证标记为 true 时，是否响应该请求。Access-Control-Allow-Headers# 用在对预请求的响应中，指示实际的请求中可以使用哪些 HTTP 头。Access-Control-Allow-Methods# 指定对预请求的响应中，哪些 HTTP 方法允许访问请求的资源。Access-Control-Expose-Headers# 指示哪些 HTTP 头的名称能在响应中列出。Access-Control-Max-Age# 指示预请求的结果能被缓存多久。Access-Control-Request-Headers# 用于发起一个预请求，告知服务器正式请求会使用那些 HTTP 头。Access-Control-Request-Method# 用于发起一个预请求，告知服务器正式请求会使用哪一种 HTTP 请求方法。Origin# 指示获取资源的请求是从什么域发起的。\n\n\n\n规范要求，对那些可能对服务器数据产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），\n浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。如果预检请求得不到回答，那么实际的HTTP请求将不会发送\n\n 可能对服务器数据产生副作用的HTTP请求\n\n阅读上文，我们注意到这句话，那么什么才是可能对服务器数据产生副作用的HTTP请求？\n简单请求一些请求不会触发CORS预检请求，这类请求称为简单请求（并不是规范术语）\n符合下面所有条件，就称为简单请求：\n\n使用GET、HEAD、POST方法\n\nHTTP请求头限制这几种字段（不得人为设置该集合之外的其他首部字段）：Accept、Accept-Language、Content-Language、Content-Type（需要注意额外的限制，safari对这个字段的值做了限制）、DPR、Downlink、Save-Data、Viewport-Width、Width\n\nContent-type只能取：application/x-www-form-urlencoded、multipart/form-data、text/plain\n\n请求中的任意XMLHttpRequestUpload对象均没有注册任何事件监听器；XMLHttpRequestUpload 对象可以使用 XMLHttpRequest.upload属性访问。\n\n请求中没有使用 ReadableStream对象。\n\n\n预检请求也就是非简单请求，会在正式的HTTP通信之前增加一次HTTP请求\n我们平常的web项目中，会有：\n\n有PUT和DELETE请求\n有TOKEN等自定义的头部串\ncontent-type类型为application/json\n\n所以我们web项目中的大部分请求全是需要预检的请求\n小结本篇说明了以下内容：\n什么是跨域？不同源即为跨域，不同源就是协议、主机、端口任意一个不相同\n什么是预检请求在处理非简单请求时，会发送预检请求，请求的方法为OPTIONS，如果预检请求失败，那么真正的HTTP请求将不会发送\n","categories":["计算机网络"],"tags":["CORS"]},{"title":"字符串子序列问题","url":"/2022/07/31/%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%90%E5%BA%8F%E5%88%97%E9%97%AE%E9%A2%98/","content":"\n    经典的字符串子序列问题，学习DP的第一步\n\n\n\n\n字符串子序列问题\n力扣字符串序列问题\n\n首先明确几个知识点\n字符串的子序列和子串不一样：\n\n子序列只要求顺序，不要求连续\n而子串要求顺序且要连续\n\n比如字符串abcdefg\n\n子序列：abc、ade、acfg\n子串：abc、a\n\n\n对于子序列问题，解法有双指针、动态规划等等解法。本文主要介绍动态规划DP这种方法\nLCS问题最长公共子序列问题是一道经典的DP问题。\n动态规划方法，通常要找边界与递推式\n假设字符串：\ns1 = &quot;[XXXXXXX]A&quot;; // 假设X为未知部分，最后一个字符为As2 = &quot;[XXXXXXXXX]A&quot;; // 最后一个字符也为A\n\n假设dp[i][j]存放了S1和S2的最长公共序列（i与j是分别指向两个字符串的指针）\n​        那么对于最后一个字符来说，他们如果相等（如S1、S2），那么此时的最长序列就是dp[i-1][j-1]+1；如果他们不相等，那么要么是在dp[i-1][j]内，要不在dp[i][j-1]内\n因此我们可以得到递推式\ndp[i][j] = dp[i-1][j-1]+1; // 当 s1.charAt(i) == s2.charAt(j)dp[i][j] = Math.max(dp[i][j-1], dp[i-1][j]); // 当 s1.charAt(i) != s2.charAt(j)\n\n此处贴一下code：\npublic int longestCommonSubsequence(String text1, String text2) &#123;    int m = text1.length();    int n = text2.length();    int [][] dp = new int[m+1][n+1];    for(int i=1; i&lt;=m; i++)&#123;        for(int j=1; j&lt;=n; j++)&#123;            if(text1.charAt(i-1) == text2.charAt(j-1))&#123;                dp[i][j] = dp[i-1][j-1]+1;            &#125;else&#123;                dp[i][j] = Math.max(dp[i-1][j], dp[i][j-1]);            &#125;        &#125;    &#125;    return dp[m][n];&#125;\n\n判断子序列判断子序列，可以有多种求法，比如双指针就可以快速的判断，但是可以看到进阶的要求，如果出现10亿级别的数据字符串，双指针效率会很低下\n这种DP可以看官方题解的视频进行理解\n此处简单介绍一下：\n原理相当于创建了26个字母的列表，分别记录字符串中该字母第一次出现的位置，如图\n\n因此当我们判断一个字符串是不是该字符串的子序列，就可以从第一行开始遍历，如果该字符出现过，那么就是一个小于原字符串长度的数，如果不存在那么就是字符串的长度\n\n如图所示：\n\n首先找dp[0][s.charAt(0)-&#39;a&#39;]，发现为0，说明存在，且下一个去找0+1\n找dp[1][s.charAt(1)-&#39;a&#39;]，发现为3，说明存在，继续找下一个3+1\n找dp[4][s.charAt(2)-&#39;a&#39;]，发现为5，说明存在，此时已经找完\n\n贴出code：\nclass Solution &#123;    public boolean isSubsequence(String s, String t) &#123;        int n = s.length(), m = t.length();        int[][] f = new int[m + 1][26];        for (int i = 0; i &lt; 26; i++) f[m][i] = m;                for (int i = m - 1; i &gt;= 0; i--) &#123;            for (int j = 0; j &lt; 26; j++) &#123;                if (t.charAt(i) == j + &#x27;a&#x27;)                    f[i][j] = i;                else                    f[i][j] = f[i + 1][j];            &#125;        &#125;        int add = 0;        for (int i = 0; i &lt; n; i++) &#123;            if (f[add][s.charAt(i) - &#x27;a&#x27;] == m)                 return false;            add = f[add][s.charAt(i) - &#x27;a&#x27;] + 1;        &#125;        return true;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n\n","categories":["算法"],"tags":["Java","算法"]},{"title":"VPN","url":"/2023/07/20/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/VPN/","content":"\n引言：Virtual Private Network，也称为网络隧道\n\n\n\n\nVPN\nVirtual Private Network 虚拟私人网络，通过加密和隧道技术在公共网络上创建一条安全的、私密的通信通道\n\nVPN出现的背景\n在1996年，互联网还处于HTTP交互时代，而HTTP是明文传输的，传输的数据容易被窃取或篡改\n\n远程办公的需要，而企业或学校内部的网络无法被外网连接（站点到站点的通信）\n\n\nVPN原理假设现在中国分公司上班的Alice需要访问在美国的总公司：\n\nAlice将请求发送给VPN服务器（或称为VPN集线器、VPN网关）\nVPN服务器会将Alice的源地址与目的地址封装起来，发送给在美国的VPN服务器\n美国的VPN服务器拆包，发送到真正要发送的目的地址\n\n这样在外人（ISP）看来，只是两个VPN服务器在通信，就达到了隐私的目的。\nVPN还需要保证数据加密（AES等）、数据完整（HASH校验）、以及身份认证（RSA、用户名密码、或是PKI）\nVPN主要的核心两大协议VPN的最大作用就是安全，他使用两种协议来保证安全：\n\nSSL/TLS（Secure Socket Layer/Transport Layer Security）\nIPSec（Internet Protocol Security）\n\nSSL/TLS即HTTPs中的s，SSL（Secure Socket Layer）是TLS（Transport Layer Security）的前身。TLS是SSL的升级版，它是在SSL的基础上发展而来的，提供更强大的加密和安全性。\nSSL/TLS建立连接在TCP三次握手建立连接之后，服务器就会返回给浏览器一个数字证书，浏览器向CA机构验证证书完整性，然后混合使用对称加密与非对称加密：\n\n通信建立前：采用非对称秘钥加密的方式交换会话秘钥，后续就不再使用非对称加密\n通信过程中：全部使用对称加密来加密明文数据\n\nIPSecTLS是位于传输层与应用层之间的协议，这意味着，在应用层的下三层，数据依旧是透明的。\nIPSec是网络层的协议（与IP同一层）负责加密IP包，保证网络层到网络层的通信也是加密后的。\n使用VPN是否万无一失\n问题1：既然VPN保密了我们访问的目的地址，就真的万无一失了吗？\n\n有这几种情况可能暴露我们访问的目的地址：\n\n浏览器的隐私设置：浏览器保存的浏览历史、Cookie、缓存\n不靠谱的VPN提供商：VPN服务商出卖了我们（免费的或是不可信的VPN经常这么做，他们出卖数据给第三方）\nDNS解析：DNS解析请求暴露我们将要访问的网站，好的VPN服务商会使用自己的DNS服务器。\n\n","categories":["计算机网络"],"tags":["计算机网络","VPN"]},{"title":"DDD领域驱动设计","url":"/2024/12/25/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/DDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/","content":"\n    引言：从OOP，到经典的设计模式，再到SOLID，再到DDD领域驱动设计\n\n\n\n\n编程思想：从OOP到DDDOOP我们经常接触OOP的语言：Java、C++，他们的核心就是面向对象\n区别于面向过程编程，OOP的重点在于从实际的业务模型中抽取出类来\n并且设计时要满足OOP的四大特点：封装、继承、多态、抽象（抽象很多人认为是基本原则）\n\n封装：将类的属性与行为封装在类中，只对外暴露公开的接口\n继承：从现有的类中继承属性和行为，从而实现代码复用和扩展\n多态：父类可以有不同的实现的子类，他们有共同的属性和行为在父类中，子类自身体现不同之处\n抽象：提供抽象的接口定义，而不是具体的实现（这个很多人认为是基本的原则）\n\nDesign Pattern从OOP开发之后，引申出了很多设计模式（关于设计模式，看此篇博客）\n\n创建型：单例、工厂、建造者、原型\n结构型：代理、桥接、装饰者、适配器、门面、组合、享元\n行为型：观察者、模版、策略、职责链、状态、迭代器、访问者、备忘录、命令、解释器、中介\n\n从不同的设计模式思想中，可以抽象出几个比较核心的，基本都遵守了设计思想：SOLID\nSOLID所谓SOLID指的是：\n\nS单一职责原则（Single Responsibility Principle，SRP）：每个类只有一个职责\nO开放封闭原则（Open/Closed Principle，OCP）：软件实体（类、模块、函数等）应该对扩展开放，对修改封闭\nL里氏替换原则（Liskov Substitution Principle，LSP）：子类应该能完全实现父类的行为\n举个违反LSP原则的例子：比如父类bird有行为fly，他的子类有一个鸵鸟，而鸵鸟是不会飞的，因此最好的办法是，将bird拆为会飞的鸟和不会飞的鸟，将fly这个行为给予会飞的鸟\n\n\nI接口隔离原则（Interface Segregation Principle，ISP）：接口应该被拆成最小，以便于客户端进行最小化的调用\nD依赖倒置原则（Dependency Inversion Principle，DIP）：模块间的依赖使用抽象实现（接口或是抽象类），而不去使用具体的实现\n\nDDD领域驱动设计DDD 是什么以上的一些设计思想，都局限在了一些具体的实现上，在现在的开发过程中，往往会引入一大堆中间件、一大堆存储池，而旧的设计思想可能会不太够用，因此DDD是非常好用的工具，去剖析复杂的业务领域\n\n领域驱动设计 DDD，Domain-Driven Design\nDDD是一套方法论，是优秀设计方式的缩影聚合，你可以在DDD中看到一大堆设计思想的缩影，比如DP、OP、工厂模式\n\nDDD依赖于是对传统的三层设计的一种改进方案，我们先从传统的三层开始介绍：\n传统的三层：\n\n\nPresentation 表示层：比如前端UI相关的代码，后端的Controller以及与前端进行交互的代码，都属于表示层\nApplication 应用层：就是Service，常写的业务逻辑、数据校验逻辑，CRUD\nInfrastructure 基础设施层：包括DAO相关、存储相关、消息队列相关等等的代码。\n\n传统的三层之间，是从上到下依次依赖的，即Controller依赖于Service、Service依赖于DAO\n存在的问题：\n\nApplication可能会过于臃肿，不利于新人接受与维护\nInfrastructure可能会过分依赖于某个组件，比如过分依赖于mysql，后期打算切换数据库或是消息队列，但因为耦合过于深入，导致放弃\n\nDDD核心概念：\n\n关于此部分的概念可以结合下一节的Demo配合理解\n\nDDD优化后，提出Domain层，而且调整了他们之间的依赖关系，DDD的四层结构：\n\n\nPresentation 表示层：基本不变\n\nPresentation与Application交互使用REST DTO\n\n\nApplication应用层：接入相同业务的不同场景（use case），比如电商系统的用户登录和店家登录\n\nApplication与Domain交互使用Entity，此处的Entity不同于POJO（贫血模型），可能还会含有校验逻辑（充血模型）\n\n\nDomain领域层：Service层可能存在一些逻辑是固定不变的（业务逻辑），这些放在Domain层，而且此处基本全部面向接口\n\nAggregate 聚合：当一个操作会涉及到多个对象的状态发生改变，那么我们应该将这一群对象聚合为一个对象，对象内部对其进行操作，只对外暴露一个接口（即暴露聚合根）聚合可以保证一群对象的状态一致\n\nVO值对象（也称为DP，即Domain原语）：抽象并封装自检和隐性属性的计算逻辑，且这些属性无状态\nEntity 实体：抽象并封装单对象有状态的逻辑\n\n\nDomain Service：可能存在一些逻辑是固定不变的（业务逻辑）\n\n\n\nInfrastructure基础设施层（也叫数据层）：此层依赖于其他三层，传输的数据是DataBase DTO，这一层需要提供具体的实现，比如Mapper、RPC\n\nRepository 存储：抽象并封装外部数据的访问逻辑（比如DAO、RPC等）\n还包括网关、缓存、第三方工具等\n\n\n\n\n领域层中的VO和Entity的区别在于：\n\n是否有状态，什么是状态？即在系统的整个运行过程中，可能会发生变化的对象\n是否唯一：实体每一个都有唯一的标识符\n是否有生命周期\n\n比如在一个抢票系统中，如果抢到了票，并且票固定了座位，那么这个座位就是有状态的；如果抢到票就可以去，随便坐，那么座位此时就是无状态的。\n\nDDD 防腐层防腐层（Anti-Corruption Layer）的位置通常在应用层和基础设施层之间，由于基础设施可能会更换（比如Mysql换为了Mq），但应用层需要一个稳定的接口，因此就提出了防腐层。\n防腐层有时被看做基础设施层的一部分，应用层通过防腐层与基础设施层进行交互，无需了解具体细节。\n引入防腐层可以进一步降低耦合度，可以说本质就是额外加了一层接口。\nDDD 代码模型具体来看，代码的分包基本是这样的：\n\ninterfaces（表示层）\nController：HTTP服务\nAPI接口：其他的DTO服务\n\n\napplication（应用层）\nService：业务逻辑（大的业务需求，需要多个domain service组合实现）\nfacade：将用户请求委托给一个或多个应用服务进行处理。\nevent：包括两个子目录publish和subscribe。主要存放事件发布、订阅的相关代码(事件处理的核心业务逻辑在领域层实现)\n\n\ndomain（领域层）：\nservice：领域服务\nentity：实体类\nRepository：做entity到DO的类型转换，调用DAO\n\n\ninfrastructure（基础设施层）：\nconfig：基础的配置\ncommon：公共组件\ndao：DB操作\n\n\n\nDDD demo现在有这样一个场景：demo来自于视频\n\n假设现在要做一个数据统计系统：\n市场专员输入客户的姓名和手机号，\n根据客户手机号的归属地和运营商将客户群体分组，分配给相应的销售组，由销售组跟进后续业务\n\n我们瀑布式开发马上就可以实现这个接单的业务：\n\n输入用户名、手机号\n校验参数\n获取手机号的归属地和运营商编号（查数据库）\n获取到分组编号\n构建客户对象，存入数据库（写数据库）\n\n大致代码如下：\npublic class RegisterServiceImpl implement RegisterService&#123;    private SaleRepository saleRepo;    private UserMapper userMapper;        public User register(String name, String phone) throw ValidationException&#123;        // 参数校验        if(name == null || name.length() == 0)&#123;            throw new ValidationException(&quot;name&quot;);        &#125;        if(phone == null || isValidPhone(phone))&#123;            throw new ValidationException(&quot;name&quot;);        &#125;        String areaCode = getAreaCode();        String opCode = getOpCode();        Sale sale = saleRepo.findRep(areaCode, opCode);        // 创建用户、落盘        User user = new User();        user.name = name;        user.phone = phone;        if(sale != null)&#123;            user.saleId = sale.id;        &#125;        return userMapper.insert(user);    &#125;&#125;\n\n这样的代码会有几个问题：\n\n输入参数是两个String，他人调用可能会出现顺序颠倒的问题；\n如果之后扩展注册方式，比如使用身份证注册，也会传入一个String，当前代码不好扩展\n参数校验逻辑写在了register逻辑里面，如果校验规则发生改变，我们有需要重新修改这段代码\n这个方法的目的是为了注册，而获取手机号的归属地和运营商好像使注册业务不再纯粹（这种为了调用某个API，而去补充参数的方式，称为胶水操作）\n\nDDD的一大思想就是充血模型，即我们其实可以定义一个类PhoneNumber，其内部进行逻辑校验（所谓贫血模型就是普通的POJO类，即只有get、set方法）\n我们给类PhoneNumber加了校验逻辑、获取手机号的归属地和运营商的逻辑，让业务逻辑变得纯粹，PhoneNumber这种充血模型设计的Bean，称为DP（Domain Primitive 领域原语），其可以自我验证，拥有自我的行为，是领域的最小组成部分\npublic class PhoneNumber&#123;    private final String number;    private final String pattern = &quot;^0?[1-9]&#123;2,3&#125;-?\\\\d&#123;8&#125;$&quot;;    public getNumber()&#123;        return number;    &#125;    public PhoneNumber(String number)&#123;        if(!isValidPhone(number))&#123;            throw new ValidationException(&quot;number格式错误&quot;);        &#125;        this.number = number;    &#125;    public String getOpCode()&#123;&#125;    public String getAreaCode()&#123;&#125;&#125;\n\n这样业务逻辑就变的十分清晰\npublic class RegisterServiceImpl implement RegisterService&#123;    private SaleRepository saleRepo;    private UserMapper userMapper;        public User register(String name, PhoneNumber phone) throw ValidationException&#123;        Sale sale = saleRepo.findRep(phone.getAreaCode(), phone.getOpCode());        User user = new User();        user.name = name;        user.phone = phone;        if(sale != null)&#123;            user.saleId = sale.id;        &#125;        return userMapper.insert(user);    &#125;&#125;\n\nDP三原则：\n\n让隐性的概念显性化（比如归属地和运营商其实是Phone的隐性属性）\n让隐性的上下文显性化\n封装多对象行为\n\n但目前我们的实现，外部依赖十分严重，比如我们直接依赖了MybatisPlus，我们在业务逻辑中，直接使用了Mapper创建了User，并且还实际存储了User对象\n\n外部依赖：不属于当前Domain的设施和服务都属于外部依赖\n比如数据库、schema、RPC、ORM、中间件\n\n如果之后我们想切换中间件，那么此处的实现就仍需要改动，此处可以进行DP（依赖倒置）原则，面向接口而不是具体的实现\npublic class RegisterServiceImpl implement RegisterService&#123;    private SaleRepository saleRepo;    private UserRepository userRepo;        public User register(String name, PhoneNumber phone) throw ValidationException&#123;        Sale sale = saleRepo.findRep(phone.getAreaCode(), phone.getOpCode());                User user = new User(name, phone, sale.Id);        return userRepo.save(user);    &#125;&#125;// userRepo 是一个接口，可以有不同的实现，比如使用MybatisPlus实现\n\n而且此时，我们是直接通过new创建的对象，如果为了更加通用，可以使用工厂类对对象进行创建。\nDDD总结DDD是一套开发可拓展性强、可维护性高的应用的一套方法论，其包含了很多设计模式的设计思想，比如OP、DP、工厂模式、面向接口等等。\nDDD的关键思想是：基础设施不再是最底层的直接依赖，而是作为旁系进行依赖\nDDD关键的概念是：VO、Entity、聚合根\nDDD常用的方式就是：充血模型，VO和Entity都可以进行充血\n","categories":["设计模式"],"tags":["设计模式","DDD"]},{"title":"WebSocket协议","url":"/2023/09/25/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/websocket%E5%8D%8F%E8%AE%AE/","content":"\n引言：WebSocket——基于TCP的全双工实时通讯\n\n\n\n\nWebSocketWebSocket的应用场景\nWebSocket：一种在单个TCP连接上进行全双工通信的协议。\n它最初被设计用于在Web浏览器和Web服务器之间提供实时、双向通信的能力，但现在已经被广泛用于各种应用程序和领域，包括在线游戏、聊天应用、金融交易系统和实时协作工具等\n\n常用在以下场景：\n\n在线实时聊天室\n**多人在线游戏 (MMOGs)**：魔兽世界、星际争霸2、Apex、我的世界等等。\n协作工具：在线协作工具，如实时白板、远程桌面共享和协同编辑，需要实时同步多个用户之间的操作。\n实时监控和仪表板：WebSocket可用于实时监控系统状态、服务器性能、传感器数据等，并将这些数据实时传送给操作人员。\n\n如何做到实时通信？在没有websocket协议之前，有这么几种伪实时通信的方式，以扫描二维码登录这件事为例：\n\n浏览器轮询：浏览器定期请求服务器，获得响应\n\n微信公众平台的扫码登录就是使用这种方式，每隔1~2s就发送一次http请求，等待响应\n\n这样的登录方式简单粗暴，但是用户在扫码后，会有等待1~2s的体验，而且频繁的http请求，对后台也是不小的负担。\n\n服务器轮询：将用户请求的超时时间设置长一点，比如30s，后端一直轮询，如果客户扫描二维码（扫描后会发送请求），就返回响应\n\n这种做法，减少了HTTP请求次数，但是后台一直轮询，对服务器的压力也比较大\nWebSocket协议\nWebSocket协议基于运输层TCP协议，WebSocket的握手阶段基于HTTP协议，数据传输是WebSocket自己的部分。\n\n握手部分在TCP连接建立后，如果想要使用WebSocket协议，需要使用HTTP协议进行握手\n1、HTTP握手请求头：\nGET ws://localhost/chat HTTP/1.1Host: localhostUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==Sec-WebSocket-Version: 13\n\n\nConnection:  Upgrade：表明浏览器想升级协议\n\nUpgrade:  websocket ：表明升级链接为websocket\n\nSec-WebSocket-Key：这是一个Base64编码的随机密钥，用于安全验证WebSocket连接请求的合法性\n\nSec-WebSocket-Version: 表示客户端支持的WebSocket协议版本，通常是13\n\n\n2、HTTP握手响应头：\nHTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=Sec-WebSocket-Protocol: chat\n\n\nHTTP/1.1 101 Switching Protocols：状态码 “101 Switching Protocols” 表示切换协议成功。\nUpgrade: websocket 和 Connection: Upgrade: 这两个头部字段表示服务器同意升级连接到WebSocket协议。\nSec-WebSocket-Accept: 这是服务器生成的Base64编码的密钥，用于验证WebSocket连接请求的合法性。服务器使用客户端发送的Sec-WebSocket-Key来计算这个值。\nSec-WebSocket-Protocol: (可选) 如果客户端请求了特定的子协议，服务器可以在这里指定所选择的子协议。\n\n数据交互部分（本节图源来自：小白debug）\n在HTTP握手建立后，就可以进行websocket通信了，websocket中的数据包称为帧\n\n数据帧的格式如图：只需要关注几个字段\n\n\n4位的opcode：表示数据的类型，1是string帧；2表示二进制帧（即bytes帧）；8表示关闭连接帧。\n四个payload字段：它的意思是，一开始只读最开始的7bit，如果是0-125，那么表示数据的长度7bit就可以表示完成；如果是126（0X7E）就继续向后读，之后的几个段同理。\n\n相关问题\n1、为什么有了HTTP协议，还要有Websocket协议？\n\nHTTP是半双工协议，是为了提供浏览服务的，设计之初没打算支持交互。\nWebSocket协议是专门用来提供交互的。\n\n2、WebSocket和HTTP的关系是什么？\n\nWebSocket握手需要使用HTTP协议，升级完成后，就与HTTP毫无关系了。\n","categories":["计算机网络"],"tags":["计算机网络","WebSocket"]},{"title":"QUIC协议","url":"/2023/07/20/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/QUIC/","content":"\n引言：Quick UDP Internet Connections，依赖于UDP，但却是TCP2.0\n\n\n\nQUIC\nQuick UDP Internet Connections 快速UDP网络连接\n\nQUIC出现的背景QUIC的提出源自于HTTP存在的问题：关于HTTP存在的问题查看此篇\n\nHTTP1.0存在的问题：无状态、明文传输、无认证、无完整性校验、非持续连接、串行发送、队头阻塞\nHTTP1.1（1997）遗留的问题：队头阻塞、串行发送、数据包头无压缩且重复发送、服务器只能被动响应客户端的请求\n无状态：使用Cookie来解决（严格意义来讲，无状态不是一个缺点，是HTTP的特性）\n明文传输、无认证、无完整性校验：结合TLS解决（即HTTPS）\n非持续连接：使用Connection:Keep-Alive解决\n队头阻塞：使用管道网络传输解决，可以无需等待响应就可以发送第二个请求，但是接收的响应必须是按顺序的，这意味着，如果返回的其中一个响应出现意外，之后的响应仍然不能接受。（管道网络解决了，但是没有解决）\n\n\nHTTP2.0（2015）仍存在的问题：队头阻塞（只解决了应用层面的队头阻塞，TCP的队头阻塞依然存在，如果出现丢包，就需要等待TCP重传）\n头部压缩：HPACK算法解决，在客户端与服务端维护关于数据包头的表，每次发送的包头将不再发送重复部分\n二进制化：HTTP2.0下的消息头和消息体都是二进制格式，加快了识别的速度，称为帧：头信息帧和数据帧\n并行发送：2.0使用多路复用解决，可以在一个连接中并行发送多个请求\n队头阻塞：2.0对于响应无需再按顺序，报文拆分为首部帧和数据帧，数据帧有流标识符标记顺序，以此实现无序接收的问题\n服务器推送：服务器可以主动推送静态资源给客户端（对于客户端：如果用户只是点错了，那么他的浏览器也会承担巨多的资源响应，增大负担；对于服务端：可能会带来DDoS攻击）\n\n\nHTTP3.0（2019）：仅仅四年就推出了3.0，说明克服TCP的性能障碍刻不容缓\n基于QUIC：QUIC整合了TCP与TLS，总的来说有\n\n\n\n\n问题1：QUIC的提出是为了解决TCP存在的问题的，为什么不修改TCP协议呢？\n\n市面上所有的OS内核，均设计了TCP的实现，修改TCP原有的实现不太现实，而恰好传输层还有一个UDP，就可以依赖于UDP实现TCP的功能了\nTLS1.2与1.3这里插一点额外的知识，介绍一下TLS1.2与1.3的区别\nTLS1.2握手细则在TCP连接建立后，在TLS协议中，DH用于密钥交换，RSA用于数字签名和证书验证：\n\nRSA与DH算法的区别：\nRSA也可以进行秘钥交换，只不过不满足前向安全特性，这意味着一旦私钥暴露，这意味着之前的所有消息都暴露；而DH算法却不会。\n“Diffie-Hellman Key Exchange”（迪菲-赫尔曼密钥交换协议）：通过每次设置不同的随机数来保证即使密钥暴露，也不会暴露之前的消息内容\n\n下面是TLS1.2的握手细则：\n\n客户端发起握手：客户端向服务器发送一个ClientHello消息\n消息包含：TLS版本（客户端支持的版本）、加密套件、Client Random第1随机数（32字节的随机数）\n\n\n服务器回应：收到ClientHello后，向客户端发送一个ServerHello消息\n消息包含：TLS版本（服务端选择具体使用什么版本）、加密套件、Server Random第2随机数（32字节随机数）\n\n\n服务器发送数字证书给客户端（可选）：服务端发送Certificate消息，证书包含公钥与证书信息（注意：这一步与上一步是两条响应消息）\n浏览器收到Certificate消息，对照信任证书列表，确认证书是否可信\n\n\n服务器端发送ServerKeyExchange消息（可选）：\n对于RSA算法，它的公钥在数字证书内，因此不需要发送ServerKeyExchange\n对于DH算法或是ECDH算法，服务器将在ServerKeyExchange消息中发送DH协商参数，包括DH公共参数和DH签名等信息\n\n\n服务器端发送ServerHelloDone消息：告诉自己发完了\n客户端认证证书与密钥交换：Client Key Exchange、Change Ciper Spec、Encrypted Handshake Message消息\n验证数字证书是否合法：如果认证通过，客户端生成一个48字节的随机数作为预主秘钥（Pre-Master Secret，第3随机数）且使用公钥加密，然后发送给服务器，服务器使用自己的私钥解密，得到预主秘钥\n\n\n计算获得会话秘钥：服务器和客户端都使用第1、2随机数生成一个对称加密密钥，该密钥将用于后续通信的加密和解密。\n\n\n解释一下第1随机数、第2随机数、预主密钥、主密钥之间的关系：\n\n预主密钥的生成依赖于客户端和服务器的随机数，而主秘钥的生成依赖于预主密钥；\n预主密钥是一个临时的对称秘钥，为了临时密钥交换和生成后续加密所需密钥；\n主秘钥是一个对称秘钥，加密会话。\n换句话说：预主密钥就是临时使用一下，之后可以升级为主秘钥\n\n解释一下这里的安全套件：\n\n安全套件是在客户端与服务器进行握手时，协商的一些加密的具体细则，TLS1.2中有37种不同的组合，这里给出其中一种：TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\n\nTLS：表示协议\nECDHE：表示秘钥交换协议，ECDHE是椭圆曲线的DH算法\nRSA：证书验证、数字签名使用RSA\nAES_256：对称加密算法\nGCM：GCM是一种加密模式，它结合了加密和认证，并提供高效的加密性能\nSHA384：哈希算法（散列算法）\n\nTLS1.3优化TLS1.3在方方面面对1.2进行了优化\n\n前向安全问题：\n1.2：静态的（即每次不设置随机数来生成秘钥）RSA算法和DH算法均存在前向不安全问题\n1.3：移除了静态的RSA密钥交换算法和静态的DH密钥交换算法（即现在只能使用动态的DH做密钥交换）\n\n\n握手建立：\n1.2：一开始的握手消息，即ClientHello与ServerHello是明文的，因此如果黑客截获ClientHello，通知服务器使用低版本的TLS协议，安全性就会变差\n1.3：优化了握手步骤\n\n\n加密套件：\n1.2：给出了37种不同组合的加密套件，格式为协议、秘钥交换、对称加密、哈希算法TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\n1.3：建议支持五种，格式为协议、对称加密、哈希TLS_AES_256_GCM_SHA384（去掉了密钥交换算法的部分）\n\n\n秘钥交换算法：\n1.3：只支持三种密钥交换算法，分别是(EC)DHE、PSK-only（类似一种对称加密的方式）、PSK with (EC)DHE，而且去掉了很多不安全的加密算法\n\n\n0-RTT恢复（一个RTT代表一次往返时间）\n1.2：2RTT\n1.3：1RTT\n\n\n\nTLS1.3握手细则：\n\n 客户端ClientHello消息：第一随机数、密码套件、直接生成DH随机参数\n\n\n由于减少了加密套件的可选策略，因此1.3的握手可以在第一次就决定DH参数\n\n\n服务器发送ServerHello：第二随机数、DH参数\n服务器发送证书给客户端\n客户端收到证书，验证证书合法性，生成预主秘钥，发送给服务器\n客户端和服务器通过预主秘钥得到主秘钥，即会话秘钥（对称秘钥）\n\n总结：TLS1.3主要优化掉了协商DH参数的部分来加快连接的建立\n0-RTTTLS 1.3中引入了0-RTT（零往返时间）的优化机制。\n如果客户端和服务器之前已经建立过TLS 1.3连接并拥有有效的会话票据（session ticket），在后续的重连时，可以使用0-RTT模式来加快连接的建立\n注意：0-RTT是存在安全性问题的\nQUIC网络模型QUIC的特点：\n\n整合了HTTP2.0的多路复用、流量控制\n整合了TLS1.3的安全加密方式\n整合了TCP的握手、拥塞控制、流量控制\n依托于UDP\n\nQUIC虽然是应用层协议HTTP3依赖的协议，但QUIC本质还是一个应用层协议，其依托于运输层的UDP，设计的核心思想都是来源于TCP和TLS\nQUIC的数据包裹在UDP的用户报内发送：如图所示\n\n\n每一个QUIC包都有独立的编号，丢失某一个只需重传那一个，依次解决了TCP存在的队头阻塞问题\n\nQUIC和TLS1.3一样，首次需要1RTT，重新建立连接只需要0RTT\n并且，QUIC规定了连接ID：\n\n在TCP连接中，一个TCP连接的建立依赖于源IP、源端口、目的IP、目的端口，只要一个发生变化，就需要重新建立TCP连接\n在QUIC定义连接ID，只要连接ID不变，就不会重新建立连接\n\nQUIC总结QUIC的优点：\n\nQUIC连接建立快：QUIC与TLS1.3一样，有1RTT和0RTT的设计，QUIC还有连接ID，这些都是为了减少连接交互，减少连接次数而设计的\nQUIC扛丢包能力强\n自带加密，多路复用：因为融合了TLS和HTTP2\n\n缺点：\n\n兼容性与部署问题：一种新型协议，对中间设备、运营商、浏览器都需要支持\n比较耗CPU性能\n报文头部比较大\n0RTT将没有前向安全性\n\n","categories":["计算机网络"],"tags":["计算机网络","QUIC"]},{"title":"速转Golang","url":"/2023/10/25/Go/golang/","content":" \n引言：字节用的Go有点多呢，速转一下\n\n\n\n\n速转GolangHello worldpackage mainimport &quot;fmt&quot;func main() &#123;\tfmt.Println(&quot;Hello world!&quot;)&#125;\n\nPrintf打印类似C语言：\n\n%d：10进制\n%b：2进制\n%o：8进制\n%x：16进制（如果是大写%X，表示输出的字母为大写，比如15：输出F，否则输出f）\n\nfmt.Printf(&quot;%d \\n&quot;, 42)fmt.Printf(&quot;%d \\t %b \\t %o \\t %x \\n&quot;, 42, 42, 42, 42)fmt.Printf(&quot;%#d \\t %#b \\t %#o \\t %#x \\n&quot;, 42, 42, 42, 42)// 加#表示带前缀输出\n\n输出为：\n4242       101010          52      2a   42       0b101010        052     0x2a\n\n有关printf的占位符看此篇\n包在go中，每一个文件就是一个包，一般一个Go项目的结果是：\n\nbin：存放可执行文件\npkg：存放其他包\nsrc：存放源代码\ngo.mod文件\n\npackage stringutil// 开头大写的变量或是函数，代表这个变量会被exportvar MyName = &quot;Todd&quot;func Reverse(s string) string &#123;\treturn reverseTwo(s)&#125;\n\npackage mainimport (    // import导入包\t&quot;GolangTraining/src/02_package/stringutil&quot;\t&quot;fmt&quot;)func main() &#123;\tfmt.Println(stringutil.Reverse(&quot;!oG ,olleH&quot;))\tfmt.Println(stringutil.MyName)&#125;\n\n变量变量的声明变量有三种声明方式：\n\n:=声明并且赋值\nvar valueName valueType：声明变量及其类型，但是没有赋值（有默认值）\nvar valueName =  value：直接给值，会自动推断类型\n\n第一种方式：:=\na := 10 // 推断为intb := &quot;golang&quot; // 推断为stringc := 4.17 // 推断为float64d := true // 推断为boole := &quot;Hello&quot; // 推断为stringf := `Do you like my hat?` // 反引号作用与双引号一样g := &#x27;M&#x27; // 推断为int32 单引号表示为字符\n\n第二种方式：var valueName valueType\nvar a int // 默认为0var b string // 默认为空字符串&quot;&quot;var c float64 // 默认为0var d bool // 默认为false\n\n第三种方式：\nvar message stringmessage = &quot;Hello World.&quot;\n\n注意：\n\n打印变量时：可以直接打印，或是使用替代符%v代表值，%T表示类型\n\n变量如果不给值会有默认值\n\n\n声明多种变量：\nvar a, b, c = 1, false, 3 // 自动推断var a, b, c int = 1, 2, 3 // 这种情况必须全为int\n\n作用域\n声明在函数外，作用域属于包package scope；\n\n声明函数内，作用域属于函数function scope\n\n声明在代码块内，作用域就属于块block scope\n\n\n1、包作用域：\npackage visimport &quot;fmt&quot;// 这两个变量都属于vis包内可见的，其他包想使用这两个变量必须导入vis包var MyName = &quot;Todd&quot; // 开头大写，代表导出，其他包可以直接使用var yourName = &quot;Future Rock Star Programmer&quot; // 小写表示私有func PrintVar() &#123;\tfmt.Println(MyName)\tfmt.Println(yourName) &#125;\n\n// 使用main打印两种变量func main() &#123;\tfmt.Println(vis.MyName) // 输出 Todd\t// fmt.Println(vis.yourName) 这个就不行了\tvis.PrintVar()    // 输出    // Todd    // Future Rock Star Programmer&#125;\n\n2、函数域：\n有函数和函数表达式两种：\nvar x = 0 // 包内可见func increment() int &#123;\tx++\treturn x&#125;func main() &#123;\tfmt.Println(increment())\tfmt.Println(increment())&#125;\n\nfunc main() &#123;\tx := 0\tincrement := func() int &#123; // increment是一个匿名函数\t\tx++ // 函数使用了外部变量num，这是一个闭包\t\treturn x\t&#125;\tfmt.Println(increment())\tfmt.Println(increment())&#125;\n\n关于什么是闭包？见下一节\n3、块域：\nfunc main() &#123;\tx := 42\tfmt.Println(x)\t&#123;\t\tfmt.Println(x)\t\ty := &quot;The credit belongs with the one who is in the ring.&quot;\t\tfmt.Println(y)\t&#125;\t// fmt.Println(y) 块外部无法打印y&#125;\n\n\n关于域出现的特性的本质：\n大括号定义了一个新的堆栈框架，因此定义了一个新的范围级别。\n变量名称可以在新的大括号内重复使用。\n当代码到达右大括号时，堆栈中的一小部分将被弹出\n\n闭包闭包是一个特殊的匿名函数, 它是匿名函数和相关引用环境组成的一个整体\n闭包允许函数在其定义的作用域外部访问变量，即使在函数执行完毕后，这些变量仍然可以被引用和操作。\n下面是一个go的demo：\nfunc wrapper() func() int &#123; // 这里函数的返回值为func()，表示返回一个函数\tx := 0\treturn func() int &#123;\t\tx++\t\treturn x\t&#125;&#125;func main() &#123;\tincrement := wrapper()\tfmt.Println(increment()) // 1\tfmt.Println(increment()) // 2&#125;\n\n在Java中，闭包一般由内部类完成（内部类操作外部类的数据）\n声明顺序函数内的变量必须要声明在使用之前\npackage mainimport &quot;fmt&quot;func main() &#123;\t// fmt.Println(x)\tfmt.Println(y)\t// x := 42 局部变量的声明必须优先于使用&#125;var y = 42\n\n变量覆盖下面是一个，变量覆盖的demo：\nfunc max(x int) int &#123;   return 42 + x&#125;func main() &#123;   max := max(7) // max和函数max()同名   fmt.Println(max) // max现在是一个值，而不再是一个方法&#125;\n\n这种是非常错误的习惯\n同一个包下的不同的代码同一个包下的代码可以写在两个文件内：\npackage mainvar x = 7\n\npackage mainimport &quot;fmt&quot;func main() &#123;   fmt.Println(x)&#125;\n\n但是执行时需要特别注意：\ngo run *.go\n\n或者\ngo build./xxx\n\n空白标识符go中，如果一个变量没有被使用，是会报错的\nfunc main() &#123;\ta := &quot;stored in a&quot;\tb := &quot;stored in b&quot;\tfmt.Println(&quot;a - &quot;, a)\t// b is not being used - invalid code\t// 如果一个变量没有使用到，编译器会报错：b declared but not used&#125;\n\n因此如果函数返回了一个值，但是我们没有用到，就可以使用_来代替：\n下面是一个http的demo：\nfunc main() &#123;\tres, err := http.Get(&quot;http://www.geekwiseacademy.com/&quot;)\tif err != nil &#123;\t\tlog.Fatal(err)\t&#125;\tpage, err := ioutil.ReadAll(res.Body)\tres.Body.Close()\tif err != nil &#123;\t\tlog.Fatal(err)\t&#125;\tfmt.Printf(&quot;%s&quot;, page)&#125;\n\n上面的code使用了err，但是如果我们现在不想校验err，那么就可以像下面一样\nfunc main() &#123;\tres, _ := http.Get(&quot;http://www.geekwiseacademy.com/&quot;)\tpage, _ := ioutil.ReadAll(res.Body)\tres.Body.Close()\tfmt.Printf(&quot;%s&quot;, page)&#125;\n\n常量声明与变量一样，有作用域：\nconst p = &quot;death &amp; taxes&quot;func main() &#123;\tconst q = 42&#125;\n\n声明多个常量可以使用括号：\nconst (\tpi       = 3.14\tlanguage = &quot;Go&quot;)\n\niota（类似于Java的枚举类型）\n有时候，我们只希望做一些区分（仅仅使用数字来区分，而不是字符串，没有实际的意义）就可以使用iota\n// 方式一const (\ta = iota // 0\tb = iota // 1\tc = iota // 2)// 方式二：第一个之后的省略const (\ta = iota // 0\tb        // 1\tc        // 2)// 方式三：可以用_省略第一个0，之后的可以给新的值const (\t_  = iota             // 0\tKB = 1 &lt;&lt; (iota * 10) // 1 &lt;&lt; (1 * 10)\tMB = 1 &lt;&lt; (iota * 10) // 1 &lt;&lt; (2 * 10)\tGB = 1 &lt;&lt; (iota * 10) // 1 &lt;&lt; (3 * 10)\tTB = 1 &lt;&lt; (iota * 10) // 1 &lt;&lt; (4 * 10))\n\n指针与C语言一样，go语言使用指针来操作内存地址：\na := 43fmt.Println(a) // 43fmt.Println(&amp;a) // 0xc000016098var b = &amp;a  // b的类型是一个int型的指针fmt.Println(b) // 0xc000016098fmt.Printf(&quot;%T \\n&quot;, b) // *intfmt.Println(*b) // 43\n\n取地址符&amp;和取内容符*（或者成为引用reference和逆向引用dereference）\n指针最大的作用就是实现地址传递，而不是值传递\n在Java中，如果一个方法传递了一个数组，默认是引用传递；在Go中除非你传递指针，否则是一个值传递。\n（也可以这么理解：go中的一切都是值传递，传递地址也是传递了一个值）\n下面是一个地址传递的demo：\nfunc zero(z *int) &#123;\t*z = 0&#125;func main() &#123;\tx := 5\tzero(&amp;x)\tfmt.Println(x) // x is 0&#125;\n\nfor循环在go中，只有for循环\n// 方式一：使用分号隔开，同Javafor i := 0; i &lt;= 100; i++ &#123;    fmt.Println(i)&#125;// 方式二：只有一个判断条件，这种很像whilei := 0for i &lt; 10 &#123;    fmt.Println(i)    i++&#125;// 死循环，直接for即可i := 0for &#123;    fmt.Println(i)    i++&#125;\n\nbreak与continue与其他语言一样\n除此外，还有类似foreach的遍历方式：for range的遍历方式\nfunc main() &#123;\tn := average(43, 56, 87, 12, 45, 57)\tfmt.Println(n)&#125;func average(sf ...float64) float64 &#123;\tfmt.Println(sf)\tfmt.Printf(&quot;%T \\n&quot;, sf)\tvar total float64    // 第一个参数是序号，第二个参数是值\tfor _, v := range sf &#123;\t\ttotal += v\t&#125;\treturn total / float64(len(sf))&#125;\n\nswitch语句switch语句和Java之类的语言的区别在于，case不会顺序执行，会自动break；\n额外提供了fallthrough关键字来提供向下执行的功能。\ndemo1：\nstate := &quot;Mhi&quot;switch state &#123;case &quot;Daniel&quot;:    fmt.Println(&quot;Wassup Daniel&quot;)case &quot;Medhi&quot;:    fmt.Println(&quot;Wassup Medhi&quot;)case &quot;Jenny&quot;:    fmt.Println(&quot;Wassup Jenny&quot;)default:    fmt.Println(&quot;Have you no friends?&quot;)&#125;\n\n执行结果是输出：Have you no friends?\n可见：\n\ncase执行完成后会自动break，不会向下顺序执行（如果还想继续执行，那么使用fallthrough）\n没有匹配到相应的语句就会进入default分支\n\ndemo2：\nswitch state &#123;case &quot;Tim&quot;:\tfmt.Println(&quot;Wassup Tim&quot;)case &quot;Jenny&quot;:\tfmt.Println(&quot;Wassup Jenny&quot;)case &quot;Marcus&quot;:\tfmt.Println(&quot;Wassup Marcus&quot;)\tfallthroughcase &quot;Medhi&quot;:\tfmt.Println(&quot;Wassup Medhi&quot;)\tfallthroughcase &quot;Julian&quot;:\tfmt.Println(&quot;Wassup Julian&quot;)case &quot;Sushant&quot;:\tfmt.Println(&quot;Wassup Sushant&quot;)\n\n输出：\nWassup MarcusWassup MedhiWassup Julian\n\n可见：\n\nfallthrough只会继续向下执行一个（一般能不使用这个关键字就不要使用，会使得逻辑混乱）\n\nif语句基本的结构是if elseif else：\nif false &#123;    fmt.Println(&quot;first print statement&quot;)&#125; else if true &#123;    fmt.Println(&quot;second print statement&quot;)&#125; else &#123;    fmt.Println(&quot;third print statement&quot;)&#125;\n\n除了基本的使用方法外，go中还支持if初始化一个属于if域的值\nb := trueif food := &quot;Chocolate&quot;; b &#123;     // 这里初始化了一个food变量，只能在这个块域中使用    fmt.Println(food)&#125;// 这里不能使用food\n\n函数关于函数和方法的区别函数一般指执行特定功能的一段代码；\n方法特定于面向对象语言中，一个类执行的一些函数；\n所以在Java中，函数等于方法；\n但是在Go中，函数是函数，方法是类中的函数。\n函数的结构\nmain函数是程序的入口\n普通的函数的结构是func functionName(param1 typ1, ...) returnValue&#123;&#125;\n\nfunc main() &#123;\tfmt.Println(greet(&quot;Jane &quot;, &quot;Doe&quot;))&#125;// 参数可以传入多个，和声明多个变量一样；返回值在后面写func greet(fname, lname string) string &#123;    //Sprint方法会拼接两个参数，当参数不是字符串时会添加空格\treturn fmt.Sprint(fname, lname)&#125;\n\n\n函数可以有多个返回值（Java只能有一个返回值）\n\nfunc greet(fname, lname string) (string, string) &#123;\treturn fmt.Sprint(fname, lname), fmt.Sprint(lname, fname)&#125;\n\n一般使用多返回值的特性来返回结果值和错误情况，下面这个demo就是一个多返回值且使用了命名返回\nfunc ReturnId() (id int, err error) &#123;   id = 10   return&#125;\n\n\n传入多个参数使用...\n\n下面这个例子计算平均值\nfunc main() &#123;\tn := average(43, 56, 87, 12, 45, 57)\tfmt.Println(n)&#125;func average(sf ...float64) float64 &#123;\tfmt.Println(sf)\tfmt.Printf(&quot;%T \\n&quot;, sf)\tvar total float64\tfor _, v := range sf &#123;\t\ttotal += v\t&#125;\treturn total / float64(len(sf))&#125;\n\n\n...可以用来拆解数组\n\nfunc main() &#123;\tdata := []float64&#123;43, 56, 87, 12, 45, 57&#125;\tn := average(data...) // 将数组拆散输入\tfmt.Println(n)&#125;func average(sf ...float64) float64 &#123;\ttotal := 0.0\tfor _, v := range sf &#123;\t\ttotal += v\t&#125;\treturn total / float64(len(sf))&#125;\n\n命名返回可以给返回值指定一个变量名，返回时会自动返回\nfunc greet(fname string, lname string) (s string) &#123;\ts = fmt.Sprint(fname, lname)\treturn&#125;\n\n注意：要避免使用命名返回\n要注意命名覆盖的情况：\nfunc ReturnId() (id int, err error) &#123;   id = 10   if id == 10 &#123;      err := fmt.Errorf(&quot;无效的 Id\\n&quot;)      // 这里会编译错误，因为你重新声明并赋值了err      return   &#125;   return&#125;\n\n这种情况与下面的情况一样，go中不允许重复声明一个变量并且给其赋值\nfunc main() &#123;   id := 10   id := 20   fmt.Printf(&quot;Id: %d\\n&quot;, id)&#125;\n\n\n大括号定义了一个新的堆栈框架，因此定义了一个新的范围级别。变量名称可以在新的大括号内重复使用。当代码到达右大括号时，堆栈中的一小部分将被弹出。\n\n因此一个大括号内，不要出现两个相同命名的变量\n函数表达式变量可以赋值为一个函数\ngreeting := func() &#123;    fmt.Println(&quot;Hello world!&quot;)&#125;greeting() // 变量名() 就可以调用函数fmt.Printf(&quot;%T\\n&quot;, greeting) // 输出 func()\n\n甚至可以不给名字：\nfunc main() &#123;\tfunc() &#123;\t\tfmt.Println(&quot;I&#x27;m driving!&quot;)\t&#125;()&#125;\n\n\n函数的返回值可以是一个函数\n\nfunc makeGreeter() func() string &#123;\treturn func() string &#123;\t\treturn &quot;Hello world!&quot;\t&#125;&#125;func main() &#123;\tgreet := makeGreeter()\tfmt.Println(greet())&#125;\n\n\n参数也可以传入函数\n\n下面这个例子过滤掉数组中所有小于等于1的数字\nfunc filter(numbers []int, callback func(int) bool) []int &#123;\tvar xs []int\tfor _, n := range numbers &#123;\t\tif callback(n) &#123;// callback返回一个bool\t\t\txs = append(xs, n)\t\t&#125;\t&#125;\treturn xs&#125;func main() &#123;    // 传入一个数组和一个函数\txs := filter([]int&#123;1, 2, 3, 4&#125;, func(n int) bool &#123;\t\treturn n &gt; 1\t&#125;)\tfmt.Println(xs) // [2 3 4]&#125;\n\ndefer关键字defer关键字可以延迟一个函数的执行直到本方法执行结束：\nfunc hello() &#123;\tfmt.Println(&quot;hello &quot;)&#125;func world() &#123;\tfmt.Println(&quot;world&quot;)&#125;func main() &#123;\tfmt.Println(1)\tdefer world() // 延迟world的执行\tfmt.Println(2)\thello()\tfmt.Println(3)&#125;\n\n输出的结果是：省去了换行\n1 2 hello 3 world\n注意：\n\ndefer和return谁先谁后？return先，defer后\n\n当多个defer出现的时候，是以栈的方式调用的，先进后出\n\n\n\n数组声明方式\n使用中括号，中间的数字表示数组的大小\n\nvar x [58]intfmt.Println(x)// 会把数组的每一位都打印出来：[0 0 0 0 00 0 0 0 0 0 0 // 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0// 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]fmt.Println(len(x)) // 58fmt.Println(x[42]) // 0x[42] = 777fmt.Println(x[42]) // 777fmt.Printf(&quot;%T&quot;, x)// [58]int\n\n这种方式限制了数组的大小，如果需要可以扩容的数组，使用切片slice\n获取数组的长度可以使用len(数组)\n数组的遍历数组的遍历，除了普通的for循环，可以使用foreach\nvar x [256]intfmt.Println(len(x))fmt.Println(x[42])// 普通方式for i := 0; i &lt; 256; i++ &#123;    x[i] = i&#125;// foreachfor i, v := range x &#123;    fmt.Printf(&quot;%v - %T - %b\\n&quot;, v, v, v)    if i &gt; 50 &#123;        break    &#125;&#125;\n\n切片int切片\n声明有两种方式：\n\n1、当明确数组的内容时，可以不写大小，进行推断：\nmySlice := []int&#123;1, 3, 5, 7, 9, 11&#125;// 或者使用varvar student []stringstudent := []int&#123;&#125;// 注意使用:=时，要加&#123;&#125;\n\n2、使用make进行分配()\nmySlice := make([]int, 0, 3)\n\n\n注意：make方式传入三个参数：\n\n1、数组的类型；\n2、数组的长度，可以使用len()获取；\n3、数组的容量，可以使用cap()获取（如果没有输入第三个参数，那么容量与长度相等）\n\n切片是可以进行自动扩容的，每次扩容为2倍原始的大小\n\n添加元素：\n\n\n1、切片添加元素可以使用下标进行赋值（这种方式不能越过容量大小！）\n2、使用append()，按顺序进行添加，会自动进行扩容\nmySlice := make([]int, 0, 3)fmt.Println(mySlice) // []fmt.Println(len(mySlice)) // 0fmt.Println(cap(mySlice)) // 3for i := 0; i &lt; 80; i++ &#123;    mySlice = append(mySlice, i)    fmt.Println(&quot;Len:&quot;, len(mySlice), &quot;Capacity:&quot;, cap(mySlice), &quot;Value: &quot;, mySlice[i])&#125;/*输出结果为：Len: 1 Capacity: 3 Value:  0   Len: 2 Capacity: 3 Value:  1   Len: 3 Capacity: 3 Value:  2   Len: 4 Capacity: 6 Value:  3 在这里可以看到容量翻倍了....*/\n\n\n与python一样，切片可以使用[:]进行切片\n\nmySlice := []int&#123;1, 3, 5, 7, 9, 11&#125;// 1、一个参数，表示按index访问对应的数字fmt.Println(mySlice[1]) // 3// 2、两个参数，左闭右开区间，返回的也是一个切片fmt.Println(mySlice[2:3]) // [5] 左闭右开区间fmt.Println(mySlice[2:5]) // [5 7 9]fmt.Println(mySlice[0:6]) // [1 3 5 7 9 11]// fmt.Println(mySlice[2:99]) //执行报错 panic: runtime error: slice bounds out of range [:99] with capacity 6// fmt.Println(mySlice[-1:]) // 不允许是负数，编译报错// 3、两个参数前后可以省略，表示从头开始或者结束fmt.Println(mySlice[:3]) //[1 3 5]fmt.Println(mySlice[3:]) //[7 9 11]fmt.Println(mySlice[:]) // [1 3 5 7 9 11]\n\n注意：与python不同的是，go的切片只支持两个参数，没有第三个参数步进\n\n切片使用append添加切片，使用...\n\nmySlice := []int&#123;1, 2, 3, 4, 5&#125;myOtherSlice := []int&#123;6, 7, 8, 9&#125;mySlice = append(mySlice, myOtherSlice...)// 如果你没有加...，代表着添加这个切片，而不是添加切片的元素！！mySlice = append(mySlice, myOtherSlice) // 与上面的区分\n\n\n切片也可以删除元素\n\nmySlice := []string&#123;&quot;Monday&quot;, &quot;Tuesday&quot;&#125;myOtherSlice := []string&#123;&quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;&#125;mySlice = append(mySlice, myOtherSlice...)fmt.Println(mySlice) //[Monday Tuesday Thursday Friday]ay Friday]mySlice = append(mySlice[:2], mySlice[3:]...)fmt.Println(mySlice) // 输出是空\n\nstring切片与int切片基本一致，除此外可以使用string访问对应元素\n&quot;AaBb&quot;[0] // 得到的是一个值 97\n\n声明方式的区别使用var和使用:=的区别是什么？\nvar student []stringstudent := []int&#123;&#125;\n\n\nvar student []string：\n这是一个声明切片类型的变量 student，但没有分配内存空间给它。\n此时，student 的值是 nil，表示它不引用任何底层数组，也没有分配内存，因此不能进行读取或写入操作。\n\n\nstudent := []int&#123;&#125;：\n这是使用切片字面量创建一个空切片，并分配了内存空间。\n这个切片引用了一个底层数组，虽然它是空的，但是可以安全地进行读取和写入操作。这个切片的长度为0。\n\n\n\n切片与数组的区别\n如何区分切片和数组？\n\n声明时是否限制了大小？\n\n如果student := [3]int，这就是一个数组\n如果是student := []int&#123;&#125;或是使用了make，就是一个切片\n\n\n切片与数组的区别是什么？\n\n\n内存方面，数组是一个连续的内存地址；而切片不是\n底层数组：数组是一个固定长度的内存块；而切片是一个地址，指向底层数组\n是否可变：数组长度不可变；切片长度可变\n参数传递：数组传递会copy一个数组（值传递）；切片直接传递地址（地址传递）\n\nmap声明方式与变量一样\n// 方式一：var声明 map[key]value，这种方式下还没分配内存 myGreeting = nilvar myGreeting map[string]string// 方式二：:=myGreeting := make(map[string]string)myGreeting := map[string]string&#123;    &quot;Tim&quot;:   &quot;Good morning!&quot;,    &quot;Jenny&quot;: &quot;Bonjour!&quot;,&#125;// 方式三：makevar myGreeting = make(map[string]string)myGreeting := map[string]string&#123;&#125;\n\n\n获取长度使用len\n\nlen\n\n\n添加、删除、判断元素是否存在\n\nmyGreeting := map[int]string&#123;    0: &quot;Good morning!&quot;,    1: &quot;Bonjour!&quot;,&#125;// 添加元素myGreeting[2] = &quot;Buenos dias!&quot;// 删除元素delete(myGreeting, 1)// 检查元素是否存在，使用第二个参数if val, exists := myGreeting[2]; exists &#123;    fmt.Println(&quot;That value exists.&quot;)    fmt.Println(&quot;val: &quot;, val)    fmt.Println(&quot;exists: &quot;, exists)&#125;\n\n\n遍历操作\n\nmyGreeting := map[int]string&#123;    0: &quot;Good morning!&quot;,    1: &quot;Bonjour!&quot;,    2: &quot;Buenos dias!&quot;,    3: &quot;Bongiorno!&quot;,&#125;for key, val := range myGreeting &#123;    fmt.Println(key, &quot; - &quot;, val)&#125;\n\nGo结构体Go的面向对象\n封装：类和结构体\n\n在Java中，面向对象编程的基本单位是类（class）\n在Go中，没有类的概念，而是使用结构体（struct）来定义自定义数据类型。Go通过在结构体上定义方法来实现面向对象编程，而不是使用类。\n\n\n继承：Go中的继承更像是组合\n\nJava支持继承，您可以创建一个子类，继承父类的属性和方法，并在子类中添加或覆盖它们。\nGo不支持显式的继承。相反，Go鼓励使用组合来重用代码，通过将一个结构体嵌入到另一个结构体中来实现组合。这被称为嵌入式类型。\n\n\n多态：接口\n\nJava使用接口（interface）来定义抽象方法，类可以实现一个或多个接口。\n\nGo也支持接口，但与Java不同，Go的接口是隐式的，即类型实现接口的方式不需要明确声明。只要一个类型实现了接口所定义的方法，它就被认为实现了该接口。\n\n\n\n\n封装使用type Name struct来声明一个结构体：\n// 结构体、结构体的值、方法，开头大写表示公有，小写表示私有type person struct &#123;\tname string\tage  int&#125;// 方法前面使用()指定属于哪一个架构体// 加*是地址传递，不加是值传递func (this *person) SetName(newName string) &#123;\tthis.name = newName&#125;func (this *person) GetName() string &#123;\treturn this.name&#125;\n\n\n注意：当只有一个数据类型时，是一个别名\ntype myInt int\n\n此时myInt就是int的一个别名，没有别的作用\n继承\n在Go中使用组合的方式去实现“继承”\n\ntype person struct &#123;\tFirst string\tLast  string\tAge   int&#125;type doubleZero struct &#123;\tperson // doubleZero继承了person\tLicenseToKill bool&#125;\n\n\n子类可以重新定义属性或方法区覆盖父类的属性或方法\n\ntype person struct &#123;\tName string\tAge  int&#125;func (p person) Greeting() &#123;\tfmt.Println(&quot;父类方法&quot;)&#125;type doubleZero struct &#123;\tperson\tLicenseToKill bool&#125;// 这里重写了父类的Greeting方法func (dz doubleZero) Greeting() &#123;\tfmt.Println(&quot;子类方法&quot;)&#125;func main() &#123;    // 定义一个父类\tp1 := person&#123;\t\tName: &quot;A&quot;,\t\tAge:  44,\t&#125;\t// 定义一个子类\tp2 := doubleZero&#123;\t\tperson: person&#123;\t\t\tName: &quot;B&quot;,\t\t\tAge:  23,\t\t&#125;,\t\tLicenseToKill: true,\t&#125;\tp1.Greeting()        // 父类方法\tp2.Greeting()        // 子类方法\tp2.person.Greeting() // 父类方法&#125;\n\n多态Go使用接口来实现多态\n// 使用关键字interface来声明一个接口type shape interface &#123;\tarea() float64&#125;type square struct &#123;\tside float64&#125;func (this *square) area() float64 &#123;\treturn this.side * this.side&#125;type circle struct &#123;\tradius float64&#125;func (this *circle) area() float64 &#123;\treturn math.Pi * math.Pow(this.radius, 2)&#125;func main() &#123;\t// 声明一个接口\tvar shape1 shape\t// 接口的本质是一个指针，所以要用取地址符&amp;\tshape1 = &amp;square&#123;10&#125;\tfmt.Println(shape1.area())\t\tshape1 = &amp;circle&#123;4&#125;\tfmt.Println(shape1.area())&#125;\n\n\nsquare和circle什么时候实现了shape接口呢？\n\nGo中，只要一个类型实现了接口所定义的方法，它就被认为实现了该接口。\n结构体标签结构体还可以添加标签来对属性进行说明：\ntype User struct &#123;\tNickname string `info:&quot;登录ID&quot; doc:&quot;nickname不可以重复&quot;`\tPassword string `info:&quot;登录密码&quot; doc:&quot;不可以设置过于简单&quot;`&#125;\n\n标签可以使用反射获取\n不过主要的用途还是用来进行orm映射或是json序列化使用：\ntype LoginUser struct &#123;    // 这里指定了json化的映射关系\tNickname string `json:&quot;nickname&quot;`\tPassword string `json:&quot;passwd&quot;`&#125;func main() &#123;\tuser1 := LoginUser&#123;&quot;小李&quot;, &quot;123&quot;&#125;\tres, err := json.Marshal(user1)\tif err != nil &#123;\t\tfmt.Println(&quot;json marshal error&quot;, err)\t\treturn\t&#125;\tfmt.Println(string(res))\t// &#123;&quot;nickname&quot;:&quot;小李&quot;,&quot;passwd&quot;:&quot;123&quot;&#125;\tuser2 := LoginUser&#123;&#125;\terr = json.Unmarshal(res, &amp;user2)\tif err != nil &#123;\t\tfmt.Println(&quot;json marshal error&quot;, err)\t\treturn\t&#125;\tfmt.Println(user2)\t// &#123;小李 123&#125;&#125;\n\n\n\n空接口interface&#123;&#125;类型断言与Java中的Object类似，Go中的一切，甚至包括基础类型int、bool都是空接口的实现。\ninterface&#123;&#125;\n\n空接口提供了“类型断言”的机制来判断是哪一种类型：\nfunc main() &#123;    // 向上转型\tvar name interface&#123;&#125; = &quot;Sydney&quot;\t// 注意：只有空接口才有这个方法    // 两个返回值：值与是与不是\tstr, ok := name.(string) // name是不是string类型？\tif ok &#123;\t\tfmt.Printf(&quot;%T\\n&quot;, str)\t&#125; else &#123;\t\tfmt.Printf(&quot;value is not a string\\n&quot;)\t&#125;&#125;\n\n类型转换空接口向下转型使用断言\nvar val interface&#123;&#125; = 7fmt.Printf(&quot;%T\\n&quot;, val.(int))\n\n普通类型转型直接转即可\nrem := 7.24fmt.Printf(&quot;%T\\n&quot;, int(rem))\n\n这里列出一些常见的类型转换：\n// int与float相互转换float64(x)int(x)// int转为stringstring(x)// byte数组与stringstring([]byte&#123;&#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;, &#x27;o&#x27;&#125;)[]byte(&quot;hello&quot;)// go还有strconv包来帮助我们转换strconv.Atoi(x) // A表示string、i表示int，表示string转为intstrconv.Itoa(x)\t// 与上面相反strconv.ParseBool(&quot;true&quot;) // 解析string为boolstrconv.ParseFloat(&quot;3.1415&quot;, 64) // 解析string为floatstrconv.ParseInt(&quot;-42&quot;, 10, 64) // 解析string为intstrconv.ParseUint(&quot;42&quot;, 10, 64) // 解析string为int\n\n反射pair结构Go中的变量包括（type, value）两部分\n\ntype：type有两种\nstatic type：编码时的类型，静态类型，比如int、string\nconcrete type：runtime系统看见的类型\n\n\nvalue：变量的值\n\n空接口interface&#123;&#125;有两个指针：一个指针指向值的类型【对应concrete type】，另外一个指针指向实际的值【对应value】\n（只有运行时的类型才有反射一说，基本类型没有反射这个概念）\nfunc main() &#123;    // tty: pair&lt;type: *os.File, value: &quot;/dev/tty&quot;的文件描述符&gt;\ttty, err := os.OpenFile(&quot;/dev/tty&quot;, os.O_RDWR, 0)\tif err != nil &#123;\t\tfmt.Println(&quot;open file error&quot;, err)\t\treturn\t&#125;    // r: pair&lt;type: , value: &gt;\tvar r io.Reader    // r: pair&lt;type: *os.File, value: &quot;/dev/tty&quot;的文件描述符&gt;\tr = tty    // w: pair&lt;type: ,value: &gt;\tvar w io.Writer        // w: pair&lt;type: *os.File, value: &quot;/dev/tty&quot;的文件描述符&gt;\tw = r.(io.Writer)// 这里的断言为什么能成功呢？\tw.Write([]byte(&quot;HELLO THIS IS A TEST!!!\\n&quot;))&#125;\n\nw = r.(io.Writer)这里的断言为什么能成功呢？\n是因为r变量的concrete type（即*os.File）也实现了w的方法！因此可以成功。\n类型断言的本质：变量的concrete type实现了要转换类型的方法\n反射获取类型和方法go提供了reflect包，主要有两个方法\n//ValueOf用来获取输入参数接口中的数据的值，如果接口为空则返回0func ValueOf(i interface&#123;&#125;) Value &#123;...&#125;//TypeOf用来动态获取输入参数接口中的值的类型，如果接口为空则返回nilfunc TypeOf(i interface&#123;&#125;) Type &#123;...&#125;\n\n对于基本的类型：\nx := 15fmt.Println(reflect.TypeOf(x))  // intfmt.Println(reflect.ValueOf(x)) // 15\n\n对于复杂类型，比如说结构体：\n结构体结构如下：\ntype User struct &#123;\t// 反射只能获取到公有的变量\tNickname string `info:&quot;登录ID&quot; doc:&quot;nickname不可以重复&quot;`\tPassword string `info:&quot;登录密码&quot; doc:&quot;不可以设置过于简单&quot;`&#125;// 反射只能获取到公有的方法func (this *User) Login() &#123;\tfmt.Println(this.Nickname)\tfmt.Println(this.Password)&#125;\n\n反射的NumField()和NumMethod()只能获取公有的属性和方法\n// 对于复杂类型：结构体user := User&#123;Nickname: &quot;hynis&quot;, Password: &quot;123&quot;&#125;// 1、获取TypeuserType := reflect.TypeOf(user)fmt.Println(userType)// 2、获取valueuserValue := reflect.ValueOf(user)fmt.Println(userValue)// 3、通过type获取字段for i := 0; i &lt; userType.NumField(); i++ &#123;    field := userType.Field(i)    value := userValue.Field(i).Interface()    fmt.Printf(&quot;%s: %v=%v\\n&quot;, field.Name, field.Type, value)&#125;// 4、通过type获取方法for i := 0; i &lt; userType.NumMethod(); i++ &#123;    method := userType.Method(i)    fmt.Printf(&quot;%s = %v&quot;, method.Name, method.Type)&#125;// 5、获取标签的内容for i := 0; i &lt; userType.NumField(); i++ &#123;    tagInfo := userType.Field(i).Tag.Get(&quot;info&quot;)    tagDoc := userType.Field(i).Tag.Get(&quot;doc&quot;)    fmt.Println(&quot;info:&quot;, tagInfo, &quot;doc&quot;, tagDoc)&#125;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","categories":["Golang"],"tags":["Golang"]},{"title":"Git远程库","url":"/2019/07/29/Git/Git%E8%BF%9C%E7%A8%8B%E5%BA%93/","content":"\n引言：\n\ngit的远程仓库如何建立？\ngit下半部分\n\n\n\n\n\n远程仓库（远程版本库）Git是分布式版本控制系统，同一个Git仓库，可以分布到不同的机器上。\n怎么分布呢？最早，肯定只有一台机器有一个原始版本库，此后，别的机器可以“克隆”这个原始版本库，而且每台机器的版本库其实都是一样的，并没有主次之分。\n实际情况通常是这样：\n找一台电脑充当服务器的角色，每天24小时开机，其他每个人都从这个“服务器”仓库克隆一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交。\n注册一个GitHub账号，就可以免费获得Git远程仓库。\n由于你的本地Git仓库和GitHub仓库之间的传输是通过SSH加密的，所以，需要一点设置：\n\n创建SSH Key\n\n在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash），创建SSH Key：\nssh-keygen -t rsa -C &quot;youremail@example.com&quot;\n注意这里的-C是大写的，然后一路enter，使用默认值\n之后我们可以在 用户主目录(~) 找到一个.ssh的文件目录，内部有id_rsa和id_rsa.pub，这两个就是SSH Key的密钥对，前者是私钥，不能泄露出来，后者是公钥，可以告诉任何人\n\n登录Github\n\n点击步骤：\nsetting -&gt; SSH and GPG keys -&gt;  New SSH -&gt; 随便输入一个Title -&gt; 把id_rsa.pub文件的内容复制到key文本框内\n为什么GitHub需要SSH Key呢？\n因为GitHub需要识别出你推送的提交确实是你推送的，而不是别人冒充的，而Git支持SSH协议，所以，GitHub只要知道了你的公钥，就可以确认只有你自己才能推送。\n最后友情提示，在GitHub上免费托管的Git仓库，任何人都可以看到喔（但只有你自己才能改）。\n如果你不想让别人看到Git库，有两个办法\n一个是交点保护费，让GitHub把公开的仓库变成私有的，这样别人就看不见了（不可读更不可写）。\n另一个办法是自己动手，搭一个Git服务器，因为是你自己的Git服务器，所以别人也是看不见的。这个方法我们后面会讲到的，相当简单，公司内部开发必备。\n添加远程库我们还得再github上建一个库\n点击步骤：\nnew repository -&gt; 输入库的名称 -&gt; 其他默认，点击Create repository\n目前，这个库是空的\n我们可以从这个仓库克隆出新的仓库，也可以把一个已有的本地仓库与之关联\n现在我们在本地的仓库下运行\n$ git remote add origin git@github.com:YourGitHubId/learngit.git\n添加后，远程库的名字就是origin，这是git默认的叫法\n输入git push -u origin master就可以把本地库的所有内容推送到远程库\n使用这个命令，其实是吧当前分支master推送到了远程\n由于远程库是空的，我们加了-u参数，Git不但会把本地的master分支内容推送到远程新的master分支，还会把本地的master分支和远程的master分支关联起来，以后推送或者拉取时就可以简化命令\n注意：执行这条命令，你的版本库必须有东西\n如果你的版本库是空的，则会报错\nerror: src refspec master does not match any\n\n成功后我们就可以在github上看到远程库的内容和本地的一模一样\n从此，只要本地做了提交，就可以通过命令\ngit push origin master\n把本地master分支的最新修改推送至GitHub\nSSH警告当第一次使用Git的clone或者push命令连接到Github上时，会得到一个警告\nThe authenticity of host &#x27;github.com (xx.xx.xx.xx)&#x27; can&#x27;t be established.RSA key fingerprint is xx.xx.xx.xx.xx.Are you sure you want to continue connecting (yes/no)?\n这是因为Git使用SSH连接，而SSH连接在第一次验证GitHub服务器的Key时，需要你确认GitHub的Key的指纹信息是否真的来自GitHub的服务器，输入yes回车即可。\nGit会输出一个警告，告诉你已经把GitHub的Key添加到本机的一个信任列表里了：\nWarning: Permanently added &#x27;github.com&#x27; (RSA) to the list of known hosts.\n这个警告只会出现一次，后面的操作就不会有任何警告了。\n从远程仓库克隆现在，假设我们从零开发，那么最好的方式是先创建远程库，然后，从远程库克隆。\n登录GitHub，建立一个新的仓库\n勾选Initialize this repository with a README,这样GitHub会自动给我们创建一个README.md的文件\n使用命令\n$ git clone git@github.com:YourGitHubId/gitskills.git\n就可以克隆到你当前的位置了\n你也许还注意到，GitHub给出的地址不止一个，还可以用https://github.com/YourId/gitskills.git\n这样的地址。实际上，Git支持多种协议，默认的git://使用ssh，但也可以使用https等其他协议。\n使用https除了速度慢以外，还有个最大的麻烦是每次推送都必须输入口令，但是在某些只开放http端口的公司内部就无法使用ssh协议而只能用https。\n分支管理分支有什么用呢？\n创建了一个属于你自己的分支，别人看不到，还继续在原来的分支上正常工作，而你在自己的分支上干活，想提交就提交，直到开发完毕后，再一次性合并到原来的分支上。\n创建与合并分支HEAD指向当前分支, master指向提交\n\n在最开始\n\nmatser是一条线,Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点\n\n每次提交\n\nmaster分支都会向前移动一步，随着不断的提交，master分支也就会越来越长\n\n当我们创建新的分支，例如dev\n\nGit创建了一个新的指针dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上\n由于是指针，所以Git创建分支非常快\n从现在开始，对工作区的修改和提交就是对dev分支,比如新提交一次后，dev指针往前移动一步，而master指针不变：\n假如我们在dev上的工作完成了，就可以把dev合并到master上，直接把master指向dev的当前提交，就完成了合并\n合并完成后，可以删除dev分支，删除dev分支就是把dev指针给删掉，删掉后我们就剩下了一条masrer分支\n知道原理我们开始实战：\n第一步：\n新建一个文件夹-&gt;git init-&gt;新建一个文件，随便加上些内容-&gt;git add-&gt;git commit\n第二步：\n创建一个分支,输入命令\ngit branch dev\n第三步：\n切换到该分支\ngit checkout dev\nBlackKnight@LAPTOP-JQFP1S4M MINGW64 /d/gitLearn (master)$ git branch devBlackKnight@LAPTOP-JQFP1S4M MINGW64 /d/gitLearn (master)$ git checkout devSwitched to branch &#x27;dev&#x27;BlackKnight@LAPTOP-JQFP1S4M MINGW64 /d/gitLearn (dev)\n(第二步第三部可以合为一步：\ngit checkout -b dev\n创建并切换一气呵成)\n第四步：\n输入命令\ngit branch\n查看当前分支\n$ git branch* dev  master\n处于哪一个分支，前面会有一个*号\n第五步：\n修改文件内容,并且git add执行git commit，然后切换回master分支，查看文件，发现修改的内容不见了\n第六步：\n合并dev分支的内容到master上,输入命令\ngit merge dev\ngit merge命令用于合并指定分支到当前分支\n再次查看文件，发现修改回来了\n$ git merge devUpdating 7666beb..19ed9b4Fast-forward hello.txt | 3 ++- 1 file changed, 2 insertions(+), 1 deletion(-)\n注意到上面有Fast-forward信息，意思是“快进模式”，也就是会直接把master指向dev的当前提交，所以合并速度十分快，之后会将其他的合并方式\n第七步：\n合并完成后，可以删除dev分支了\ngit branch -d dev\n输入git branch查看分支状态\n$ git branch* master\n发现只有一个分支了\n解决冲突合并分支，可能遇到冲突的问题\n准备一个新的分支\n$ git checkout -b featurelSwitched to a new branch &#x27;featurel&#x27;\n\n修改文件的内容,最后一行加一个bye world,并且添加add提交commit\n切换到master分支git checkout master\n更改文件内容,最后一行加hello world,然后继续add和commit\n现在，分支就变成了这个样子\n合并分支\n$ git merge featurelAuto-merging hello.txtCONFLICT (content): Merge conflict in hello.txtAutomatic merge failed; fix conflicts and then commit the result.\n消息告诉我们，文件存在冲突，必须手动解决冲突再提交\n打开我们的文件\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADhello world=======bye world&gt;&gt;&gt;&gt;&gt;&gt;&gt; featurel\ngit用这种方式标记出不同分支的内容\n我们修改为bye world后再add提交commit\n现在分支成为了这个样子\n用git log --graph可显示分支图\n*   commit 24143f569703452d66dd7c4df3c65ed48a70aec5|\\  Merge: 6b29d3c 4c0b8fa| | Author: YesYourHighness &lt;1046467756@qq.com&gt;| | Date:   Mon Jul 29 11:05:23 2019 +0800| || |     conflict fixed| || * commit 4c0b8fa27ff654311802bc3db98dc085cd4e0dd3 (featurel)| | Author: YesYourHighness &lt;1046467756@qq.com&gt;| | Date:   Mon Jul 29 10:54:24 2019 +0800| || |     init| |* | commit 6b29d3cabf64b2ac9a65cc2677dbcb41b8bc4cfc|/  Author: YesYourHighness &lt;1046467756@qq.com&gt;|   Date:   Mon Jul 29 10:55:40 2019 +0800|\n最后删除分支\n分支管理策略合并分支时，Git会尽量用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。\n如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。\n我们实战一下--no-ff方式的git merge\n首先创建并切换dev分支\ngit checkout -b dev\n修改文件内容，并且提交一个新的commit\n然后切换回master\n然后合并分支，注意--no-ff参数表示禁用Fast forward模式,因为会自动创建一个commit我们需要加-m\n$ git merge --no-ff -m &#x27;merge with no-ff&#x27; devMerge made by the &#x27;recursive&#x27; strategy. hello.txt | 3 ++- 1 file changed, 2 insertions(+), 1 deletion(-)\n我们用git log --graph查看分支\n*   commit 061646bf6b4321746b6f27f1926a528f7dec16e3 (HEAD -&gt; master)|\\  Merge: bb2ba62 405dd2a| | Author: YesYourHighness &lt;1046467756@qq.com&gt;| | Date:   Mon Jul 29 11:19:31 2019 +0800| || |     merge with no-ff| || * commit 405dd2a7fc7c047c837eee1fac4976a4c213e555 (dev)|/  Author: YesYourHighness &lt;1046467756@qq.com&gt;|   Date:   Mon Jul 29 11:17:29 2019 +0800||       change in dev|\n\n策略在实际开发中，我们应该按照几个基本原则进行分支管理：\n首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活；\n那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本；\n你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以\nBug分支假设你接到一个修复一个代号101的bug的任务时，很自然地，你想创建一个分支issue-101来修复它，但是你当前正在dev上进行到一半的工作还没有提交\nGit还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作：\n$ git stashSaved working directory and index state WIP on master: 061646b merge with no-ff\n用git status查看发现是干净的(除非有没有被Git管理的文件)\n首先确定要在哪个分支上修复bug，假定需要在master分支上修复，就从master创建临时分支\n修复完成后，切换到master分支，并完成合并，最后删除分支\n接着回去dev\ngit checkout dev\n发现工作区是干净的,输入\n$ git stash liststash@&#123;0&#125;: WIP on master: 061646b merge with no-ff\n工作现场还在，只是保存到另一个地方了\n需要恢复有两个办法\n第一种：\ngit stash apply恢复后，stash内容并不删除，需要git stash drop来删除\n第二种：\ngit stash pop恢复的同时删除\n这是再查git stash list就看不到任何内容了\n你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令：\n$ git stash apply stash@&#123;0&#125;\n\nFeature分支软件开发中，总有新的功能要不断添加进来。\n添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。\n于是准备开发，在当你add并且提交新的分支之后，切回主分支\n但是经理要求阉割此功能，于是我们要删除这个功能\n$ git branch -d wqerror: The branch &#x27;wq&#x27; is not fully merged.If you are sure you want to delete it, run &#x27;git branch -D wq&#x27;.\ngit阻止了操作，提醒你删除后将丢失数据，强行删除用大写的D\n现在我们强行删除\n$ git branch -D wqDeleted branch wq (was e055832).\n删除成功\n多人协作当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin。\n要查看远程库的信息\ngit remote\n加v可以获得更详细的信息\ngit remote -v\n这条命令显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址。\n推送分支，就是把该分支上的所有本地提交推送到远程库\ngit push origin master\n如果要推送其他分支，比如dev，就改为\ngit push origin dev\n\nmaster分支是主分支，因此要时刻与远程同步；\n\ndev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步；\n\nbug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug；\n\nfeature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。\n\n\n抓取分支\n当你从远程库clone时，默认情况下，你只能看到本地的master分支\n所以想要在dev上开发就必须创建远程的origin的dev分支到本地\ngit checkout -b dev origin/dev\n现在就可以在dev上修改推送了\n多人推送，难免会发生冲突\n解决办法，先把最新的提交pull下来\n$ git pullThere is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details.    git pull &lt;remote&gt; &lt;branch&gt;If you wish to set tracking information for this branch you can do so with:    git branch --set-upstream-to=origin/&lt;branch&gt; dev\n在本地合并解决冲突在推送,但是我们需要先建立本地dev与远程origin/dev的链接\n$ git branch --set-upstream-to=origin/dev devBranch &#x27;dev&#x27; set up to track remote branch &#x27;dev&#x27; from &#x27;origin&#x27;.\n解决冲突，再推就可以了\n因此，多人协作的工作模式通常是这样：\n\n首先，可以试图用git push origin &lt;branch-name&gt;推送自己的修改；\n\n如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并；\n\n如果合并有冲突，则解决冲突，并在本地提交；\n\n没有冲突或者解决掉冲突后，再用git push origin &lt;branch-name&gt;推送就能成功！\n\n\n如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;。\n这就是多人协作的工作模式，一旦熟悉了，就非常简单。\n标签创建标签切换到需要标签的分支\n$ git tag v1.0\n查看所有标签\ngit tag\n也可以找到commit id来打标签\ngit tag v0.9 f52c633\n标签不是按时间顺序列出，而是按字母排序的。\n还可以创建带有说明的标签,-a指定标签名-m指定说明文字\ngit tag -a v0.1 -m &quot;version 0.1 released&quot; 1094adb\n\n可以用git show &lt;tagname&gt;查看标签信息：\n$ git show v1.0commit 061646bf6b4321746b6f27f1926a528f7dec16e3 (HEAD -&gt; master, tag: v1.0)Merge: bb2ba62 405dd2aAuthor: YesYourHighness &lt;1046467756@qq.com&gt;Date:   Mon Jul 29 11:19:31 2019 +0800    merge with no-ff\n\n如果标签打错了，也可以删除：\n$ git tag -d v0.1Deleted tag &#x27;v0.1&#x27; (was f15b0dd)\n因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除\n如果要推送某个标签到远程，使用命令git push origin ：\n$ git push origin v1.0Total 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag]         v1.0 -&gt; v1.0\n或者，一次性推送全部尚未推送到远程的本地标签：\n$ git push origin --tagsTotal 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag]         v0.9 -&gt; v0.9\n 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除：\n$ git tag -d v0.9Deleted tag &#x27;v0.9&#x27; (was f52c633)\n然后，从远程删除。删除命令也是push，但是格式如下：\n$ git push origin :refs/tags/v0.9To github.com:michaelliao/learngit.git - [deleted]         v0.9","categories":["Git"],"tags":["Git"]},{"title":"JDBC-1","url":"/2019/09/01/JDBC/JDBC-1/","content":"\n引言：\n\n把Java和数据库联系起来\n这就是JDBC\n\n\n\n\n\nJDBC概念：Java DataBase Connectivity Java数据库连接\n本质：官方定义的一套操作所有关系型数据库的规则，即接口。\n各个数据库厂商去实现这套接口，提供数据库驱动jar包。我们可以使用这套接口编程，真正执行的代码是驱动jar包中的实现类\n快速入门步骤：\n示例代码：\n//1. 导入驱动jar包//   - 复制jar包到目录下//   - 右键添加到library`add as library`//2. 注册驱动/*现在大部分的jar包都可以直接的注册，只要jar包内含有 META-INF/services/java.sql.Dirver 这个文件，这个文件内已经有 com.mysql.cj.jdbc.Driver 这条信息， 所以可以自动的注册驱动，如果不能自动注册驱动，再来手动的注册驱动*/Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);//System.setProperty(&quot;jdbc.drivers&quot;,&quot;com.mysql.cj.jdbc.Driver&quot;);//也可以使用这条语句进行注册，这种注册方式可以通过&quot;:&quot;分离来一次填入多个驱动/* 执行这条语句后,我们就有了一个驱动器对象 DriverManager*///3. 获取数据库连接对象Connection conn = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/database?serverTimezone=UTC&quot;,&quot;root&quot;,&quot;root&quot;);/*sql语句中使用了类似URL的相似语法来描述数据源 在这里我们能看出这个语句的格式是：jdbc:[数据库运营商]://[要连接的数据库的URL]:[端口号]/[建立的数据库]?serverTimezone=UTC*///4. 定义SQL语句String sql = &quot;update deliver set bank = 500 where id = 1&quot;;//5. 通过获得的连接获取执行sql的对象 StatementStatement statement = conn.createStatement();//6. 执行SQLint count = statement.executeUpdate(sql);/*executeUpdate(String sql)方法可以执行sql语句，并且会返回一个int类型的值，这个值表示此sql语句影响的行数*///7. 处理结果   System.out.println(count);//8. 释放资源statement.close();conn.close();\n\n详解JDBC各个对象概览：\n\nDirverManager:驱动管理对象\nConnection：数据库连接对象\nStatement：执行SQL对象\nResultSet：结果集对象\nPreparedStatement：执行SQL对象（是Statement的子接口，但功能更加强大）\n\nDirverManagerDirverManager是驱动管理类\n功能：\n\n注册驱动\n获取数据库连接包路径java.sql\n注册驱动现在大部分的jar包都可以直接的注册，只要jar包内含有 META-INF/services/java.sql.Dirver 这个文件，这个文件内已经有 com.mysql.cj.jdbc.Driver 这条信息， 所以可以自动的注册驱动，如果不能自动注册驱动，再来手动的注册驱动\n\nmysql5.0 版本后注册驱动的代码可以省略，jar包会自动注册\nstatic void registerDriver(Driver driver) //注册与给定的驱动程序 DriverManager 。 //写代码使用:Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);//Class.forName用来注册类//此类中含有static静态代码块,我们无需自己调用registerDriver方法/*static &#123;    try &#123;        DriverManager.registerDriver(new Driver());        //这里帮我们执行了此方法    &#125; catch (SQLException var1) &#123;        throw new RuntimeException(&quot;Can&#x27;t register driver!&quot;);    &#125;&#125;*/    \n\n\n获取数据库连接sql语句中使用了类似URL的相似语法来描述数据源,url的MySQL语法：jdbc:mysql://ip地址(域名):端口号/数据库名称\nstatic Connection getConnection(String url, String user, String password) //尝试建立与给定数据库URL的连接。  //静态方法，可以用类名直接调用//url：指定的路径//url的MySQL语法：jdbc:mysql://ip地址(域名):端口号/数据库名称\n如果连接的是本机127.0.0.1的mysql服务器，并且myql服务端默认为3306，则url可以简化为\n&quot;jdbc:mysql:///数据库 名称&quot;// 这里有三个/\nConnectionConnection数据库连接对象\n功能：\n\n获取执行SQL的对象statement\n管理事务\n\n包路径java.sql\n获取执行sql的对象Statement createStatement() //创建一个Statement对象，用于将SQL语句发送到数据库。PreparedStatement prepareStatement(String sql) //创建一个 PreparedStatement对象，用于将参数化的SQL语句发送到数据库。  \n管理事务# 开启事务void setAutoCommit(boolean autoCommit) //将此连接的自动提交模式设置为给定状态。//设置值为false，即开启事务# 提交事务void commit() //使自上次提交/回滚以来所做的所有更改都将永久性，并释放此 Connection对象当前持有的任何数据库锁。  # 回滚事务void rollback() //撤消在当前事务中所做的所有更改，并释放此 Connection对象当前持有的任何数据库锁。  \n\nStatement用于执行静态SQL语句并返回其生成的结果的对象\n功能：\n\n执行sql\n\n包路径java.lang\n\n执行sqlboolean execute(String sql) /*执行任意的SQL语句，这可能会返回多个结果集或者是影响个数 ,通常用于 由用户提供的交互式查询如果返回值是true，说明第一个执行结果是一个结果集，此时可以调用getResultSet()方法来获得结果集反之，返回false，此时可以调用getUpdateCount获得影响个数*/int executeUpdate(String sql) //执行DML(INSERT,UPDATE,或 DELETE语句)语句,执行DDL语句(create,alter,drop)语句，不能执行查询SELECT语句，返回值是这条sql语句影响的行数//可以通过返回值来判断语句是否成功,大于0则成功ResultSet executeQuery(String sql) //执行查询的SQL语句，该语句返回单个ResultSet对象。 返回值是一个结果集对象\nResultSetjava.sql\n\n数据库的列表就是一个结果集，一开始结果集的光标在最上方，表头的部分，我们需要先将它移动至下一行才能读取数据next()\n获取数据getXxx(参数)Xxx代表数据类型，参数可以写int型的列编号 从1开始，可以写String型的字段\n例如：这样的一张表\n+----+------+----------+| id | name | PASSWORD |+----+------+----------+|  1 | 李   | 123      ||  2 | 王   | 456      ||  3 | 张   | 789      |+----+------+----------+\nwhile (resultSet.next())&#123;    System.out.print(        resultSet.getInt(1)        + &quot;-&quot;        + resultSet.getString(2)        + &quot;-&quot;        + resultSet.getInt(3)+&quot;\\r\\n&quot;    );&#125;/*注意：1. 在sql表中，第一列对应的就是1，不是02. 在使用getString()这个方法时，参数可以是列数，也可以是列表的表头名称，例如，可以如下这么写3. 当get方法类型和获取的参数类型不一致的时候，每个get方法都会进行合理的数值转换*/while (resultSet.next())&#123;    System.out.print(        resultSet.getInt(&quot;id&quot;)        +&quot;-&quot;+        resultSet.getString(&quot;name&quot;)        +&quot;-&quot;+        resultSet.getInt(&quot;password&quot;)+&quot;\\r\\n&quot;    );&#125;/*打印出结果1-李-1232-王-4563-张-789*/\nResultSet结果集方法boolean next();//将结果集向前移动一行，如果已经是最后一行的后面，则返回false，注意：初始情况下必须先调用该方法才能移动到第一行Xxx getXxx()// 各种类型的get方法void close();//立即关闭当前结果集\n\n管理连接、语句、结果集每个Connection对象都可以创建一个或者多个Statement语句，同一个Statement对象可以用于多个不相关的命令和查询，但是一个Statement对象最多只能有一个打开的结果集\n这就是说，如果我们要进行多组插入或者删除，只需要一个Statement对象即可\n但是如果需要执行多个查询操作，并且要同时分析查询结果，我们要创建多个Statement对象\n但实际上，我们不需要同时处理多个结果集，对数据库进行组合查询比使用java遍历结果集要高效的多\nPreparedStatement\nprepared statement 预备语句：一个带有宿主变量的查询语句，可以进行动态的查找\n\n优点：\n\n安全，防止代码注入问题\n高效，改进了查询的性能\n\n通过连接获得预备语句PreparedStatement Connection.prepareStatement(String sql)\n构造完成后，我们还不能直接的执行sql语句，我们必须先进行一下绑定\n与变量?绑定setXxx(参数1，参数2)/*     参数一：?的位置编号，从1开始    参数二: ?的值*/\n注意： 只有查询涉及变量时，才应该使用预备语句\n如果想要重用已经执行过的sql语句，必须先使用setXxx()或者clearParameters方法重新设置宿主变量和绑定，否则这些绑定关系都不会改变\n示例原本\nString sql = &quot;select * from  user where name = ? and password = ?&quot;;//这样会导致sql注入问题，我输入 (a&#x27; or &#x27;a&#x27; = &#x27;a) 所有人都可以进入\n现在\nString sql = &quot;select * from  user where name = ? and password = ?&quot;;preStat = conn.prepareStatement(sql);//设置?的值preStat.setString(1,name);preStat.setString(2,pass);//这里将不需要传参rs = preStat.executeQuery();\n预备语句方法void serXxx(int n, Xxx x)//设置第n个?的值为xvoid clearParameters()//清除预备语句中所有的当前参数ResultSet executeQuery()//执行查询语句，并返回一个结果集对象int executeUpdate()// 执行INSERT、UPDATE、DELETE预备sql语句\n\n\ndemo示例1. 简单的demopublic class JdbcDemo2 &#123;    public static void main(String[] args) &#123;        Statement stat = null;        Connection conn =null;        try &#123;            //1. 注册驱动            Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);            //2. 定义sql            String sql = &quot;insert into deliver values(null,&#x27;李&#x27;,3000)&quot;;            //3. 获取Connection对象            conn = DriverManager.getConnection(&quot;jdbc:mysql:///database?serverTimezone=UTC&quot;, &quot;root&quot;, &quot;root&quot;);            //4. 执行sql语句            stat = conn.createStatement();            int i = stat.executeUpdate(sql);            if(i&gt;0)&#123;                System.out.println(&quot;添加成功&quot;);            &#125;else &#123;                System.out.println(&quot;添加失败&quot;);            &#125;        &#125; catch (ClassNotFoundException e) &#123;            e.printStackTrace();        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;finally &#123;            //避免空指针异常            if(stat!=null)&#123;                try &#123;                    stat.close();                &#125; catch (SQLException e) &#123;                    e.printStackTrace();                &#125;            &#125;            if(conn!=null)&#123;                try &#123;                    conn.close();                &#125; catch (SQLException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;&#125;\n\n\n2. 完整的demo创建了Jdbcutils的工具类JdbcUtils\n/** * JDBC工具类 */public class JdbcUtils &#123;/*文件只需要读取一次即可,可以使用静态代码块静态代码块会随着类的加载而加载，且只加载一次这里定义一些静态的变量，因为静态代码块只能访问静态变量*/private static String url;private static String user;private static String password;private static String driver;static &#123;    try &#123;        //获取资源配置文件        //1. 创建Properties        Properties pro = new Properties();        //2. 加载文件        //src下文件的获取方式--&gt;ClassLoader类加载器        ClassLoader cl = JdbcUtils.class.getClassLoader();        URL res = cl.getResource(&quot;jdbc.properties&quot;);        //返回一个URL对象，使用getPath方法可以定位一个字符串路径        String path = res.getPath();        //路径是一个绝对路径        pro.load(new FileReader(path));        //3. 获取数据，赋值        url = pro.getProperty(&quot;url&quot;);        user = pro.getProperty(&quot;user&quot;);        password = pro.getProperty(&quot;password&quot;);        driver = pro.getProperty(&quot;driver&quot;);        //4. 注册驱动        Class.forName(driver);    &#125; catch (IOException | ClassNotFoundException e) &#123;        e.printStackTrace();    &#125;&#125;//静态方法，直接可以使用类名调用/**    * 获取连接    *    * @return 连接对象    */public static Connection getConnection() throws SQLException &#123;    return DriverManager.getConnection(url,user,password);&#125;/**    * 释放资源    *    * @param stat    * @param conn    */public static void close(Statement stat, Connection conn) &#123;    if (stat != null) &#123;        try &#123;            stat.close();        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;    &#125;    if (conn != null) &#123;        try &#123;            conn.close();        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;/**    * 重载函数    * 释放资源    *    * @param rs    * @param stat    * @param conn    */public static void close(ResultSet rs, Statement stat, Connection conn) &#123;    if (stat != null) &#123;        try &#123;            stat.close();        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;    &#125;    if (conn != null) &#123;        try &#123;            conn.close();        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;    &#125;    if (rs != null) &#123;        try &#123;            rs.close();        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;&#125;//end\n配置文件jdbc.properties\nurl = jdbc:mysql:///database?serverTimezone=UTCuser = rootpassword = rootdriver = com.mysql.cj.jdbc.Driver\n\n保存的类对象Person\npublic class JdbcDemo4 &#123;    public static void main(String[] args) &#123;        List&lt;Person&gt; list = new JdbcDemo4().findAll();        System.out.println(list);    &#125;    public List&lt;Person&gt; findAll() &#123;        Connection conn = null;        Statement stat = null;        ResultSet rs = null;        List&lt;Person&gt; list = null;        try &#123;            //使用工具类            conn = JdbcUtils.getConnection();            String sql = &quot;select * from  deliver&quot;;            stat = conn.createStatement();            rs = stat.executeQuery(sql);            Person p = null;            list = new ArrayList&lt;Person&gt;();            while (rs.next())&#123;                int id = rs.getInt(1);                String name = rs.getString(2);                int bank = rs.getInt(3);                p = new Person();                p.setId(id);                p.setName(name);                p.setBank(bank);                list.add(p);            &#125;        &#125;catch (SQLException e) &#123;            e.printStackTrace();        &#125; finally &#123;            //使用工具类            JdbcUtils.close(rs,stat,conn);        &#125;        return list;    &#125;&#125;\n\n3. 登录的demopublic class JdbcDemo5 &#123;    public static void main(String[] args) &#123;        Scanner sc = new Scanner(System.in);        String name = sc.next();        String password = sc.next();        if (new JdbcDemo5().login(name, password)) &#123;            System.out.println(&quot;登陆成功&quot;);        &#125; else &#123;            System.out.println(&quot;登录失败&quot;);        &#125;    &#125;    public boolean login(String name, String pass) &#123;        Connection conn = null;        PreparedStatement preStat = null;        ResultSet rs = null;        if (name != null &amp;&amp; pass != null) &#123;            try &#123;                conn = JdbcUtils.getConnection();                String sql = &quot;select * from  user where name = ? and password = ?&quot;;                preStat = conn.prepareStatement(sql);                preStat.setString(1,name);                preStat.setString(2,pass);                rs = preStat.executeQuery();                return rs.next();            &#125; catch (SQLException e) &#123;                e.printStackTrace();            &#125; finally &#123;                JdbcUtils.close(rs, preStat, conn);            &#125;            return false;        &#125; else &#123;            return false;        &#125;    &#125;&#125;\n\n支付操作的demopublic class JdbcDemo6 &#123;public static void main(String[] args) &#123;    Connection conn = null;    PreparedStatement preStat1 = null;    PreparedStatement preStat2 = null;    ResultSet rs = null;    try &#123;        conn = JdbcUtils.getConnection();        //开启事务        conn.setAutoCommit(false);        String sql1 = &quot;update deliver set bank = bank -? where id = ?&quot;;        String sql2 = &quot;update deliver set bank = bank +? where id = ?&quot;;        preStat1 = conn.prepareStatement(sql1);        preStat2 = conn.prepareStatement(sql2);        preStat1.setString(1,&quot;500&quot;);        preStat1.setString(2,&quot;3&quot;);        preStat2.setString(1,&quot;500&quot;);        preStat2.setString(2,&quot;2&quot;);        preStat1.executeUpdate();        preStat2.executeUpdate();        //提交        conn.commit();    &#125; catch (Exception e) &#123;        e.printStackTrace();        if(conn!=null)&#123;            try &#123;                //回滚                conn.rollback();            &#125; catch (SQLException ex) &#123;                ex.printStackTrace();            &#125;        &#125;    &#125;finally &#123;        JdbcUtils.close(rs,preStat1,conn);        JdbcUtils.close(null,preStat2,null);    &#125;    &#125;&#125;\n","categories":["后台","JDBC"],"tags":["JDBC"]},{"title":"JAVA-集合与Map","url":"/2019/08/14/Java/JAVA-%E9%9B%86%E5%90%88%E4%B8%8EMap/","content":"\n引言：Collection与Map\n\n\n\n\n\n集合Java中实现了部分的数据结构（Data Structure）的内容，并把他们封装成了类\n集合是什么集合是一种可以存储多个数据的容器（此集合非彼集合）\n优点：\n\n集合的长度可以随意变化\n集合存储的都是对象，而且对象的类型可以不同\n\n将集合接口与实现分离例如：队列\n\n队列：先进先出(FIFO)，头的一端可以删除元素，尾的一端可以添加元素，并且可以查找队列中元素的个数\n\n队列Queue接口可能是这么实现的\npublic interface Queue&lt;E&gt;&#123;    void add(E element);    E remove();    int size();&#125;//这里只是做个示例\n队列有两种实现：\n\n循环数组public class CircularArrayQueue&lt;E&gt; implements Queue&lt;E&gt;&#123;    private int head;    private int tail;    CircularArrayQueue(int capcity)&#123;...&#125;    public void add(E e)&#123;...&#125;    public E remove()&#123;...&#125;    public int size()&#123;...&#125;    private E[] elements;&#125;//这里只是做个示例\n链表public class LinkedListQueue&lt;E&gt; implements Queue&lt;E&gt; &#123;    private Link head;    private Link tail;    LinkedListQueue()&#123;...&#125;    public void add(E element)&#123;...&#125;     public E remove()&#123;...&#125;    public int size()&#123;...&#125;&#125;//这里只是做个示例\n\n当在程序中使用队列时，一旦构建了集合就不需要知道究竟使用了哪种实现，所以，只有在构建集合对象的时候，使用具体的类才有意义，例如：\nQueue&lt;MyClass&gt; myClass = new CircularArrayQueue&lt;&gt;(100);myClass.add(new MyClass(&quot;Jack&quot;));/*    一旦我们改变了想法，我们只需要改变调用构造方法的那一块，如下*/Queue&lt;MyClass&gt; myClass = new LinkedListQueue&lt;&gt;(100);myClass.add(new MyClass(&quot;Jack&quot;));\n\n集合关系图在Java中，集合类的基本接口是Collection接口\n\nCollection接口\n  定义了所有单列集合中共性方法，  所有单列集合都可以使用的方法，没有带索引的方法\n\nList接口\n有序的集合（存储和取出元素的顺序相同）\n允许存储重复的元素\n有索引，可以使用普通的for循环遍历\n\n\nSet接口\n不允许存储重复元素\n没有索引，不能使用普通的for循环遍历\n无序\n\n\nLinkedHashSet  例外，是有序的集合\n\n\n\n学习集合的方法：\n\n学习顶层：学习顶层接口/抽象类的共性方法，所有的子类都可以使用\n使用底层：顶层无法创建对象使用，需要使用底层来创建对象\n\nCollection接口public interface Collection&lt;E&gt;&#123;    boolean add(E element);    Iterator&lt;E&gt; iterator();    ...&#125;\niterator()实现了Iterator接口，首先了解一下迭代器\n迭代器Iterator迭代器接口有四个方法：    1.  next()：逐个访问集合中的每个元素，但是如果到带了集合的末尾会抛出一个NoSuchElementException异常            Java的迭代器可以看做是位于两个元素之间的，当调用next()的方法时，迭代器就越过下一个元素，并返回刚刚越过的元素的引用    2.  hasNext()：判断是否还有下一个元素    3.  remove()：删除一个刚刚越过的元素    4.  forEachRemaining：流式编程\npublic interface Iterator&lt;E&gt;&#123;    E next();    boolean hasNext();    void remove();    default void forEachRemaining(Consumer&lt;? super E&gt;action)&#125;\n\n迭代器的使用迭代器的使用\nCollection&lt;String&gt; coll = ...;Iterator&lt;String&gt; iter = coll.iterator();//调用集合的iterator()方法while(iter.hasNext())&#123;    String e = iter.next();    //do something&#125;\nfor each也可以简单的表示同样的循环操作\nfor(String e : c)&#123;    //do something&#125;\nJavaSE8后，可以调用Iterator最后一个方法foreachRemaining方法，这个方法会提供一个Lambda表达式\niter.forEachRemaining(element -&gt; doSomething)\n\nCollection的常用方法常用方法\nint size() //返回当前存储在集合中的元素个数boolean isEmpty()//如果此 collection 不包含元素，则返回 true。boolean contains(Object o)//判断当前集合是否包含给定的对象，包含返回true，不包含返回falseboolean containsAll(Collection&lt;?&gt; other)//如果这个集合包含other中所有的元素，返回trueboolean add(E e)/*如果此 collection 由于调用而发生更改，则返回 true。如果此 collection 不允许有重复元素，并且已经包含了指定的元素，则返回 false。*/boolean addAll(Collection&lt;? extends E&gt; other)//将other中所有的元素添加到这个集合boolean remove(Object o)//从此 collection 中移除指定元素的单个实例,不存在此元素返回falseboolean removeAll(Collection&lt;?&gt; other)//从这个集合中删除other集合中存在的所有元素boolean retainAll(Collection&lt;?&gt; other) //从这个集合中删除所有与 other 集合中的元素不同的元素。如果由于这个调用改变了集合， 返回 truevoid clear()//移除此 collection 中的所有元素,集合是还存在的Object[] toArray()//返回包含此 collection 中所有元素的数组。\n代码示例Collection&lt;String&gt; coll = new ArrayList&lt;&gt;();//接口的构造//add方法boolean b1 = coll.add(&quot;张三&quot;);//把给定的对象添加到集合当中，返回值一般都是true，可以不用接受System.out.println(coll);//[张三] 不是地址,说明重写了toString方法System.out.println(b1);//trueCollection&lt;String&gt; coll = new ArrayList&lt;&gt;();//接口的构造coll.remove(&quot;张三&quot;);//删除方法coll.contains(&quot;张三&quot;);//是否含有方法coll.isEmpty(); //是否为空方法coll.size();//获取长度coll.toArray();//把集合变为数组coll.clear();//清空元素方法\n\nIterator迭代器： 一种通用的取出集合元素的方法\nIterator是一个接口，我们无法直接使用\n需要使用实现类对象，获取它的实现类比较特殊\n迭代： 在取元素之前判断集合中有没有该元素，如果有就取出这个元素，继续判断，直到取出集合中所有需要的元素\n实现类获取实现类的方法\nCollection接口有一个iterator()方法，此方法直接返回实现类对象\n常用方法boolean hasNext()//如果仍有元素可以迭代，则返回 true。（换句话说，如果 next 返回了元素而不是抛出异常，则返回 true）。 E next()//返回迭代的下一个元素。 \n\n常用方法Collection&lt;String&gt; coll = new ArrayList&lt;&gt;();coll.add(&quot;姚明&quot;);coll.add(&quot;科比&quot;);coll.add(&quot;麦迪&quot;);coll.add(&quot;詹姆斯&quot;);coll.add(&quot;艾弗森&quot;);//iterator&lt;&gt;也有泛型Iterator&lt;String&gt; it = coll.iterator();//Iterator有泛型&lt;&gt;//通过Collection的Iterator()方法获得实现类while (it.hasNext())//判断是否含有下个元素    System.out.println(it.next());//循环获得元素\n\nforeachJDK1.5之后的一个高级for循环，专门用来遍历数组和集合的，它的内部其实是个iterator迭代器\n所以在遍历的过程中，不能对集合中的元素进行增删操作\n所有的单列集合都可以使用增强for\nfor(元素的数据类型 变量 : Collection集合/数组)&#123;    //操作代码，不能对集合中的元素进行增删操作&#125;\n\nCollection&lt;String&gt; coll = new ArrayList&lt;&gt;();coll.add(&quot;姚明&quot;);coll.add(&quot;科比&quot;);coll.add(&quot;麦迪&quot;);coll.add(&quot;詹姆斯&quot;);coll.add(&quot;艾弗森&quot;);for (String s : coll) &#123;    System.out.println(s);&#125;\n\n泛型泛型是一种未知的数据类型，当我们不知道使用声明数据类型的时候，我们可以使用泛型\n可以看成一个变量，可以用来接收数据类型\nArrayList集合在定义的时候，不知道集合中都会存储声明元素的数据，所以类型使用泛型\npublic class ArrayList&lt;E&gt;&#123;    public boolean add(E e)&#123;&#125;    public E get(int index)&#123;&#125;&#125;\n\n泛型数据类型的确定时间在创建对象的那一刻\n优缺点\n优点\n\n避免了类型转换的麻烦，存储的是什么类型，取出的就是什么类型\n把运行期异常(代码运行之后会抛出的异常)，提升到了编译器(写代码的时候会报错)\n\n\n弊端\n泛型是什么类型只能存储声明类型\n\n\n如果不加泛型，默认Object类，可以存储任何对象，但不安全，但容易引发异常\n（例如：当存入Integer对象和String对象，遍历时想调用toString方法，而这样就必须向下转型，在运行中也可能会报错）\n泛型类泛型类public class father&lt;E&gt; &#123;    private E name;    public void setName(E name) &#123;        this.name = name;    &#125;    public E getName() &#123;        return name;    &#125;&#125;\n\n调用\nfather f = new father();f.setName(&quot;字符串&quot;);f.setName(123);f.setName(true);//不管是什么类型都可以使用\n\n泛型方法public &lt;E&gt; void method (E e)&#123;    System.out.println(e);&#125;public static &lt;S&gt; void methodStatic(S s)&#123;    System.out.println(s);&#125;\n\n泛型接口public interface api&lt;E&gt; &#123;    public void out(E e);&#125;\n\n接口实现类\npublic class apiImpl &lt;E&gt; implements api&lt;E&gt;&#123;    @Override    public void  out(E e)&#123;        System.out.println(e);    &#125;&#125;\n\n高级用法泛型通配符？\n不知道使用什么类型时可以使用\n但是此时只能接受数据，而不能存储数据\npublic static void print(ArrayList&lt;?&gt; list)&#123;    Iterator&lt;?&gt; it = list.iterator();    while (it.hasNext())&#123;        System.out.println(it.next());    &#125;&#125;\n\n高级用法：\n\n泛型的上限限定：? extends E 代表使用的泛型只能是E类型的子类/本身\n\n泛型的下限限定：?  super  E代表使用的泛型只能是E类型的父类/本身\n\n\n数据结构简述栈(stack)先进后出\n只有一个口，最先进去的，最后才能出去\n类似于手枪弹夹\n队列(quene)先进先出\n有一个入口一个出口，先进去的先出去\n数组(array)查询快，增删慢\n查询快：\n数组的地址是连续的，我们通过数组的首地址可以找到数组，通过数组的索引值可以快速的找到某一个元素\n增删慢：\n数组的长度是固定的，我们增删一个元素，必须创建一个新的数组，把原数组的数据复制过来，而原数组会被垃圾回收\n链表(linked list)查询慢，增删快\n查询慢: 链表的地址不是连续的，每次查询元素必须从头开始\n增删快：链表结构增删一个元素，对整体没有影响\n链表的每一个元素称之为一个节点,\n一个节点包括三个部分(自己的地址+数据+下一个节点的地址)\n两种列表\n单向列表\n链表中只有一条链子，不能保证元素的顺序（存储元素和去除元素的顺序有可能不一致）\n\n双向列表\n链表中有两条链子，一条专门记录元素的顺序，一条是一个有序的集合\n\n\n红黑树特点：趋于平衡的树，查询的速度非常快\n约束：\n\n节点可以是红色也可以是黑色\n\n根节点是黑色\n\n叶子结点（空节点）是黑色\n\n每个红色的节点的子节点都是黑色的\n\n任何一个节点到其每一个叶子结点的路径上黑色节点相同\n\n\nList集合特点\n有序：存储与取出的顺序是一致的\n有索引：包含常用的索引方法\n允许重复\n\n常用方法public void add(int index,E element)//将指定的元素添加到指定的位置上public E remove (int index)//移除表中指定位置的元素，返回被移除的元素public E set(int index,E element)//用指定元素替换几何中指定位置的元素，返回更新前的元素\n\n示例\nList&lt;String&gt;list = new ArrayList&lt;&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);list.add(&quot;c&quot;);list.add(&quot;d&quot;);list.add(3,&quot;啦啦啦&quot;);// 添加方法System.out.println(list);list.remove(&quot;啦啦啦&quot;);// 移除方法System.out.println(list);list.set(2,&quot;A&quot;);// 替换方法System.out.println(list);\n\n遍历方法\n//普通for循环for(int i = 0;i&lt;list.size();i++)&#123;    String s = list.get(i);    System.out.println(s);&#125;//foreach遍历for (String s : list) &#123;    System.out.println(s);&#125;//迭代器遍历Iterator&lt;String&gt; it = list.iterator();while (it.hasNext())&#123;    String s = it.next();    System.out.println(s);&#125;\n\n常见报错IndexOutofBoundsException//索引越界异常，集合会报ArrayIndexOutofBoundsException//数组索引越界异常StringIndexOutOfBoundsException//字符串索引越界异常\n\nArrayListList 接口的大小可变数组的实现。\n实现了所有可选列表操作，并允许包括 null在内的所有元素。\n除了实现 List接口外，此类还提供一些方法来操作内部用来存储列表的数组的大小\n尖括号内的E叫做泛型，装在该集合当中的所有元素都必须是统一的类型\n泛型只能是引用类型，不能是基本类型\n包路径：\njava.util\n\n构造方法：\npublic ArrayList(Collection&lt;? extends E&gt; c)//构造一个包含指定 collection 的元素的列表，//这些元素是按照该 collection的迭代器返回它们的顺序排列的。 \n\n常用方法\npublic E set(int index,E element);  //输入索引值和相同的泛型内容替换原有的内容public E get(int index)             //返回索引值对应的内容public boolean add(E e)             //把指定元素添加到集合的尾部public void add(int index,E element)//添加指定的元素到索引值处，后面的内容索引值加一public E remove(int index)          //移除集合上指定位置上的元素public boolean remove(Object o)     //移除此列表中首次出现的指定元素（如果存在）。如果列表不包含此元素，则列表不做改动public void clear()                 //移除集合中的所有元素public boolean addAll(Collection&lt;? extends E&gt; c)//将另一个集合并入此集合public boolean addAll(int index,Collection&lt;? extends E&gt; c)//从指定位置并入另一个集合public void ensureCapacity(int minCapacity)//增加此ArrayList的容量,以确保至少能容纳参数所指定的元素数public boolean isEmpty()            //判断集合是否为空public boolean contains(Object o)   //判断集合是否含有指定的元素public int indexOf(Object o)//返回此列表中首次出现的指定元素的索引，或如果此列表不包含元素，则返回 -1。public int lastIndexOf(Object o)//返回此列表中最后一次出现的指定元素的索引，或如果此列表不包含索引，则返回 -1。\n\n示例代码：\nArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();// 创建了一个ArrayList的集合，// 泛型为String类型，代表这个集合内只能含有String类型的数据System.out.println(list);//返回[]//直接打印空集合，返回的并不是地址，而是一个空数组list.add(&quot;小明&quot;);//添加方法list.add(1,&quot;小白&quot;);//指定添加String str = list.get(0);//得值方法list.set(0, &quot;小红&quot;);//替换方法list.remove(0);//移除方法list.remove(&quot;小白&quot;);//移除第一个指定值list.ensureCapacity(9);//最小兼容方法list.isEmpty();//是否空方法list.contains(&quot;小白&quot;);//是否包含方法list.indexOf(&quot;小白&quot;);//求首次出现索引方法list.lastIndexOf(&quot;小白&quot;);//求末次出现索引方法ArrayList&lt;String&gt; list2 = new ArrayList&lt;&gt;();list2.addAll(list);//合并另一个ArrayListlist.size();//返回长度for (int i = 0; i &lt; list.size(); i++) &#123;    System.out.println(list.get(i));&#125;//输入list.fori+TAB快速得到遍历集合的循环\n\n泛型只能导入引用类型，那怎么存入基本类型呢？\n使用基本类型的对应的包装类\n从JDK1.5开始，支持自动装箱拆箱\nArrayList&lt;Integer&gt; list1 = new ArrayList&lt;&gt;();list1.add(100);//完成了自动装箱list1.add(new Integer(100));//手动装箱，同上\n\nLinkedList底层是一个双向列表，\n查询慢，增删快，多线程\n也有list的三个特点(有序，可索引，可重复)\n包路径java.util\n\n常用方法添加方法\npublic void addFirst(E e)//将指定元素插入此列表的开头public void addLast(E e)//将指定元素添加到此列表的结尾public void push(E e)//将元素推入此列表所表示的堆栈。换句话说，将该元素插入此列表的开头,同addFirst\n\n获取方法\npublic E getFirst()//返回此列表的第一个元素public E getLast()返回此列表的最后一个元素\n\n移除方法\npublic E removeFirst()//移除并返回此列表的第一个元素。 public E removeLast()//移除并返回此列表的最后一个元素。 public E pop()//从此列表所表示的堆栈处弹出一个元素。换句话说，移除并返回此列表的第一个元素。 //此方法等效于 removeFirst()。 \n\n示例代码LinkedList&lt;String&gt; linked = new LinkedList&lt;&gt;();linked.add(&quot;a&quot;);linked.add(&quot;b&quot;);linked.add(&quot;c&quot;);//向集合添加一些内容//添加内容linked.addFirst(&quot;www&quot;);linked.push(&quot;aaa&quot;);//与addFirst相同linked.addLast(&quot;com&quot;);System.out.println(linked);//获取内容System.out.println(linked.getFirst());System.out.println(linked.getLast());//移除方法linked.removeFirst();linked.removeLast();System.out.println(linked);\n\nVector是一个同步的集合（单线程，速度慢）\n了解即可，最早期的一个集合\nHashSet特点:\n\n继承set接口\n没有重复元素\n没有索引，也不能使用普通的for循环\n\n\nHashSet特点\n不同步（多线程）\n无序的集合\n没有索引\n底层是一个哈希表结构（查询速度非常快）\n\n\n\n包路径java.util\n\n构造函数public HashSet()//构造一个新的空 set，其底层 HashMap 实例的默认初始容量是 16，加载因子是 0.75。\n\nSet&lt;Integer&gt; set = new HashSet&lt;&gt;();//构造一个HashSet集合set.add(1);set.add(12);set.add(12);//填入两个12set.add(3);System.out.println(set);//[1, 3, 12]只有一个12\n\n存储自定义类型的元素对于自定义元素\nSet&lt;father&gt; set = new HashSet&lt;&gt;();//构造一个HashSet集合father f1 = new father(&quot;一号小弟&quot;,15);father f2 = new father(&quot;二号小弟&quot;,15);father f3 = new father(&quot;一号小弟&quot;,15);//有三个变量，其实只有两个人，对于f1和f3是同一个人set.add(f1);set.add(f2);set.add(f3);System.out.println(set);//但是发现，三个人都存进去了，这显然不是我们想要的\n\n我们必须重写hashCode和equals方法，来保证不重复\n@Overridepublic boolean equals(Object o) &#123;    if (this == o) return true;    if (o == null || getClass() != o.getClass()) return false;    father father = (father) o;    return age == father.age &amp;&amp;            Objects.equals(name, father.name);&#125;@Overridepublic int hashCode() &#123;    return Objects.hash(name, age);&#125;\n\n再次运行，发现重复的人就被去掉了\n哈希值哈希值是一个十进制的整数，由系统随机给出\n就是对象的地址值，是一个逻辑地址，是模拟出来的地址，不是数据实际存储的物理地址\n在Obejct类中有一个方法可以返回对象的哈希值\nfather f1 = new father();int h1 = f1.hashCode();System.out.println(h1);//961\n\nString s1 = &quot;重地&quot;;String s2 = &quot;通话&quot;;System.out.println(s1.hashCode());//1179395System.out.println(s2.hashCode());//1179395//通话和重地有一个巧合，哈希值相同\n\n哈希表HashSet集合存储数据的结构（哈希表）\n把元素进行了分组，相同哈希值的元素分为一组，每一组都是一个链表，这些元素的哈希值相同\n如果链表超过了8位，那么就会把链表转化为红黑树，提高查询速度\n\njdk1.8之前：哈希表 = 数组+链表\n\njdk1.8之后：\n哈希表 = 数组 +链表\n哈希表 = 数组 + 红黑树（提高查询的速度）\n哈希表的特点：速度快 \n\n\nset不重复原理add方法会计算字符串的哈希值，得到哈希值会去寻找是否存在此哈希值。\n如果没有就会存储到集合当中\n如果有(哈希冲突)就会调用equals方法对这两个相同的字符进行比较，比较如果不同才会存储这个元素，挂在同一个位置\nLinkedHashSet继承了HashSet集合，底层是一个哈希表(数组+链表/红黑树)+链表\n多了一条链表（记录元素的顺序），可以保证元素有序\n包路径java.util\n\nHashSet无序,LinkedHashSet有序\n可变参数JDK1.5之后，如果我们需要接受多个参数，并且多个参数的类型一致，我们就可以简化成如下的格式：\npublic static void sum(int... a)&#123;//这样接收&#125;\n\n//调用sum(1,3,5,545,8,4);//可以接收任意个相同类型的参数\n\n注意事项：一个方法的参数列表，只能有一个 可变参数如果方法的参数有多个，那么可变参数必须写在最右边\n小实例：计算任意项的和\npublic static void main(String[] args) throws ParseException &#123;    sum(1,3,5,545,8,4);&#125;public static void sum(int... a)&#123;    int sum = 0;    for (int i : a) &#123;        sum+=i;    &#125;    System.out.println(sum);//566&#125;\n\nCollections此类完全由在 collection 上进行操作或返回 collection 的静态方法组成。\n它包含在 collection 上操作的多态算法，即“包装器”，包装器返回由指定 collection 支持的新 collection，以及少数其他内容。\n常用方法Collections.addAll()//参数第一个是一个集合，后面是任意个元素Collections.shuffle//参数：一个集合,打乱集合//1.Collections.sort()//参数只能是一个List集合，不能是set集合！//将集合的元素按默认排序，默认是升序，从小到大//自定义类型的sort必须重写Comparable接口中CompareTo这个方法，否则默认报错//2.Collections.sort()//两个参数，第一个是集合，第二个是方法new //区别: //Comparator相当于找一个第三方的裁判，比较两个//Comparable自己和参数比较，自己需要实现Comparable接口，重写比较的规则compareTO方法\n\n示例代码ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();Collections.addAll(list,&quot;a&quot;,&quot;v&quot;,&quot;w&quot;,&quot;6&quot;,&quot;g&quot;);Collections.shuffle(list);//打乱System.out.println(list);//[g, 6, v, a, w]Collections.sort(list);//默认升序排序System.out.println(list);//[6, a, g, v, w]\n\n自定义元素sort,需要在自定义类中重写compareTo方法\n引入Comparable&lt;&gt;接口\npublic class father implements Comparable&lt;father&gt;&#123;    //这里要引入一个接口Comparable,注意写入泛型    @Override    public int compareTo(father f)&#123;        return this.getAge() - f.getAge();        //return 0;默认返回一个零，认为是相同的    &#125;...&#125;\n\nfather f1 = new father(&quot;一号&quot;,10);father f2 = new father(&quot;二号&quot;,18);father f3 = new father(&quot;三号&quot;,40);ArrayList&lt;father&gt; list = new ArrayList&lt;&gt;();Collections.addAll(list,f1,f2,f3);Collections.sort(list);\n\nComparable&lt;&gt;接口的排序规则:\nthis - 参数 -&gt; 升序\n参数 - this -&gt; 降序\nMapMap&lt;K,V&gt;\n\nK键：此映射所维护的键的类型\nV键：映射值的类型\n\nMap是一个双列集合，与Collection不同\n将键映射到值的对象。一个映射不能包含重复的键；每个键最多只能映射到一个值。 \n特点：\n\nMap集合是一个双列集合，包含一个键一个值\n键和值的数据类型不相关\nkey不可以重复，但是value可以重复\nkey和value一一对应\n\n包路径java.util\n\n实现类\nHashMap(底层是一个哈希表)\n查询速度快\n底层是哈希表\n无序集合\n\n\nLinkedHashMap\n底层是一个哈希表+链表\n有序集合\n\n\n\n常用方法V put(K key, V value)//将指定的值与此映射中的指定键关联（可选操作）//如果此映射以前包含一个该键的映射关系，则用指定值替换旧值//存储键值对的时候//key不重复，返回值v是null//key重复，会使用新的v替换map中重复的v，返回被替换的value值V remove(Object key)//key存在，返回被删除的值//key不存在，返回nullV get(Object key)//返回指定键所映射的值//如果此映射不包含该键的映射关系，则返回 nullboolean containsKey(Object key)//如果此映射包含指定键的映射关系，则返回 true。//更确切地讲，当且仅当此映射包含针对满足 (key==null ? k==null : key.equals(k)) 的键 k 的映射关系时，返回 true。Set&lt;K&gt; keySet()//把Map集合中所有的key取出，存入到Set集合当中\n\n示例代码Map&lt;String,String&gt; map = new HashMap&lt;&gt;();map.put(&quot;李晨&quot;,&quot;范围&quot;);//不重复返回nullmap.put(&quot;李晨&quot;,&quot;范冰冰&quot;);//重复返回被替换去掉的值map.put(&quot;杨过&quot;,&quot;小龙女&quot;);System.out.println(map);//&#123;杨过=小龙女, 李晨=范冰冰&#125;map.remove(&quot;李晨&quot;);System.out.println(map);//&#123;杨过=小龙女&#125;System.out.println(map.get(&quot;杨过&quot;));//小龙女System.out.println(map.containsKey(&quot;李晨&quot;));//falseSet&lt;String&gt; set = map.keySet();//转化为set集合System.out.println(set);//[杨过]\n\nMap遍历\n法一：利用keySet方法\n\nMap&lt;String,String&gt; map = new HashMap&lt;&gt;();map.put(&quot;李晨&quot;,&quot;范围&quot;);map.put(&quot;阿q&quot;,&quot;abc&quot;);map.put(&quot;杨过&quot;,&quot;小龙女&quot;);Set&lt;String&gt; set = map.keySet();for (String s : set) &#123;    System.out.println(s + &quot;,&quot; + map.get(s));&#125;\n\n\n法二：使用entrySet方法\n\nMap&lt;String,String&gt; map = new HashMap&lt;&gt;();map.put(&quot;李晨&quot;,&quot;范围&quot;);map.put(&quot;阿q&quot;,&quot;abc&quot;);map.put(&quot;杨过&quot;,&quot;小龙女&quot;);//通过Map名来找到Entry对象for(Map.Entry&lt;String, String&gt; s : map.entrySet())&#123;    System.out.println(s.getKey()+&quot;,&quot;+s.getValue());&#125;\n\n存储自定义类型，记得要重写hashCode方法，去重\nMap.EntryMap接口中有一个内部接口Entry\n作用：当Map集合一旦创建，那么就会在Map集合中创建一个Entry对象，用来记录键与值的关系\n他有两个方法:\n\ngetKey\ngetValue用来获取V和K\n\nJDK9优化jdk9中，list，set，map都存入了一个静态of方法，只适用于这三个接口，不适用于这三个接口的实现类\n\n可以用来  一次性 添加  多个元素\nof方法的返回值是一个不能改变的集合，该集合不能再用add，put存入元素\nSet和Map接口在调用of方法时不能有重复的元素所以要在数量确定的时候再用\n\nList&lt;String&gt; list = List.of(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;);\n\n","categories":["后台","Java"],"tags":["Java"]},{"title":"ConcurrentHashMap深入理解","url":"/2021/08/14/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/ConcurrentHashMap%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/","content":"\n    引言：深入学习ConcurrentHashMap\n\n\n\n\nConcurrentHashMap有很多东西与HashMap相同，如果不了解HashMap，建议先去研究HashMap\n并发下的Hash存在的问题本节介绍为什么要引入ConcurrentHashMap\n1、多线程下的HashMap存在什么问题？总结自敖丙\nHashMap不能再多线程下使用，在JDK1.7版本，HashMap使用头插法，可是在并发扩容下容易形成链表环，如果此时进行遍历，那么将会导致死锁\n在JDK1.8，使用尾插法，虽然不会形成链表环，但是并发操作下，由于不是原子操作，如果修改的一瞬间，切换了线程，新的线程完成了正常的修改逻辑，切换回旧线程后，又会把值修改回来。\n2、多线程下怎样使用哈希表？有三种方法：\n\n使用Collections.synchronizedMap(Map)创建线程安全的map集合；\nHashtable\nConcurrentHashMap\n\n3、为什么不使用HashTable​    虽然HashTable也是线程安全的，但是它的内部实现是用synchronized，效率太低了\n4、为什么不使用Collections.synchronizedMap​    其内部是一个普通的Map＋排斥锁，排斥锁可以自己给，内部也有自己的Obejct作为排斥锁\n​    它实现线程安全就是使用synchronized( mutex)\nConcurrentHashMap要点汇总本文将要点总结在此：\n\n为什么设置容量为2的幂次：\n\n方便计算找下标\n加快扩容时转移数据的速度\n\n\nConcurrentHashMap可以保证高并发的原理\n\nJDK1.7 分段锁：segments+HashEntry\n\nsegment是一个ReentrantLock，每个segment对应第一个HashEntry\nHashEntry就是普通的数组+链表的map（1.7也没有红黑树）\n\n\nJDK1.8 ：CAS+syn\n\nCAS：如果数据放在了数组上（即，数据还没拉链出来），就可以直接CAS判断放置\nSynchronized：如果数据要添加在链表或是树上，就需要syn同步\n检索操作不用加锁，get方法是非阻塞的\n\n\n\n\n\n\nConcurrentHashMap的key和value都不允许为null\nConcurrentHashMap如何进行快速扩容？\n并发扩容，最少每一个线程需要搬运16个桶\n搬运时巧妙的计算下标index，只需要看1bit\n比如从16位扩展到32bit，原本的下标计算方式是hash&amp;(n-1)，即原本的hash与15计算，即低4bit，而32-1就是31，就是最低5bit，所以我们只需要看多出来的那一个bit\n\n\n\n\n\nConcurrentHashMap基本了解ConcurrentHashMap也是数组加链表，在JDK1.7与1.8的实现稍有不同：\nJDK1.7中的ConcurrentHashMap实现如下：\nstatic final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123;// 继承了ReentrantLock    private static final long serialVersionUID = 2249069246763182397L;    // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶    transient volatile HashEntry&lt;K,V&gt;[] table;    transient int count;    // 记得快速失败（fail—fast）么？    transient int modCount;    // 大小    transient int threshold;    // 负载因子    final float loadFactor;&#125;\n\n里面提到了我们熟悉的概念负载因子、table数组等等；还有我们不熟悉的modCount\n\n快速失败 fail fast 机制：\n​        是Java集合中的一种机制， 在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。\n\n原理就是使用一个 modCount，在每次修改的时候改变modCount值，集合遍历期间，发现modCount值发生改变，就将抛出异常（原理与解决ABA问题的原理相同）\n与快速失败机制相关的还有一个 fail safe：\n\n安全失败机制（fail-safe），这种机制会使你此次读到的数据不一定是最新的数据。\n\n\n扯远了，再回到主角上来\nConcurrentHashMap实现并发的机制就是 table数组HashEntry使用了volatile关键字\n并发度高的原因使用Segment，每个线程分别占用一个Segment，互不影响，默认的并发度为16，也即默认初始有16个Segment\n算是一种空间换时间的策略\nput与get方法高并发的原因public V put(K key, V value) &#123;    Segment&lt;K,V&gt; s;    if (value == null)        throw new NullPointerException();    \t//这就是为啥他不可以put null值的原因    int hash = hash(key);    int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;    // 定位到对应的segment再进行put操作    if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject                   (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null)         s = ensureSegment(j);    return s.put(key, hash, value, false);&#125;\n\nfinal V put(K key, int hash, V value, boolean onlyIfAbsent) &#123;    // 将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry    HashEntry&lt;K,V&gt; node = tryLock() ? null :    scanAndLockForPut(key, hash, value);    V oldValue;    try &#123;        HashEntry&lt;K,V&gt;[] tab = table;        int index = (tab.length - 1) &amp; hash;        HashEntry&lt;K,V&gt; first = entryAt(tab, index);        for (HashEntry&lt;K,V&gt; e = first;;) &#123;            if (e != null) &#123;                K k;                // 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。                if ((k = e.key) == key ||                    (e.hash == hash &amp;&amp; key.equals(k))) &#123;                    oldValue = e.value;                    if (!onlyIfAbsent) &#123;                        e.value = value;                        ++modCount;                    &#125;                    break;                &#125;                e = e.next;            &#125;            else &#123;                // 不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。                if (node != null)                    node.setNext(first);                else                    node = new HashEntry&lt;K,V&gt;(hash, key, value, first);                int c = count + 1;                if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)                    rehash(node);                else                    setEntryAt(tab, index, node);                ++modCount;                count = c;                oldValue = null;                break;            &#125;        &#125;    &#125; finally &#123;        //释放锁        unlock();    &#125;    return oldValue;&#125;\n\nput高并发总结：\n\n首先定位到对应的segment再进行hash操作（分段锁）\n判断当前put是否被占用\n如果被占用：自旋锁，直到获取或达到MAX_SCAN_RETRIES，改为使用阻塞锁\n\n\n\nget方法更加简单，直接定位到segment再一步定位元素即可（因为有volatile保证可见性）\nJDk1.8中的ConcurrentHashMap以上的讨论，都是在JDK1.7时，这个版本HashMap有的问题它也都有\n（比如说链表环导致死锁）\n一句话：JDK1.8抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。（数据结构方面也加入了红黑树）\n\nCAS：如果数据放在了数组上（即，数据还没拉链出来），就可以直接CAS判断放置\nSynchronized：如果数据要添加在链表或是树上，就需要syn同步\n\n各数据的来源依据private static final int DEFAULT_CAPACITY = 16;// 初始容量，在HashMap一节也说过，这个容量设置必须是2的幂次static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;// 最大数组大小，为什么要减去8？是因为Array在JVM中还有一些元数据信息要进行存储private static final int DEFAULT_CONCURRENCY_LEVEL = 16;// 默认的并发级别 是16private static final float LOAD_FACTOR = 0.75f;// 负载因子 0.75static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;// 树化和退化的临界阈值static final int MIN_TREEIFY_CAPACITY = 64;// 树化的另一个条件，数组的容量得达到64以上\n\n为什么容量必须是2的幂次？\n​        Hash运算大致为 k % m ，显然m如果是一个素数会让整个Hash散列的更加均匀。但是java中选择了幂数，是因为%的效率远远低于位运算的效率\n假设一个数1234，这个数的二进制是0100 1101 0010\n假设当前容量为16，1234%16=2\n如果我们直接使用这个二进制数的后四位0010与16-1的二进制1111进行位与运算，结果0010 &amp; 1111 = 0010，这个结果也是2\n完全避免了使用%，在Java中也是如此实现的：\nk &amp; (n-1) // n为长度\n\n如果容量为2的幂次，那么容量-1，这个数的二进制为全1，这样就可以加快寻找index的速度\n除此之外，设置为2的幂次还可以加快扩容时转移数据的速度，下文将进行介绍\n为什么是初始值为16？\n​        统计分析的结果，使用过程中16作为初始容量最为合适，不会太大也不会太小。\n我使用构造方法new ConcurrentHashMap&lt;&gt;(4)，它的容量大小会是多少？\n在JDK源码中：会发现我们给了4他也会进行一些计算\npublic ConcurrentHashMap(int initialCapacity) &#123;    if (initialCapacity &lt; 0)        throw new IllegalArgumentException();    int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ?               MAXIMUM_CAPACITY :               tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1));    this.sizeCtl = cap;&#125;\n\ntableSizeFor方法会返回一个大于输入值的最小的2的幂次数\n如果是4的话，传入tableSizeFor方法的参数就是7，那么sizeCtl的值会是 8\n所以要知道，我们给的容量并不是实际的容量\n初始化&amp;sizeCtl变量和HashMap一样，ConcurrentHashMap的初始化方法并不在构造方法内，而是放在了第一次put方法中\nif (tab == null || (n = tab.length) == 0)    tab = initTable();\n\n我们主要来研究initTable这个方法，再看源码之前，我们必须得有些前置了解：\n1、首先注意sizeCtl这个值代表的意思：\nprivate transient volatile int sizeCtl;//表初始化和调整控制。// 值为-1 表示进行初始化// 值为-n 表示正在扩容// 值为整数 表示当前数组要扩容时的阈值（比如容量为16，此值就为16*0.75=12）\n\n2、在内部还会有SIZECTL这个变量\n// Unsafe mechanicsprivate static final sun.misc.Unsafe U;private static final long SIZECTL;...static &#123;        try &#123;            U = sun.misc.Unsafe.getUnsafe();            Class&lt;?&gt; k = ConcurrentHashMap.class;            SIZECTL = U.objectFieldOffset                (k.getDeclaredField(&quot;sizeCtl&quot;));            // 直接从内存中获取输入参数的（即获取内存中sizeCtl）地址偏移量        &#125;    ...&#125;\n\n再次强调，**SIZECTL是sizeCtl在内存中的地址偏移量**\n3、CAS操作：\n3、CAS（Compare And Swap/Set）：比较并变换，是一个原子操作，相同则更新\n\nCAS(V,E,N)\nV 表示要更新的变量（内存值）\nE 表示预期值（旧的）\nN 表示新值\n\n\n如果 V==E 值时，会将 V=N（内存值 == 预期值，说明没有线程对当前变量进行写操作）\n如果 V!=E，则当前线程什么都不做（内存值！= 预期值，说明已经有其他线程做了更新，那么现在就不能更改这个值）\n最后，CAS 操作返回当前 V 的真实值\n\ninitTable源码如下：\nprivate final Node&lt;K,V&gt;[] initTable() &#123;    Node&lt;K,V&gt;[] tab; int sc;    while ((tab = table) == null || tab.length == 0) &#123;        if ((sc = sizeCtl) &lt; 0)            // 小于0 代表有线程正在进行初始化或是扩容          \t// 如果此时其他并发线程进入，会直接yield            Thread.yield(); // lost initialization race; just spin        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123;            // CAS操作！！this与SIZECTL可以确定内存地址，如果此地址的值与sc相同，说明当前没有线程进行写操作，会将-1赋值给SIZECTL            try &#123;                if ((tab = table) == null || tab.length == 0) &#123;                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;                    @SuppressWarnings(&quot;unchecked&quot;)                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];// 此处终于创建了数组                    table = tab = nt;                    sc = n - (n &gt;&gt;&gt; 2);                    // 此处相当于 n - (n / 4) = 0.75 * n                    // 相当于乘了负载因子                &#125;            &#125; finally &#123;                sizeCtl = sc;            &#125;            break;        &#125;    &#125;    return tab;&#125;\n\nput()方法put方法很长，我们将分解的进行对put()方法的探究：\npublic V put(K key, V value) &#123;    return putVal(key, value, false);    // put调用了另一个方法&#125;\n\n1、spread方法：\n​        因为&gt;&gt;&gt;无符号右移就是把低位去掉保留高位。然后高位和低位进行^位运算。这样不管是高位发生变化，还是低位发生变化都会造成其结果的中低位发生变化。\n为什么我们关注其结果的中低位呢，那是因为后面算index的时候，用了h &amp; (length-1)，它的意思就是把高位去掉。如果没有进行扰动计算，当key仅仅发生高位变动的时候就会发生hash冲突，这对Hashmap来说往往是致命的\n​        简而言之，就是为了增大随机性，减少哈希碰撞的次数\nstatic final int spread(int h) &#123;    return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;    // HASH_BITS 是各位全为1的值&#125;\n\n2、tabAt方法\n​        tabAt(tab, i = (n - 1) &amp; hash)在源码中如此使用，意思很明确\n(n - 1) &amp; hash代表下标，此函数的意思就是返回table[index]的值\n下面来正式看代码\nfinal V putVal(K key, V value, boolean onlyIfAbsent) &#123;    if (key == null || value == null) throw new NullPointerException();    int hash = spread(key.hashCode());    // spread 扰动函数    int binCount = 0;    for (Node&lt;K,V&gt;[] tab = table;;) &#123;        // 一个死循环        Node&lt;K,V&gt; f; int n, i, fh;        if (tab == null || (n = tab.length) == 0)            tab = initTable();// 上文介绍了initTable方法        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123;// 如果此位置为null，说明此处是一个空桶，即没有哈希碰撞过            if (casTabAt(tab, i, null,                         new Node&lt;K,V&gt;(hash, key, value, null)))                //使用cas给此位置赋值                break;                   // no lock when adding to empty bin源码的注释也很明确，空桶不用加锁（使用CAS思想）        &#125;        else if ((fh = f.hash) == MOVED)            ...        else &#123;            ...        &#125;    &#125;    addCount(1L, binCount);// 扩容方法    return null;&#125;\n\naddCount()方法addCount中其实并没有进行扩容，而是主要进行了扩容的判断（与扩容阈值sizeCtl进行判断）\nprivate final void addCount(long x, int check) &#123;    CounterCell[] as; long b, s;    if ((as = counterCells) != null ||        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123;      \t// 上面这一堆我们只需关注 s 即可 ，每次都会给s进行增加 s表示当前的size，在下面会对其进行判断        ...    &#125;    if (check &gt;= 0) &#123;        Node&lt;K,V&gt;[] tab, nt; int n, sc;        // 注意下面这个判断条件，用s和sizeCtl比较大小，这是扩容的时机        while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp;               (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123;            int rs = resizeStamp(n);// 标识当前数组            if (sc &lt; 0) &#123;                ...            &#125;            else if (U.compareAndSwapInt(this, SIZECTL, sc,                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))                transfer(tab, null);            // transfer方法：正式的开始扩容！            s = sumCount();        &#125;    &#125;&#125;\n\ntransfer()方法我们知道，在Java中没有动态数组，所谓的动态数组，都是在达到一定程度，进行了几步操作，才实现的\n那么扩容需要几步？\n\n开辟一块新空间\n将旧数组的数据转移到新数组\n\n而其中第二步，转移操作，需要寻找下标，原本计算下标的方式是k&amp;(n-1)，这里是否还需要这样做呢？\n这里Java的操作十分巧妙\n假设有数据为：1110 0011 // 原数据与 16-1 进行与运算，即得到末尾4位现在扩容到了32位，就是要与末尾5位进行比较但是我们不需要再这样操作了，只需要看倒数第五位即可！如果倒数第五位为0：说明与原数组下标相同如果为1：只需要将0001 0000加上原数组位置即可\n\n其次，为了加快迁移速度，还可以使用多线程，使用多线程不能让数据混乱，因此：\n​        在ConcurrentHashMap中，会将原数组进行分段，最少每一个线程完成16个桶的迁移工作，如果不足16个桶，那么就由一个线程来进行迁移\ntransfer就完成了这两步操作：\nprivate final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123;    int n = tab.length, stride;    // 下面的判断是为了使用多线程进行数据迁移；NCPU默认为8，与电脑有关    if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)        stride = MIN_TRANSFER_STRIDE; // subdivide range 切分数组进行数据迁移     if (nextTab == null) &#123;            // initiating        try &#123;            @SuppressWarnings(&quot;unchecked&quot;)            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];// 这里，直接扩容了两倍 &lt;&lt;1 代表乘以2            nextTab = nt;        &#125;        ...    &#125;    ...    else &#123;        synchronized (f) &#123;            if (tabAt(tab, i) == f) &#123;                // 此处是正式的转移操作：分为链表的与红黑树两部分                Node&lt;K,V&gt; ln, hn;                if (fh &gt;= 0) &#123;                    ...                    // 这里的转移方法特别巧妙，就是上面我说明的方法\t\t\t\t\t// 上面省略的部分会将为0的与为1的分为两个链表然后分别进行操作                    setTabAt(nextTab, i, ln);//ln代表0对应的链表                    setTabAt(nextTab, i + n, hn);//hn代表1对应的链表                    setTabAt(tab, i, fwd);                    advance = true;                &#125;                ...            &#125;        &#125;        ...             &#125;\n\n\n\n相关链接\nHashMap源码探究\n\n","categories":["Java源码","ConcurrentHashMap"],"tags":["Java源码","ConcurrentHashMap"]},{"title":"Mybatis复习","url":"/2021/09/12/Mybatis/Mybatis/","content":"\n引言：Mybatis框架复习\n\n\n\nMybatisJDBC开发JDBC开发我们连接数据库需要以下几步操作：\n\n编写Sql语句\n预编译\n设置参数\n执行Sql\n封装结果返回\n\n\n为什么不使用JDBC，而要去使用框架呢？\n\n\n功能简单，Sql直接编写在代码中，高耦合（如果我们之后想更换其中的Sql语句还需要重新打包上线）\n\nORM\nORM：Object Relation Mapping 对象关系映射\n将对象与数据库内的记录进行映射\n\n实现了ORM的框架：\n\nHibernate：一个全自动ORM框架\nMybatis：一个半自动ORM框架\n\n全自动：指一切过程（包括Sql的编写）都由框架来帮助我们实现\n半自动：Sql由我们来写\n\n为什么不用Hibernate，这么好用，Sql都不用自己写？\n\n\nSql由框架封装，没办法优化\n如果要自定义Sql，要去学习HQL，增加学习负担\nHibernate还是一个全映射框架，意味着Bean有多少字段，就会去数据库查多少字段，即使你只需要1个而已，也会全部查出（即一直回表）\n\nMybatis工作原理\n读取全局配置文件（比如mybatis-config.xml）：配置了比如数据源、事务等相关逻辑\n加载映射文件（比如Mapper1.xml Mapper2.xml，需要在全局配置文件注册）\n构造会话工厂SqlSessionFactory：此对象可以创建SqlSession会话，\n构造会话对象SqlSession：此对象用来与数据库进行会话，注意这个对象不是线程安全的！\nExecutor执行器：会根据SqlSession传递的参数动态的生成所需要执行的Sql语句，同时负责查询缓存的维护\nMapperStatement对象：mapper的一个sql对应一个MapperStatement对象，Sql的id就是MapperStatement的id\n输入参数映射\n输出参数映射\n\n我们只需要使用接口式编程，Mybatis会为我们创建代理对象，代理对象去执行增删改查\n注意：\n\n原生：Dao -&gt; DaoImpl；mybatis: Mapper -&gt; xxMapper.xml\nSqlSession代表与数据库的一次会话，使用完成后必须关闭\nSqlSession不是线程安全的！所以我们每次都要去获取新的SqlSession对象，而不是作为成员引用\nmapper接口没有实现类，是因为Mybatis帮我们生成了一个代理对象！\n两个重要的配置文件：\nMybatis全局配置文件（这个配置文件可以没有，可以通过new的方式获得载入SqlSessionFactory中）：配置数据源、事务管理器等\nSql映射文件\n\n\n\nMybatis全局配置文件&lt;configuration&gt;是Mybatis框架全局配置文件的根元素，其子元素还有：\n\n&lt;properties&gt;：将配置外在化（比如配置在properties文件中）配置数据源，比如数据库驱动、数据库url、用户名、密码等\n\n&lt;settings&gt;：配置Mybatis运行时的行为\n\n\n\n设置参数\n作用\n有效值\n默认值\n\n\n\ncacheEnabled\n影响所有映射器中配置的缓存全局开关（配置的是二级缓存）\ntrue/false\nfalse\n\n\nlazyLoadingEnabled\n延迟加载的全局开关\ntrue/false\ntrue\n\n\nuseColumnLabel\n使用列标签代替列名\ntrue/false\ntrue\n\n\ndefaultStatementTimeOut\n设置超时时间，决定驱动等待数据库响应的秒数\n正整数\n没有设置\n\n\nmapUnderscoreToCamelCase\n是否开启驼峰命名规则\ntrue/false\nfalse\n\n\n\n&lt;typeAliases&gt;：设置别名，可以减少冗余的全限定名\n&lt;typeAliases&gt;    &lt;typeAlias alias=&quot;user&quot; type=&quot;com.xx.xx.User&quot;&gt;        &lt;!--配置后user就可以在mybatis配置文件的任何位置代替其全限定名--&gt; &lt;/typeAliases&gt;\n\n\n如果不配置alias，默认就是类名的首字母小写后的名称\n\n注意别名不区分大小写\n\n也可以使用注解的方式@Alias(value=&quot;user&quot;)在类上加（会覆盖原来的别名）\n\n可以使用扫描包的形式，批量设置别名\n&lt;typeAliases&gt;    &lt;package name=&quot;com.xx.xx.pojo&quot;&gt;&lt;/typeAliases&gt;\n\n\n&lt;typeHandlers&gt;：处理对象与数据库数据类型之间映射的桥梁，之后详细说明，非常重要！\n\n&lt;objectFactory&gt;\n\n&lt;plugins&gt;：Mybatis支持拦截调用，拦截调用是通过插件来实现的\n\n&lt;environments&gt;：用于对环境进行配置，比如数据源、比如事务；可以用来配置多种环境，比如开发环境、生产环境、测试环境等\n\n子标签&lt;environment&gt;必须要配置&lt;transactionManager&gt;和&lt;dataSource&gt;\n&lt;transactionManager type=&quot;&quot;&gt;其中事务管理器Mybatis有两种，但是一般Mybatis是与Spring一起使用的，所以直接使用Spring的事务管理即可\n&lt;dataSource type=&quot;&quot;&gt;数据源有三种配置：UNPOOLED、POOLED、JNDI（所以当然使用POOLED这种方式）\n如果要使用自己的数据源，比如C3P0、Druid，需要自定义数据源：要实现DataSourceFactory接口\n\n\n&lt;databaseIdProvider&gt;：适应不同的数据库，然后再select语句中可以使用databaseId属性来标记这个sql去哪个数据库查\n&lt;databaseIdProvider type=&quot;DB_VENDOR&quot;&gt;    &lt;property name=&quot;MySQL&quot; value=&quot;mysql&quot; /&gt;    &lt;property name=&quot;Oracle&quot; value=&quot;oracle&quot; /&gt;&lt;/databaseIdProvider&gt;\n&lt;mappers&gt;：配置Sql映射文件mapper.xml的位置；如果使用注解的方式，没有写mapper文件，也可以配置在这里（推荐使用xml文件的方式！解耦合）\n&lt;mappers&gt;    &lt;mapper resource=&quot;配置Mapper.xml文件的位置&quot;/&gt;    &lt;mapper class=&quot;配置到接口，接口上有@Select等注解&quot;&gt;    &lt;package name=&quot;批量注册&quot;/&gt;&lt;/mappers&gt;\n\nMybatis映射文件映射文件标签配置Mybatis最重要的地方，Mybatis的强大就来源于映射文件的编写！\n根为一个&lt;mapper&gt;标签，其子标签有很多：\n\n&lt;insert&gt; &lt;update&gt; &lt;delete&gt;：增删改，其子标签有\n\nid：此Sql的唯一标识符，设置要与接口的方法名一致\nparameterType：输入参数类型，可以省略\n关于返回值：mybatis为增删改自动封装了几个返回值\ninteger / long：操作的行数\nboolean：操作了大于0行，返回true\n\n\n关于insert的主键自增：配置useGeneratedKeys=&quot;true&quot;与keyProperty=&quot;bean中的主键名&quot;即可\n\n\n&lt;select&gt;：查询操作\n\n要用resultType标识返回值的类型\n\n&lt;mapper namespace=&quot;cn.yesmylord.login.demo.dao.UserDao&quot;&gt;    &lt;select id=&quot;selectUserByUsername&quot; resultType=&quot;cn.yesmylord.login.demo.pojo.User&quot;&gt;        select uid,username,password,salt from login_user where username = #&#123;username&#125;;    &lt;/select&gt;&lt;/mapper&gt;\n\n\n如果返回值是一个集合，resultType也要去标识其中元素的类型！\n\n如果想返回一个Map，key为列名，value为值，就使用resultType=&quot;map&quot;\n\n如果想返回一个Map，key为表的键，value为封装后的记录，就用resultType=&quot;封装的对象比如Student&quot;，然后使用@MapKey(&quot;id&quot;)注解让Mysql知道key为哪一个值\n\nresultMap用来自定义映射关系！实现高级的结果集映射，对于不指定的会自动进行映射\n&lt;resultMap&gt;    &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt;    &lt;!-- 用id专门来对应键 --&gt;    &lt;result column=&quot;email&quot; property=&quot;email&quot;/&gt;    &lt;!-- 其他普通的属性用result --&gt;&lt;/resultMap&gt;\n\n\n&lt;sql&gt;\n\n&lt;cache&gt;：配置缓存\n\n&lt;cache-ref&gt;\n\n&lt;resultMap&gt;\n\n\n参数处理\nmybatis是如何通过#&#123;id&#125;就能获取到值的呢？\n\n这里面涉及到参数处理过程\n1、对于单个参数，mybatis不会做特殊处理，会直接返回结果\n此时不管你#&#123;xxx&#125;内写什么，都可以返回正确的结果\n2、对于多个参数，比如 getUser(String username, String password)\n如果你使用#&#123;username&#125; #&#123;password&#125;是获取不到对应的值的！\n\n原因：多参数时mybatis会做特殊处理，会将这些参数封装为一个map，map的key为param1、param2、param3，value为：传入的参数值\n\n所以多参数需要使用#&#123;param1&#125; #&#123;param2&#125;获取，但是这样太反人类了，所以我们可以使用注解，像这样\ngetUser(@Param(&quot;username&quot;)String username, @Param(&quot;password&quot;)String password)\n\n这样使用#&#123;username&#125; #&#123;password&#125;就能获取到值了\n\n原因：此时mybatis封装map时，就会用我们给的名作为key了！\n\n3、如果参数很多，与POJO类一样，那么直接传POJO类就可以了\n4、如果参数很多，但不是POJO类，我们可以传入map对象\n5、如果参数很多，而且这个方法很常用，那我们需要编写一个TO（Transfer Object）\n6、如果是一个集合，取法类似于#&#123;list[0]&#125;这样\n源码探究我们执行这样一个方法，打断点，进入深层查看：\nUser libai = userDao.selectUserByUsername(&quot;李白&quot;);\n\n第一层：MapperProxy代理类\npublic class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123;    // 可以看到，这个MapperProxy是一个代理对象    // 因为有这个代理对象，我们的接口才可以直接运行\t... 省略    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        // 如果是继承自Object的方法，直接跳过        if (Object.class.equals(method.getDeclaringClass())) &#123;            try &#123;                return method.invoke(this, args);            &#125; catch (Throwable var5) &#123;                throw ExceptionUtil.unwrapThrowable(var5);            &#125;        &#125; else &#123;            MapperMethod mapperMethod = this.cachedMapperMethod(method);            // 我们再进入下一层            return mapperMethod.execute(this.sqlSession, args);        &#125;    &#125;&#125;\n\n第二层：MapperMethod，虽然多，但是我们不需要管其他的，注意我们执行的是一个select方法就好\npublic class MapperMethod &#123;    public Object execute(SqlSession sqlSession, Object[] args) &#123;        Object param;        Object result;        if (SqlCommandType.INSERT == this.command.getType()) &#123;            param = this.method.convertArgsToSqlCommandParam(args);            result = this.rowCountResult(sqlSession.insert(this.command.getName(), param));        &#125;        ...省.去.一.堆...        else if (SqlCommandType.SELECT == this.command.getType()) &#123;            // 我们执行select会进入这里            if (this.method.returnsVoid() &amp;&amp; this.method.hasResultHandler()) &#123;                this.executeWithResultHandler(sqlSession, args);                result = null;            &#125; else if (this.method.returnsMany()) &#123;                result = this.executeForMany(sqlSession, args);            &#125; else if (this.method.returnsMap()) &#123;                result = this.executeForMap(sqlSession, args);            &#125; else if (this.method.returnsCursor()) &#123;                result = this.executeForCursor(sqlSession, args);            &#125; else &#123;                //这里就是处理参数的地方                param = this.method.convertArgsToSqlCommandParam(args);                // 然后进入这里，发现我们的方法，其实就是由sqlSession执行的                result = sqlSession.selectOne(this.command.getName(), param);            &#125;        &#125;         ..省去一堆..&#125;\n\n第三层：还是这个类中MapperMethod，进入这个方法convertArgsToSqlCommandParam\npublic Object convertArgsToSqlCommandParam(Object[] args) &#123;    int paramCount = this.params.size();    if (args != null &amp;&amp; paramCount != 0) &#123;        if (!this.hasNamedParameters &amp;&amp; paramCount == 1) &#123;            // 如果没有注解并且参数只有1个就不做处理            return args[(Integer)this.params.keySet().iterator().next()];        &#125; else &#123;            // 多于1个或是有注解，就要开始封装map了！            Map&lt;String, Object&gt; param = new MapperMethod.ParamMap();            int i = 0;\t\t\t// 遍历 maps            for(Iterator i$ = this.params.entrySet().iterator(); i$.hasNext(); ++i) &#123;                Entry&lt;Integer, String&gt; entry = (Entry)i$.next();                param.put(entry.getValue(), args[(Integer)entry.getKey()]);                String genericParamName = &quot;param&quot; + String.valueOf(i + 1);                // 从param1开始计数作为key                if (!param.containsKey(genericParamName)) &#123;                    param.put(genericParamName, args[(Integer)entry.getKey()]);                &#125;            &#125;            return param;        &#125;    &#125; else &#123;        return null;    &#125;&#125;\n\nthis.hasNamedParameters这个值是一个boolean值，在构造时就会判断有没有加注解\n#&#123;&#125;与$&#123;&#125;Mybatis有两种取值的方法#&#123;&#125;与$&#123;&#125;\n\n都可以获取map中的值或pojo对象的值\n\n区别#&#123;&#125;以预编译的形式，将参数设置到Sql语句中，类似于PrepareStatement，可以防止Sql注入\n但是$&#123;&#125;就是简单的将参数拼装在Sql中，会有安全问题\n\n那还有$&#123;&#125;干什么呢？\n\nJDBC并不是所有操作都支持占位符，比如分表操作、排序操作，都只能使用$&#123;&#125;\n\n#&#123;&#125;的进阶操作\n\n在#&#123;&#125;还可以配置javaType、jdbcType、mode、numericScale、resultType、typeHandler、jdbcTypeName、expression\njavaType用来标记当前字段的Java中的类型，一般无需使用\nmode是存储过程中设置IN、OUT、INOUT\njdbcType可以设置对应数据库中的类型，当传入的值为NULL时，Mybatis会映射为OTHER，Mysql可以识别但是Oracle不可以，所以这里需要处理一下\n#&#123;email, jdbcType=OTHER&#125;\n\nresultMap实现关联查询比方说在Employee对象内，有一个成员为Department，这也是一个对象\n显然自动映射是不可能帮我们实现这样的映射关系的，所以我们可以使用resultMap来实现\n方式一：级联属性封装结果集\n&lt;resultMap&gt;    &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt;    &lt;result column=&quot;email&quot; property=&quot;email&quot;/&gt;    &lt;result column=&quot;did&quot; property=&quot;depart.id&quot;/&gt;    &lt;result column=&quot;dName&quot; property=&quot;depart.name&quot;/&gt;&lt;/resultMap&gt;\n\n方式二：使用association：可以实现一对一关联\n\nproperty：指定哪个属性为联合对象\njavaType：指定这个属性对象的类型（不可以省略）\n\n&lt;resultMap&gt;    &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt;    &lt;result column=&quot;email&quot; property=&quot;email&quot;/&gt;\t&lt;association property=&quot;dept&quot; javaType=&quot;com.xx.xx.pojo.Department&quot;&gt;\t\t&lt;id column=&quot;did&quot; property=&quot;id&quot;/&gt;    \t&lt;result column=&quot;dName&quot; property=&quot;departmentName&quot;/&gt;    &lt;/association&gt;&lt;/resultMap&gt;\n\n方式三：使用association：进行分步查询，并在此之上可以实现延迟加载\n\n延迟加载：我们一直用到了Employee，但不一定会用到Department，所以只有我们用到Department再去查Department，节省资源\n\n&lt;resultMap&gt;    &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt;    &lt;result column=&quot;email&quot; property=&quot;email&quot;/&gt;\t&lt;association                  property=&quot;dept&quot;                 select=&quot;com.xx.xx.dao.DepartmentMapper.getDepartmentById&quot;                 column=&quot;did&quot;                 &gt;        &lt;!-- 基于分段查询可以实现延迟加载 --&gt;    &lt;/association&gt;&lt;/resultMap&gt;\n\n开启懒加载需要两步：\n\n在全局配置文件配置懒加载开启lazyLoadingEnabled为true\n在全局配置文件配置aggressiveLazyLoading为false\n\n&lt;settings&gt;    &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt;    &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt;&lt;/settings&gt;\n\n\n现在我们要去查一个部门下的所有员工，这属于一对多，就需要用到collection\n\nproperty：指定哪个属性为联合对象\nofType：指定集合里面的对应元素的类型\nselect：也可以实现延迟加载\n\n&lt;resultMap&gt;    &lt;id column=&quot;did&quot; property=&quot;id&quot;/&gt;    &lt;result column=&quot;dName&quot; property=&quot;departmentName&quot;/&gt;\t&lt;collection property=&quot;emps&quot; ofType=&quot;com.xxx.xx.pojo.Employee&quot;&gt;        &lt;id column=&quot;eid&quot; property=&quot;id&quot;/&gt;        &lt;result column=&quot;name&quot; property=&quot;name&quot;/&gt;    &lt;/collection&gt;&lt;/resultMap&gt;\n\nMybatis缓存Mybatis默认定义了两级缓存\n\n一级缓存：默认情况下只有一级缓存开启，是SqlSession级别的缓存，也称为本地缓存\n二级缓存：需要手动开启，是namespace级别的缓存，也叫全局缓存\n\n为了提高扩展性，Mybatis也提供了缓存接口Cache，我们可以实现Cache来实现自定义二级缓存\n\n缓存本质就是：一个map对象\n\n一级缓存\n一级缓存会存放：与数据库同一次会话期间查询到的数据\n\n如果之后又用到了这些数据，会直接去缓存取值，但是一级缓存有四种情况，它会失效：\n\nsqlSession不同：如果你查询同一个数据，但是**用了两个不同的SqlSession**，此时就会失效，因为一级缓存是SqlSession级别的\nsqlSession相同，但是查询条件不同：（这是必然的）因为本地缓存没有\nsqlSession相同，但是两次查询期间，执行了增删操作！：因为你的增删操作可能修改了我要查的值\nsqlSession相同，但是手动清除了一级缓存：调用session.clearCache()，删除了一级缓存\n\n二级缓存基于namesapce级别的缓存，一个namespace对应一个二级缓存\n\n二级缓存的工作机制：\n\n\n一个会话查询一个数据，查询完成后会将这个数据放在一级缓存中\n如果这个会话关闭，那么会将一级缓存的数据保存在二级缓存中\n不同的namespace指的就是不同的Mapper，比如说EmployeeMapper查询的数据会放在自己的Map中，DepartmentMapper查询的数据会放在它的Map中\n\n\n二级缓存使用 \n\n\n开启二级缓存（不同版本是否开启不一样，所以我们的全局配置最好显示配置一下）\n\n&lt;settings&gt;    &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;&lt;/settings&gt;\n\n\n在mapper.xml中引入cache标签\n\n&lt;cache eviction=&quot;&quot; blocking=&quot;&quot; readOnly=&quot;&quot; flushInterval=&quot;&quot; size=&quot;&quot; type=&quot; &quot;&gt;&lt;/cache&gt;&lt;!--eviction：缓存的回收策略，有四种\t\tLRU（默认）、FIFO、SOFT（移除软引用对象）、WEAK（移除弱引用对象）flushInterval：缓存刷新间隔，即缓存多长时间清空一次，默认为不清空，可以设置，单位为msreadOnly：是否只读\ttrue：设置为只读，mybatis就会认为你不会进行修改，每次都会返回缓存中的值，                  速度快，但是不安全\tfalse：设置为非只读，mybatis会觉得数据会被修改，会利用序列化与反序列化克隆一份新的数据给你                  速度慢，但是安全，是默认的设置size：缓存的大小type：自定义缓存的全类名，实现cache接口，然后把实现类的全类名写在type内--&gt;\n\n\n由于cache默认设定为非只读，会用到序列化，所以POJO需要实现序列化接口\n\n这样就开启了二级缓存\n\n注意：\n\n所有数据都会先放在一级缓存\n如果SqlSession提交或者关闭之后，才会放入二级缓存\n\n缓存有关的配置项1、cacheEnable=true：全局配置文件中这一项配置的是二级缓存，对一级缓存没有影响\n2、 每个select标签都有useCache=&quot;true&quot;：这里也指的是二级缓存，设置为false，也不会影响一级缓存的使用\n3、 每个增删改标签的flushCache=&quot;true&quot;：增删改执行完成后就会清除缓存，会将一二级缓存全部清空\n4、 sqlSession.clearCache()只是清除当前Session的一级缓存\n5、全局配置文件中的localCacheScope：设置为statement可以禁用一级缓存\n查询时缓存的顺序\n当一个SqlSession去查询数据时，会先查二级缓存，然后才去查一级缓存，如果两级缓存都没有，才回去查数据库\n\n\n","categories":["Mybatis"],"tags":["Mybatis"]},{"title":"Netty","url":"/2021/10/06/Netty/Netty/","content":"\n引言：Netty\n\n\n\nNettyNetty概述\nNetty是什么？\n一个异步的、基于事件驱动的网络应用框架\n\n\n异步：通过回调+Future实现\n事件：通过ChannelHandler实现\n\n（Netty在网络应用框架的地位等同于Spring在JavaEE的地位）\n\nNetty如何引入？\n\nMaven引入包，即可使用Netty\n&lt;dependency&gt;    &lt;groupId&gt;io.netty&lt;/groupId&gt;    &lt;artifactId&gt;netty-all&lt;/artifactId&gt;    &lt;version&gt;4.1.39.Final&lt;/version&gt;&lt;/dependency&gt;\n\n\nNetty的构成\n\nNetty主要由五大部分组件构成：（下面我们会依次介绍）\n\nEventLoop &amp; EventLoopGroup\nChannel &amp; ChannelFuture\nFuture &amp; Promise\nHandler &amp; PipeLine\nByteBuf\n\nEventLoop &amp; EventLoopGroup\nEventLoop（事件循环）：相当于一个单线程执行器，维护了一个Selector\n（我们可以把EventLoop当做一个Thread+Selector）\n\n作用：内部有run方法处理channel上源源不断的IO事件\n基本APIEventLoop的继承：\n\n继承j.u.c.ScheduledExecutorService，有关于定时线程的相关方法\n继承EventExecutor，内部有方法可以查看EventLoop属于的组，以及判断一个线程属不属于此EventLoop\n\n核心API：\n\n其可以通过EventLoop的next方法获得\n（因为继承了ScheduledExecutorService，所以有执行任务的方法）\nexcute(Runnable)执行任务\nsubmit(Runnable)执行任务，返回一个Future对象\nscheduleAtFixedRate(Runnable, initialDelay, period, TimeUnit)执行定时任务\n\n\nEventLoopGroup（事件循环组）：内部包含一组EventLoop\n\n这个接口的实现类有很多，常用的实现类有：\n\nNioEventLoopGroup：负责处理IO事件、普通任务、定时任务\nDefaultEventLoopGroup：负责处理普通任务、定时任务\n\n核心API：\n\nnew NioEventLoopGroup(int)：创建一个NioEventLoopGroup，参数是int类型的值，如果不传，按默认的值来设置\nDEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt(&quot;io.netty.eventLoopThreads&quot;, NettyRuntime.availableProcessors() * 2));// 默认是1或是配置文件配置的线程数或是电脑核心线程数*2的较大值\nnext()：可以获得一个下一个EventLoop对象\n\n\n\n这里简单的一个Demo介绍一下如何使用：    \nEventLoopGroup group1 = new NioEventLoopGroup(5); //此对象可以处理： io事件、普通任务、定时任务EventLoopGroup group2 = new DefaultEventLoopGroup(); //此对象可以处理： 普通任务、定时任务group1.execute(() -&gt; &#123;    System.out.println(&quot;执行普通任务&quot;);&#125;);group1.next().scheduleAtFixedRate(() -&gt; &#123;    System.out.println(&quot;执行定时任务&quot;);&#125;, 0, 1, TimeUnit.SECONDS);\n\nNioEventLoopGroup最主要的作用是处理IO事件，下面我们会单独专门讲述\n执行IO请求NioEventLoopGroup可以处理三种任务：IO事件、普通任务、定时任务\n处理IO事件不是NioEventLoopGroup一个就可以完成的，他需要与其他组件合作\nnew ServerBootstrap()    .group(new NioEventLoopGroup())    // 这一步就是创建EventLoopGroup    .channel(NioServerSocketChannel.class)    // 设置通道    .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;        @Override        protected void initChannel(NioSocketChannel ch) throws Exception &#123;            // 进行处理            ch.pipeline().addLast(new ChannelInboundHandlerAdapter()&#123;                @Override                public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;                    ByteBuf byteBuf = (ByteBuf) msg;                    log.debug(byteBuf.toString(Charset.defaultCharset()));                &#125;            &#125;);        &#125;    &#125;)    .bind(8080);\n\n任务分工与细化分工NIO一节，我们学过boss与worker模型，boss负责ACCEPT请求，worker负责读写请求，在Netty的任务可以细分：\nnew ServerBootstrap()    // 这里可以指定两个EventLoopGroup    // 第一个就是boss，第二个就是worker    .group(new NioEventLoopGroup(), new NioEventLoopGroup())\n\n\n如果第一个参数是boss，只负责ACCEPT请求，那么我们是不是要设置参数为1呢？比如这样.group(new NioEventLoopGroup(1), new NioEventLoopGroup())\n\n不需要的，Netty默认就是Boss只会被启动一个，所以可以不用指定1\n细化\n设想这么一个场景，如果有比较重量级的操作，我们可以单独给其分配一个EventLoopGroup来专门执行这种重量级操作，以免阻塞我们的其他任务\n\n//【细化】让一个group专门去做耗时的工作EventLoopGroup group = new DefaultEventLoop();new ServerBootstrap()    // 【分工】：这里可以指定两个EventLoopGroup    // 第一个就是boss，第二个就是worker    .group(new NioEventLoopGroup(), new NioEventLoopGroup())    .channel(NioServerSocketChannel.class)    .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;        @Override        protected void initChannel(NioSocketChannel ch) throws Exception &#123;            ch.pipeline().addLast(&quot;handler1&quot;,new ChannelInboundHandlerAdapter()&#123;                @Override                public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;                    ByteBuf byteBuf = (ByteBuf) msg;                    log.debug(byteBuf.toString(Charset.defaultCharset()));                    System.out.println(&quot;handler1&quot;);                    ctx.fireChannelRead(msg);// 这个方法可以传msg到下一个handler                &#125;            &#125;).addLast(group,&quot;handler2&quot;, new ChannelInboundHandlerAdapter()&#123;                @Override                public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;                    System.out.println(&quot;handler2&quot;);                    System.out.println(msg);                &#125;            &#125;);        &#125;    &#125;)    .bind(8080);\n\nChannel &amp; ChannelFuture\nchannel： 一个到实体的开放连接\n实体包括一个硬件设备、一个文件、一个Socket等等内容\n\n类似于NIO的通道，Netty的Channel本身也是对Channel的一个封装\n核心API\nclose()可以用来关闭channel\ncloseFuture()：用来处理channel的关闭，可以附加其他操作\nsync方法作用是同步等待channel关闭\naddListener异步等待channel关闭\n\n\npipeline()：方法添加处理器\nwrite()方法将数据写入（写入发送缓冲区，但不一定立即发送，可能达到一定大小，才会发送出去）\nwriteAndFlush()将数据立刻写入并刷出（写入缓冲区并且立即发送）\n这个方法相当于调用write()与flush()两个方法\n\n\n\nChannelFuture对象\nChannelFuture：异步IO操作的返回结果（成功、失败、或是取消）\n\n​        由于Netty中所有的IO操作都是异步的，这意味着任何IO调用都将立即返回，但不保证请求的IO操作已在调用结束时完成\n​        所以就有了ChannelFuture这个对象，用于在某个时间点确定操作结果\n理解Netty的操作都是异步的很重要，比如我们的客户端连接操作\nChannelFuture channelFuture = new Bootstrap()    .group(new NioEventLoopGroup())    .channel(NioSocketChannel.class)    .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;        @Override        protected void initChannel(NioSocketChannel ch) throws Exception &#123;            ch.pipeline().addLast(new StringEncoder());        &#125;    &#125;)    .connect(new InetSocketAddress(&quot;localhost&quot;, 8080));// 获得ChannelFuture对象channelFuture    //.sync() // 我们现在不去调用同步方法    .channel()    .writeAndFlush(&quot;hello world&quot;);\n\n执行会发现，不会给服务器发送hello world的信息\n\n为什么不会给客户端不会发送hello world的信息？\n\n​        因为Netty是异步非阻塞的，main线程发起调用，但其实是创建了一个新的NIO线程来执行connect()操作（异步），这个连接操作很耗时\n​        而main线程调用完后，会立即向下执行（非阻塞），因此获得的channel对象不是成功建立连接后的对象，它发消息也就发不出去了\n\n如何解决这个问题？\n\n\n【法一】调用sync方法，这个方法会让main线程与运行connect的线程同步（即阻塞main线程直到channel创建完成）\n【法二】调用addListener(回调对象)，传入一个GenericFutureListener接口，我们可以传入其子接口ChannelFutureListener\n\nchannelFuture.addListener(new ChannelFutureListener() &#123;    @Override    // operationComplete方法会由执行NIO的线程执行完成后调用    public void operationComplete(ChannelFuture future) throws Exception &#123;        Channel channel = future.channel();        channel.writeAndFlush(&quot;hello&quot;);    &#125;&#125;);\n\n\n注意：\n​        Channel对象的关闭与连接一样，都是由另外的线程真正执行的关闭操作，Channel对象可以调用sync同步或者addListener异步来执行通道关闭后的操作\n\nFuture &amp; Promise\nFuture是另一种在操作完成时通知APP的方式\n（还有一种是回调方法,比如新的连接建立触发：channelActive()）\n\n两个Future与Promise的关系JUC也有Future对象，Netty的Future继承了JUC的Future，Promise是对Netty Future的进一步扩展\n\n一句话：Promise继承 nettyFuture；netty Future 继承 JUC Future\n\n区别：\n\nJDK Future只能同步等待任务结束，才能得到结果\nNetty Future可以同步/异步等待任务结束，然后获得结果\nPromise不仅有Future的功能，而且脱离了任务独立存在，作为两个线程间传递结果的容器\n\n核心API对比：\n\n\n\n功能\nJDK Future\nNetty Future\nPromise\n\n\n\ncancel\n取消任务\n继承\n继承\n\n\nisCanceled\n判断任务是否取消\n继承\n继承\n\n\nisDone\n判断任务是否结束（成功/失败）\n继承\n继承\n\n\nget\n获得结果（阻塞等待）\n继承\n继承\n\n\ngetNow\n无\n获取任务结果，非阻塞，会先立即返回null\n继承\n\n\nawait\n无\n等待任务结束（任务失败不会抛出异常）\n继承\n\n\nsync\n无\n等待任务结束（任务失败抛出异常）\n继承\n\n\nisSuccess\n无\n判断任务是否成功\n继承\n\n\ncause\n无\n获取失败信息（非阻塞），如果没有失败返回null\n继承\n\n\naddListener\n无\n添加回调，异步接收结果\n继承\n\n\nsetSuccess\n无\n无\n设置成功返回的结果\n\n\nsetFailure\n无\n无\n设置失败返回的结果\n\n\n事件 &amp; ChannelHandler &amp; ChannelPipeLine\n事件：事件是某些动作完成时发送的信息\n\n入站端的事件比如有：连接已激活或失活、数据读取、用户事件、错误事件\n出站事件：打开关闭远程节点的连接、数据写到或冲刷到套接字\n\nChannelHandler：处理IO事件或拦截IO操作，并将其转发到其PipeLine中的下一个handler（可以理解为一道工序）\n\n简单的我们可以理解为：是一个可以响应不同事件的回调方法\n这里有个图，很好的表示了事件和ChannelHandler的关系\n\n如图所示，在一个事件发生后，会经过一系列的处理器（即Handler）最后成功入站或出站\n\n注意：Netty服务器至少需要两部分：\n\n至少一个 ChannelHandler\n引导：客户端Bootstrap、服务端ServerBootstrap\n\n引导的作用：为了配置服务器，比如连接服务器到指定的端口\n\n\nChannelPipeLine：一个Handler的列表（可以理解为一条流水线）或者说是ChannelHander的容器\n\nInboundHandler有两种ChannelHandler，分为入站、出站两种（注意是站，不是栈）\nChannelInboundHandlerAdapter\nChannelHandler是一个父接口，使用需要重写很多方法，所以实现时，我们可以使用他们的适配器Adapter的子类，来很快的达到目的\n\n入站处理器通常是ChannelInboundHandlerAdapter的子类，下面是它的相关事件的回调\n（所谓回调：当触发对应事件的时候，会调用相关方法）\n\nchannelRead()：每个消息传入都会调用此方法\nchannelReadComplete()：当前批量读取的最后一条消息会触发此方法\nexceptionCaught()：读取操作发生异常会调用此方法\n\nSimpleChannelInboundHandler此类是ChannelInboundHandlerAdapter的子类，它的相关回调有：\n\nchannelActive()：当连接建立后将被调用\nchannelRead0()：收到一条消息就被调用\nexceptionCaught()：读取操作发生异常会调用此方法\n\n\n注意：channelRead0可能会执行很多次，因为由服务器发送的消息可能会被分块接收。\n也就是说，如果服务器发送了 5 字节，那么不能保证这5字节会被一次性接收\n\n那么SimpleChannelInboundHandler和他的父类ChannelInboundHandlerAdapter有什么区别呢？\n前者会帮我们释放关于ByteBuf的内存引用，而后者没有实现。\nOutboundHandler出站处理器通常是ChannelOutboundHandlerAdapter的子类，主要用来对写回数据进行加工\n通过通道获取PipeLine，通过PipeLine的addLast方法添加处理器\nChannelPipeline与Handler的执行流程PipeLine（或者说Handler的执行流程）的结构就是一个双向链表\n两个特殊的Handler：一个head，一个tail\n\n注意：\n\npipeline.addLast(xxx)：会将handler加到tail之前，并不是真正的最后\nInbound负责执行读操作，是从head开始的\nOutBound负责执行写操作，是从tail开始的\n\n\nInboundhandler内一个handler如何传递对象给下一个handler？\n\n可以通过调用super.channelRead(ctx,msg);方法，将想要传递的对象作为msg传递给下一个handler，\n其内部其实调用的是fireChannelRead方法\n@Skip@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;    ctx.fireChannelRead(msg);&#125;\n\n如果某一个handler没有调用此方法，那么传递链就会断开\n\nchannel的write与ctx的write的区别！（重要）\n\n这两个容易搞混，如图示：\n\nchannel的write是从tail开始向前找到第一个Outboundhandler（注意：是从tail开始！找的OutBoundHandler，不找InboundHandler）\nctx的write是从当前handler开始向前找Outboundhandler（注意：是从当前handler开始，也是找的outboundhandler）\n\nByteBufByteBuf是netty对NIO ByteBuffer的一个增强\nByteBuf的创建创建一个ByteBuf不能直接new，需要ByteBufAllocator来创建\n\n使用ByteBufAllocator.DEFAULT.buffer()\n默认字节数组长度256字节，可以自己指定\n如果存满，会自动扩容（NIO会报错）\n\n// 可以传入一个Capacity，默认是256字节，而且可以扩容ByteBuf byteBuf = ByteBufAllocator.DEFAULT.buffer();System.out.println(byteBuf);StringBuilder sb = new StringBuilder();for (int i = 0; i &lt; 300; i++) &#123;    sb.append(&quot;2&quot;);&#125;byteBuf.writeBytes(sb.toString().getBytes());System.out.println(byteBuf);/* 输出：（ridx读指针、widx写指针）        PooledUnsafeDirectByteBuf(ridx: 0, widx: 0, cap: 256)        PooledUnsafeDirectByteBuf(ridx: 0, widx: 300, cap: 512)*/\n\n\n默认创建的就是直接内存，也可以创建堆内存\n\nByteBufAllocator.DEFAULT.buffer();// 默认就创建直接内存ByteBufAllocator.DEFAULT.directBuffer();// 创建直接内存ByteBufAllocator.DEFAULT.heapBuffer();// 创建堆内存\n\n\n直接内存与堆内存的区别：\n\n1、管理机制不同：直接内存由OS管理，堆内存由JVM管理\n2、创建速度：直接内存创建比较麻烦，堆内存创建十分迅速\n综上：\n直接内存的优点是读写性能好（会少一次数据Copy的过程），但是创建比较慢，而且需要自己进行释放\n而堆内存的优点是创建速度快，但是读写性能会低一点\n\nPS：此处再贴一个调试ByteBuf的小工具\nimport static io.netty.buffer.ByteBufUtil.appendPrettyHexDump;import static io.netty.util.internal.StringUtil.NEWLINE;private static void log(ByteBuf buffer)&#123;    int length = buffer.readableBytes();    int rows = length / 16 + (length % 15 == 0 ? 0 : 1) + 4;    StringBuilder buf = new StringBuilder(rows * 80 * 2)        .append(&quot;read index&quot;).append(buffer.readerIndex())        .append(&quot; write index&quot;).append(buffer.writerIndex())        .append(&quot; capacity&quot;).append(buffer.capacity())        .append(NEWLINE);    appendPrettyHexDump(buf, buffer);    System.out.println(buf.toString());&#125;\n\n池化思想\n为什么ByteBuf引入池化思想？\n\nNetty采用了直接内存，但是直接内存的缺点是创建比较慢，所以引入了池化思想，来优化\n池化功能在4.1之前不成熟，默认是非池化的\n在4.1之后，默认是池化创建（非Android平台）\n可以配置参数设置是否开启池化\nByteBuf的组成ByteBuf由四部分组成：废弃部分、可读部分、可写部分、可扩容部分\n\n\n有读指针和写指针\n\n最大容量代表int类型的最大值（我们的内存可能都没有那么大）\n\n\n\n相比较NIO 的Buffer，ByteBuf有什么优势呢？\n\n\n可以扩容（有可扩容部分）\n不必再来回切换读写模式（有读指针和写指针）\n\n\nByteBuf的扩容规则\n\n写入后容量大小是否超过512？\n\n未超过：则选择下一个16的整数倍\n\n超过：选择下一个2^n\n\n\n注意：扩容不能超过最大容量，否则报错\n​        比如，假设当前为默认容量256，在写入一个数据后，为257，此时触发扩容，由于小于512，所以会选择下一个16的倍数，即272\n​        一直写入，写入到513字节时，触发扩容，扩容为2的幂次，即1024。\n核心API\n写操作\n\nByteBuf给每一个基本数据类型都提供了写方法，此处捡重点说一下\n\nwriteBoolean(boolean)：ByteBuf内部存储时，使用0表示false，1表示true\nwriteInt(int) &amp; writeIntLE(int)：这两个方法有什么区别呢？\nwriteInt(int)就是常用的方法，他是大端存储的\nwriteIntLE(int)是小端存储的\n\n\n\n大端存储6，其结构就是0000 0110，而小端存储为0110 0000\n（一般内存设计都是大端存储的，极个别的内存厂商使用小端存储）\n\nwriteBytes(xxx)：这个方法可传入的参数非常多，甚至包括NIO的ByteBuf\nwriteCharSequence(CharSequence子类, 字符集)：这个方法可以传入字符串等等CharSequence的子类\n\n\n读操作\n\n读操作主要的方法有三个\n\nreadByte()：读取1个字节\nreadInt()：读取4个字节\nmarkReaderIndex()：标记当前的读位置\nresetReaderIndex()：重置读位置到标记的位置\n\nByteBuf的销毁与内存释放ByteBuf的种类：\n\nUnpooledHeapByteBuf：使用JVM内存，只需等待GC\nUnpooledDirectByteBuf 使用直接内存，也可以等待GC，但是这样回收不及时，需要特殊的方法来回收内存\nPooledByteBuf 和它的子类使用了池化机制，需要更复杂的规则来回收内存\n\n\nNetty采用了引用计数法来控制回收内存\n\n每个ByteBuf都实现了ReferenceCounted接口\n\n每个ByteBuf对象初始计数为1\n\n调用release方法将计数减1，如果计数为0，ByteBuf内存被回收\n\n调用retain方法计数加1，表示调用者没用完之前，其他handler即使调用了release也不会造成回收\n\n如果计数为0，那么它的内存就会被回收，即使ByteBuf对象还在，它的方法也不能正常使用\n\n\npublic interface ReferenceCounted &#123;    boolean release();    ReferenceCounted retain();    ...&#125;\n\n\nhandler释放ByteBuf的规则是什么？\n\n因为pipeLine上有很多handler，所以我们要保证所有的handler都不会再使用ByteBuf了，再去释放\n因此规则就是：谁最后使用，谁释放\n\nhead handler与tailhandler也会帮我们进行对ByteBuf的处理\n\ntailhandler：\n学习handler一节我们知道，channel的write方法，会先找到tail，所以tail其实也是一个Inboundhandler，因此我们主要关注channelRead()方法\n// A special catch-all handler that handles both bytes and messages.final class TailContext extends AbstractChannelHandlerContext implements ChannelInboundHandler &#123;    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) &#123;        onUnhandledInboundMessage(ctx, msg);    &#125;    ...省略其他方法...&#125;   \n\n到最后会遍历到一个方法ReferenceCountUtil.release()，此方法如下\npublic static boolean release(Object msg) &#123;    if (msg instanceof ReferenceCounted) &#123;        // 如果msg是ByteBuf的实例，那么就将其release，将计数-1        // 每一个ByteBuf都实现了ReferenceCounted        return ((ReferenceCounted) msg).release();    &#125;    return false;&#125;\n\n\n\nhead handler：\nheadhandler既是一个InboundHandler，也是一个OutboundHandler\nfinal class HeadContext extends AbstractChannelHandlerContext    implements ChannelOutboundHandler, ChannelInboundHandler &#123;    @Override    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) &#123;        unsafe.write(msg, promise);    &#125;&#125;\n\n找到这个方法的实现类（这个方法实现涉及到了outboundBuffer，我们之后再了解）\npublic final void write(Object msg, ChannelPromise promise) &#123;    assertEventLoop();    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;    if (outboundBuffer == null) &#123;        // If the outboundBuffer is null we know the channel was closed and so        // need to fail the future right away. If it is not null the handling of the rest        // will be done in flush0()        // See https://github.com/netty/netty/issues/2362        safeSetFailure(promise, newClosedChannelException(initialCloseCause));        // release message now to prevent resource-leak        ReferenceCountUtil.release(msg);        // 此处进行了删除        return;    &#125;    int size;    try &#123;        msg = filterOutboundMessage(msg);        size = pipeline.estimatorHandle().size(msg);        if (size &lt; 0) &#123;            size = 0;        &#125;    &#125; catch (Throwable t) &#123;        safeSetFailure(promise, t);        ReferenceCountUtil.release(msg);        return;    &#125;    outboundBuffer.addMessage(msg, size, promise);&#125;\n\nByteBuf的零拷贝Netty的ByteBuf的零拷贝体现，与NIO的有所不同\n在NIO中的零拷贝，意思是不会将重复的数据拷贝到用户内存中；\n在ByteBuf中的零拷贝，意思是仅仅是逻辑上的复制或拷贝（仅仅只有读写指针是相互独立的，但是内存其实共用的一块内存）\n\n零拷贝体现一：slice(index, length)\n\n获取源byteBuf的一部分，两者共用同一块内存，仅仅是读写指针独立\nByteBuf buffer = ByteBufAllocator.DEFAULT.buffer();buffer.writeCharSequence(&quot;abcde&quot;, StandardCharsets.UTF_8);ByteBuf slice1 = buffer.slice(2, 2);//cdbuffer.setByte(2, &#x27;C&#x27;);// 更改了源，slice也会变\n\n由于ByteBuf这种零拷贝特性，如果发生这种情况就会出错：\nbuffer.release();log(slice1);// 源bytebuf已经释放，引用slice就会报错\n\n所以为了防止这种问题，所以我们应该在slice后，调用一次retain()方法\n\n零拷贝体现二：duplicate()\n\n将源数据整个复制一份，其他遇slice一样，可以理解为slice(0, buffer.capacity())\n\n零拷贝体现三：CompositeByteBuf\n\n与slice正好相反，这个方法是将多个buf合为一个buf，不会发生复制操作，也是逻辑上的合并\n// 创建两个buf等待合并操作ByteBuf buffer1 = ByteBufAllocator.DEFAULT.buffer();buffer1.writeBytes(new byte[]&#123;1,2,3,4,5&#125;);ByteBuf buffer2 = ByteBufAllocator.DEFAULT.buffer();buffer2.writeBytes(new byte[]&#123;6,7,8,9,10&#125;);ByteBuf bufUnion1 = ByteBufAllocator.DEFAULT.buffer();bufUnion1.writeBytes(buffer1).writeBytes(buffer2);// 这种方式也可以实现合并，但是发生了复制，影响性能CompositeByteBuf bufUnion2 = ByteBufAllocator.DEFAULT.compositeBuffer();bufUnion2.addComponents(true,buffer1, buffer2);// 这种方式就是零拷贝的方式\n\naddComponents()第一个参数为true代表自动调整写指针（默认是不会调整写指针的）\n虽然提高了性能（零拷贝），但是不便于维护\n\n不同与零拷贝，ByteBuf实现了copy()函数，进行深拷贝\n","categories":["Java","Netty"],"tags":["Java","Netty"]},{"title":"Spring进阶","url":"/2020/08/25/Spring/Spring%E8%BF%9B%E9%98%B6/","content":"\n引言：Spring回顾与进阶\n\n\n\n\nSpring回顾（未完成）SpringSpring是流行的AOP、IOC核心框架，核心组件有七个：Spring Context、Spring Core、Spring Web、Spring MVC、Spring AOP、Spring Dao、Spring ORM\n1、为什么要用Spring？\n低侵入式：代码污染极低\n集中管理：IoC让相互协作的组件保持松散的耦合\n代码复用：AOP编程允许你把遍布于应用各层的功能分离出来形成可重用的功能组件\n对主流框架的支持\n\n2、什么是IOC？IOC，控制反转，与DI 依赖注入其实描述的是一个事情。\nIOC控制反转，就是将对bean的控制权，转交给容器，让容器来帮助我们管理；\nDI依赖注入，就是将有关对象的信息，注入到容器中，让容器帮我们创建对象，在Spring中就是用@Autoweired，populateBean来帮我们完成的属性注入。\n容器是什么呢？\n​        容器是用来存储对象的，在Spring中，有三级缓存，singletonObejcts用来存放完整的bean对象，bean从创建到销毁的过程都是由容器来管理的。\n\n容器的创建过程\n\n\n向bean工厂中设置一些参数（BeanPostProcessor，Aware接口的子类）等\n加载解析Bean对象，准备要创建的bean对象的定义对象beanDefinition（xml或者注解的解析过程）\nbeanFactoryPostProcessor的处理（扩展点，PlaceHolederConfigureSupport，ConfigurationClassPostProcessor）\nbeanPostProcessor注册功能，方便后续对bean完成具体的功能扩展\n通过反射将beandefinition对象实例化成具体的bean对象\nbean对象的初始化过程（填充属性，调用Aware方法、调用BeanPostProcessor前置处理方法、调用init-method、调用BeanPocessor的后置处理方法）\n生成完成的bean对象，就可以通过getBean直接获取\n销毁过程\n\n\nIOC的底层实现：\n\n先通过createBeanFactory创建出一个Bean工厂（DefaultListableBeanFactory）\n开始循环创建对象，因为容器中的bean默认都是单例的，所以优先通过getBean、doGetBean从容器中查找，找不到的话\n通过createBean、doCreateBean方法，以反射的方式创建对象，一般情况下使用的是无参的构造方法（getDeclareConstructor、newInstance）\n进行对象的属性填充populateBean\n进行其他的初始化操作（initializingBean）\n\n3、什么是AOP？AOP 面向切面，用于将那些与业务无关的代码，比如说日志、事务、权限验证等内容，抽成一个切面，降低代码的耦合程度\nAOP的具体实现，就是代理模式的使用，代理模式分为静态代理和动态代理，在Spring中，静态代理为AspectJ、动态代理为JDK动态代理和CG lib动态代理\n4、JDK动态代理和CG lib动态代理的区别JDK动态代理：\n​        只能代理那些具有接口的实现类，如果一个类没有实现任何接口，那么JDK动态代理将不能实现\n具体的实现原理：动态代理类实现InvocationHandler接口，重写invoke方法（三个参数：代理类、代理的方法、方法参数）\npublic class ProxyInvocationHandler implements InvocationHandler &#123;    // 真实对象    private Object target;    public void setTarget(Host target) &#123;        this.target = target;    &#125;    // 获得代理类    public Object getProxy()&#123;        return Proxy.newProxyInstance(                this.getClass().getClassLoader(),                target.getClass().getInterfaces(),                this        );    &#125;    @Override    // 处理代理实例，返回对象    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        System.out.println(&quot;A操作&quot;);        Object invoke = method.invoke(target, args);        System.out.println(&quot;B操作...&quot;);        return invoke;    &#125;&#125;\n\nCG lib动态代理：\n​        CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成指定类的一个子类对象，并覆盖其中特定方法并添加增强代码，从而实现AOP\n​        CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的\n具体实现：实现MethodInterceptor接口，重写intercept方法\n/** * 注意是org.springframework.cglib.proxy这个包下的MethodInterceptor */public class MyCglibProxy implements MethodInterceptor &#123;    private ProductDao productDao;    public MyCglibProxy(ProductDao productDao) &#123;        this.productDao = productDao;    &#125;    public Object creatProxy()&#123;        //1. 核心类        Enhancer enhancer = new Enhancer();        //2. 设置父类        enhancer.setSuperclass(productDao.getClass());        //3. 设置回调，类似于InvocationHandler这个类        enhancer.setCallback(this);        Object proxy = enhancer.create();        return proxy;    &#125;    @Override    public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123;        if(&quot;save&quot;.equals(method.getName()))&#123;            // 这里意思是 当方法为 save ，就启动权限检验功能            System.out.println(&quot;权限检验&quot;);            return methodProxy.invokeSuper(proxy,args);        &#125;        return methodProxy.invokeSuper(proxy,args);    &#125;&#125;\n\n5、Bean的作用域七种作用域：\n\nsingleton：在SpringIOC容器中仅存在一个Bean实例，Bean以单例的方式存在\nprototype：每次调用getBean()时都会返回一个新的实例\nrequest：每次HTTP请求都会创建一个新的Bean（仅适用在WebApplicationContext环境）\nsession：同一个HTTP Session共享一个Bean，不同的HTTP Session使用不同的Bean（仅适用在WebApplicationContext环境）\nglobal-session：全局作用域，所有会话共享一个实例\napplication：每个ServletContext创建一个实例\nwebsocket：每个websocket创建一个实例\n\n6、Bean的生命周期简单来说，Spring Bean的生命周期只有四个阶段：\n实例化 Instantiation -&gt; 属性赋值 Populate  -&gt; 初始化 Initialization -&gt; 销毁 Destruction\n\n具体过程：\n1、实例化Bean：反射方式生成对象\n\n对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。\n\n对于ApplicationContext容器，当容器启动结束后，通过获取BeanDefinition对象中的信息，实例化所有的bean。\n\n\n（区别就是，Application一次性全载入了所有的bean，而BeanFactory采用的是延迟加载）\n2、设置对象属性（依赖注入）\n​        实例化后的对象被封装在BeanWrapper对象中，紧接着，Spring根据BeanDefinition中的信息以及通过BeanWrapper提供的设置属性的接口完成属性设置与依赖注入。\n3、处理Aware接口\n​        Spring会检测该对象是否实现了xxxAware接口，通过Aware类型的接口，可以让我们拿到Spring容器的一些资源：\n\n如果这个Bean实现了BeanNameAware接口，会调用它实现的setBeanName(String beanId)方法，传入Bean的名字；\n如果这个Bean实现了BeanClassLoaderAware接口，调用setBeanClassLoader()方法，传入ClassLoader对象的实例。\n如果这个Bean实现了BeanFactoryAware接口，会调用它实现的setBeanFactory()方法，传递的是Spring工厂自身。\n如果这个Bean实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文；\n\n4、 BeanPostProcessor前置处理\n​        （这个阶段实现了AOP）\n​        如果想对Bean进行一些自定义的前置处理，那么可以让Bean实现了BeanPostProcessor接口，那将会调用postProcessBeforeInitialization(Object obj, String s)方法。\n5、InitializingBean\n​        如果Bean实现了InitializingBean接口，执行afeterPropertiesSet()方法。\n6、init-method\n​        如果Bean在Spring配置文件中配置了init-method 属性，则会自动调用其配置的初始化方法。\n7、BeanPostProcessor后置处理\n​        如果这个Bean实现了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法；\n​        由于这个方法是在Bean初始化结束时调用的，所以可以被应用于内存或缓存技术；\n\n以上几个步骤完成后，Bean就已经被正确创建了，之后就可以使用这个Bean了\n\n8、DisposableBean：当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用其实现的destroy()方法；\n9、destroy-method：最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法\n7、Spring中的Bean是线程安全的么？如果线程不安全，如何处理？分不同类型来讨论：\n1、对于prototype作用域的Bean，每次都创建一个新对象，也就是线程之间不存在Bean共享，因此不会有线程安全问题。\n2、对于singleton作用域的Bean，所有的线程都共享一个单例实例的Bean，因此是存在线程安全问题的。但是如果单例Bean是一个无状态Bean，也就是线程中的操作不会对Bean的成员执行查询以外的操作，那么这个单例Bean是线程安全的。\n\n有状态Bean(Stateful Bean) ：就是有实例变量的对象，可以保存数据，是非线程安全的。（比如Model和View）\n无状态Bean(Stateless Bean)：就是没有实例变量的对象，不能保存数据，是不变类，是线程安全的。（比如Controller类、Service类和Dao等，这些Bean大多是无状态的，只关注于方法本身）\n\n解决办法：\n\n最简单的办法，将singleton改为prototype\n还可以采用ThreadLocal存\n\n6、Bean的实例化方式\n构造器实例化（默认的无参构造方法）\n静态工厂方法实例化\n配置&lt;bean factory-method=&quot;xxx&quot;/&gt;\n\n\n实例工厂方式实例化\n要配两个bean\n实例工厂的bean要配置&lt;bean id=&quot;xxx&quot; factory-bean=&quot;xxx&quot; factory-method=&quot;xxx&quot;&gt;\n\n\n\n7、Bean的依赖注入方式有三种：\n\nXML注入属性\n\n注解注入属性\n\n自动注入属性\n\n\nXML注入属性Spring有两种基于XML的注入方式：设值注入、构造注入\n原理：Spring先调用对象的构造方法，然后通过反射调用setter方法给对象设置属性\n\n设值注入（必须满足两点要求）\n\n\n有默认的无参构造方法\n有setter方法\n\n然后bean文件配置子标签&lt;property&gt;即可\n\n构造注入\n\n要提供带所有参数的有参构造方法\n然后bean文件配置子标签&lt;constrictor-arg&gt;即可\n注解注入属性注解注入，就比较简单了，常见有\n@Component // 任何层次@Repository // 数据访问层DAO@Service // 业务层@Controller // 控制层@Autowired // 对Bean的属性变量、属性的setter方法及构造方法进行标注；\t\t\t// 作用是：可以与对应的注解处理器，完成自动配置工作@Resource // 作用与Autowired一样，区别是Resource按name装配、Autowired按type装配@Qualifier // 与Autowired配合，将默认的按Bean类型装配修改位按Bean实例名称装配\n\n注解使用时，要开启自动扫描注解\n&lt;context:component-scan base-package=&quot;bean所在的包&quot;&gt;\n\n自动注入属性有些项目并没有使用注解方式开发，为了减少代码量，才有了这种方式\n在bean中配置autowire属性即可\n&lt;bean id=&quot;xxx&quot; class=&quot;xxx&quot; autowire=&quot;xxx&quot;/&gt;\n\nSpring MVCSpring BootSpring进阶循环依赖问题\n循环依赖问题：类与类之间的依赖关系形成了闭环，就会导致循环依赖问题的产生\n\n循环依赖的理论依据其实是基于Java的引用传递：当我们获取到对象的引用时，对象的field或则属性是可以延后设置的（但是构造器必须是在获取引用之前）\n循环依赖问题在Spring中主要有三种情况：\n\n通过构造方法进行依赖注入时产生的循环依赖问题。\n通过setter方法进行且是在原型模式下产生的循环依赖问题。\n通过setter方法进行依赖注入且是在单例模式下产生的循环依赖问题。\n\n在Spring中，只有第三种问题被解决了，解决的办法是三级缓存\nSpring的三级缓存​        三级缓存都是Map类型，这三个缓存是彼此互斥的，不会针对同一个Bean的实例同时存储\n源码如下：很重要\n@Nullableprotected Object getSingleton(String beanName, boolean allowEarlyReference) &#123;    // 从一级缓存获取单例对象    Object singletonObject = this.singletonObjects.get(beanName);    // isSingletonCurrentlyInCreation 此方法是判断当前的单例bean是不是在创建中    // 创建中是什么意思？就是A中用了B，而B还没被创建，所以得先去创建B    // 此时的A的状态，就属于创建中    // 这里判断第一级缓存没有这个对象并且这个对象还在创建中，才会继续执行以下代码    if (singletonObject == null &amp;&amp;         isSingletonCurrentlyInCreation(beanName)) &#123;        // 上锁，锁住第一级缓存        synchronized (this.singletonObjects) &#123;\t\t\t// 从二级缓存获取单例对象            singletonObject = this.earlySingletonObjects.get(beanName);            // allowEarlyReference            // 是否允许从singletonFactorys中用getObejct拿到bean            // 从第二级缓存也拿不到            if (singletonObject == null &amp;&amp; allowEarlyReference) &#123;                // 从第三级缓存获取                ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);                                if (singletonFactory != null) &#123;                    // 通过单例工厂获取单例bean                    singletonObject = singletonFactory.getObject();                    // 下面两行代码是，从三级缓存移动到二级缓存                    this.earlySingletonObjects.put(beanName, singletonObject);                    this.singletonFactories.remove(beanName);                &#125;            &#125;        &#125;    &#125;    return singletonObject;&#125;\n\n如果调用getBean，则需要从三个缓存中依次获取指定的Bean实例\n\n一级缓存：Map&lt;String, Object&gt; singletonObjects\n用来存放单例模式下，外部创建的Bean（就是我们创建的bean，已经创建完成了）\nkey为bean的名称\nvalue为bean的实例对象\n\n\n二级缓存：Map&lt;String, Object&gt; earlySingletonObjects\n用于存储单例模式下创建的Bean实例（注意：这个Bean是被提前暴露的引用，该Bean还在创建中）\nSpring框架内部逻辑使用该缓存\n作用：为了解决第一个classA引用最终如何替换为代理对象的问题（如果有代理对象）\nk-v与一级缓存相同\n\n\n三级缓存：Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories\n通过ObjectFactory对象来存储单例模式下提前暴露的Bean实例的引用（正在创建中）\nSpring框架内部逻辑使用该缓存\n此缓存是解决循环依赖最大的功臣\nKey 存储bean的名称\nValue存储ObjectFactory，该对象持有提前暴露的bean的引用\n\n\n\n\n为什么第三级缓存要使用ObjectFactory？\n\n这个图非常棒，从左到右，从上往下看。\n\n如果仅仅是解决循环依赖问题，使用二级缓存就可以了，但是如果对象实现了AOP，那么注入到其他bean的时候，并不是最终的代理对象，而是原始的\n所以需要通过三级缓存的ObjectFactory才能提前产生最终的需要代理的对象\n\n什么时候将Bean的引用提前暴露给第三级缓存的ObjectFactory持有？\n\n时机就是在实例化之后，依赖注入之前，完成将Bean的引用提前暴露给第三级缓存\n（这就是解决了第三种循环依赖的关键）\nprotected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;    Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;);    synchronized (this.singletonObjects) &#123;        // 如果一级缓存没有才会去add        if (!this.singletonObjects.containsKey(beanName)) &#123;            // 放入三级缓存中            this.singletonFactories.put(beanName, singletonFactory);            // 从二级缓存移除            this.earlySingletonObjects.remove(beanName);            this.registeredSingletons.add(beanName);        &#125;    &#125;&#125;\n\n\n\n为什么构造方法的循环依赖问题解决不了？\n\n​        经过上一个问题，应该可以了解了，循环依赖问题是在实例化后、依赖注入之前，通过提前暴露给SingletonFactory的ObjectFactory\n​        而构造方法的循环引用，还不会进入这个阶段，所以不能解决这种情况的问题。\n\n如何解决构造方法循环依赖问题？\n\n​        对于类A和类B都是通过构造器注入的情况，可以在A或者B的构造函数的形参上加个@Lazy注解实现延迟加载\n（这应该算程序员外部解决内部循环依赖的一种办法）\n\n@Lazy实现原理：当实例化对象时，如果发现参数或者属性有@Lazy注解修饰，那么就不直接创建所依赖的对象了，而是使用动态代理创建一个代理类\n\n​        比如，类A的创建：A a = new A(B)，需要依赖对象B，发现构造函数的形参上有@Lazy注解，那么就不直接创建B了，而是使用动态代理创建了一个代理类B1，此时A跟B就不是相互依赖了，变成了A依赖一个代理类B1，B依赖A\n​        但因为在注入依赖时，类A并没有完全的初始化完，实际上注入的是一个代理对象，只有当他首次被使用的时候才会被完全的初始化。\nBeanFactory与FactoryBean的区别相同点：都是用来创建对象的\n不同点：使用BeanFactory创建对象时，必须要遵循严格的生命周期流程，太复杂了，如果想简单的自定义某个对象的创建，同时创建完成的对象想交给Spring来管理，就要实现FactoryBean接口\nSpring中用到的设计模式\n单例模式\n原型模式\n工厂模式：BeanFactory\n模板模式：HashMap\n代理模式\n策略模式：XMLBeanDefinition\n观察者模式：listener、event\n适配器模式：Adapter\n责任链模式：使用aop会生成一个拦截器链\n\nSpring事务Spring事务的实现方式当我们使用Spring来支持事务时，多半是由于数据库不支持事务（Mysql的Innodb是支持事务的）\nSpring支持两种方式实现事务：\n\n编程式事务：通过 TransactionTemplate或者TransactionManager手动管理事务，实际应用中很少使用\n声明式事务：通过AOP实现，比如@Transactional\n\n编程式事务TransactionTemplate\n@Autowiredprivate TransactionTemplate transactionTemplate;public void testTransaction() &#123;        transactionTemplate.execute(new TransactionCallbackWithoutResult() &#123;            @Override            protected void doInTransactionWithoutResult(TransactionStatus transactionStatus) &#123;                try &#123;                    // ....  业务代码                &#125; catch (Exception e)&#123;                    //回滚                    transactionStatus.setRollbackOnly();                &#125;            &#125;        &#125;);&#125;\n\nTransactionManager\n@Autowiredprivate PlatformTransactionManager transactionManager;public void testTransaction() &#123;  TransactionStatus status = transactionManager.getTransaction(new DefaultTransactionDefinition());          try &#123;               // ....  业务代码              transactionManager.commit(status);          &#125; catch (Exception e) &#123;              transactionManager.rollback(status);          &#125;&#125;\n\n声明式事务使用注解@Transactional\n\n方法：推荐将注解使用于方法上，不过需要注意的是：该注解只能应用到 public 方法上，否则不生效。\n类：如果这个注解使用在类上的话，表明该注解对该类中所有的 public 方法都生效。\n\n\n\n\n属性名\n说明\n\n\n\npropagation\n事务的传播行为，默认值为 REQUIRED，可选的值在上面介绍过\n\n\nisolation\n事务的隔离级别，默认值采用 DEFAULT，可选的值在上面介绍过\n\n\ntimeout\n事务的超时时间，默认值为-1（不会超时）。如果超过该时间限制但事务还没有完成，则自动回滚事务。\n\n\nreadOnly\n指定事务是否为只读事务，默认值为 false。\n\n\nrollbackFor\n用于指定能够触发事务回滚的异常类型，并且可以指定多个异常类型。\n\n\n\n@Transaction是如何实现的？\n\n通过AOP，\n如果一个类或者一个类中的 public 方法上被标注@Transactional 注解的话，Spring 容器就会在启动的时候为其创建一个代理类，在调用被@Transactional 注解的 public 方法的时候，实际调用的是，TransactionInterceptor 类中的 invoke()方法。这个方法的作用就是在目标方法之前开启事务，方法执行过程中如果遇到异常的时候回滚事务，方法调用完成之后提交事务\n自调用问题@Servicepublic class MyService &#123;private void method1() &#123;     method2();     //......&#125;@Transactional public void method2() &#123;     //......  &#125;&#125;\n\n使用注意：如果事务方法与调用方法处于同一个类，事务会失效，比如上面的代码。\n原因是因为：代理对象的判断逻辑是其他类的方法调用时会产生事务，本类的调用逻辑则不会\n为了解决自调用问题，可以：\n\n避免同一类中自调用\n使用 AspectJ 取代 Spring AOP 代理\n\nSpring实现事务的关键接口Spring的事务实现方式，遵守了TCC（Try、Commit、Cancel）的方式：\n\nPlatformTransactionManager：（平台）事务管理器（TCC规定了事务管理器和资源管理器），是事务运行机制的管理者，是一个接口，为JDBC、JPA、Hibernate等等提供了事务管理的接口，具体还需要各自实现。\n\npublic interface PlatformTransactionManager &#123;    //获得事务    TransactionStatus getTransaction(@Nullable TransactionDefinition var1) throws TransactionException;    //提交事务    void commit(TransactionStatus var1) throws TransactionException;    //回滚事务    void rollback(TransactionStatus var1) throws TransactionException;&#125;\n\n\nTransactionDefinition：定义事务的信息，比如传播方式、隔离级别\n\nTransactionStatus：事务运行状态。\n\n\n事务传播在 Spring 框架中，事务传播（transaction propagation）定义了当一个事务方法被另一个事务方法调用时，事务的行为方式。\n@Transactional(propagation = Propagation.REQUIRED)public void methodA() &#123;    // some logic    serviceB.methodB();    // some logic&#125;\n\n有七种传播方式，他们总体来说定义了在原本有事务时，是选择加入、创建新事物、创建嵌套事物、还是报错；在原本没有事务时，是选择新建事务，还是直接以非事务的方式执行。\n\nREQUIRED：（默认）\n\n存在事务：加入\n不存在事务：新建\n\n\nREQUIRES_NEW：\n\n存在事务：新建（原有的事务会被挂起，直到新事务完成）两个事务之间互不干扰，各自回滚各自的，但是如果事务抛出了异常且没有捕获，可能会导致两个事务都回滚\n不存在事务：新建\n\n\nNESTED：\n\n存在事务：创建一个嵌套事务。（外部事物失败，内部也会回滚；内部事务失败，外部无影响）\n\n不存在事务：新建。\n\nSUPPORTS：\n\n存在事务：加入\n不存在事务：以非事务方式执行\n\n\nNOT_SUPPORTED：\n\n存在事务：挂起原事务，以非事务执行\n不存在事务：以非事务执行\n\n\nMANDATORY：\n\n存在事务：加入\n不存在事务：抛出异常。\n\n\nNEVER：\n\n存在事务：抛出异常\n不存在事务：非事务方式执行\n\n\n\n隔离级别RU、RC、RR、Serial\npublic interface TransactionDefinition &#123;    ......    int ISOLATION_DEFAULT = -1; // 默认方式会使用对应数据库的默认方式，比如mysql RR、oracle RC    int ISOLATION_READ_UNCOMMITTED = 1;    int ISOLATION_READ_COMMITTED = 2;    int ISOLATION_REPEATABLE_READ = 4;    int ISOLATION_SERIALIZABLE = 8;    ......&#125;\n\n事务只读public interface TransactionDefinition &#123;    ......    // 返回是否为只读事务，默认值为 false    boolean isReadOnly();&#125;\n\n事务只读属性，如果设置为true，表面当前事务只会涉及到一些查询操作\n\n有什么作用？在开启后，数据库会有一些优化手段\n\n比如mysql每个连接默认都是autocommit的，每一个sql语句都会开启一个事务，如果不开启事务去执行，那么每次都读取的是最新值，但是如果涉及到一些批量查询，可能就需要前后一致性，就可以开启事务，保证多个sql在一个事物内执行！\n\n对于一次性执行单条查询语句来说，没必要开启\n对于一次性执行多条查询语句，例如统计查询，报表查询，在这种场景下，多条查询 SQL 必须保证整体的读一致性，否则，在前条 SQL 查询之后，后条 SQL 查询之前，数据被其他用户改变，则该次整体的统计查询将会出现读数据不一致的状态，此时，应该启用事务支持\n\n相关链接\n三级缓存很不错的blog\nJava EE 企业级开发教程\n\n","categories":["Spring"],"tags":["Spring","循环依赖","Spring三级缓存"]},{"title":"16.Vue路由起步","url":"/2019/07/24/Vue/16-Vue%E8%B7%AF%E7%94%B1%E8%B5%B7%E6%AD%A5-%E6%9C%AA%E5%AE%8C/","content":"\n引言：\n\n规模化必须先搞定路由\n加油加油\n精简自官方文档\n\n\n\n\n基础起步我们需要做的是，将组件 (components) 映射到路由 (routes)，然后告诉 Vue Router 在哪里渲染它们。\n&lt;script src=&quot;https://unpkg.com/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://unpkg.com/vue-router/dist/vue-router.js&quot;&gt;&lt;/script&gt;&lt;!--通过CDN直接使用vue-router--&gt;&lt;div id=&quot;app&quot;&gt;  &lt;h1&gt;Hello App!&lt;/h1&gt;  &lt;p&gt;    &lt;!-- 使用 router-link 组件来导航. --&gt;    &lt;!-- 通过传入 `to` 属性指定链接. --&gt;    &lt;!-- &lt;router-link&gt; 默认会被渲染成一个 `&lt;a&gt;` 标签 --&gt;    &lt;router-link to=&quot;/foo&quot;&gt;Go to Foo&lt;/router-link&gt;    &lt;router-link to=&quot;/bar&quot;&gt;Go to Bar&lt;/router-link&gt;  &lt;/p&gt;  &lt;!-- 路由出口 --&gt;  &lt;!-- 路由匹配到的组件将渲染在这里 --&gt;  &lt;router-view&gt;&lt;/router-view&gt;&lt;/div&gt;\n\n// 0. 如果使用模块化机制编程，导入Vue和VueRouter，要调用 Vue.use(VueRouter)// 1. 定义 (路由) 组件。// 可以从其他文件 import 进来const Foo = &#123; template: &#x27;&lt;div&gt;foo&lt;/div&gt;&#x27; &#125;const Bar = &#123; template: &#x27;&lt;div&gt;bar&lt;/div&gt;&#x27; &#125;// 2. 定义路由// 每个路由应该映射一个组件。 其中&quot;component&quot; 可以是// 通过 Vue.extend() 创建的组件构造器，// 或者，只是一个组件配置对象。// 我们晚点再讨论嵌套路由。const routes = [  &#123; path: &#x27;/foo&#x27;, component: Foo &#125;,  &#123; path: &#x27;/bar&#x27;, component: Bar &#125;]// 3. 创建 router 实例，然后传 `routes` 配置// 你还可以传别的配置参数, 不过先这么简单着吧。const router = new VueRouter(&#123;  routes // (缩写) 相当于 routes: routes&#125;)// 4. 创建和挂载根实例。// 记得要通过 router 配置参数注入路由，// 从而让整个应用都有路由功能const app = new Vue(&#123;  router&#125;).$mount(&#x27;#app&#x27;)// 现在，应用已经启动了！\n\n通过注入路由器，我们可以在任何组件内通过 this.$router 访问路由器，也可以通过 this.$route 访问当前路由：\n// Home.vueexport default &#123;  computed: &#123;    username () &#123;      // 我们很快就会看到 `params` 是什么      return this.$route.params.username    &#125;  &#125;,  methods: &#123;    goBack () &#123;      window.history.length &gt; 1        ? this.$router.go(-1)        : this.$router.push(&#x27;/&#x27;)    &#125;  &#125;&#125;\n动态路由匹配我们经常需要把某种模式匹配到的所有路由，全都映射到同个组件。\n例如，我们有一个 User 组件，对于所有 ID 各不相同的用户，都要使用这个组件来渲染。那么，我们可以在 vue-router 的路由路径中使用“动态路径参数”(dynamic segment) 来达到这个效果：\nconst User = &#123;  template: &#x27;&lt;div&gt;User&lt;/div&gt;&#x27;&#125;const router = new VueRouter(&#123;  routes: [    // 动态路径参数 以冒号开头    &#123; path: &#x27;/user/:id&#x27;, component: User &#125;  ]&#125;)\n现在呢，像 /user/foo 和 /user/bar 都将映射到相同的路由。\n一个“路径参数”使用冒号 : 标记。\n当匹配到一个路由时，参数值会被设置到 this.$route.params，可以在每个组件内使用。于是，我们可以更新 User 的模板，输出当前用户的 ID：\nconst User = &#123;  template: &#x27;&lt;div&gt;User &#123;&#123; $route.params.id &#125;&#125;&lt;/div&gt;&#x27;&#125;\n\n你可以在一个路由中设置多段“路径参数”，对应的值都会设置到$route.params中。例如：\n\n\n\n模式\n匹配路径\nroute.params\n\n\n\n/user/:username\n/user/evan\n{ username: ‘evan’ }\n\n\n/user/:username/post/:post_id\n/user/evan/post/123\n{ username: ‘evan’, post_id: ‘123’ }\n\n\n响应路由参数的变化提醒一下，当使用路由参数时，例如从 /user/foo 导航到 /user/bar，原来的组件实例会被复用。\n因为两个路由都渲染同个组件，比起销毁再创建，复用则显得更加高效。不过，这也意味着组件的生命周期钩子不会再被调用。\n复用组件时，想对路由参数的变化作出响应的话，你可以简单地 watch (监测变化)$route对象：\nconst User = &#123;  template: &#x27;...&#x27;,  watch: &#123;    &#x27;$route&#x27; (to, from) &#123;      // 对路由变化作出响应...    &#125;  &#125;&#125;\n或者使用 2.2 中引入的 beforeRouteUpdate 导航守卫：\nconst User = &#123;  template: &#x27;...&#x27;,  beforeRouteUpdate (to, from, next) &#123;    // react to route changes...    // don&#x27;t forget to call next()  &#125;&#125;\n捕获所有路由或 404 Not found 路由常规参数只会匹配被 / 分隔的 URL 片段中的字符。如果想匹配任意路径，我们可以使用通配符 (*)：\n&#123;  // 会匹配所有路径  path: &#x27;*&#x27;&#125;&#123;  // 会匹配以 `/user-` 开头的任意路径  path: &#x27;/user-*&#x27;&#125;\n\n当使用通配符路由时，请确保路由的顺序是正确的，也就是说含有通配符的路由应该放在最后。路由 &#123; path: &#39;*&#39; &#125; 通常用于客户端 404 错误。如果你使用了History 模式，请确保正确配置你的服务器。\n当使用一个通配符时，$route.params 内会自动添加一个名为pathMatch参数。它包含了 URL 通过通配符被匹配的部分：\n// 给出一个路由 &#123; path: &#x27;/user-*&#x27; &#125;this.$router.push(&#x27;/user-admin&#x27;)this.$route.params.pathMatch // &#x27;admin&#x27;// 给出一个路由 &#123; path: &#x27;*&#x27; &#125;this.$router.push(&#x27;/non-existing&#x27;)this.$route.params.pathMatch // &#x27;/non-existing&#x27;\n匹配优先级有时候，同一个路径可以匹配多个路由，\n此时，匹配的优先级就按照路由的定义顺序：谁先定义的，谁的优先级就最高。\n嵌套路由实际生活中的应用界面，通常由多层嵌套的组件组合而成。\n同样地，URL 中各段动态路径也按某种结构对应嵌套的各层组件，例如：\n/user/foo/profile                     /user/foo/posts+------------------+                  +-----------------+| User             |                  | User            || +--------------+ |                  | +-------------+ || | Profile      | |  +------------&gt;  | | Posts       | || |              | |                  | |             | || +--------------+ |                  | +-------------+ |+------------------+                  +-----------------+\n\n借助 vue-router，使用嵌套路由配置，就可以很简单地表达这种关系。\n接着上节创建的 app：\n&lt;div id=&quot;app&quot;&gt;  &lt;router-view&gt;&lt;/router-view&gt;&lt;/div&gt;\nconst User = &#123;  template: &#x27;&lt;div&gt;User &#123;&#123; $route.params.id &#125;&#125;&lt;/div&gt;&#x27;&#125;const router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/user/:id&#x27;, component: User &#125;  ]&#125;)\n这里的 &lt;router-view&gt; 是最顶层的出口，渲染最高级路由匹配到的组件。\n同样地，一个被渲染组件同样可以包含自己的嵌套 &lt;router-view&gt;。\n例如，在 User 组件的模板添加一个 &lt;router-view&gt;：\nconst User = &#123;  template: `    &lt;div class=&quot;user&quot;&gt;      &lt;h2&gt;User &#123;&#123; $route.params.id &#125;&#125;&lt;/h2&gt;      &lt;router-view&gt;&lt;/router-view&gt;    &lt;/div&gt;  `&#125;\n要在嵌套的出口中渲染组件，需要在 VueRouter 的参数中使用 children 配置：\nconst router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/user/:id&#x27;, component: User,      children: [        &#123;          // 当 /user/:id/profile 匹配成功，          // UserProfile 会被渲染在 User 的 &lt;router-view&gt; 中          path: &#x27;profile&#x27;,          component: UserProfile        &#125;,        &#123;          // 当 /user/:id/posts 匹配成功          // UserPosts 会被渲染在 User 的 &lt;router-view&gt; 中          path: &#x27;posts&#x27;,          component: UserPosts        &#125;      ]    &#125;  ]&#125;)\n要注意，以 / 开头的嵌套路径会被当作根路径。 这让你充分的使用嵌套组件而无须设置嵌套的路径。\n你会发现，children 配置就是像 routes 配置一样的路由配置数组，所以呢，你可以嵌套多层路由。\n此时，基于上面的配置，当你访问 /user/foo 时，User 的出口是不会渲染任何东西，这是因为没有匹配到合适的子路由。如果你想要渲染点什么，可以提供一个 空的 子路由：\nconst router = new VueRouter(&#123;  routes: [    &#123;      path: &#x27;/user/:id&#x27;, component: User,      children: [        // 当 /user/:id 匹配成功，        // UserHome 会被渲染在 User 的 &lt;router-view&gt; 中        &#123; path: &#x27;&#x27;, component: UserHome &#125;,        // ...其他子路由      ]    &#125;  ]&#125;)\n编程式导航除了使用 &lt;router-link&gt; 创建 a 标签来定义导航链接，我们还可以借助 router 的实例方法，通过编写代码来实现。\nrouter.push(location, onComplete?, onAbort?)注意：在 Vue 实例内部，你可以通过 $router 访问路由实例。因此你可以调用 this.$router.push。\n想要导航到不同的 URL，则使用 router.push 方法。这个方法会向 history 栈添加一个新的记录，所以，当用户点击浏览器后退按钮时，则回到之前的 URL。\n当你点击 &lt;router-link&gt; 时，这个方法会在内部调用，所以说，点击 &lt;router-link :to=&quot;...&quot;&gt; 等同于调用 router.push(...)。\n\n\n\n声明式\n编程式\n\n\n\n&lt;router-link :to=&quot;...&quot;&gt;\nrouter.push(...)\n\n\n该方法的参数可以是一个字符串路径，或者一个描述地址的对象。例如：\n// 字符串router.push(&#x27;home&#x27;)// 对象router.push(&#123; path: &#x27;home&#x27; &#125;)// 命名的路由router.push(&#123; name: &#x27;user&#x27;, params: &#123; userId: &#x27;123&#x27; &#125;&#125;)// 带查询参数，变成 /register?plan=privaterouter.push(&#123; path: &#x27;register&#x27;, query: &#123; plan: &#x27;private&#x27; &#125;&#125;)\n\n注意：如果提供了 path，params 会被忽略，上述例子中的 query 并不属于这种情况。\n取而代之的是下面例子的做法，你需要提供路由的 name 或手写完整的带有参数的 path：\nconst userId = &#x27;123&#x27;router.push(&#123; name: &#x27;user&#x27;, params: &#123; userId &#125;&#125;) // -&gt; /user/123router.push(&#123; path: `/user/$&#123;userId&#125;` &#125;) // -&gt; /user/123// 这里的 params 不生效router.push(&#123; path: &#x27;/user&#x27;, params: &#123; userId &#125;&#125;) // -&gt; /user\n同样的规则也适用于 router-link 组件的 to 属性。\n在 router.push 或 router.replace 中提供 onComplete 和 onAbort 回调作为第二个和第三个参数。\n这些回调将会在导航成功完成 (在所有的异步钩子被解析之后) 或终止 (导航到相同的路由、或在当前导航完成之前导航到另一个不同的路由) 的时候进行相应的调用。\n注意： 如果目的地和当前路由相同，只有参数发生了改变 (比如从一个用户资料到另一个 /users/1 -&gt; /users/2)，你需要使用 beforeRouteUpdate 来响应这个变化 (比如抓取用户信息)。\nrouter.replace(location, onComplete?, onAbort?)跟 router.push 很像，唯一的不同就是，它不会向 history 添加新记录，而是跟它的方法名一样 —— 替换掉当前的 history 记录。\n\n\n\n声明式\n编程式\n\n\n\n&lt;router-link :to=&quot;...&quot; replace&gt;\nrouter.replace(...)\n\n\nrouter.go(n)这个方法的参数是一个整数，意思是在 history 记录中向前或者后退多少步，类似 window.history.go(n)。\n例子\n// 在浏览器记录中前进一步，等同于 history.forward()router.go(1)// 后退一步记录，等同于 history.back()router.go(-1)// 前进 3 步记录router.go(3)// 如果 history 记录不够用，那就默默地失败呗router.go(-100)router.go(100)\n命名路由有时候，通过一个名称来标识一个路由显得更方便一些，\n特别是在链接一个路由，或者是执行一些跳转的时候。\n你可以在创建 Router 实例的时候，在 routes 配置中给某个路由设置名称。\nconst router = new VueRouter(&#123;  routes: [    &#123;      path: &#x27;/user/:userId&#x27;,      name: &#x27;user&#x27;,      component: User    &#125;  ]&#125;)\n要链接到一个命名路由，可以给 router-link 的 to 属性传一个对象：\n&lt;router-link :to=&quot;&#123; name: &#x27;user&#x27;, params: &#123; userId: 123 &#125;&#125;&quot;&gt;User&lt;/router-link&gt;\n这跟代码调用 router.push() 是一回事：\nrouter.push(&#123; name: &#x27;user&#x27;, params: &#123; userId: 123 &#125;&#125;)\n这两种方式都会把路由导航到 /user/123 路径。\n命名视图有时候想同时 (同级) 展示多个视图，而不是嵌套展示，\n例如创建一个布局，有 sidebar (侧导航) 和 main (主内容) 两个视图，这个时候命名视图就派上用场了。\n你可以在界面中拥有多个单独命名的视图，而不是只有一个单独的出口。如果 router-view 没有设置名字，那么默认为 default。\n&lt;router-view class=&quot;view one&quot;&gt;&lt;/router-view&gt;&lt;router-view class=&quot;view two&quot; name=&quot;a&quot;&gt;&lt;/router-view&gt;&lt;router-view class=&quot;view three&quot; name=&quot;b&quot;&gt;&lt;/router-view&gt;\n一个视图使用一个组件渲染，因此对于同个路由，多个视图就需要多个组件。确保正确使用 components 配置 (带上 s)：\nconst router = new VueRouter(&#123;  routes: [    &#123;      path: &#x27;/&#x27;,      components: &#123;        default: Foo,        a: Bar,        b: Baz      &#125;    &#125;  ]&#125;)\n重定向和别名重定向重定向也是通过 routes 配置来完成，下面例子是从 /a 重定向到 /b：\nconst router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/a&#x27;, redirect: &#x27;/b&#x27; &#125;  ]&#125;)\n重定向的目标也可以是一个命名的路由：\nconst router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/a&#x27;, redirect: &#123; name: &#x27;foo&#x27; &#125;&#125;  ]&#125;)\n甚至是一个方法，动态返回重定向目标：\nconst router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/a&#x27;, redirect: to =&gt; &#123;      // 方法接收 目标路由 作为参数      // return 重定向的 字符串路径/路径对象    &#125;&#125;  ]&#125;)\n注意导航守卫并没有应用在跳转路由上，而仅仅应用在其目标上。在下面这个例子中，为 /a 路由添加一个 beforeEach 或 beforeLeave 守卫并不会有任何效果。\n别名“重定向”的意思是，当用户访问 /a时，URL 将会被替换成 /b，然后匹配路由为 /b，那么“别名”又是什么呢？\n/a 的别名是 /b，意味着，当用户访问 /b 时，URL 会保持为 /b，但是路由匹配则为 /a，就像用户访问/a一样。\n上面对应的路由配置为：\nconst router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/a&#x27;, component: A, alias: &#x27;/b&#x27; &#125;  ]&#125;)\n“别名”的功能让你可以自由地将 UI 结构映射到任意的 URL，而不是受限于配置的嵌套路由结构。\n路由组件传参在组件中使用 $route 会使之与其对应路由形成高度耦合，从而使组件只能在某些特定的 URL 上使用，限制了其灵活性。\n使用 props 将组件和路由解耦：\n取代与 $route 的耦合\nconst User = &#123;  template: &#x27;&lt;div&gt;User &#123;&#123; $route.params.id &#125;&#125;&lt;/div&gt;&#x27;&#125;const router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/user/:id&#x27;, component: User &#125;  ]&#125;)\n通过 props 解耦\nconst User = &#123;  props: [&#x27;id&#x27;],  template: &#x27;&lt;div&gt;User &#123;&#123; id &#125;&#125;&lt;/div&gt;&#x27;&#125;const router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/user/:id&#x27;, component: User, props: true &#125;,    // 对于包含命名视图的路由，你必须分别为每个命名视图添加 `props` 选项：    &#123;      path: &#x27;/user/:id&#x27;,      components: &#123; default: User, sidebar: Sidebar &#125;,      props: &#123; default: true, sidebar: false &#125;    &#125;  ]&#125;)\n这样你便可以在任何地方使用该组件，使得该组件更易于重用和测试。\n布尔模式如果 props 被设置为 true，route.params 将会被设置为组件属性。\n对象模式如果 props 是一个对象，它会被按 原样 设置为组件属性。当 props 是静态的时候有用。\nconst router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/promotion/from-newsletter&#x27;, component: Promotion, props: &#123; newsletterPopup: false &#125; &#125;  ]&#125;)\n函数模式你可以创建一个函数返回 props。\n这样你便可以将参数转换成另一种类型，将静态值与基于路由的值结合等等。\nconst router = new VueRouter(&#123;  routes: [    &#123; path: &#x27;/search&#x27;, component: SearchUser, props: (route) =&gt; (&#123; query: route.query.q &#125;) &#125;  ]&#125;)\nURL /search?q=vue 会将 &#123;query: &#39;vue&#39;&#125; 作为属性传递给 SearchUser 组件。\n请尽可能保持 props 函数为无状态的，因为它只会在路由发生变化时起作用。如果你需要状态来定义 props，请使用包装组件，这样 Vue 才可以对状态变化做出反应\nHTML5 History 模式vue-router 默认 hash 模式 —— 使用 URL 的 hash 来模拟一个完整的 URL，于是当 URL 改变时，页面不会重新加载。\n如果不想要很丑的 hash，我们可以用路由的 history 模式，\n这种模式充分利用 history.pushState API 来完成 URL 跳转而无须重新加载页面。\nconst router = new VueRouter(&#123;  mode: &#x27;history&#x27;,  routes: [...]&#125;)\n当你使用 history 模式时，URL 就像正常的 url，例如 http://yoursite.com/user/id，也好看！\n不过这种模式要玩好，还需要后台配置支持。因为我们的应用是个单页客户端应用，如果后台没有正确的配置，当用户在浏览器直接访问 http://oursite.com/user/id 就会返回 404，这就不好看了。\n所以呢，你要在服务端增加一个覆盖所有情况的候选资源：如果 URL 匹配不到任何静态资源，则应该返回同一个 index.html 页面，这个页面就是你 app 依赖的页面。\n警告给个警告，因为这么做以后，你的服务器就不再返回 404 错误页面，因为对于所有路径都会返回 index.html 文件。\n为了避免这种情况，你应该在 Vue 应用里面覆盖所有的路由情况，然后在给出一个 404 页面。\nconst router = new VueRouter(&#123;  mode: &#x27;history&#x27;,  routes: [    &#123; path: &#x27;*&#x27;, component: NotFoundComponent &#125;  ]&#125;)\n或者，如果你使用 Node.js 服务器，你可以用服务端路由匹配到来的 URL，并在没有匹配到路由的时候返回 404，以实现回退。\n","categories":["前端","Vue"],"tags":["Vue"]},{"title":"Spring_Bean","url":"/2020/03/08/Spring/Spring-Bean/","content":"\n引言：\nSpring_配置Bean\n\n\n\n\n\nSpring工厂Spring工厂全家福一览\n\n看下面的代码\nApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);UserService usrService = (UserService) applicationContext.getBean(&quot;usrService&quot;);usrService.sayHello();\n我们用到了两个工厂ApplicationContext、ClassPathXmlApplicationContext\n在老版本的Spring中，用的工厂其实是BeanFactory，ApplicationContext是后来版本的工厂类，ApplicationContext除了具有BeanFactory的所有方法外，他还具有\n\nEasier integration with Spring’s AOP features  更容易与 Spring 的 AOP 特性集成\n\nMessage resource handling (for use in internationalization)消息资源处理(用于国际化)\n\nEvent publication活动刊物\n\nApplication-layer specific contexts such as the WebApplicationContext for use in web applications.应用层特定的上下文，例如 web 应用程序中使用的 WebApplicationContext。\n\n\n他们创建Bean的实例的时机也是不一样的\n\nBeanFactory会在调用getBean()方法时，才会创建这个Bean的实例\nApplicationContext在读取Spring配置文件时，就会把配置文件中所有单例模式生成的类全部生成\n\n工厂对比：\n@Testpublic void springTest1()&#123;    /**     * 使用Spring     */    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);    UserService usrService = (UserService) applicationContext.getBean(&quot;usrService&quot;);    usrService.sayHello();&#125;@Testpublic void springTest2()&#123;    BeanFactory bf = new XmlBeanFactory(new ClassPathResource(&quot;applicationContext.xml&quot;));    //XmlBeanFactory()这个方法已经淘汰    UserService usrService = (UserService) bf.getBean(&quot;usrService&quot;);    usrService.sayHello();&#125;\n\n\nBean管理Spring管理Bean的方式主要有两种，分别是XML和注解\n我们分别来看这两种\nXMLSpring实例化Bean的三种方法\n\n使用类构造器实例化（默认无参数）\n使用静态工厂方法实例化（简单工厂方法）\n使用实例工厂方法实例化（工厂方法模式）\n\n使用类构造器实例化public class Bean1 &#123;    public Bean1() &#123;        System.out.println(&quot;Bean1被实例化了&quot;);    &#125;&#125;\n配置文件\n&lt;bean id=&quot;bean1&quot; class=&quot;com.dongwenhao.demo02.Bean1&quot; /&gt;\n测试\n@Testpublic void test1()&#123;    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);    Bean1 bean1 = (Bean1) applicationContext.getBean(&quot;bean1&quot;);&#125;\n结果\nlog4j:WARN No appenders could be found for logger (org.springframework.core.env.StandardEnvironment).log4j:WARN Please initialize the log4j system properly.Bean1被实例化了\n\n使用静态工厂方法实例化public class Bean2 &#123;    Bean2()&#123;        System.out.println(&quot;Bean2被创建了&quot;);    &#125;&#125;\n工厂\npublic class Bean2Factory &#123;    public static Bean2 getBean2()&#123;        return new Bean2();    &#125;&#125;\n\n配置文件\n&lt;bean id=&quot;bean2&quot; class=&quot;com.dongwenhao.demo02.Bean2Factory&quot; factory-method=&quot;getBean2&quot; /&gt;\n测试\n@Testpublic void test2()&#123;    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);    Bean2 bean2 = (Bean2) applicationContext.getBean(&quot;bean2&quot;);&#125;\n结果\nlog4j:WARN No appenders could be found for logger (org.springframework.core.env.StandardEnvironment).log4j:WARN Please initialize the log4j system properly.Bean2被创建了\n\n\n使用实例工厂方法实例化public class Bean3 &#123;    Bean3()&#123;        System.out.println(&quot;Bean3被创建了&quot;);    &#125;&#125;\n工厂类\npublic class Bean3Factory &#123;    public Bean3 getBean3()&#123;        return new Bean3();    &#125;&#125;\n\n配置文件\n&lt;bean id=&quot;bean3Factory&quot; class=&quot;com.dongwenhao.demo02.Bean3Factory&quot; /&gt;&lt;bean id=&quot;bean3&quot; factory-bean=&quot;bean3Factory&quot; factory-method=&quot;getBean3&quot; /&gt;\n测试\n@Testpublic void test3()&#123;    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);    Bean3 bean3 = (Bean3) applicationContext.getBean(&quot;bean3&quot;);&#125;\n结果\nlog4j:WARN No appenders could be found for logger (org.springframework.core.env.StandardEnvironment).log4j:WARN Please initialize the log4j system properly.Bean3被创建了\n\nBean的配置&lt;bean /&gt;\nid 和 name\n一般情况下我们使用id而不是name\nid属性在IOC必须是唯一的\n如果Bean名称有特殊字符，就需要使用name属性\n\nclass用来设置一个类的完全路径名称，主要作用是IOC容器生成类的实例\nscope定义Bean的作用域，值有四个\n\nsingleton：在SpringIOC容器中仅存在一个Bean实例，Bean以单例的方式存在\nprototype：每次调用getBean()时都会返回一个新的实例\nrequest：每次HTTP请求都会创建一个新的Bean（仅适用在WebApplicationContext环境）\nsession：同一个HTTP Session共享一个Bean，不同的HTTP Session使用不同的Bean（仅适用在WebApplicationContext环境）\n\nBean的生命周期\n为了体验一个完整的生命周期，我们需要建两个类\npublic class Man implements BeanNameAware, ApplicationContextAware, InitializingBean, DisposableBean &#123;    private String name;    public Man() &#123;        System.out.println(&quot;第一步：实例化&quot;);    &#125;    public void setName(String name) &#123;        System.out.println(&quot;第二步：设置属性&quot;);        this.name = name;    &#125;    @Override    //实现BeanNameAware接口    public void setBeanName(String name)&#123;        System.out.println(&quot;第三步：设置bean的name：&quot;+name);    &#125;    @Override    //实现ApplicationContextAware接口    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123;        System.out.println(&quot;第四步：了解工厂信息&quot;);    &#125;        // 第五步和第八步在另一个类中         @Override    //实现InitializingBean接口    public void afterPropertiesSet() throws Exception &#123;        System.out.println(&quot;第六步：属性设置后&quot;);    &#125;        //初始化方法，需要在xml中指出    public void setup()&#123;        System.out.println(&quot;第七步：Man被初始化了&quot;);    &#125;    //类自身的方法    public void run()&#123;        System.out.println(&quot;第九步：执行自身的业务方法&quot;);    &#125;    @Override    //实现DisposableBean接口    public void destroy() throws Exception &#123;        System.out.println(&quot;第十步：执行Spring的销毁方法&quot;);    &#125;    //销毁方法，需要在xml中指出    public void teardown()&#123;        System.out.println(&quot;第十一步：Man被销毁了&quot;);    &#125;&#125;\npublic class MyBeanPostProcessor implements BeanPostProcessor &#123;    /*    实现BeanPostProcessor接口    第五步和第八步是最重要的两步！！    之后我们详细说    */    @Override    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        System.out.println(&quot;第五步：初始化前方法&quot;);        return bean;    &#125;    @Override    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;        System.out.println(&quot;第八步：初始化后方法&quot;);        return bean;    &#125;&#125;\n配置文件\n&lt;bean id=&quot;man&quot;          class=&quot;com.dongwenhao.demo03.Man&quot;          init-method=&quot;setup&quot;          destroy-method=&quot;teardown&quot;    &gt;    &lt;property name=&quot;name&quot; value=&quot;小王&quot; /&gt;&lt;/bean&gt;&lt;bean class=&quot;com.dongwenhao.demo03.MyBeanPostProcessor&quot; /&gt;&lt;!--不需要配置id，这个类会在Spring生成类的实例时自动调用--&gt;\n测试方法\n@Testpublic void test() &#123;    ClassPathXmlApplicationContext ac = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);    Man man = (Man) ac.getBean(&quot;man&quot;);    man.run();    ac.close();&#125;\n\n\n打印结果\nlog4j:WARN No appenders could be found for logger (org.springframework.core.env.StandardEnvironment).log4j:WARN Please initialize the log4j system properly.第一步：实例化第二步：设置属性第三步：设置bean的name：man第四步：了解工厂信息第五步：初始化前方法第六步：属性设置后第七步：Man被初始化了第八步：初始化后方法第九步：执行自身的业务方法第十步：执行Spring的销毁方法第十一步：Man被销毁了\n\n生命周期中，重要的就是第五步和第八步，这个阶段可以增强我们的方法\nBeanPostProcessor可以在生成类的过程中对类产生代理，并且可以对其中的方法进行增强\n例如这么一个类\npublic interface UserDao &#123;    void findAll();    void save();    void update();    void delete();&#125;public class UserDaoImpl implements UserDao&#123;    @Override    public void findAll() &#123;        System.out.println(&quot;查询用户&quot;);    &#125;    @Override    public void save() &#123;        System.out.println(&quot;保存用户&quot;);    &#125;    @Override    public void update() &#123;        System.out.println(&quot;修改用户&quot;);    &#125;    @Override    public void delete() &#123;        System.out.println(&quot;删除用户&quot;);    &#125;&#125;\n怎么增强一个类的方法呢？\n这里我们比如说给save()方法运行前，还需要进行校验\n这里就需要用到我们的BeanPostProcessor接口了\npublic class MyBeanPostProcessor implements BeanPostProcessor &#123;    @Override    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        System.out.println(&quot;第五步：初始化前方法&quot;);        return bean;    &#125;    @Override    public Object postProcessAfterInitialization(final Object bean, String beanName) throws BeansException &#123;        System.out.println(&quot;第八步：初始化后方法&quot;);        if(&quot;userDao&quot;.equals(beanName))&#123;            Object proxy = Proxy.newProxyInstance(bean.getClass().getClassLoader(), bean.getClass().getInterfaces(), new InvocationHandler() &#123;                @Override                public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;                    if(&quot;save&quot;.equals(method.getName()))&#123;                        System.out.println(&quot;权限校验&quot;);                        //权限校验使用打印来代替一下                        return method.invoke(bean,args);                    &#125;                    return method.invoke(bean,args);                &#125;            &#125;);            return proxy;        &#125;        return bean;    &#125;&#125;\nxml配置\n&lt;bean class=&quot;com.dongwenhao.demo03.MyBeanPostProcessor&quot; /&gt;&lt;!--不需要配置id，这个类会在Spring生成类的实例时自动调用--&gt;&lt;bean id=&quot;userDao&quot; class=&quot;com.dongwenhao.demo03.UserDaoImpl&quot; /&gt;\n\n测试类：\n@Testpublic void test2() &#123;    ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);    UserDao userDao = (UserDao) ac.getBean(&quot;userDao&quot;);    userDao.findAll();    userDao.delete();    userDao.update();    userDao.save();&#125;\n打印结果：\nlog4j:WARN No appenders could be found for logger (org.springframework.core.env.StandardEnvironment).log4j:WARN Please initialize the log4j system properly.第五步：初始化前方法第八步：初始化后方法查询用户删除用户修改用户权限校验保存用户\n\n属性注入对于类的成员变量，我们一般有三种办法来存储他们的实例\n\n构造函数\nsetter方法\n接口注入\n\n在Spring中，支持上面两种方法\n构造方法注入假设有一个类\npublic class User &#123;    private String name;    private int age;    public User(String name, int age) &#123;        this.name = name;        this.age = age;    &#125;&#125;\n在构造方法中传入参数，我们只需要增加一个constructor-arg标签即可\n成员变量名用name，值使用value\n&lt;bean id=&quot;user&quot; class=&quot;com.dongwenhao.demo04.User&quot;&gt;    &lt;constructor-arg name=&quot;name&quot; value=&quot;匿名&quot; /&gt;    &lt;constructor-arg name=&quot;age&quot; value=&quot;0&quot; /&gt;&lt;/bean&gt;\n\nsetter方法注入public class User &#123;    private String name;    private int age;    public void setName(String name) &#123;        this.name = name;    &#125;    public void setAge(int age) &#123;        this.age = age;    &#125;&#125;\n我们只需要增加一个property标签即可\n成员变量名用name，值使用value\n&lt;bean id=&quot;user&quot; class=&quot;com.dongwenhao.demo04.User&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;匿名&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;age&quot; value=&quot;0&quot;&gt;&lt;/property&gt;&lt;/bean&gt;\n\n如果有一个成员变量时类怎么办？\npublic class Cat &#123;    private String name;    public void setName(String name) &#123;        this.name = name;    &#125;&#125;\n\npublic class User &#123;    private String name;    private int age;    private Cat cat;    public void setName(String name) &#123;        this.name = name;    &#125;    public void setAge(int age) &#123;        this.age = age;    &#125;    public void setCat(Cat cat) &#123;        this.cat = cat;    &#125;&#125;\n因为Cat也是一个类，我们也需要配置，而且实际上在User中，Cat其实还是set方法来注入的，所以我们仍然使用property\n但是有一个区别，对于普通的值我们可以使用value给值，但是对于配置了的类，我们需要使用ref\n像这样：\n&lt;bean id=&quot;user&quot; class=&quot;com.dongwenhao.demo04.User&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;匿名&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;age&quot; value=&quot;0&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;cat&quot; ref=&quot;cat&quot; &gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;cat&quot; class=&quot;com.dongwenhao.demo04.Cat&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;小橘猫&quot;&gt;&lt;/property&gt;&lt;/bean&gt;\n使用构造方法注入时，也是使用ref\n引入p命名其实上述的xml配置都可以通过p来简化，例如可以这样\n&lt;bean id=&quot;user&quot; class=&quot;com.dongwenhao.demo04.User&quot; p:name=&quot;小明&quot; p:age=&quot;18&quot; p:cat-ref=&quot;cat&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;cat&quot; class=&quot;com.dongwenhao.demo04.Cat&quot; p:name=&quot;Kitty&quot;&gt;&lt;/bean&gt;\n但是直接改会报错的，我们必须在beans中增加这么一个\nxmlns:p=&quot;http://www.springframework.org/schema/p&quot;\n\nSpEl注入\nSpEL：spring expression language  spring表达式语言\n\n语法：#&#123;表达式&#125;\n例如：其中category和 productInfo都是类\n&lt;bean id =&quot;category&quot; class=&quot;com.dongwenhao.demo04.Category&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;#&#123;&#x27;男装&#x27;&#125;&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id = &quot;productInfo&quot; class=&quot;com.dongwenhao.demo04.ProductInfo&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;product&quot; class=&quot;com.dongwenhao.demo04.Product&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;#&#123;&#x27;外套&#x27;&#125;&quot;&gt;&lt;/property&gt;    &lt;!--注意字符串要加引号--&gt;    &lt;property name=&quot;price&quot; value=&quot;#&#123; productInfo.backPrice()&#125;&quot;&gt;&lt;/property&gt;    &lt;!--这样可以通过成员方法来给值--&gt;    &lt;property name=&quot;category&quot; value=&quot;#&#123;category&#125;&quot;&gt;&lt;/property&gt;    &lt;!--成员变量是类直接写就可以--&gt;&lt;/bean&gt;\n\n复杂类型注入假如一个类像这样，该怎么注入呢？\npublic class CollectionBean &#123;    private String[] arr;    private List&lt;String&gt; list;    private Set&lt;String&gt; set;    private Map&lt;String,Integer&gt; map;    private Properties;    ...(省略set方法)&#125;\n注入类型\n&lt;bean id=&quot;collectionBean&quot; class=&quot;com.dongwenhao.demo04.CollectionBean&quot;&gt;    &lt;!--数组注入--&gt;    &lt;property name=&quot;arr&quot;&gt;        &lt;list&gt;            &lt;value&gt;a&lt;/value&gt;            &lt;value&gt;b&lt;/value&gt;            &lt;value&gt;c&lt;/value&gt;        &lt;/list&gt;    &lt;/property&gt;    &lt;!--list注入，和数组注入一样--&gt;    &lt;property name=&quot;list&quot;&gt;        &lt;list&gt;            &lt;value&gt;a&lt;/value&gt;            &lt;value&gt;b&lt;/value&gt;            &lt;value&gt;c&lt;/value&gt;            &lt;!--如果这里是引用类型，要使用ref--&gt;        &lt;/list&gt;    &lt;/property&gt;    &lt;property name=&quot;set&quot;&gt;        &lt;set&gt;            &lt;value&gt;a&lt;/value&gt;            &lt;value&gt;b&lt;/value&gt;            &lt;value&gt;c&lt;/value&gt;        &lt;/set&gt;    &lt;/property&gt;    &lt;property name=&quot;map&quot;&gt;        &lt;map&gt;            &lt;entry key=&quot;a&quot; value=&quot;1&quot;/&gt;            &lt;entry key=&quot;b&quot; value=&quot;2&quot;/&gt;            &lt;entry key=&quot;c&quot; value=&quot;3&quot;/&gt;            &lt;!--map集合内使用 entry--&gt;        &lt;/map&gt;    &lt;/property&gt;    &lt;property name=&quot;properties&quot;&gt;        &lt;props&gt;            &lt;prop key=&quot;username&quot;&gt;root&lt;/prop&gt;            &lt;prop key=&quot;password&quot;&gt;123&lt;/prop&gt;        &lt;/props&gt;    &lt;/property&gt;&lt;/bean&gt;\n\n注解方式需要引入约束\n&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;       http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans.xsd       http://www.springframework.org/schema/context       http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;!-- 开启注解扫描   --&gt;     &lt;context:component-scan base-package=&quot;com.dongwenhao.demo05&quot;/&gt;&lt;/bean&gt;\n在加载此xml文件时，开启注解扫描，就会去对应包下找类\n@Component(&quot;userService&quot;)public class UserService &#123;    public void sayHello(String name)&#123;        System.out.println(&quot;你好：&quot;+name);    &#125;&#125;\n这句话@Component(&quot;userService&quot;)相当于配置xml文件&lt;bean id=&quot;userService&quot; class=&quot;xxx/&gt;\n为了清晰的标注类本身的用途，Spring提供了3个功能基本和@Component等效的注解\n\n@Respository用于对DAO实现类进行标注\n@Service用于对Service实现类进行标注\n@Controller用于对Controller实现类进行标注\n\n复杂的注解注入@Repository(&quot;userDao&quot;)public class UserDao &#123;    public void save()&#123;        System.out.println(&quot;数据保存&quot;);    &#125;&#125;@Repository(&quot;userService&quot;)public class UserService &#123;    /**     * @Value     * 如果有set方法就可以加在set方法上，没有set方法就加在属性上     */    @Value(&quot;肉包子&quot;)    private String food;    /**     * @Autowired     * 自动注入，默认按照类型匹配，忽略名称；如果类型相同，则按名称注入     * 可以加在set方法上，也可以加在变量上     * @Qualifier(&quot;name&quot;)     * 保证名称也得相同，假如UserDao的注释是@Repository(&quot;userDao123456&quot;)     * 而这里是userDao，那么便不会匹配     * @Resource     * 有一个name属性，使用@Resource(name=&quot;userDao&quot;)，相当于同时使用了上面两个     */    //@Autowired    //@Qualifier(&quot;userDao&quot;)    @Resource(name=&quot;userDao&quot;)    private UserDao userDao;    public void sayHello(String name)&#123;        System.out.println(&quot;你好：&quot;+name);    &#125;    public void eat()&#123;        System.out.println(&quot;eat&quot; + food);    &#125;    public void save()&#123;        System.out.println(&quot;Service执行保存&quot;);        userDao.save();    &#125;&#125;\n\n生命周期的注解用到生命周期时，使用xml方式是这样的\n&lt;bean id=&quot;man&quot;          class=&quot;com.dongwenhao.demo03.Man&quot;          init-method=&quot;setup&quot;          destroy-method=&quot;teardown&quot;    &gt;    ...&lt;/bean&gt;\n\n使用注解是什么样的呢？\n/** * @Scope(&quot;xx&quot;) * 设置这个类的模式： * - singleton 单例模式 * - prototype 多例模式 * - request 每次请求都会返回新的对象（仅适用在WebApplicationContext环境） * - session 一个会话session内，返回同一个对象（仅适用在WebApplicationContext环境） */@Component(&quot;bean&quot;)@Scope(&quot;prototype&quot;)public class Bean &#123;    @PostConstruct    public void init()&#123;        System.out.println(&quot;初始化&quot;);    &#125;    public void run()&#123;        System.out.println(&quot;运行&quot;);    &#125;    /**     * @PreDestroy     * 这个注解只当单例模式singleton有效     */    @PreDestroy    public void destroy()&#123;        System.out.println(&quot;销毁&quot;);    &#125;&#125;\n\n传统xml和注解配合使用我们回顾xml和注解，发现他们其实各有优劣\n\nxml方式： 结构清晰，易于阅读\n注解方式：开发便捷，注入方便\n\n如果我们bean注入使用xml，而属性注入使用注解，是不是很方便呢\n混合使用他们，我们得先\n\n引入context命名空间\n在配置文件中添加context:annotation-config标签\n\n&lt;!--&lt;context:component-scan base-package=&quot;xxx&quot;/&gt;--&gt;&lt;!--我们之前使用的是包扫描，它会扫描包下的注解，下方的这个标签其实是包扫描的一部分--&gt;&lt;context:annotation-config /&gt;&lt;!--这个注解只能识别那些属性注入的注解--&gt;&lt;bean id=&quot;productService&quot; class=&quot;com.dongwenhao.demo05.ProductService&quot; /&gt;&lt;bean id=&quot;category&quot; class=&quot;com.dongwenhao.demo05.CategoryDao&quot; /&gt;&lt;bean id=&quot;userDao&quot; class=&quot;com.dongwenhao.demo05.UserDao&quot; /&gt;\n\npublic class ProductService &#123;    @Resource(name = &quot;userDao&quot;)    private UserDao userDao;    @Resource(name = &quot;category&quot;)    private CategoryDao categoryDao;    public void save()&#123;        System.out.println(&quot;Product开始保存&quot;);        categoryDao.save();        userDao.save();    &#125;&#125;\n\n","categories":["Spring"],"tags":["Spring"]},{"title":"Java常量与变量","url":"/2019/08/08/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%9E%84/Java%E6%9C%80%E5%9F%BA%E7%A1%80%E7%9A%84%E5%86%85%E5%AE%B9/","content":"\n引言：认识Java的常量、变量的基本类型、运算符等\n\n\n\n\n常量常量类型\n\n字符串常量&#39;abc&#39;,&#39;hello&#39;\n整数常量100,200\n浮点数常量2.5,3.14\n字符常量:单引号引起来的单个字符&#39;a&#39;,&#39;w&#39;,&#39;2&#39;,&#39;啊&#39;可以是汉字，但是不能什么都没有\n布尔常量false,true\n空常量null代表没有任何数据(null不能用来打印输出)\n\n基本数据类型\n\n\n数据类型\n关键字\n内存占用\n取值范围\n\n\n\n字节型\nbyte\n1字节\n-128 ~ 127\n\n\n短整型\nshort\n2字节\n-2^15 ~ 2^15-1\n\n\n整型\nint\n4字节\n-2^31 ~ 2^31-1\n\n\n长整型\nlong\n8字节\n-2^63 ~ 2^63-1\n\n\n单精度浮点型\nfloat\n4字节\n超大\n\n\n双精度浮点型\ndouble\n8字节\n超级大\n\n\n字符型\nchar\n2字节\n0~65535(2^16-1)\n\n\n布尔类型\nboolean\n1字节\ntrue &amp; false\n\n\n整数型 byte short int long\n浮点型 float double\n字符型 char\n布尔型 boolean\n注意：\n\n字符串不是基本类型，是引用类型\n浮点型可能只是近似一个值，而并非是其精确值\n数字范围和字节数不一定相关，例如float和long\n浮点数默认类型是double，用float，得加F后缀\n整数默认为int，用long，要加L后缀\n\n变量定义变量注意他们的取值范围：\nbyte x = 10; //正确byte x = 128; //错误// byte范围在-128~127之间\n注意long，要加L\nlong x = 300000000000; // 错误long x = 300000000000L; //正确\n注意float，要加F\nfloat x = 2.5; //错误float x = 2.5F; //正确\n注意事项：\n\n变量名不能重复\nfloat和long要加后缀\n未赋值的变量不可以使用\n使用byte和short要注意取值范围\n变量不要超出变量的取值范围\n一定要先声明后使用，java是从上到下执行的\n\n数据类型转换自动类型转换(隐式)\n自动完成\n数据范围从小到大转换\n布尔类型在JAVA中就是布尔，不能运算，不是0,1\n\n强制转换int num = (int)100L; //带上括号就可以实现强制转换\n注意：\n\n强制类型转换要谨慎使用，易发生精度损失、数据溢出\nbyte/short/char都可以数学运算，都会被首先提升为int来进行运算byte x = 60;byte y = 50;byte result = x + y;//这样会报错//byte + byte -&gt; int + int -&gt; int != byte\n在运算过程中，他们会变为int，可以改成\n\nint result = x + y;\n或者\nbyte result = byte(x + y);\n\n运算符运算符类型加减乘除 +-*/\n取模 %只对于整数有效\n自增自减 ++ --\n赋值运算符 =\n比较运算符 &gt; &lt; == &lt;= &gt;=\n逻辑运算符 &amp;&amp; || !\n三元运算符 ?:\n\n加法多种用法\n\n\n加法的运算结果是运算范围最大的那一个\nchar类型的加法会变为int\n可以用于字符串相加减\n\n\n逻辑运算符\n\n逻辑运算符||和&amp;&amp;有短路效果，\n如果根据左边已经可以判断得到最终的结果，右侧的代码将不会执行\n\n赋值运算符\n\n赋值运算符隐含一个强制的转换类型\n方法定义格式\npublic static void xxx()&#123;    //方法体  &#125;\n\n调用方法\n\n单独调用 function()\n打印调用 System.out.print(function()\n赋值调用 int x = function\n\n注意：void的方法只能单独调用，也可以使用return;直接返回\n同c++，可以根据数据类型的不同和参数的数量不同来实现重载。\n唯一的区别–可以通过多类型的顺序区别\nsum(int a,double b);sum(double a, int b);\n\n语句结构基本内容同c语言\n区别：switch(x)其中x只能为基本数据类型：byte/short/char/int引用数据类型：String/enum\n数组数组是一种引用数据类型\n\n特点：\n\n\n一个数组中的数据类型必须一致\n数组的长度在运行期间长度不可改变\n\n\n初始化:\n\n\n动态初始化——指定长度\n静态初始化——指定内容，自动推算长度\n\n\n创建：String[] str;str = new String[5];//动态str = new String[]&#123;&quot;a&quot;,&quot;b&quot;,&quot;c&quot;&#125;;//静态\n可以化为一步int[] sum = new int[50];//动态指定长度创建数组String[] arr = new String[]&#123;&quot;你好啊&quot;,&quot;你是谁啊&quot;&#125;;//静态指定数组内容创建数组\n\n当使用动态初始化数组的时候，其中的元素会自动拥有一个默认值（java的这个特点让我们可以使用数组时不用初始化了）\n整数--&gt;0浮点--&gt;0.0字符--&gt;&#x27;\\u000&#x27;布尔--&gt;false引用--&gt;null\n\n数组长度：直接.length即可\nSystem.out.println(arr.length)\n访问：\n\n\n直接访问数组名，得到该数组对应的内存地址哈希值\n[I@1b6d3586\n\n传递数组参数\npublic static void fun(int[] xxx)&#123;&#125;\n引用：当一个数组赋值给数组时，他们指向同一片内存\nint[] arr = new int[5];int[] arr2 = arr;arr[0]=1;System.out.println(arr[0]);// 1System.out.println(arr2[0]);// 1\n数组的长度不可变\nint[] arr = new int[5];System.out.println(arr.length);//5arr = new int[10];System.out.println(arr.length);//10//这样看似是更改了数组的长度//其实是创建了一个新的长度的数组//更改了原先数组指向的地址\n\n\n关于void是不是基本类型当我们提到java的基本类型时，一般都说是八种。但在Thinking in java 这本java圣经中，将void归为基本类型。\n倒也可以说得通：基本类型和引用类型的区别是：\n\n基本类型： 数据在栈中划分内存，值存储在栈上\n引用类型： 数据在栈中划分一块内存用来存储其引用（地址），而其真正的数据存放在堆中\n\n而void不可以new出来（因为 void 的源码中，将构造函数设置为 private 的，所以外部不能 new 对象），void也是存储在栈上的，所以将它归为了基本类型\n在Java的Class反射内有一个方法isPrimitive() ，可以判断是否是基本类型，当我们输入代码void.class.isPrimitive()，它的返回值是true，再一次证明void分为基本类型是有道理的\nstatic关键字静态成员数据​        在类中，加了static的关键字，意味着该变量不再属于某一个成员，而是属于类本身，该类的所有对象共用一个静态数据\n调用：\nPerson stu1 = new person();System.out.println(stu1.year);//不推荐使用对象来调用静态成员数据，这种写法在之后也会被javac翻译为类名称，静态方法名System.out.println(Person.year);//推荐这种写法\n\n静态代码块static&#123;    System.out.println(&quot;你好啊&quot;);&#125;\n\n特点：\n\n静态代码块只会在类加载时执行唯一的一次\n是用来对属性赋值的\n静态内容先于非静态\n\n注意：\n\n静态成员函数只能访问静态成员变量，非静态函数可以访问所有的内容\n没有this指针\n\n覆盖重写方法的覆盖重写(override):\n方法的名称一样，参数列表也一样此时会发生方法的覆盖重写\n特点：因为创建时创建的对象是子类的，所以在调用方法时，一定会先调用子类中覆盖重写的函数\n注意：\n\n必须保证名称相同，参数列表相同\n@override写在覆盖重写的函数前，用来检测是否成功的覆盖重写\n子类方法的返回值必须小于等于父类的返回值范围\n子类方法的权限必须大于等于父类方法的权限修饰符（public&gt; protected &gt; (default)(即什么都不写) &gt; private）\n\n//假设此类已经投入属于，我们要添加功能，不要对此类进行更改public class phone &#123;   public void call()&#123;       System.out.println(&quot;打电话&quot;);   &#125;   public void send()&#123;       System.out.println(&quot;发送短信&quot;);   &#125;   public void show()&#123;       System.out.println(&quot;显示号码&quot;);   &#125;&#125;\n\n//新建一个新的类，重写要增加功能的方法public class newPhone extends phone &#123;    @Override    public void send()&#123;        System.out.println(&quot;发送短信&quot;);        System.out.println(&quot;发送微信&quot;);    &#125;&#125;\n\nsuper用法：\n\n在子类的成员方法中，访问父类的成员变量\n子类中访问父类的成员方法\n子类的构造方法中，访问父类的构造方法super();\n\n转型​        无论是上转还是下转都是为了让类的使用范围和适用范围发生变化，以便操作不同范围的变量或者方法。\n向上转型father up = new son();//向上转型up.cry();//不能使用子类新增的方法up.teach();// 向上转型无法使用子类新增的方法，// 但是可以使用覆盖重写父类的方法\n\n\n上转型是指将子类对象使用父类引用进行引用。\n\n特点：\n\n上转型对象可以操作和使用子类继承或者重写的方法\n\n上转型对象不能使用子类的新方法或者变量\n\n向上转型一定是安全的，因为是小范围想大范围的转换\n\n\n向下转型\n与向上转型相反，即是把父类对象转为子类对象：作用也与上转相反\n\n向下转型的应用并不多\n特点：\n\n是向上转型的一个还原过程，强制转换会导致报错\n\n向下转型不安全，因此应保证原本该对象就是子类的一个内容，不能指鹿为马\n\n\n什么意思呢？\nint num = (int) 10.0;//正确，10.0本身其实就是一个整型int num = (int) 10.5;//错误，10.5本身是一个浮点型\n\n示例\npublic static void main(String[] args) &#123;    father up = new son();//向上转型    son down = (son) up;//向下转型    down.cry();//可以调用子类的新增方法了&#125;\n\ninstanceof的使用向下转型的过程中我们可能会失败报错，所以一定要先判断\n格式： 对象名 instanceof 类名\npublic static void main(String[] args) &#123;    father f1 = new son();//向上转型    father f2 = new father();    son son1 = new son();    son son2 = (son) f1;//向下转型    System.out.println(f1 instanceof father);   //true    System.out.println(f1 instanceof son);      //true    System.out.println(f2 instanceof father);   //true    System.out.println(f2 instanceof son);      //false    System.out.println(son1 instanceof father); //true    System.out.println(son1 instanceof son);    //true    System.out.println(son2 instanceof father); //true    System.out.println(son2 instanceof son);    //true&#125;\n\nfinal关键字final关键字，代表不可改变的\n用法：修饰一个类，方法，局部变量，成员变量\n修饰类public  final class father \n\nfinal类不能有任何的子类（太监类），final类中所有的成员方法不可被覆盖重写\n修饰方法public final void teach()&#123;    System.out.println(&quot;123&quot;);&#125;\n\n不管是类还是方法，final和abstract只能使用一个\n修饰局部变量final局部变量修饰完成，则其不能再被更改（类似C++的const）\nfinal int x ;x = 10;//第一种赋值方法final int y = 10;//第二种赋值方法\n\n只需要保证有一次赋值即可\n注意：\n\n对于基本类型，final表示变量的数据不可以改变\n\n对于引用类型，final表示变量的地址值不可以改变(其中的值可以变)\n\n\n修饰成员变量由于成员变量有默认值，所以用了final之后必须初始化！\n\n直接赋值\n用构造函数赋值\n\nfinal String name;father(String str)&#123;    this.name = str;  &#125;\n\n权限修饰符java中有四种修饰符\n\n\n\n权限符\npublic\nprotected\n(default)\nprivate\n\n\n\n同一个类\nYes\nYes\nYes\nYes\n\n\n同一个包\nYes\nYes\nYes\nNo\n\n\n不同包子类\nYes\nYes\nNo\nNo\n\n\n不同包非子类\nYes\nNo\nNo\nNo\n\n\n内部类一个类的内部包含另一个类\n分类：\n\n成员内部类\n局部内部类\n\n成员内部类成员内部类：\n格式：\n修饰符 class 外部类名称&#123;    修饰符  class  内部类名称&#123;    &#125;&#125;\n\npublic abstract class father &#123;    public class fatherIn&#123;            &#125;&#125;\n\n内部类用外部类可以随意使用，但是外部类调用内部类需要建立内部类的对象。\n使用成员内部类\n间接方法（通过外部类的对象，调用外部类的方法，里面间接在再调用内部类的方法）\n直接方法（格式：外部类名称.内部类名称  对象名 = new 外部类名称().new 内部类）\n\nfather.fatherIn innerClass = new father().new fatherIn();\n\n使用成员内部类的同名变量public class father &#123;    int num = 10;    public class fatherIn&#123;        int num = 20;        public void whichNum()&#123;            int num =30;            System.out.println(num);//30            System.out.println(this.num);//20            System.out.println(father.this.num);//10        &#125;    &#125;&#125;\n\n格式：外部类名.this.变量名\n局部内部类定义在方法内部的类\n只能调用方法来使用，离开方法将不能使用它。\npublic static void main(String[] args) &#123;    father f1 = new father();    f1.innerFun();&#125;\n\n主函数\npublic class father &#123;    public void innerFun()&#123;    class innerClass&#123;        innerClass()&#123;            System.out.println(&quot;局部内部类&quot;);        &#125;    &#125;    innerClass inner = new innerClass();    &#125;&#125;\n\n局部内部类\n局部内部类的final问题java8+开始，只要局部变量内部没有发生实质性的变化，那么final是可以省略的\nclass innerClass&#123;        final int num = 20;//            int num = 20;同上        innerClass()&#123;            System.out.println(&quot;局部内部类&quot;);        &#125;    &#125;        innerClass inner = new innerClass();&#125;\n\n原因：new创建的对象是在堆内存当中的，局部变量是在栈内存当中的\n所以在方法内的局部内部类，在调用后，方法会入栈出栈，但是对象仍然会存在，所以这个变量的值是不可以改变的\n该对象调用此变量的时候会复制一份给自己使用，但是如果变量发生变化，就会报错\n匿名内部类也是一种局部内部类\n如果接口的实现类只需要使用唯一的一次，那么这种情况下就可以省略掉该类的定义，改为使用匿名内部类。\n接口：\n接口名称 对象名 = new 接口名称()&#123;    //覆盖重写所有抽象方法&#125;\n\npublic static void main(String[] args) &#123;        api obj = new api() &#123;            @Override            public void out() &#123;                System.out.println(&quot;匿名内部类，只使用一次&quot;);            &#125;        &#125;;    &#125;\n\n注意：\n\n匿名内部类在创建对象的时候，只能使用唯一的一次\n如果想多次使用，请使用实现类\n匿名内部类省略了实现类/子类名称，匿名内部类是有名字的，但是匿名对象省略了对象名\n\n内部类中权限修饰符的使用\n外部类： public/default\n成员内部类： public/default/protected/private\n局部内部类: default\n\ndefault是不需要写的意思\n包装类日常使用的基本数据类型，使用起来方便，但是没有对应的方法来操作这些基本类型的数据。\n可以使用一个类，把基本类型的数据装起来，在类中定义一些方法，这个类就叫包装类。\n包装类可以把基本类型变为对象类型，**方便使用ArrayList**，因为ArrayList是无法填入基本类型的\n\n\n\n基本类型\n对应的包装类\n\n\n\nbyte\nByte\n\n\nshort\nShort\n\n\nint\nInteger\n\n\nlong\nLong\n\n\nfloat\nFloat\n\n\ndouble\nDouble\n\n\nchar\nCharacter\n\n\nboolean\nBoolean\n\n\n只有int类型和char类型的包装类名字是Integer和Character这两个，其他全是开头字母大写\n装箱和拆箱装箱把基本类型的数据包装到包装类中(基本类型的数据-&gt;包装类)\n构造方法：(整型举例)\n\nInteger(int value)构造一个新分配的Integer对象，他表示指定的int值\nInteger(String s)构造一个新分配的Integer对象，他表示String参数所指示的int值。传递的字符串必须是基本类型的字符串，否则会抛出异常，eg:“100”正确   “a”错误\n\n静态方法:\n\nstatic Integer valueOf(int i)返回一个表示指定int值的Integer实例对象\nstatic Integer valueOf(String s)返回保存指定的String的值的Integer对象\n\npublic static void main(String[] args) &#123;    //构造方法    Integer in1 = new Integer(1);    System.out.println(in1);// 1    Integer in2 = new Integer(&#x27;1&#x27;);    System.out.println(in2);// 49    Integer in3 = new Integer(&quot;1&quot;);    System.out.println(in3);// 1    //静态方法    Integer in4 = Integer.valueOf(1);    System.out.println(in4);// 1    Integer in5 = Integer.valueOf(&#x27;1&#x27;);    System.out.println(in5);// 49    Integer in6 = Integer.valueOf(&quot;1&quot;);    System.out.println(in6);// 1&#125;// java中注意单引号与双引号\n\n拆箱在包装类中去除基本类型的数据（包装类-&gt;基本数据类型）\n成员方法:\nint intValue()//以int类型返回该Integer的值\n\n// 构造方法Integer in1 = new Integer(1);int i = in1.intValue();System.out.println(i);\n\n自动装箱和拆箱// 自动装箱Integer in = 1;//相当于  Integer in = new Integer(1);手动装箱int i = in + 0;//相当于in.intValue()\n\n自动装箱和拆箱直接会在ArrayList中使用\nArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;();// ArrayList集合无法直接存储整数，可以存储Integer包装类list.add(1);//自动装箱:list.add(new Integer(1))int a = list.get(0);//自动拆箱: list.get(0).intValue();\n\n基本类型与字符串类型之间的相互转换\n基本类型 -&gt; 字符串\n基本类型 + “” (空字符串)\n使用包装类的静态方法toString(参数),不是Object的toString方法\nString类的静态方法valueOf(参数)\n\n\n字符串 -&gt; 基本类型\n使用包装类的静态方法parseXXX(&quot;数值类型的字符串&quot;)\n\n\n\n// 基本类型 -&gt; 字符串int i1 = 1;String s1 = i1 + &quot;&quot;;System.out.println(s1 + 2);//12String s2 = Integer.toString(1);System.out.println(s2 + 3);//13String s3 = String.valueOf(1);System.out.println(s3 + 4);//14// 字符串 -&gt; 基本类型int i2 = Integer.parseInt(&quot;-100&quot;);System.out.println(i2 + 5);//-95int i3 = Integer.parseUnsignedInt(&quot;1&quot;);System.out.println(i3 + 6);//7\n\n","categories":["Java"],"tags":["Java"]},{"title":"Protobuf及其不同方式的测试","url":"/2024/01/03/%E5%BA%8F%E5%88%97%E5%8C%96/Protobuf/","content":"\n引言： 2024年的第一篇：一个将压缩与编解码速度做的很好的序列化工具Protobuf\n\n\n\n\nProtobuf序列化原理protocol buffers 诞生之初是为了解决服务器端新旧协议(高低版本)兼容性问题，名字也很贴切，“协议缓冲区”。只不过后期慢慢发展成用于传输数据。\nProtobuf结构假设有json串：\n&#123;    &quot;userName&quot;: &quot;Martin&quot;,    &quot;favoriteNumber&quot;: 1337,    &quot;interests&quot;: [        &quot;daydreaming&quot;,        &quot;hacking&quot;    ]&#125;\n\n定义IDL：\nmessage Person &#123;    required string user_name       = 1;    optional int64  favorite_number = 2;    repeated string interests       = 3;&#125;\n\nPB会序列化为33个字节的TLV格式的bytes数组：\n\n如图可见：PB的序列化原理是将原有格式序列化为TLV的字节流\n\n每一个字段都是TLV格式\nT：不序列化字段名，tag与type打包为一个字节：tag使用5H，type使用后3L\nL：如果是字符串就是长度；可变数字没有L标识\nV：相应的值\n\n\n数字：可变长度数字\n比如1337，在IDL中定义为一个int64，正常来说会占用8字节，但是实际上只占用了2字节\n每一个字节的最高位表示是否还有后续的值，以此取代L的占用，比如 13的最高位为0, 37的最高位为1（小端存储，调转位置）\n\n\n数组：与Thrift不同，Pb没有type为list的形式，而是标记为重复repeated\n\nProtobuf的数据结构(wire_type)\n\n对于float、double（即32bit和64bit）：protobuf没有压缩优化\n对于int（即Varint）：protobuf已有优化\n对于String字段或是标记为Repeated的字段，都会有TLV的结构，TL就会占用2个字节\n\nField TagField tag代替了字段名，标识字段的类型。\nmessage  FeatureCtx&#123;  int32 intvalue = 2;  sint32 sintvalue = 3;&#125;需要注意的是：\n\n\n范围 1~15 中的字段编号，占用1个字节进行编码（包括字段编号和字段类型）\n16~2047占用2个字节\n19000~19999是PB自己使用的tag\n\n比如这个string user_name = 1;，field tag占了前5位，type占用了后3位\n\n\n问题1：为什么field tag占了5bit，命名可以表示最大到31，为什么只有1~15是1字节呢?\n\n因为field tag本质也是一个Varint，因此他的最高位已经被占用了。\n因此请尽量把1~15分配给常用的类型\n可变数字类型PB对Varint的优化很好，Varint 是一种紧凑的表示数字的方法。它用一个或多个字节来表示一个数字，值越小的数字使用越少的字节数。\nVarint 中的每个字节（最后一个字节除外）都设置了最高有效位（msb），这一位表示还会有更多字节出现。\n每个字节的低 7 位用于以 7 位组的形式存储数字的二进制补码表示，最低有效组首位。\n正整数对于int32：\n\n[0, 128) 使用1个字节\n[128, 16384) 使用2个字节\n[16384, 2^21) 3个字节\n[2^21, 2^28) 4个字节\n[2^28, 2^32) 5个字节（这意味着，对于较大的数，会比int32多1字节）\n\n\nVarint对于值越小的数越省空间，从统计的角度来说，一般不会消息中所有的数字都是大数。\n\n计算逻辑是：\nchar* EncodeVarint32(char* dst, uint32_t v) &#123;    // Operate on characters as unsigneds    unsigned char* ptr = reinterpret_cast&lt;unsigned char*&gt;(dst);    static const int B = 128;    if (v &lt; (1&lt;&lt;7)) &#123;        *(ptr++) = v;    &#125; else if (v &lt; (1&lt;&lt;14)) &#123;        *(ptr++) = v | B; // 每个字节的最高位置为1        *(ptr++) = v&gt;&gt;7; // 右移7位    &#125; else if (v &lt; (1&lt;&lt;21)) &#123;        *(ptr++) = v | B;        *(ptr++) = (v&gt;&gt;7) | B;        *(ptr++) = v&gt;&gt;14;    &#125; else if (v &lt; (1&lt;&lt;28)) &#123;        *(ptr++) = v | B;        *(ptr++) = (v&gt;&gt;7) | B;        *(ptr++) = (v&gt;&gt;14) | B;        *(ptr++) = v&gt;&gt;21;    &#125; else &#123;*(ptr++) = v | B;            *(ptr++) = (v&gt;&gt;7) | B;            *(ptr++) = (v&gt;&gt;14) | B;            *(ptr++) = (v&gt;&gt;21) | B;            *(ptr++) = v&gt;&gt;28;           &#125;    return reinterpret_cast&lt;char*&gt;(ptr);&#125;\n\n比如300：\n300 = 256 + 32 + 8 + 4 = 1 0010 1100v = 1 0010 1100v | B = 1 0010 1100 | 1000 0000 =1 1010 1100 // *(ptr++) = v | B;v &gt;&gt; 7 = 1 0010 1100 &gt;&gt; 7 = 000 0010 // *(ptr++) = v&gt;&gt;7;最后结果是：1010 1100 // Low0000 0010 // High\n\n负整数对于负数，最好存储为sint类型，sint在被解析的时候采用zigzag编码\nZigzag(n) = (n &lt;&lt; 1) ^ (n &gt;&gt; 31) // n 为 sint32 时\n\n\n将2^32分为两半，奇数表示负数，偶数表示正数。\n\n意味着sint存储的范围在[-2^31, 2^31 - 1]\n\n\n问题1：pb的int32可以存储负数类型吗？占用几个字节？\n\nint32可以存储负数类型。\n如果使用int32类型存储负数，那么不管是int32还是int64位都会使用10个字节来存储（源码会强制转为）\nvalue3 := []int32&#123;&#125;value3 = append(value3, -1)test_data3 := FeatureCtx&#123;Int32Array: value3&#125;value2 := []int32&#123;&#125;value2 = append(value2, -1)test_data2 := FeatureCtx&#123;Sint32Array: value2&#125;mashal_res3, _ := proto.Marshal(&amp;test_data3)mashal_res2, _ := proto.Marshal(&amp;test_data2)println(len(mashal_res3)) // 11 字节println(len(mashal_res2)) // 2 字节\n\n关于Packed=true的作用\nPB3中默认，对基础数据类型（如整数、枚举等）的 repeated 字段都默认开启packed=true。\n\nrepeated int32 array1 = 1 [packed=true];repeated int32 array2 = 2 [packed=false];\n\n对于array1和arry2的区别是什么呢？\n假设我们分别给他们存入4个1，即数组的内容是&#123;1, 1, 1,1&#125;\n他们的区别是：\n\narray1： T, L V, V, V, V = 2(TV) + 4(4个V) = 6bytes\narray2： TV, TV, TV, TV =  2 * 4 = 8 bytes\n\n“Packed”格式特别适用于 repeated 字段中包含大量相邻的小整数值的情况。\nSnappy压缩原理Snappy 使用了一个哈希表来存储已经见过的短语（通常是 4 到 11 字节的小片段）。在压缩数据时，它会扫描输入数据，并通过哈希表来查找匹配的短语。\n当 Snappy 找到重复的短语时，它会用一个复制标记来表示“复制前面出现过的内容”。如果找不到匹配的短语，它就会使用字面量的方式来存储数据。\n背景目前，特征仓库的特征传递目前使用字符串逗号拼接的形式：param1,param2,param3。\n预计将序列化方式进行protobuf改造，为了寻求一种更好的序列化存储方式，本文测试了使用Protobuf协议，在使用oneof、float、double等几种类型的不同序列化方式的对比。\n序列化大小对比——随机数据测试方式四种序列化方式：\n\n普通数组（或称为原生数组）：即idl直接定义的数组repeated float float_array = 10;\n\noneof数组：即oneof类型的数组（oneof类型不能直接repeat）\n\n\n  message DataValue &#123;    oneof Data &#123;        string strVal = 1;        int32 i32Val = 2;        float floatVal = 3;        double doubleVal = 4;        int64 int64Val = 5;    &#125;&#125;message  FeatureCtx&#123;\trepeated DataValue data = 1;&#125;\n\n\n占位符：并不使用数组，而是使用一个字段表示数组中的一位\n\n  message DataStruct &#123;    string sval0 = 1;    string sval1 = 2;    string sval2 = 3;    string sval3 = 4;    // 省略...&#125;\n\n\n字符串拼接\n\n纯小数：不同精度，使用逗号拼接：比如精度为2时，一个case是”0.11,0.23,0.12”，精度为3就是”0.222,0.333,0.122”\n非纯小数：只要字符数与纯小数相同，性能就相同\n精度2 = 每个值的字符数是5：比如”0.12,” == “1.23,” == “12.3,”\n精度3 = 每个值的字符数是6：比如”0.123,” == “1.234,” == “12.34,” == “123.4,”\n精度4 = 每个值的字符数是7\n精度5 = 每个值的字符数是8\n精度6 = 每个值的字符数是9\n\n\n\n\n\n数据生成方式：int数据的生成方式：生成指定范围的数据\nfunc genRandomInt(min, max int32) int32 &#123;    rand.Seed(time.Now().UnixNano())    randomNumber := rand.Int31n(max-min+1) + min    return randomNumber&#125;小数的生成方式：指定生成范围以及精度func generateRandomFloat(min, max float64, precision int) float32 &#123;    rand.Seed(time.Now().UnixNano())    // 生成在指定范围内的随机浮点数    randomValue := min + rand.Float64()*(max-min)    // 将浮点数舍入到指定精度    return round(randomValue, precision)&#125;\n\nfloat数组对比测试1：数组长度1~20（有占位符）构造了1~20不同长度float、double数组，数组的每一个元素使用random构造，每一个小数都是纯小数（即整数部分为0）；对于字符串类型，额外需要精度，比如精度为2即保留小数点后两位：”0.12,0.23,”\n对于float类型：原生数组 &lt; string拼接(精度2) &lt; string拼接(精度3) = 占位符 &lt; string拼接(精度4)\n\n也能看出：占位符的性能大致为string精度为3时的性能\n\n测试2：数组长度1~100（有snappy压缩，无占位符）1、在数据随机生成的情况下（即数据重复率很低时）有以下结论：\n\nSnappy在数组长度50之后，压缩效果比较好。\nSnappy对原生float数组压缩几乎没有效果。\n在数组长度大于50之后，string.2拼接略好于原生数组\n\n2、在数据随机生成的情况下（即数据重复率很低）时，总体排序为：\nstring.2压缩 &lt; 原生数组 &lt; string.3压缩 &lt; string.2 &lt; string.4压缩 &lt; string.3 = oneof 压缩 &lt; string.5压缩 &lt; string.4 = oneof &lt; string.6压缩 &lt; string.5 &lt; string.6\n3、在数据随机生成的情况下（即数据重复率很低）时，Snappy压缩率：当数组长度为50→100\n\n原生数组压缩率：不压缩\noneof压缩率：87%\nstring.2压缩率：72%\nstring.3压缩率：80%\nstring.4压缩率：84%\nstring.5压缩率：86%\nstring.6压缩率：87%\n\n4、假设string拼接方式为1，那么使用不同的序列化方式的字节占用是：（取数组长度为35时的结果）\n\n\n\n不同精度\nfloat数组\noneof数组\noneof数组+snappy\n\n\n\nstring.2\n0.80\n1.38\n1.26\n\n\nstring.3\n0.67\n1.15\n1.05\n\n\nstring.4\n0.58\n0.99\n0.90\n\n\nstring.5\n0.51\n0.87\n0.79\n\n\nstring.6\n0.45\n0.77\n0.70\n\n\n精度为6，使用float的优势比string拼接好一半多。\ndouble数组对比测试1：数组长度1~20（有占位符）对于double类型：\nstring拼接(精度2) &lt; string拼接(精度3)&lt;string拼接(精度4)&lt;string拼接(精度5) = 原生double数组 &lt; 占位符数组 &lt; oneof数组\n测试2：数组长度1~100（有snappy压缩，无占位符）1、整体来看：\n\nSnappy对原生double数组压缩没有效果。\nstring拼接要好于原生数组（普通数组），因为pb对double没有优化，直接会直接给8字节\n\n2、总体排序：\nstring.2压缩 &lt; string.3压缩 &lt; string.2 &lt; string.4压缩 &lt; string.3 &lt; string.5压缩 &lt; string.4 &lt; string.6压缩 &lt; string.5 = 原生数组 &lt; string.6 &lt; oneof数组压缩 &lt; oneof数组\n3、假设当前的string拼接方式为1，那么使用原生数组、压缩字符串、压缩oneof数组的占用是（取数组长度为35时的结果）\n\n\n\n\ndouble数组\noneof数组\noneof数组+snappy\n\n\n\nstring.2\n1.59\n2.16\n1.96\n\n\nstring.3\n1.33\n1.81\n1.64\n\n\nstring.4\n1.14\n1.55\n1.41\n\n\nstring.5\n1.00\n1.36\n1.24\n\n\nstring.6\n0.89\n1.21\n1.10\n\n\n当string精度为5，double数组与string拼接基本相同。\n当string精度为6，double数组好于string拼接。\nint数组对比测试1：int数组对比其他格式由于数据的长度对String拼接的方式影响比较大，因此我们分别测试了数量级在0-100、100-1w\n\n\n对比可见，pb对int数组的优化是十分明显的，不论数量级在什么级别，原生的int数组有压倒性的优势。\n排序为：原生数组 &lt;&lt; 占位符数组 = 0100数量级string拼接 &lt; oneof数组 = 1001w数量级string拼接\n测试2：在要求精度的前提下，对比float2int与float要求精度accuracy的前提下，将float*accuracy存在int数组内，与直接使用float数组进行对比。\n\n当数据是纯小数时，约束精度是非常有效的。\n\n\n随着数量级的提高，使用此方法的优势下降，此方式适合于整数部分比较少，小数部分较多的情况。我们假设使用float为1，那么各种精度的int类型收益如表所示：\n\n\n\n数量级\n精度2\n精度3\n精度4\n精度5\n精度6\n\n\n\n0~1(纯小数)\n0.25\n0.47\n0.49\n0.71\n0.73\n\n\n1~100\n0.50\n0.71\n0.75\n0.94\n1.00\n\n\n100~1w\n0.75\n0.94\n1.00\n1.17\n2.19\n\n\nPB对比总结1、字节占用天梯图（字节占用从小到大排序）\n取数组长度在30~50之间时（一个特征组的特征基本在这个区间内）\n\nint数组\n占位符(int)、数据量级在0~100string拼接\noneof(int)、数据量级在0~1w string拼接\nfloat数组、snappy(string.2)\nstring.2、snappy(string.3) \nstring.3、snappy(string.4) 、占位符(float)\nstring.4、snappy(string.5) 、oneof数组(float)、压缩oneof(float)\nstring.5、snappy(string.6) 、double数组\nstring.6、snappy(string.7) \nstring.7、oneof数组(double)、压缩oneof(double)\nstring.N\n\n2、使用int替代float，会在小数部分多，整数部分少的情况下有明显收益。\n与现行方案string拼接对比，使用int收益如下（string不同精度 / int不同进度）\n\n\n\n数量级\n精度2\n精度3\n精度4\n精度5\n精度6\n\n\n\n0~1(纯小数)\n0.20\n0.32\n0.28\n0.35\n0.33\n\n\n1~100\n0.34\n0.41\n0.38\n0.42\n0.40\n\n\n100~1w\n0.38\n0.42\n0.40\n0.43\n0.73\n\n\n序列化大小对比——真实数据与随机生成的数据相比，真实的数据通常有几个特点：\n\n重复率会高一点：因此Snappy压缩情况会好一点。\n空值率会高一点：空值需要额外的存储。\n\n真实的数据，可能存在为空的情况，也不好使用0这种有意义的数值表示null，因此需要存放空值的下标，关于下标的存储方式有这么两种：\n\n可以使用int[]数组存放下标\n使用int[]数组，但是每一个元素使用bitmap，每一位对标一个下标，那么总共需要length / 31个int数作为bitmap。\n\n\nPS：这里使用31，而不是32，是为了避免出现负数，Protobuf的int32类型对于负数的存储不论大小，都会占用10字节。（pb对于负数的优化是sint类型）\n\n测试数据case1此处使用真实数据测试，但数据源不能公示，此处仅展示结论idl：\nmessage  FeatureCtx&#123;  repeated string strArray = 1;  repeated int32 intArray = 2; // 存放值  repeated int32 emptyArray = 3; // bitmap  repeated float floatArray = 4;&#125;\n\n\nint+int表示使用int数组存数据，且使用int数组存null值下标\nint+bitmap表示使用int数组存数据，且使用bitmap存null值下标\n\n\n表中可见：\n\n数据压缩后：int+bitmap &lt; float + bitmap &lt; string &lt;oneof &lt; int + int &lt; float + int\nint+int的方式表现不如string，是因为表的字段大部分为空，string拼接使用”N”来表示空，大量重复的N在压缩后效果十分明显（case1数据Null字段/全部字段=48/53）\nsnappy的压缩，对string、oneof效果最好，对基本数组的压缩很小。（之前的测试对int、float、double等类型完全没有压缩，是因为生成的数都是随机的，重复率比较小）\n该case数据的小数精确到4位，拿精度为4的int+bitmap对比string，比值为0.56 : 1\n数据null值字段 / 全部字段 = 48/53，空值很多，如果数据比较充实，那么int+bitmap的效果会比string更好。\n\n测试数据case2case2也是一个较为稀疏的表。我们将null的数据除去，使用剩下的字段构造一个稠密表进行测试：float_compress:string = 0.50以及float_compress:string_compress=0.76\n测试数据case3由于此表的数据含有int、string、bigint、float四种数据，因此不同的序列化方式的区别仅在于对于float类型，是使用int存储还是float数组存储。（对于null值的处理，除string拼接外均使用bitmap)测试方式：Idl：\nmessage  FeatureCtx&#123;    repeated DataValue data = 1; // oneof    repeated string strArray = 2; // 存放string    repeated int32 intArray = 3; // 存放int数值    repeated int32 emptyArray = 4; // 存放空元素下标，Array    repeated float floatArray = 5; // 存放float值    repeated int32 intFloatArray = 6; // 存放float值，使用 float * accuracy = int    repeated int64 longArray = 7; // 存放float值，使用不同精度    // tag最好在1~15，因为1~15使用1个byte    //  optional string dataVersion = 14; //数据的版本；例如离线表Hive的分区；    //  string metaVersion = 15;//特征组的元数据版本。&#125;\n\n测试udf：\npublic static Integer evaluate(String name, String version, Map&lt;String, String&gt; keyItems, Map&lt;String, String&gt; valueItems, int accuracy, int compress) throws IOException &#123;    // 初始化部分    int paramSize = valueItems.size();    // 最多使用31位，使用32会出现负数，pb的int32存储负数需要10字节    final int bitmapSize = 31;    List&lt;Integer&gt; intArray = new ArrayList&lt;&gt;();    List&lt;Integer&gt; emptyArray = new ArrayList&lt;&gt;();    int bitmapNum = paramSize / bitmapSize;    for (int j = 0; j &lt;= bitmapNum; j++) &#123;        emptyArray.add(0);    &#125;    List&lt;Long&gt; longArray = new ArrayList&lt;&gt;();    List&lt;String&gt; stringArray = new ArrayList&lt;&gt;();    List&lt;Integer&gt; floatArray = new ArrayList&lt;&gt;();    // 遍历参数，判断类型，放入不同的list    int i=-1;    for(String key : valueItems.keySet())&#123;        i++;        String ele = valueItems.get(key);        if (Strings.isEmpty(ele)) &#123;            int bitmap = emptyArray.get(i / bitmapSize) | (1 &lt;&lt; (i % bitmapSize));            emptyArray.set(i / bitmapSize, bitmap);            continue;        &#125;        String type = keyItems.get(key);        if(type == null) continue;        switch (type) &#123;            case &quot;int&quot;:                // 放入数组队列                intArray.add(Integer.parseInt(ele));                break;            case &quot;long&quot;:                // 放入long队列                // 先转为double再换为long，防止某些NaN转为0.0导致parse出错                longArray.add((long) Double.parseDouble(ele));                break;            case &quot;float&quot;:                // 【方式1】放入float队列——int*精度                int val = (int) (Float.parseFloat(ele) * accuracy);                floatArray.add(val);                // 【方式二】直接放入float队列                // floatArray.add(Float.parseFloat(ele));                break;            case &quot;string&quot;:                // 放入string队列                stringArray.add(ele);                break;        &#125;    &#125;    FeatureCtx.Builder builder = FeatureCtx.newBuilder();    builder.addAllIntArray(intArray);    builder.addAllEmptyArray(emptyArray);    builder.addAllIntFloatArray(floatArray);    builder.addAllLongArray(longArray);    builder.addAllStrArray(stringArray);    byte[] bytes = builder.build().toByteArray();    if(compress == 1)&#123;        bytes = Snappy.compress(bytes);    &#125;    return bytes.length;&#125;\n\n\n结果如下：\n对比float+bitmap与string拼接比值为138 / 203 = 0.66\n\n问题一：为什么前面六种方式的数据大小基本一致？\n\n因为数据本身float占比很小，特征参数的统计如下： \n\nInt 27个\nString 17个\nBigint 1\nFloat 2\n\n大部分都是string和int，除string外的方式，前面六种方式只对float类型有所区分而已，因此基本一致。\n\n问题二：为什么数据压缩率不高？甚至压缩完会比原来更高\n\n对于每一组特征，重复率不高，因此压缩率不高。比如：使用基本的int数组或是float数组进行存储时，原本的100bytes，压缩后变为103bytes，多的3bytes存储了Snappy的数据结构，数据条数比较多（20231210分区数据：3,604,946,782条，1T数据大小），而数据本身重复率不高，空值率不高，因此压缩率不高，甚至返增。\n测试数据case4\nfloat+snappy : string 比值为：20.09 : 69.46 = 0.28float+snappy与int6+snappy压缩完大小基本一致。\n测试数据case5float+snappy : string 比值为：7.5 : 31.86 = 0.23\nfloat+snappy与int6+snappy压缩完大小基本一致。\n测试数据case6float+snappy : string 比值为：83.48 : 302.47 = 0.27\nfloat+snappy与int6+snappy压缩完大小基本一致。\nPB化结论\n对于不同的数据，最好使用不同的pb数据结构：\n\n对于字符串：使用字符串\n对于int、long：使用int32、int64\n对于浮点数：优先使用float数组，使用int*accuracy比float数组少一点，但是差异不大，反而引入精度问题。\n对于null值：使用int[]，其中每一个元素都是一个bitmap\n\n\n关于snappy\n\n可以在序列化后直接加Snappy，稀疏情况下使用效果比较好（对于比较稠密的、而且重复比较少的数据，可能会增大size）\n\nSnappy的原理是根据数据构造了一个重复语句的哈希表，重复越多压缩率越高。\n\n\n\n\n\n参考文档\n很棒的博文：https://halfrost.com/protobuf_encode/#toc-19\n一本书：《数据密集型应用系统设计》\n\n","categories":["序列化"],"tags":["Protobuf"]},{"title":"文件管理","url":"/2021/01/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/","content":"\n  新年到来了！！新年的第一篇blog\n  \n  引言：操作系统的文件系统与文件管理方式\n\n\n\n\n文件管理文件与文件系统有关基本概念数据的组成：\n\n数据线\n基本数据项（最小的逻辑数据单位）\n组合数据项\n\n\n记录：一组相关数据项的集合\n文件：记录在外存上的具有文件名的一组相关信息的集合\n有结构文件：若干个相关记录组成\n无结构文件：被看成一个字符流（绝大部分都是无结构文件）\n\n\n\n文件、记录、数据项的层次关系：\n\n文件属性：文件名、文件类型、文件长度、文件物理位置、建立日期\n文件名：不同系统有长度限制、特殊字符不能用于文件名\n扩展名：后缀名，window系统中的概念，在类Unix系统中仅仅只有表意的作用\n文件类型：\n\n按用途分类\n系统文件\n用户文件\n库文件：.lib静态库文件.dll动态库文件\n\n\n按数据形式分类\n源文件\n目标文件.obj\n可执行文件.exe\n\n\n按存取控制属性分类\n只执行文件\n只读文件\n读写文件\n\n\n按组织形式和处理方式分类（Unix系统）\n普通文件\n目录文件\n特殊文件：各类IO设备\n\n\n按使用情况分类：\n临时文件：工作完毕会自动删除\n永久文件\n档案文件：系统或一些实用工具软件包在工作过程中记录在案的文挡资料文件\n\n\n\n文件的特点：\n\n具有保存性\n按名存取\n一组信息的集合\n\n文件系统的主要功能\n实现按文件名存取文件信息\n为用户提供统一的和友好的接口 \n实施对文件和文件目录的管理\n文件存储器空间的分配和回收\n提供有关文件的共享和保护\n\n可以从用户和系统的角度来看：\n\n从用户的角度：\n实现了信息的按名存取\n\n\n从系统的角度\n文件存储器空间的分配回收\n文件的保护和检索\n\n\n\n文件系统的结构层次可分为三个层次：从上到下\n\n文件系统接口\n命令接口：键盘中断敲入命令\n程序接口：系统调用来使用\n\n\n对对象操纵和管理的软件集合（核心）\n文件存储空间的管理\n文件目录的管理\n文件的逻辑地址与物理地址转换机制\n对文件的读和写的管理\n对文件的共享和保护\n\n\n对象及其属性\n文件\n目录\n磁盘存储空间\n\n\n\n文件系统 = 文件管理程序 + 它所管理的全部文件\n文件系统特点\n使用方便\n安全可靠\n便于共享\n统一管理\n\n文件操作文件系统以系统调用的方式，为用户提供服务\n基本的文件操作创建文件\n系统为新文件分配必要的外存空间\n在文件系统的目录中为该文件建立一个目录项，目录项中记录新文件的文件名及其在外存的地址等属性\n\n删除文件\n系统从文件目录中找到要删除文件的目录项，使之成为空闲目录项\n回收该文件所占用的存储空间。\n\n读/写文件读文件：把文件中的数据从外存读入内存的用户区\n写文件：当用户要求对文件添加或修改信息时，可用该命令将信息写入文件\n应在系统调用中给出文件名和存放读出内容的内存地址\n打开文件目的：为了避免用户在每次访问文件时从外存中查找文件目录\n所谓“打开”：系统将文件的属性（目录信息）从外存复制到内存打开文件表中，并返回该表目的编号给用户，建立了用户与文件间的联系。以后若再访问此文件，则利用编号直接在内存中检索，从而节省大量的检索开销，提高了文件的操作速度\n关闭文件将文件的属性从内存打开表中删除，从而切断用户与文件间的联系\n其他文件操作\n对于文件属性的操作\n改变文件名\n改变文件的拥有者\n改变文件的访问权\n查询文件的状态\n\n\n对目录的操作\n创建、删除\n改变当前工作目录\n实现文件共享\n\n\n\n文件的使用\n建立一个新文件\n建立文件\n写文件\n关闭文件\n\n\n读一个已存在的文件\n打开文件\n读文件\n关闭文件\n\n\n\n文件的逻辑结构在系统中文件有两种形式的结构：\n\n物理结构\n文件的存储结构，与存储介质有关\n\n\n逻辑结构\n从用户的观点观察到的文件组织形式\n\n\n\n文件的逻辑结构和物理结构都将影响文件的检索速度\n文件逻辑结构的类型\n按文件是否有结构分类：\n有结构的记录式文件\n定长记录：文件中所有记录长度相同\n变长记录\n按文件的组织方式分类，可以将有结构文件分为\n顺序文件\n索引文件\n索引顺序文件\n\n\n\n\n无结构的流式文件\n由字符流构成\n长度：字节为单位\n访问：读写指针\n\n\n\n\n\n顺序文件排序方式：\n\n串结构：记录顺序与关键字无关，按存入时间的先后顺序排列\n顺序结构：记录顺序按关键字排序\n\n优点：\n\n顺序存取速度较快（批量存取）\n对定长记录，还可方便实现直接存取\n只有顺序文件才能存储在磁带上，并能有效地工作\n\n缺点：\n\n如果用户要求查找或修改单个记录，系统要逐个地查找诸记录, 效率很差，尤其是当文件较大时，情况更为严重\n增加或删除一个记录较困难\n对变长记录，直接存取低效\n\n索引文件为解决变长记录文件的直接存取低效问题\n\n为变长记录文件建立一张索引表\n\n优点：\n\n通过索引表可方便地实现直接存取，具有较快的检索速度。\n易于进行文件的增删\n\n缺点：\n\n索引表的使用增加了存储费用\n索引表的查找策略对文件系统的效率影响很大\n\n索引顺序文件为解决变长记录文件的直接存取低效且存储费用增加的问题\n\n将所有记录分为若干个组(例如，50个记录为一个组)；\n为顺序文件建立一张索引表，在索引表中为每组中的第一个记录建立一个索引项，其中含有该记录的键值和指向该记录的指针\n\n优点\n\n通过索引表可方便地实现直接存取，具有较快的检索速度\n易于进行文件的增删\n\n缺点\n\n索引表的查找策略对文件系统的效率影响很大.\n\n文件的存取方法通常有三种：\n\n顺序存取\n直接存取（随机存取）\n按键存取\n\n顺序存取对于定长记录文件：\n设置读/写指针rptr与wptr指向下一次读/写的地址\n读/写完指针做对应修改：rptr = rptr + L\n对于不定长记录文件：\n每次将读写指针加上Li，Li是刚读或刚写完的记录的长度：\nrptr = rptr+Li\n\n\n\n\n\n直接存取允许按任意顺序存取文件中的任何一个记录\n对于定长记录文件：\n​    rptr = addr + i*L\n对于变长记录文件：\n顺序文件不能使用；\n索引文件可以使用（由于索引表本身是定长的）；\n按键存取实质是直接存取法，根据记录中的关键字（键）经过某种方法计算转换成相应的物理地址\n注意：\n顺序文件中的记录寻址有：\n\n显示寻址：\n通过文件中记录的位置\n对于定长记录文件就可以通过计算\n对于可变记录文件必须从头遍历\n\n\n通过关键字\n\n\n隐式寻址：就是顺序寻址\n\n文件的物理结构物理结构指存储结构：\n\n连续分配方式：将是顺序式的文件结构；\n链接分配方式将形成链接式文件结构；\n索引分配方式则将形成索引式文件结构\n\n顺序结构\n也叫连续结构，最简单的物理文件结构，它将一个文件的信息存放在若干连续的物理块中。（类似内存的连续分配）\n\n\n特点：\n\n顺序存取速度快，所需的磁盘寻道次数和寻道时间最少\n浪费空间：动态存储分配问题，产生外零头\n可以通过紧凑技术合并空闲的区域\n\n优点：\n\n顺序访问容易\n顺序访问速度快\n\n缺点：\n\n要求分配连续的存储空间\n必须实现知道文件长度\n不能灵活的删除和插入记录\n不利于动态增长的文件，存在外零头\n\n链接结构\n又称串联结构，将一个逻辑上连续的文件信息存放在外存的不连续(或连续)物理块中\n隐式链接：每个盘块中有指向下一个块的指针\n显式链接：有文件分配表FAT\n\n隐式链接：\n\n显式链接：\n\n优点：\n\n提高了磁盘空间利用率\n不存在外部碎片问题\n有利于文件插入和删除\n有利于文件动态扩充\n\n缺点：\n\n存取速度慢，不适于随机存取，对顺序存取特别有效。（找到一个盘块才能知道下一个盘块位置）\n可靠性问题，如指针出错（隐式链接）\n更多的寻道次数和寻道时间。（分配的每个盘块可能不连续，可能分布于不同的磁道中）\n链接指针占用一定的空间。（隐式链接）\n\n链接结构的一个变形: 文件分配表FAT－显式链接\n索引结构\n文件的信息存放在若干不连续物理块中，系统为每个文件建立一个专用数据结构–索引表，并将这些块的块号存放在一个索引表中。\n\n特点：\n\n索引快地址由FCB指出\n支持随机存取\n不会产生外零头\n适用于大文件\n\n分类：\n\n单级索引分配\n多级索引分配\n混合索引分配\n\n单级索引分配\n优点：\n\n支持直接访问。读i个块时，从索引块中找到盘块号\n不会产生外部碎片\n文件较大时，优于链接结构\n\n缺点：\n\n可能花费较多的外存空间。每建立一个文件，必须分配一个索引块（索引块本身也是一个盘块） 。\n一般系统中小型文件居多，索引块利用率低。\n对于大文件来说，索引块也会占用不少的盘块\n\n多级索引分配\n例如：设每个盘块的大小为4 KB，每个盘块号占4个字节，则在一个索引块中可存放1K个盘块号。\n解：\n采用单级索引时所允许的最大文件长度为4 MB；\n而采用两级索引时，最多可包含的存放文件的盘块的盘块号总数N = 1K × 1K = 1 M个盘块号，则允许的最大文件长度可达4 GB。 \n混合索引分配既有一级、也有二级、三级，在类Unix系统中使用\n\n优点：\n\n保持了链接结构的优点,又解决了其缺点：\n既能顺序存取,又能随机存取\n满足了文件动态增长、插入删除的要求\n也能充分利用外存空间。\n\n\n\n缺点：\n\n较多的寻道次数和寻道时间\n索引表本身带来了系统开销，如：内外存空间，存取时间。\n\n文件存储空间管理分配盘块的方式\n\n空闲表法\n空闲链表法\n位视图\nUnix成组链接\n\n空闲表法\n系统为外存上的所有空闲区建立一张空闲表，每个空闲区对应于一个空闲表项，其中包括表项序号、该空闲区的第一个盘块号、该区的空闲盘块数等信息\n\n\n\n\n序号\n第一空白块号\n空白块个数\n空闲物理块号\n\n\n\n1\n2\n4\n（2，3，4，5）\n\n\n2\n7\n3\n（7，8，9）\n\n\n3\n15\n5\n（15，16，17，18，19)\n\n\n4\n—\n—\n—\n\n\n\n仅当有少量的空白区时才有较好的效果。（多个空白区说明这些空白区是不连续的）\n如果存取空间中有着大量的小的空白区，则空闲表变得很大，效率大为降低。\n这种分配技术适用于建立连续文件\n\n空闲链表法\n将所有空闲盘区拉成一条空闲链\n\n分为两种：\n\n空闲盘块链：以盘块为单位拉成一条链 \n空闲盘区链：以盘区(1个盘区可包含若干连续的盘块)拉成一条链\n每个盘区上除有指示下一个盘区的指针外，还应指明本盘区大小\n分配盘区通常采用首次适应算法\n回收盘区时，也要将回收区与相邻接的空闲盘区相合并\n\n\n\n位视图法\n系统建立一张位示图，以反映整个存储空间的分配情况\n\n用二进制位反映磁盘空间的分配, \n每个物理块对应一位, “1”表示对应的物理块已分配，“0”表示其对应的块未分配\n分配：\n\n 顺序扫描位示图，从中找出一个或一组其值为“0”的二进制位(“0”表示空闲时)。\n将二进制位转换成相应的盘块号。假定找到的其值为“0”的二进制位位于位示图的第i行、第j列，则其相应的盘块号应按b = n(i-1) + j   （n表示每行的位数）\n修改为1\n\n回收：\n\n将回收盘块的盘块号转换成位示图中的行号和列号。转换公式为\ni = (b - 1) DIV n + 1j = (b - 1) MOD n + 1\n修改为0\n\n\n优点：\n\n易找到空闲盘块\n占用空间少\n\n成组链接法特点：\n\n栈结构\ns.free表示该盘块号内空闲的盘块\n每个盘块号栈的第一个位置链接到下一个盘块号栈，为0代表没有下一个盘块\n\n注意：\n例题：某个系统采用成组链接法来管理磁盘的空闲空间，目前磁盘的状态如下图所示：\n\n\n在为某个文件分配3个盘块后，系统要删除另一个文件，并回收它所占的5个盘块，它们的盘块号依次为700、711、703、788、701，请画出回收后的盘块链接情况。\n\n\n文件目录文件目录\n文件目录：把所有的FCB组织在一起，就构成了文件目录，即文件控制块的有序集合\n目录项：就是FCB\n目录文件：为了实现对文件目录的管理，通常对文件目录以文件形式保存在外存\n\n当文件多时，文件目录占用磁盘上大量的盘块 ，设文件目录所占用的盘块数为N，按顺序法查找一个目录项平均需调入盘块**(N+1)／2**次\n一个FCB为64B，盘块大小为1KB，则每个盘块中只能存放16个FCB；\n若一个文件目录中共有640个FCB，需占用40个盘块，故平均查找一个文件需启动磁盘20次\n解决：把文件名与文件描述信息分开存放\n\n索引结点：文件除文件名外的描述信息单独形成一个称为索引结点的数据结构，简称为i结点\n\n\n\n\n文件名\n索引结点编号\n\n\n\n文件名1\n\n\n\n文件名2\n\n\n\n文件名14B，i 结点指针2B。 1 KB盘块中可做64个目录项，平均启动磁盘次数缩小，节省了系统开销\n目录管理\n实现“按名存取” \n提高对目录的检索速度 \n文件共享 \n允许文件重名（允许不同用户对不同文件用相同文件名。）\n\n文件目录结构\n单级目录结构：在整个系统中只建立一张目录表\n优点：简单，易实现按名存取\n缺点：\n不允许重名\n查找速度慢\n不利于文件共享（不利于不同用户用不同文件名来访问同一个文件）\n\n\n\n\n两级目录结构\n每个用户建一个用户文件目录UFD\n系统为所有用户建立一个主文件目录MFD\n优点：\n提高了检索速度\n不同用户目录可重名\n不同用户用不同文件名来访问同一个文件\n\n\n缺点：\n限制了个用户文件的共享\n不太适合大量用户和大量文件的大系统\n\n\n\n\n多级文件目录\n树型目录结构\n根目录根节点、数据文件是叶子结点\n删除方式\n不删除非空目录：得调用递归才能删除多目录结构\n可删除非空目录（危险）\n\n\n优点\n层次结构清晰\n易于管理保护\n有利于文件分类\n解决重名问题\n提高检索速度\n能进行权限控制\n\n\n缺点：\n查找一个文件按路径名逐层检查，由于每个文件都放在外存，多次访盘影响速度\n\n\n\n\n\n","categories":["操作系统","文件系统"],"tags":["操作系统","文件系统","文件管理"]},{"title":"处理器调度","url":"/2020/12/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/","content":"\n    引言：操作系统中处理器调度（高级调度、中级调度、低级调度）\n\n\n\n\n处理器调度处理机调度的层次根据分配对象的不同，分为三种层次：\n\n高级调度（作业调度、长程调度）\n调度对象：作业\n根据某种算法，将后备作业调入内存\n\n\n中级调度（交换调度、中程调度、均衡调度）\n调度对象：进程是否进入内存\n负责进程在主存和外存之间的换进换出（挂起与激活）\n\n\n低级调度（进程调度、短程调度）\n调度对象：进程（或内核级线程）\n决定就绪队列哪一个可以获得处理机\n\n\n\n高级调度（作业调度）较多存在于多道处理系统中的概念\n\n多道批处理系统：\n\n多道：系统内可同时容纳多个作业。这些作业放在外存中，组成一个后备队列，系统按一定的调度原则每次从后备作业队列中选取一个或多个作业进入内存运行，运行作业结束、退出运行和后备作业进入运行均由系统自动实现，从而在系统中形成一个自动转接的、连续的作业流\n\n成批：在系统运行过程中，不允许用户与其作业发生交互作用，即：作业一旦进入系统，用户就不能直接干预其作业的运行。\n\n\n\n作业是什么?\n作业（Job）：在某些操作系统中，作业（job）是计算机操作者（或是一个叫做作业调度器的程序）交给操作系统的执行单位。是用户一次请求计算机系统为它完成任务所进行的工作总和\n\n作业的组织：作业 = 程序 + 数据 + 作业说明书\n\n作业步（Job Step）：例如一个c语言程序（作业），需要经过编辑、编译、链接、才能执行，其中编译链接就是这个作业完成所需要的两个作业步\n\n作业步之间的关系：\n每个作业步运行的结果产生下一个作业步所需要的文件\n一个作业步能否正确执行依赖于前一个作业步是否成功的完成\n\n作业的控制流程：装配就是链接，此时载入的库函数是静态库函数，在运行时载入的库函数是动态库函数\n\n作业的类型根据计算机对作业的处理方式不同，分为两类：\n\n脱机作业（批处理作业）\n使用作业控制语言来写一份作业控制说明书，规定如何控制作业的执行\n\n\n联机作业（交互式作业或终端型作业）\n使用OS提供的命令语言直接提出对作业控制要求\n\n\n\n作业控制块JCB在多道批处理系统中，为了感知作业的存在，为每一个作业都设立了一个作业控制块，记录了作业有关的信息\n内容：\n\n作业的基本情况：用户名、作业名、状态、使用的语言等等\n作业的控制要求：控制方式、类型、优先数、操作顺序和出错处理\n作业的资源要求：建立的时间、运行的事件、最迟完成的事件等等\n\n作业的状态一个作业的一生有四个状态：提交、后备（收容）、执行、完成\n\n提交状态：通过终端设备向磁盘中输入作业信息\n后备状态：作业的信息全部输入完毕（输入到输入井），等待作业调度\n执行状态：被作业调度程序选中，分配资源，开始执行\n完成状态：完成全部任务，进程撤销，做善后处理\n\n他们之间的转换如图：\n\n作业调度作为用户来看：希望自己的作业运行时间短\n作为系统来看：希望各个作业的平均周转时间尽量短\n作业调度主要需要考虑两个问题：\n\n接纳多少个作业：决定从后备队列中选取多少调入内存，取决于多道程序度（即决定多少个作业在内存中执行）\n太少：资源利用率和吞吐率低\n太多：运行时内存不足发生中断次数频增，导致平均周转时间延长\n\n\n接纳哪些作业：决定从后备队列中选取哪些进入内存，取决于所采用的调度算法\n先来先服务算法：简单\n短作业优先：常用\n基于作业优先级：较常用\n响应比高者优先：比较好\n\n\n\n低级调度（进程调度）多道批处理、分时和实时系统都必须配置这级调度。\n低级调度的任务\n保存处理器的现场信息：PC、通用寄存器内容等送入PCB\n按某种算法选取进程\n把处理器分配给进程，由分派程序（Dispatcher）把处理器分配给进程\n\n对应这三个任务，进程调度就有三个基本机制\n\n上下文切换程序：负责进行现场信息的切换\n分派器：按照预订的算法，将处理器分配给该进程\n排队器：排成一个或者多个队列\n\n进程调度方式有两种方式：\n\n非抢占方式：\n一旦程序把处理机分配给该进程便让其一直运行下去，直到进程完成或发生某事件而阻塞时，才把处理机分配给另一个进程\n\n优点：早期多使用这种方式，简单，系统开销小，适用于批处理系统\n缺点：难满足紧急任务的要求，实时系统不宜采用\n\n\n抢占方式：\n按照一定的原则，将一个正在运行的进程的处理机分配给另一个进程\n\n优先权原则：优先级别高的进程优先运行\n短进程优先原则：新的短进程抢占长时间的进程\n时间片原则：各进程按照预分配的时间片轮转运行，时间片使用完后，便重新调度\n\n\n\n中级调度为了提高内存利用率和系统吞吐量，将暂时不能运行的进程调到外存等待。\n三种调度方式的比较\n\n\n调度方式\n区别\n\n\n\n作业调度\n运行频率最低，作业调度的周期较长\n\n\n进程调度\n运行频率最高，不宜太复杂，避免占用太多CPU时间\n\n\n中级调度\n介于两者之间\n\n\n调度准则面向用户的准则周转时间\n周转时间：从作业被提交开始，到作业完成为止\n\n作业的周转时间有四个部分：\n\n作业在外存后备队列的等待时间\n进程在就绪队列的等待时间\n进程在CPU上执行的时间\n等待IO操作完成的时间\n\n周转时间 = 结束时刻 - 提交时刻(到达时间) \t\t = 等待时间 + 运行时间\n\n由此可得平均周转时间为：\n\n\n注意：T是作业周转时间，n是作业个数\n可以用于：\n\n衡量不同调度算法对同一作业流的调度性能\n平均T越小，该作业调度算法性能越好\n等待时间越短，用户满意度越高\n\n主要是批处理系统需要考虑的\n带权周转时间W = T / Ts// Ts是提供服务时间， 提供服务的事件即 作业结束时间 - 作业开始时间W = Σ (Wi)／n//带权周转时间公式\n\n常用于：\n\n衡量同一调度算法对不同作业流的调度性能(长短任务差别)\n平均W越小，作业调度算法对该作业流的调度性能越好\n\n主要是批处理系统需要考虑的\n响应时间\n响应时间：从用户通过键盘提交一个请求开始，直至系统首次产生响应为止的时间。\n\n包括三部分：\n\n从键盘输入的请求信息传送到处理机的时间。\n处理机对请求信息进行处理的时间。\n响应信息回送回终端显示器的时间。 \n\n主要是实时系统中需要考虑的\n截止时间\n截止时间：某任务必须开始执行的最迟时间或必须完成的最迟时间\n\n主要是实时系统中需要考虑的\n面向系统的准则批处理、实时、分时操作系统都需要考虑的问题\n资源利用率CPU的资源利用率 = CPU有效工作时间 / (CPU有效工作时间 + CPU空闲等待时间)\n\n公平性\n对于相同类型的进程都获得相同合理的CPU时间，不同的类型按照紧要性来分配\n\n平衡性\n应使系统中的CPU及各种设备都处于忙碌状态，调度算法应该保持平衡性\n\n策略强制执行\n所制定的策略必须执行，受到延迟也要执行\n\n不同系统考虑的因素批处理操作系统\n平均周转时间T（平均带权周转时间）短\n系统吞吐量高\n吞吐量：单位时间内完成的作业树，如果单纯为了提高吞吐量，应该多选短作业执行\n\n\n处理器利用率高\n单纯是为了提高CPU的利用率，应该多选用计算量大的作业运行\n\n\n\n可以看出，这些要求之间是有矛盾的\n分时系统\n响应时间快\n均衡性\n均衡性：系统响应时间的快慢与作业的复杂性相适应\n\n\n\n实时系统\n截止时间的保证\n\n对于HRT（Hard Real-time）硬实时操作系统必须使任务在确定的时间内完成\n对于SRT（Soft Real-time）软实时操作系统能让绝大多数任务在确定时间内完成\n\n\n可预测性\n\n\n调度算法先来先服务调度算法既可以用于作业调度，也可以用于进程调度\n\nFCFS（First Come First Server）：\n​        系统按照先后顺序对作业或是进程进行排序，对于先进入后备队列或是就绪队列的作业或进程优先\n\n例如：\n\n我们由公式可以知道\n\n服务时间 = 结束时间 - 开始时间\n周转时间 = 结束时间 - 提交时间\n带权周转时间 = 周转时间 - 服务时间\n\n由此运算出各个值，我们发现，对于C来说，只需要运行1，但是却等待了100，对于同类型的调度算法，我们看W，发现C与D的差别非常大，对于与C是非常吃亏的\n再看一个正常情况下的表：\n\n对于E来说是非常不公平的\n结论：\n\n有利于长作业或进程\n有利于CPU繁忙型作业，不利于IO繁忙型的作业\n\n短作业（进程）优先算法既可以用于作业调度，也可以用于进程调度\n看到FCFS调度算法非常不利于短作业，所以推出了短作业优先算法\n\n短作业优先算法（SJF或SPF）：服务时间短的作业或进程优先选择\n\n例如：\n\n我们看到：\n\n除了第一个到达的作业外，都是按照服务时间短的先选的\n\n结论：\n\n适用：进程调度、作业调度\n优点：易于实现，效率比较高，降低作业的平均等待时间。\n缺点：\n只照顾短作业而不考虑长作业的利益，长作业长时间等待而“饿死”。      \n未考虑作业的紧迫程度\n需要预知作业的运行时间，估计执行时间不足，算法无法真正实现\n人机无法交互\n\n\n\n高优先权优先调度算法既可以用于作业调度，也可以用于进程调度\n\nHPF（Highest Priority First）：抢占式，静态优先级算法\n​        总是把处理机分配给就绪队列中具有最高优先权的进程\n\n分类：\n\n非抢占式优先权调度算法：适用于批处理系统\n抢占式优先权调度算法：适用于分时系统和实时系统\n\n优先权的类型：\n\n静态优先权：在创建时就已经确定\n依据：进程类型、用户需求等等\n优点：开销小\n缺点：不精确\n\n\n动态优先权：创建时创立一个优先权，优先数可以动态改变\n优点：精确\n缺点：开销大\n\n\n\n抢占式优先算法：\n\n从到达时间0开始，P1先运行，在时间为2时，优先权更大的P2（本题数字越小优先权越大），开始运行，直到所有的进程运行完毕\n我们可以计算出：周转时间 = 结束时间 - 提交时间\n\nP1：15 - 0 = 15\nP2：10 - 2 = 8\nP3：16 - 4 = 12（注意是结束时间-提交时间）\nP4：9 - 5 = 4\n平均周转时间 ：(15+8+12+4) / 4 = 39 / 4 = 9.75\n\n高响应比优先调度算法\nHRP（Highest Response Priority）：非抢占式，动态优先级算法\n​        优先选取响应比值最大的作业。即兼顾等待时间长和运行时间短的作业，它是FCFS和SJF算法的结合。克服了饥饿状态，兼顾了长作业。\n\n\n响应比：指作业的响应时间与作业估计运行时间的比值\n​        响应比 = 响应时间 / 要求服务时间\n​                    = (等待时间 + 要求服务时间) / 要求服务时间\n​                    = 1+ 等待时间 / 要求服务时间\n\n例如：\n\n​    由于算法是非抢占式的，所以当A到达时，B还没到达，所以A到执行完都不用考虑其他进程，对于B也一样，直到B运行完毕后，发现CDE都到达，所以此时要动态计算优先级——响应比：\n\nC ： 等待时间9 - 4，服务时间4，所以响应比为( (9-4)+4 ) / 4 =2.25 \nD：响应比( (9-6)+5)/5 = 1.6\nE：响应比((9-8) + 2)/2 = 1.5\n\n此时，发现C的优先级最高，所以优先运行C，在C运行完毕后，重新运算DE的优先级，再进行运行。\n总结：\n\n当等待时间相同时，要求服务时间短的进程会优先运行，此时类似于SPF\n当要求服务时间一样时，等待时间长的进程会优先运行，此时类似于FCFS算法\n等待时间越长，优先级会增加\n\n基于时间片的轮转调度算法（RR）分时系统中，为了满足系统对响应时间的要求，通常采用时间片轮转调度算法。\n简单轮转法\n​        把所有就绪进程按先后顺序（FCFS）形成一个就绪队列，就绪队列中的所有进程按时间片依次轮流获得处理机\n\n\n关键在于时间片的大小的选择：\n\n时间片很小，利于短作业执行，但是频繁的发生中断与进程上下文转换\n时间片太长，退化为FCFS算法\n时间片略大于一次典型的交互所需要的时间，可使大多数进程在一个时间片内完成。\n根据进程要求系统给出应答的时间（T）和进入系统的进程数（N）来决定：时间片大小q = T / N\n\n\n\n\t有五个任务A,  B,  C,  D,   E，它们几乎同时先后到达，预计它们运行时间为10，6，2，4，8min，采用时间片轮转算法，令时间片为2min，计算其平均进程周转时间。（进程切换可不考虑）解：5个任务轮流执行的情况为：         第1轮  (A,   B,    C,   D,    E)           第2轮  (A,   B,   D,    E)         第3轮  (A,   B,   E)         第4轮  (A,   E)         第5轮  (A)               平均周转时间 T=(30+22+6+16+28)/5=20.4min\n\n\n\n优点：\n\n简单、方便\n\n缺点：\n\n由于采用固定时间片的方式，调度欠灵活。\n服务质量不够理想。\n\n改进：\n\n将固定时间片方式改为可变时间片方式\n\n 固定周期轮转法: 每一轮调度中所得的时间片q值的大小仅在这一轮调度中有效。系统的响应时间T固定，在每一轮调度中，根据当前就绪队列中的进程数n计算这一轮调度\n 时间片的大小取决于优先级的高低，优先级高的进程分得的时间片较大，优先级低的进程分得的时间片较小。 \n短作业的时间片较小，长作业的时间片较大\n\n\n将单就绪队列改为多就绪队列。 \n\n\n多级反馈队列算法前面的算法都需要知道进程的长度，如果未知进程需要服务的时间，那么都将无法使用，多级反馈队列算法可以不用事先知道进程的长度\n示意图：\n\n特点：\n\n有多个队列，每个队列内使用FCFS算法，队列之间的优先级不同\n从第一个队列到最后一个队列时间片逐渐增加，如果一个进程在一个时间片内未完成，那么它将被分配到下一个队列的队尾\n最后一个队列使用简单轮转法\n\n","categories":["操作系统"],"tags":["操作系统","处理器调度","进程调度","作业调度"]},{"title":"x86 CPU工作的三种模式","url":"/2021/10/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/x86CPU%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/","content":"\n    引言：X86CPU工作的三种模式，十分硬核！啃了整整两天\n\n\n\n\nx86 CPU工作的三种模式\nx86 CPU有三种工作模式：实模式、保护模式、长模式\n\n内容硬核，涉及到很多OS的知识，如有错误，请通知我！\n实模式实模式概念\n实模式：实地址模式\n\n他有两个特点：\n\n运行真实的指令（即任何指令都可以直接执行）\n执行的内存地址是实际的物理内存地址\n\n实模式下的寄存器\n寄存器此处简单罗列一下，这里涉及到很多汇编的知识，先混个眼熟，之后用到了，我会细说\n\n寄存器按类型分为三种：通用寄存器、控制寄存器、段寄存器\n\n通用寄存器：（分三类）\n\n数据寄存器：AX、BX、CX、DX\n指针寄存器：SP、BP\n变址寄存器：SI、DI\n\n\n控制寄存器：IP（IP与PC是一个意思）、FLAGS\n\n段寄存器：CS、DS、ES、SS\n\n\n注意：实模式下的段寄存器存放内存段的基地址\n取指令\n取指令涉及到的关键寄存器：CS 与 IP\n\n\nCS：代码段寄存器\nIP：IP就是PC，指向下一个指令的地址\n\n（注意：涉及到代码段寄存器与普通寄存器的操作，都需要将段寄存器左移4位，然后与IP寄存器的值相加）\n\n\n为什么要设计为段寄存器左移4位，然后与IP寄存器相加这种形式呢？\n\n​        因为当时硬件设计者，设计了20条地址线，但是一个寄存器是16位的，一个寄存器是不能遍历2^16的地址，所以需要左移4位2^16&lt;&lt;4就能访问到所有的地址了\n（离谱，为什么硬件设计者要这么搞？难为软件工程师）\n访问内存数据实模式下的中断\n中断也是一块大的知识点，可以看此篇补充\n\n不同的书籍对于中断的具体描述不太一样，这里给出一种理解方式（CSAPP是另一种方式）\n中断的分类中断分为软件中断与硬件中断：\n\n软件中断：比如系统调用，指系统内部出现的调用\n硬件中断：（根据产生的原因，分为内外中断）\n内中断：指CPU内部出现的中断信号，比如除零、缺页等\n外中断：指外部IO设备发到CPU的中断信号，比如键盘输入\n可屏蔽异常（CPU可以不予理会，继续执行）\n不可屏蔽异常\n\n\n\n\n\n\n中断的处理过程首先我们先搞清几个问题：\n\n1、如何让CPU执行我们需要的程序？\n\n​        CPU会执行CS+IP（或称为PC）对应的指令，想让CPU执行我们需要的指令，只需要设置CS+IP指向我们编写的程序即可\n\n2、如何处理中断？\n\n其实很简单：注意两件事情即可\n\n处理中断：让CPU执行中断处理程序即可（即让CS+IP为中断处理程序）\n\n（中断处理程序是我们编写的一段处理各种中断的代码，对于不同的中断，我们需要有不同的解决办法）\n\n处理中断之前：如果处理完成中断，我们还要返回当前处理的指令位置，所以我们需要保存一下当前的CS与IP\n\n\n3、如何找到中断处理程序？\n\n设计了以下结构：\n\n中断号：表示不同的中断（其实代表了偏移地址）\n中断表（IDT，Interrupt Descriptor Table）：存放不同中断处理程序的入口地址（一个表目由两个字节组成，段地址与偏移（如下图））\nIDTR寄存器（IDTR）：记录中断表的起始地址与长度\n\n\n4、索引的具体过程（重点，细品）\n\n\n收到中断信号，取中断类型码：其来源可能是CPU内部、也可能是IO设备发来的\n内部的中断：CPU内部可以直接得到中断号；\n外部的中断：那么数据总线会传入其中断号；\n\n\n保存当前的CPU状态（比如FLAGS寄存器）\n保存当前的CS、IP（将CS、IP入栈即可）\n通过IDTR寄存器+中断号去查中断表\n设置CS为代码段基地址，IP为代码段内偏移\n执行对应CS+IP的程序\n执行完成后，出栈，再返回执行原来的指令\n\n\n保护模式实模式存在的问题设想如此的一段代码：\nint main()&#123;    int* addr = (int*)0;    cli(); //关中断    while(1)    &#123;        *addr = 0;        addr++;    &#125;    return 0;&#125;\n\n它会做些什么？关闭中断，进入死循环，不停的将内存地址置零\n简单来说，这段程序清空了内存，实模式下竟然可以运行这样的代码，显然是不合理的，因此提出了保护模式\n\n\n实模式下存在的问题有：\n\n\n使用16位的寄存器，寻址范围小\n任何指令都可以执行\n可以访问任何内存地址\n\n\n因此保护模式要实现：\n\n\n扩展寻址范围（扩展寄存器位数）\n区分的执行指令（特权级）\n限制可以访问的内存范围（段描述符）\n\n保护模式的寄存器\n为了解决寻址范围小的问题，将16位寄存器改为了32位寄存器\n\n（名字直接加了个E表示32位，注意：没有扩展段寄存器）\n\n通用寄存器：（分三类）\n\n数据寄存器：EAX、EBX、ECX、EDX\n指针寄存器：ESP、EBP\n变址寄存器：ESI、EDI\n\n\n控制寄存器：\n\n扩展为32位：EIP、EFLAGS\n新加入：CR0、CR1、CR2、CR3（也是32位，控制CPU的功能控制特性，比如开启保护模式就用到CR0寄存器等等）\n\n\n段寄存器（注意：没有扩展段寄存器，因此仍然是16位的）：\n\n原有：CS、DS、ES、SS\n新加入：FS、GS\n\n\n\n注意：保护模式下的段寄存器虽然位数没有变化，但是存放的内容由一个简单的基地址，转变为内存段的描述符索引\n特权级\n为了实现区分的执行指令，CPU实现了特权级\n\n总共分为4中权级别，从R0-R3，权利依次降低，他们的权利范围如图：\n\n\n可以用两位表示这四个权级\n00 R001 R110 R211 R3\n\n因此，越小表示权利越大\n（注意：Linux系统只实现了R0与R3，即内核态与用户态）\n段描述符\n为了限制内存的访问范围，设置了段描述符\n\n注意：目前我们仍然是分段模型\n\n什么是段描述符？\n\n段描述符：即描述一个段的有关信息\n\n段描述符存放在什么地方？\n\n存放在内存中。\n（由于CPU扩展，所以此时的段基地址与段内偏移第一世故32位，但是段寄存器没有扩展，因此，只能将信息存放在内存中）\n\n段描述符的结构如下：\n\n\n重点要注意DPL（Descriptor Privilege Level），实现了特权级，之后会细说\n\n我标记了一下位数，可以看出来，段描述符的布局很乱（历史原因）\n\n\n\n全局段描述符表\n很多段描述符就构成了段描述符表\n\n​        访问时，根据GDTR寄存器（类似于IDTR寄存器）结合代码段寄存器，找到段描述符，然后根据段描述符再去找对应的段\n如图：\n\n注意：这个过程中代码段不是简简单单的存放偏移（或者说不是简单存放段描述符的索引，而是存放段选择子）\n段选择子代码段不是简单的存储一个段描述符的偏移，其也是一个复杂的结构，如图\n\n\n影子寄存器：arm架构有的一个硬件部分，是一个段描述符的高速缓存，可以减少性能损耗（其对程序员不可见，因此无需特别了解）\n\n段描述符索引：占了13位\n\n为什么段描述符只占了13位？这样能存下偏移吗？\n\n​        本来应该就是16位，但是由于八字节对齐，所以最低三位均为000，所以最低三位可以用来做其他事情，这里就用2位表示RPL，1位表示TI\n\nRPL（Request Privilege Level）：注意这个结构，之后会详细介绍\n\n\nRPL、DPL、CPL进行权限校验经过上面，我们知道：\n段描述符内有DPL，段寄存器的段选择子有RPL\n在CS与SS中的RPL就组成了CPL（Current Privilege Level），而一般情况下，这两个值是相同的（RPL = CPL）\n\n【重点】因此 CPL 就表示发起访问者要以什么权限去访问目标段\n\n当 CPL &gt; DPL ：CPU 禁止访问\n\n当 CPL &lt;= DPL：可以访问。\n\n\n\n总结：\n使用当前的存放在CS、SS中的RPL作为CPL，与将要操作的段的DPL进行比较；\n小于等于表明当前权力大，可以访问；\n大于说明权利不足，禁止访问；\n平坦模式\n为什么要使用平坦模型？\n\n\n分段模型有缺陷：\n注意，现在我们还是处于分段模式，这个模式有很多缺陷，所以现在基本都在使用分页模型\n\n\n但是硬件规定：x86 CPU 并不能直接使用分页模型，而是要在分段模型的前提下，根据需要决定是否要开启分页\n因此设计了平坦模型\n\n什么是平坦模型？\n\n一句话：平坦模型是将全部的4GB内存整体作为一个大段来处理，而不是分成小的区块\n这种模型下：\n\n所有段都是4GB\n段基址都是0x0000 0000\n段长度都是0xffff ffff\n依然存在着段接线和数据访问的检查（但不会产生违例的情况，因为所有段的基址和长度都一样，可以访问任意地方）\n\n\n如何实现平坦模型？\n\n\n设置基地址为0，设置段长度为0xfffff（因为段长度只有20bit位，所以只有5个f）\n\n设置粒度为4kb，即设置G=1\n\n\n这样，就实现了平坦模型\n\n此处例子：\nGDT_START:knull_dsc: dq 0;第一个段描述符CPU硬件规定必须为0kcode_dsc: dq 0x00cf9e000000ffff;0x00cf9e000000ffff相当于：;1、段基地址=0，段长度=0xfffff;2、G=1,D/B=1,L=0,AVL=0 ;3、P=1,DPL=0,S=1;4、T=1,C=1,R=1,A=0kdata_dsc: dq 0x00cf92000000ffff;0x00cf92000000ffff相当于：;1、段基地址=0，段长度=0xfffff;2、G=1,D/B=1,L=0,AVL=0 ;3、P=1,DPL=0,S=1;4、T=0,C=0,R=1,A=0GDT_END:GDT_PTR:GDTLEN  dw GDT_END-GDT_START-1GDTBASE  dd GDT_START\n\n可见，这段代码中kcode_dsc与kdata_dsc两个段的起始地址与段长度都相同\n且均设G=1代表段长度的粒度为4KB，均设DPL为R0级别才可以访问\n（可以结合前面段描述符的图来看）\n保护模式的中断\n与实模式的中断处理的区别？中断门\n\n保护模式提出了特权级及其切换，所以需要检查特权，因此有了新的结构中断门描述符（中断门）\n\n中断门的结构：类似于段描述符\n\n\n\n中断向量表条目换成中断门\n\n\n\n处理中断的步骤【重点】\n\n\n收到中断信号，取中断类型码：其来源可能是CPU内部、也可能是IO设备发来的\n内部的中断：CPU内部可以直接得到中断号；\n外部的中断：那么数据总线会传入其中断号；\n\n\n保存当前的CPU状态（比如FLAGS寄存器）\n保存当前的CS、EIP（将CS、IP入栈即可）\n通过IDTR寄存器+中断号去查中断表\n【新】检查中断号是否超过范围（即大于最后一个中断门，x86允许256个中断源）\n【新】检查描述符类型（是中断门还是陷阱门、是否是系统描述符、是否在内存中）\n【新】检查中断门描述符中的段选择子指向的段描述（即找到中断处理程序）\n【新，重点】权限检查：如果CPL&lt;=中断门DPL &amp;&amp; CPL &gt;=中断门段选择子DPL就设置CS为代码段基地址，EIP为代码段内偏移\n执行对应CS+EIP的程序（这里还涉及到通过GDTR寄存器，再去查GDT全局段描述符表，然后再找对应的段）\n执行完成后，出栈，再返回执行原来的指令\n\n\n以上是我的理解方式，下面放一个不错的理解，建议结合食用：\n保护模式中断发生步骤：\n\n中断发生后，根据中断号码，对比cpu IDTR寄存器指示的中断门描述符表，找出中断对应的中断门描述符表 \n中断门描述符表中，找出中断门对应的DPL判断权限， 目标代码偏移地址，目标代码段选择子。\n根据目标代码段选择子中的段描述符索引，查找GDTR寄存器（指向全局段描述符表）指示的全局段描述符表，找出择子指向目标代码的段描述符，目标代码段RPL（进行权限判断）\n 根据段描述符，找出对应的中断程序代码段地址。\n根据以上步骤将目标代码段地址及偏移地址 装载到CS:EIP 寄存器 其中权限对比\ncpl &gt;=中断段选择符DPL，保证中断服务处理程序权限大于触发中断的应用程序，禁止中断调用用户程序，防止恶意用户程序，而又不妨碍用户态和内核态产生中断； \ncpl&lt;= 中断门描述符DPL ，确保应用程序有足够的权限引起中断，防止用户态程序调用特殊中断。\n\n\n\n\n权限检查为什么要CPL&lt;=中断门DPL &amp;&amp; CPL &gt;=中断门段选择子DPL？\n\n\nCPL&lt;=中断门DPL：只有权比门大，才能让门打开（确保应用程序有足够的权限引起中断，防止用户态程序调用特殊中断）\nCPL &gt;=中断门段选择子DPL：表示引起中断的程序的权利不能比中断处理程序的权利大（防止恶意用户程序，而又不妨碍用户态和内核态产生中断）\n\n实模式切换到保护模式总共需要4步：\n\n准备全局描述符表GDT\nGDT_START:knull_dsc: dq 0kcode_dsc: dq 0x00cf9e000000ffff ;记得设置开启平坦模式kdata_dsc: dq 0x00cf92000000ffff ;记得设置开启平坦模式GDT_END:GDT_PTR:GDTLEN  dw GDT_END-GDT_START-1GDTBASE  dd GDT_START\n设置GDTR寄存器，指向GDT\nlgdt [GDT_PTR]\n设置CR0寄存器（开启保护模式）\n;开启 PEmov eax, cr0bts eax, 0   ;CR0.PE =1mov cr0, eax ;CR0的最低位为\n\nbts指令的意思是bit test and set 位测试并设置，在此处的作用是：判断eax与0，若eax == 0：bts会将CF = 1，并将eax置位（置位的意思就是设置为1）\n\n进行长跳转\njmp dword 0x8 :_32bits_mode ;_32bits_mode为32位代码标号即段偏移\n\n此刻，我们的OS就进入了保护模式！\n\n\n为什么要进行长跳转？\n\n​        因为我们无法直接或间接 mov 一个数据到 CS 寄存器中，因为刚刚开启保护模式时，CS 的影子寄存器（影子寄存器是硬件，程序员没办法设置）还是实模式下的值，所以需要告诉 CPU 加载新的段信息\n\n为什么要设置为0x8?\n\n段描述符索引    TI(第三位) CPL(最后两位)0000 0000 0000 1000\n\n\n即表示以R0的权限访问0x1的值（即GDT第一个描述符）\n长模式\n长模式，又名 AMD64 模式，最早由 AMD 公司制定\n\n为什么要进入长模式在保护模式中，我们的位数32位，这显然不能满足我们的使用（尤其是今日，你在用多大的内存呢）\n所以长模式，就进行了进一步的扩展，长模式在保护模式的基础上，把寄存器扩展到 64 位同时增加了一些寄存器\n使 CPU 具有了能处理 64 位数据和寻址 64 位的内存地址空间的能力\n长模式的段描述符长模式的段描述符去掉了段基址、段长度、Type内的一些字段\n\n注意：\n\nG无效了\nL可以设置为是否为64位模式（数据段无效）\n段长度和段基址都是无效的填充为 0，CPU 不做检查\n\n长模式的中断门描述符扩展到64位，使用高32位存储代码段偏移的高位，其他内容与保护模式相同\n\n切换到长模式切换到长模式可以从实模式直接切换，也可以从保护模式切换\n\n准备全局描述符\nex64_GDT:null_dsc:  dq 0;第一个段描述符CPU硬件规定必须为0c64_dsc:dq 0x0020980000000000  ;64位代码段d64_dsc:dq 0x0000920000000000  ;64位数据段eGdtLen   equ $ - null_dsc  ;GDT长度eGdtPtr:dw eGdtLen - 1  ;GDT界限     dq ex64_GDT\n准备MMU（内存管理单元）页表（长模式必须开启分页，长模式下内存地址空间的保护交给了 MMU）\nmov eax, cr4bts eax, 5   ;CR4.PAE = 1mov cr4, eax ;开启 PAEmov eax, PAGE_TLB_BADR ;页表物理地址mov cr3, eax\n加载 GDTR 寄存器，使之指向全局段描述表\nlgdt [eGdtPtr]\n开启长模式，要同时开启保护模式和分页模式\n（此处还涉及到MSR寄存器，rdmsr、wrmsr是操作msr寄存器专门的指令，IA32_EFER寄存器的第八位决定是否开启长模式）\n;开启 64位长模式mov ecx, IA32_EFERrdmsrbts eax, 8  ;IA32_EFER.LME =1wrmsr;开启 保护模式和分页模式mov eax, cr0bts eax, 0    ;CR0.PE =1bts eax, 31mov cr0, eax \n跳转，加载CS段寄存器，刷新影子寄存器\njmp 08:entry64 ;entry64为程序标号即64位偏移地址\n\n长模式总结结构方面：扩展到64位，增加了寄存器\n长模式的改变：弱化段模式管理，只保留了权限级别的检查，忽略了段基址和段长度，而地址的检查则交给了 MMU\n参考资料\n《CSAPP》\n《汇编语言》王爽著\n极客时间《操作系统实战45讲》\n《x86汇编语言 从实模式到保护模式》\n\n","categories":["操作系统"],"tags":["操作系统","CPU","实模式","保护模式","长模式","中断"]},{"title":"设备管理","url":"/2020/12/31/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/","content":"\n  新年到来了！！今年的最后一篇博客 \n  引言：操作系统中的设备是如何管理的？\n\n\n\n\n设备管理外部设备本节主要讨论外部设备：\n\n外部设备：除CPU与主存外的设备\n特点：\n\n多、杂、乱\nIO速度慢\n\n\n设备的分类：\n\n按所属关系分类：\n系统设备（操作系统生成时已登记于系统中的标准设备。如键盘、打印机、磁盘等）\n用户设备（如绘图机、扫描仪）\n\n\n按设备使用特性分类：\n存储设备\n输入输出设备\n\n\n按传输速率分类\n低速设备：键盘、鼠标\n中速设备：打印机\n高速设备：磁带机、磁盘机、光盘机\n\n\n按信息交换方式分类\n块设备（主存和外设之间的信息交换是以块为单位（一块通常是512字节~4K个字节）进行的设备：磁盘、磁带）\n字符设备（主存与设备之间的信息交换是以字符为单位进行的设备：键盘、显示器）\n\n\n从资源分配角度分类\n独占设备：一般是低速设备\n共享设备\n虚拟设备（为提高设备的利用率，通过Spooling技术把独占设备改造为共享设备，用来模拟独占设备的那部分共享设备称为虚拟设备）\n\n\n\n设备管理的功能功能：\n\n隐藏物理设备的细节\n外部设备多、乱，这些细节不能让用户感受到\n\n\n与设备的无关性\n用户可以用抽象命令控制设备，例如read write可以读写不同的设备\n\n\n提高CPU与IO设备的利用率\n对IO设备进行控制\n有四种控制方式\n轮询\n中断\nDMA\n通道\n\n\n\n\n确保对设备的正确共享\nSPOOLing技术\n\n\n错误处理\n持久性错误：必须向上层报告\n临时性错误：可以重试解决\n\n\n\nI/O系统的层次结构I/O软件组织：\n\n硬件\n中断处理程序（负责IO完成时唤醒设备，发起中断）\n设备驱动程序（设置设备寄存器，检查寄存器状态）\n设备独立性软件（映射、保护、分块、缓冲）\n用户层IO软件\n\nIO系统本身也可分为三层：\n\n中断处理程序\n设备驱动程序\n设备独立性软件\n\n设备控制器一个设备控制器可以控制多个硬件设备\n设备与设备控制器的关系：用三条线管理设备：\n\n数据信号线\n状态信号线\n控制信号线\n\n注意他们的方向\n\n设备管理器的结构与功能设备管理器的结构：三部分组成：\n\n与CPU的接口\n与设备的接口\nIO逻辑\n\n\nIO逻辑用来控制设备：\n\n控制线与处理器交互，发送IO命令、译码\n地址信号去选择一个设备接口\n\n控制寄存器：存放CPU发来的指令\n状态寄存器：存放设备现在的状态信息\n设备管理器的功能：\n接收和识别命令\n设置控制寄存器接收CPU的命令和参数，译码\n\n进行数据交换\n\n\n标识和报告设备的状态：设置状态寄存器记录设备状态\n\n地址识别：设置地址译码器识别所控制的每个设备的地址\n\n数据缓冲：设置缓冲器缓解IO设备与CPU的速度差异\n\n差错控制\n\n\n中断技术\n中断：CPU对IO设备发来的中断信号的一种响应（外中断）\n陷入（内中断）：由CPU内部所引起的中断\n他们俩的区别主要是中断的来源不同\n\n中断事件的类型\n强迫性中断事件\n硬件故障中断（停电、读写错误）\n程序性中断（数据溢出）\n外部中断（键盘输入命令）\n输入输出中断（外部设备故障）\n\n\n自愿性中断事件（运行进程所需要的）\n访管中断（执行一条“访管指令”请求系统调用）\n\n\n\n\n访管指令（陷入指令）：\n​        当运行的用户进程或系统实用进程欲请求操作系统内核为其服务时，可以安排执行一条陷入指令引起一次特殊异常。用户态请求内核态服务\n\n中断向量表通常会为每一个设备配一个中断处理程序，并且每一个设备的中断请求申请一个中断号\n然后把这个中断处理程序的入口地址存放在中断向量表中对应的中断号表项下\n当IO设备发来中断信号，中断控制器就通过收到中断号去中断向量表中查询中断处理程序的入口地址，进而处理中断\n中断响应\n CPU收到中断请求后转相应的中断处理程序的过程称为中断响应\n\nCPU在收到中断后：\n\n发现和识别中断事件：硬件设有中断装置发现和识别中断事件\n交换PSW（FLAG寄存器）\n中断码存入PSW寄存器的中断码位\n将旧PSW存到主存\n将新PSW送入PSW寄存器\n\n\n\n中断处理的原则\n强迫性中断事件\n硬件故障中断：输出事件性质\n程序性中断（数据溢出）：输出进程名、程序断点\n外部中断（键盘输入命令）：接收外部请求转例子程序\n输入输出中断（外部设备故障）\n正常情况释放等待进程\n异常情况告知信息错误\n\n\n\n\n自愿性中断事件（运行进程所需要的）\n访管中断：根据访管指令功能号转对应的系统调用\n\n\n\n中断优先级硬件故障中断＞自愿性中断＞程序性中断＞外部中断＞输入输出中断\n中断屏蔽对于多中断源，一般有两种处理方式：\n\n屏蔽中断：屏蔽所有中断\n嵌套中断：\n优先响应高优先级的中断\n高优先级中断抢占低优先级中断\n\n\n\n中断处理过程\n测定是否有未响应的中断\n保存现场信息\n通常由硬件自动保存现场信息，保存在处理机状态字PSW和程序计数器PC中\n\n\n转到中断处理程序\n通过收到的中断号查询中断向量表得到中断程序的入口地址\n\n\n中断处理\n根据中断处理原则进行处理\n\n\n恢复CPU现场\n退出中断或者处理下一个中断\n取决于选择的中断屏蔽方式：是屏蔽中断还是嵌套中断\n\n\n\n设备驱动程序设备驱动程序\n\n负责IO进程与设备控制器之间的通信：\n​        接收上层软件发来的抽象I/O要求，如read、write命令，在把它转换为具体要求后，发送给设备控制器，启动设备去执行。由设备控制器发来的信号传送给上层软件。\n\n功能\n将设备独立软件发来的抽象命令转换为具体命令\n检查用户I/O请求的合法性，了解I/O设备的状态，传递有关参数，设置设备的工作方式\n发出I/O命令（如空闲，则启动I/O，完成指定的I/O 操作，阻塞驱动程序）\n及时响应中断请求，并唤醒（设备发出中断后会被阻塞），根据其中断类型调用相应的中断处理程序进行处理\n根据用户的I/O请求，自动构成通道程序\n\n功能分为两大块：\n\n启动IO设备功能\n设备中断处理程序\n\n特点属于低级的系统例程，与一般的应用程序及系统程序有以下区别：\n\nIO进程与设备控制器的一个桥梁\n与硬件紧密相关，甚至一部分必须使用汇编语言编写\n允许可重入（一次调用完可能会被再次调用）\n不允许系统调用\n\n设备处理方式有三种不同的设备处理方式：\n\n为每一类设备设置一个IO进程\n整个系统设置一个IO进程\n不专门设立设备处理进程，只为各类设备设置设备驱动程序\n\n设备独立性软件设备独立性：用户在编制程序时使用的设备与实际使用的设备无关，用户程序中使用的是逻辑设备\n即我们使用一台设备，如打印机，我们不会管是什么打印机，惠普打印机还是联想打印机，设备独立性软件就负责把我们使用的逻辑设备变为物理设备\n实现了I/O重定向\n\n即用于I/O操作的设备可以更换\n\n逻辑设备表LUT（Logic Unit Table）\n一张联系逻辑设备名称和物理设备名称的映射表，实现逻辑设备名到物理设备名映射\n\n\n\n\n逻辑设备名\n物理设备名\n驱动程序入口地址\n\n\n\n/dev/tty\n3\n1024\n\n\n/dev/printer\n5\n2046\n\n\n当进程用逻辑设备名请求分配I/O设备时，系统为它分配相应的物理设备，并在LUT上建立一个表目\nLUT的设置方式：\n\n整个系统一张LUT\n每个用户一张LUT\n\n设备独立性软件\n为了实现设备独立性，须再在驱动程序之上设置一层软件，称为设备独立性软件\n\n\n实现所有设备都需要的功能，向用户级软件提供接口\n映射设备名\n设备保护：系统防止无权存取设备的用户存取设备\n掩盖底层有差异性质，提供无差别的服务\n缓冲技术\n\nIO控制方式四种IO控制方式：\n\n使用轮询的可编程IO方式\n使用中断的可编程IO方式\n直接存储器DMA方式\nIO通道控制方式\n\n使用轮询的可编程IO方式CPU必须重复测试外设的状态\n\n缺点：\n\nCPU利用率低\n设备不能并行工作\n不支持多道程序\n\n\n中断驱动IO控制方式：每当设备完成I／O操作时，便向CPU发出中断请求信号\n\n优点：\n解放了CPU\n使设备与CPU可以并行操作\n\n\n缺点：\n如果传送一个数据都要中断一次，那么会大大的降低CPU的处理速度\n\n\n\n直接存储器访问DMA\n特点：\n设备与主存直接传送数据\n需要DMA控制器\n传输的基本单位是数据块\n仅在传输数据的开始与结束需要CPU干预\n\n\nDMA控制器的结构：\n与主机的接口\n与设备的接口\nIO逻辑\n而且必须实现四类寄存器：\n命令/状态寄存器CR\n内存地址寄存器MAR\n数据寄存器DR\n数据计数器DC\n\n\n\n\n缺点：\n传输的方向、数据长度、内存地址都需要CPU控制\n每台设备都配置DMA的话，成本太高\n\n\n\nI/O通道控制方式\n通道：专门负责I／O控制的处理机\n它接收CPU的委托，独立地执行自己的通道程序，管理和控制输入输出操作，实现主存贮器与外围设备之间的成批数据传送。\n\n通道程序：由通道指令构成的程序\n每条指令包含以下信息：\n\n操作码：表示本次执行读还是写操作\n内存地址：操作的地址\n计数：本次操作的字节数\n通道程序结束位P：表示通道程序是否结束，P=1表示本指令是本通道程序最后一条指令\n记录结束标志R：R=0表示本通道指令与下一条指令所处理的数据是同一个记录；R=1表示是处理本记录的最后一条指令\n\n例如：下表中列出的是一段简单的通道程序（内含6条指令），在下面的各个选项中叙述不正确的是（     ）\n\n\n\n操作\nP\nR\n计数\n内存地址\n\n\n\nWRITE\n0\n1\n90\n743\n\n\nWRITE\n0\n1\n100\n250\n\n\nREAD\n0\n1\n230\n1200\n\n\nWRITE\n0\n0\n120\n400\n\n\nWRITE\n0\n1\n120\n350\n\n\nREAD\n1\n1\n70\n2000\n\n\nA 该段通道程序包括6条、2类通道指令。\nB 这些指令涉及的数据内存地址有相邻接的地方。\nC 该段通道程序共处理了5条记录。\nD 单记录最大为230个字节。\n解：我们可以这么看：\nA：P=1代表本通道程序结束；数一数有6条，有WRITE与READ两类指令\nB：例如第五行与第六行\nC、D：\nR=1代表这是该数据的最后一条记录所以可以看出：\n​        第一行属于一个记录、第二行属于一个记录、第三行属于一个记录、第四五行属于一个记录，第六行属于一个记录\n所以选D，最大应该是240字节\n\n特点\n彻底解放CPU\n每次传输一组数据块\n\n\n通道与一般处理机的区别：\n指令类型单一，简单，仅限于IO操作\n通道没有自己的内存\n\n\n通道的瓶颈：\n由于通道成本高，所以通道数量很少，通道不足容易造成瓶颈现象\n可以使用多通路方式解决瓶颈问题\n\n\n类型：\n字节多路通道（以字节为单位传输，连接大量慢速设备）\n数组选择通道（每次选择一台高速设备，执行一个通道程序）\n数组多路通道（分时轮转同时控制多台设备）\n\n\n\n\n\n设备分配为了防止进程无序争夺资源，系统必须对资源进行统一分配\n设备分配所需的数据结构\n设备控制表DCT（记录设备特性，每个设备一张）\n系统设备表SDT（记录系统中所有设备的情况，整个系统一张）\n控制器控制表COCT（每个控制器一张）\n通道控制表CHCT（每个通道一张）\n\n分配策略考虑不同的设备有不同的分配原则：\n按三种设备分类：\n\n独占设备\n共享设备\n虚拟设备\n\n独占性设备设备分配给某作业后便由该作业独占，直到该作业完成并释放\n\n静态分配：进程运行前分配\n缺点：设备利用率低\n\n\n动态分配：运行过程中进程提出请求再给予分配\n优点：效率高\n缺点：可能会发生死锁\n\n\n\n共享设备可以同时分配给多个进程同时访问，但是要注意对进程访问设备的先后次序进行合理的调度\n虚拟设备虚拟设备属于可共享设备，可以同时分配给多个进程使用\n分配算法\n先来先服务\n优先权高者优先\n\n分配的安全性\n安全分配方式\n特点：进程发出IO请求便阻塞，直到请求完成被唤醒\n缺点：进程推进缓慢，不能并行工作\n\n\n不安全分配方式\n特点：进程发出I/O请求后仍继续运行，需要时又发出第二个I/O请求、第三个I／O请求。仅当进程所请求的设备己被另一进程占用时，进程才进入阻塞状态\n优点：一个进程可操作多个设备，且可以并行工作\n缺点：分配不安全，可能导致死锁\n解决方法：使用银行家算法\n\n\n\n独占设备的分配过程进程请求IO设备后：\n\n根据进程请求的逻辑名，查LUT表\n获得物理设备名，查SDT，找DCT\n找到该设备的COCT与CHCT\n\n整个过程：分配设备-&gt;分配控制器-&gt;分配通道\n用户层IO软件系统调用与库函数\n系统调用：\n\n不允许运行在用户态的应用程序直接去调用运行核心态的OS进程\n某些应用进程必须取得OS进程提供的服务\n\n为了解决这两点的矛盾，引入了系统调用\n系统调用是应用程序获得OS所有服务的唯一途径\n\n小部分用户IO软件是由与用户程序连接在一起的库过程，甚至完全由运行于内核外的程序构成\n用户层软件必须通过一组系统调用来取得操作系统服务，通常由库过程实现\n注意这里的库过程：只是将系统调用时所用的参数放在合适的位置，由其它的I/O过程实际实现真正的操作\nSPOOLing技术脱机输入、输出技术为了缓和CPU的高速性与IO设备的低速矛盾\n\n脱机输入输出：即在外围控制机控制下实现低速的IO设备与高速的磁盘之间进行数据传送\n\n外围机作用下输入和输出可以与主机并行\nSPOOLing技术\nSPOOLing技术（假脱机技术）：多道程序下，使用一个程序来模拟外围控制机，实现将数据从磁盘传送到低速的输出设备上，再模拟一台外围控制机，来实现输入，从而在主机的直接控制下，实现脱机输入与脱机输出\n\n可以将一项将独占设备改造成为共享设备的技术\nSPOOLing技术的组成：\n\n使用大容量磁盘来实现输入井与输出井（模拟脱机输入输出的磁盘）\n\n使用内存来实现输入输出缓冲区\n\n输入进程：将用户输入的数据通过缓冲区送到输入井，当CPU需要输入数据时，直接从输入井读入内存\n\n输出进程：将输出的数据先送出到输出井，待设备空闲时，将输出井数据经过输出缓冲区送到输出设备\n\n井管理程序：控制用户进程和磁盘井之间交换信息\n\n\n现象：一个资源转换技术，用空间（输入输出井）换取CPU的时间\n实质：利用系统中的外存空间（磁盘）代替独占型的设备，以便模拟出一些物理上不存在的设备供用户使用\n例如：假若进程打开打印机特殊文件后几小时内无所事事，其他进程什么都打印不了，那么我们可以使用SPOOLing技术来共享打印机！\n\n输出进程在输出井申请一块空闲区，将要打印的数据输入\n\n输出进程为用户建立一张IO请求表，将表挂到请求打印队列上\n\n如果有打印机空闲，输出进程从请求打印队列的队首取出一张请求打印表，根据表中的要求将要打印的数据\n\n输出进程是唯一获准使用打印机特殊文件的进程，用以打印请求打印队列中的文件。\n\n\n特点：\n\n提高了IO速度\n对低速I/O设备进行的I/O操作变为对输入井或输出井的操作\n\n\n设备并没有分配给任何进程\n在输入井或输出井中，分配给进程的是一存储区和建立一张I/O请求表\n\n\n实现了虚拟设备功能\n多个进程同时使用一独占设备，而对每一进程而言，都认为自己独占这一设备，不过，该设备是逻辑上的设备\n\n\n\n缓冲技术为什么要引入缓冲技术？\n改善CPU速度与IO设备速度不匹配的问题\n减少中断CPU的次数\n减少占用通道的时间\n\n实现思想\n​        当一个进程执行写操作输出数据时，先向系统申请一个主存区域——缓冲区，然后，将数据高速送到缓冲区。若为顺序写请求，则不断把数据填到缓冲区，直到它被装满为止。此后，进程可以继续它的计算，同时，系统将缓冲区内容写到I/O设备上。\n\n缓冲的类型\n硬缓冲：寄存器\n软缓冲：在主存中开辟一片区域充当缓冲区，并设置IO指针\n\n根据系统设置缓存区的数目可以分为：\n\n单缓冲\n双缓冲\n循环缓冲\n缓冲池\n\n\n单缓冲T表示把数据从磁盘输入到缓冲区的输入时间，M表示将数据传送到用户区的时间，C表示处理器的计算时间\n系统对每一块数据的处理时间：Max(C , T) + M\n双缓冲系统对每一块数据的处理时间：Max(C , T)\n循环缓冲R表示空缓冲区\nG表示缓冲区已满\n有三个指针：\n\nnexti：表示下次可用的空缓冲区\nnextg：表示计算进程下一个使用的缓冲区\ncurrent：表示计算进程当前使用缓冲区\n\n\n使用以下两个过程来使用循环缓冲：\n\nGetBuf过程：获得缓冲区\nReleasebuf过程：释放缓冲区\n\n同步问题：\n\nnexti追上nextg指针：表示系统受计算限制\nnextg追上nexti指针：系统受I/O限制\n\n总结：资源共享技术\n虚拟存储器\n以CPU时间和外存空间换取昂贵内存空间。\n\n缓冲技术\n以内存空间来换取CPU与I/O设备速度上匹配。\n\nSPOOLING技术\n利用系统中的外存空间代替独占型的设备，模拟出一些物理上不存在的设备供用户使用，以解决独占设备资源不足，不能满足用户的使用请求和制约系统运行的瓶颈问题\n\n\n磁盘存储器的性能与调度磁盘存储器的性能和调度\n为文件分配存储空间\n合理地组织文件的存储方式，以提高访问速度\n提高磁盘存储空间地利用率\n提高磁盘I/O速度，改善文件性能\n确保文件系统的可靠性（备份）\n\n磁盘的类型\n固定头磁盘：每条磁道一个读写磁头（用于大容量磁盘上）\n\n移动头磁盘：每个盘面一个读写磁头（应用于中小型磁盘设备中）\n\n\n磁盘访问时间\n寻道时间：指把磁臂(磁头)移动到指定磁道上所经历的时间\n\nTs = m*n +s\n\nm常数，与磁盘驱动器速度有关\nn表示第几条磁道\ns表示启动磁臂的时间\n\n旋转延迟时间Tr：指定扇区移动到磁头下面所经历的时间\n\n不同的磁盘类型中，旋转速度至少相差一个数量级，如软盘为300 r/min，硬盘一般为7200～15 000 r/min，甚至更高\n\n传输时间：把数据从磁盘读出或向磁盘写入数据所经历的时间\n\nTt = b / rN\n\nb表示：每次读写的字节数\nr表示：旋转速度\nN表示一条磁道上的字节数\n可访问时间Ta表示为\nTa = Ts+ 1/2r + b/rN可访问时间 = 寻道时间 + 旋转延迟 + 传输时间\n\n\n\n磁盘调度算法考虑的就是使得平均寻道时间最短\n例如：假定磁盘有200个磁道，当前有9个访问者（进程）先后提出I/O操作，需要访问的磁道分别为：55，58，39，18，90，160，150，38，184；又假定当前磁头位置为100\n先来先服务/先进先出优点：公平\n缺点：未考虑优化寻道，有大量进程访问者竞争一个磁盘，则这种算法的性能接近于随机调度\n\n最短寻道时间优先（SSTF）\n选择使磁头臂从当前位置开始移动距离最短的I/O访问者\n\n缺点：每次选择距离最短者同时，忽略了可能由于不断的有新的I/O请求进程加入到队列中，且与当前磁头位置较近，会使得原请求队列中的距离远的访问者总也得不到调度，产生所谓“饥饿”现象\n\n扫描算法SCAN\n考虑了两个方面的问题：\n\n方向\n与当前磁道号距离最短\n\n作先由内向外运动，再由外向内运动，或反之。这样就避免了饥饿现象。\n由于这种算法使得磁臂移动规律颇似电梯的运动，因而也称为电梯算法。\n\n\n缺点：\n会导致某些请求会被延迟读写\n循环扫描算法CSCAN\n为了减少这种延迟，**规定磁头单向读/写运动(如只由内向外)，完成读写后立即返到最小/大磁道号的位置(构成循环)**，再进行扫描。即CSCAN算法\n\n\n","categories":["操作系统"],"tags":["操作系统","设备管理","Spooling技术","通道","寻道算法"]},{"title":"HTTP协议","url":"/2020/03/17/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/http%E5%8D%8F%E8%AE%AE/","content":"\n引言：\nHTTP协议（已更新：加了总结部分，方便复习，直接看正题，减少废话）\n\n\n\n\nHTTP知识点总结这里总结所有HTTP知识点\n\nHTTP是一个半双工协议（通信双方只能有一人说话）\nHTTP不需要连接（虽然底层TCP需要连接）\nHTTP无状态\nHTTP端口80；HTTPS端口443\nHTTP请求报文由请求行、请求头、请求空行、请求体组成\n请求行组成：请求方法 URL HTTP版本（例如GET www.baidu.com HTTP/1.1）\n重要的请求头字段：Referer防盗链、Cookie、Connection请求完成后是否断开\nGET与POST区别：是否可见、是否有请求体、是否有长度限制、是否幂等、是否安全（幂等：无论调用几次结果都一样；安全：请求不会破坏服务器资源）GET幂等安全、POST不幂等不安全\nHTTP响应报文由响应行、响应头、响应空行、响应体组成（如HTTP/1.1 200 ok）\n重要的状态码：1xx中间状态需后续操作、200一切正常、301资源永久重定向、302资源临时重定向（会将POST转化为GET）、307与302相同（但不会转变为GET）、403禁止访问、404资源找不到、5xx服务器端错误\n重要的响应头字段：Set-Cookie提醒浏览器设置Cookie、Connecion、Location要跳转到哪个网页\nHTTP1.0缺点：非持续连接（每次都会断开）、每次只能发送一个请求，等待响应后才能发第二个；队头阻塞（一个Http阻塞会阻塞之后的所有请求）、明文传输、不会检查身份、无法检验信息是否完整、请求/响应头没有压缩\nHTTP1.1改进：持续连接、管道网络传输（可以发完一个再发一个，是按序接收请求的，即没有优先级）、加入Cookie（解决无状态）；仍存在的问题：明文传输、请求/响应头没有压缩、队头阻塞、没有优先级控制\nHTTPS：加了SSL/TSL（传输层安全协议）\nHTTPS：通过三个手段解决HTTP明文传输问题：混合加密（解决不安全）、摘要算法（解决信息不完整）、数字证书\n对称加密：使用相同秘钥进行加密；不对称加密：各自持有私钥加密\nHTTPS采用的加密方式：通信建立前用不对称加密（安全）、通信中用对称加密（速度快）\n摘要算法：用摘要算法算明文的指纹（指纹：即明文的一部分信息）来校验完整性\n数字证书CA：第三方机构，存放公钥\nHTTPS建立过程：首先客户端访问服务器；服务器返回数字证书；客户端检查数字证书合法性并提取出公钥；使用公钥加密后发送给服务器；服务器使用私钥解密，提取指纹；之后一直使用指纹加密；\nHTTP2.0优化：头部压缩（HPACK算法）、传输二进制格式、不按顺序发送（客户端发出的编号为奇数、服务器端发出的编号为偶数）、解决了队头阻塞（并发的进行响应）、服务器开始可以向客户端发送消息\nHPACK算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，以提高速度\n服务器推送：在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，减少延时的等待\nHTTP2.0缺点：HTTP2.0多请求复用一个TCP连接，如果丢包会阻塞所有的HTTP请求（使用TCP的短板）\nHTTP3.0：使用UDP协议作为底层，用QUIC协议保证可靠\nQUIC协议：解决了UDP不可靠的缺点\n\n前言最近在复习Servlet的过程中，突然感觉自己的HTTP协议忘光光了，于是就写了这篇，参考了很多大牛的博客以及《计算机网络 自顶向下方法》这本书\n如遇错误，纯属正常，望请指正\n\n前置知识再开始学习HTTP之前，我们需要几个前置的知识，来保证之后我们之后的学习不会出了问题\n计算机网络体系结构众所周知，ISO提出了7层模型，但是这只是理论上的，实际上，我们平常所使用的是5层结构：（从底层到最上层）\n\n物理层\n数据链路层\n网络层\n传输层\n应用层\n\n例如我们这篇博客要学习的HTTP就是应用层的一层协议，同是应用层的还有DNS（一个解析域名的协议，并不是我们今天的重点，不过后面会提到，先混个脸熟）\n而TCP协议就是传输层的\n网络层有IP协议\n通信分类\n单工协议：单向传输：例如电视机、广播\n双工协议：双向传播\n半双工：同一时刻只能有单向通信，如对讲机\n全双工：允许双方通信，如手机通话\n\n\n\nTCP运输层的一个协议，当你使用浏览器访问百度时，他们之间会首先的建立起一个TCP连接，TCP连接是通过三次握手和四次挥手来建立连接和失去连接的，TCP是一个全双工的协议，TCP很重要，但不是今天的主角\n\n其他的就先不聊了，我们正式开始学习HTTP\nHTTP为什么要学习HTTP当你使用一个浏览器，去访问百度时，百度的服务器就会给你响应，他们之间是通过HTTP协议来交流的\n我们要写一个项目，进行前后端的交接，当你的电脑访问它的电脑时，也是通过HTTP协议来交流的\nHTTP是什么HTTP (HyperText Transfer Protocol)超文本 传输 协议，我们从三个名词来了解HTTP\n\n什么是协议？\n一种规范，人与人之间的约定就叫协议，同样计算机之间的约定就叫协议。\nHTTP是一个半双工，意味着同时只能有一方说话。\nHTTP是应用层的一层协议，应用层是计算机网络体系结构的最高层，意味着，这一层可以不去管底层是怎么控制的，底层可以进行更换，这一点我们之后会更加深入的去谈。\n\n什么是传输？\n传输字面意思从A点到B点运输，在HTTP中我们要求的A点和B点，分别是客户端和服务器\n\n什么是超文本？\n不仅仅局限于文字，图片、视频、音乐、压缩包等等都是超文本\n\n\nHTTP定义很简单，首先我们要有两个端（客户端+服务器），其次就是他们之间通过HTTP报文进行会话，满足这两个要求就是HTTP，浏览器就是实现了HTTP的客户端，假设我们要连接一个服务器，现在我们就只差HTTP报文来交流了\nHTTP报文HTTP请求报文由这么四个部分组成：\n\n请求行：方法 URL 版本 \n请求头（首部行）：字段 值\n请求空行：一个空行\n请求体（实体体）\n\n\n方法有哪几种？\n\nGET： 用于请求访问已经被URI（统一资源标识符）识别的资源，可以通过URL传参给服务器\nPOST：用于传输信息给服务器，主要功能与GET方法类似，但一般推荐使用POST方式。\nPUT： 传输文件，报文主体中包含文件内容，保存到对应URI位置。\nHEAD： 获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效。\nDELETE：删除文件，与PUT方法相反，删除对应URI位置的文件。\nOPTIONS：查询相应URI支持的HTTP方法。\n\n在这里我们要注意几个地方：\n\n首先GET方法虽然是一个获取资源的方法，尽管他没有请求体（或者说它的实体体为空），但他依然可以传输数据，经常网络冲浪的你可能会见到www.abc.com/getstudent?stu=1，机智的GET方法依靠这样的方式机智的传了数据，但是这样的方法有两个缺点：\n请求行的内容大小有限，通常限制在几k（不同的浏览器和服务器的限制会不同）\n请求的参数裸奔。。。\n\n\n最主要的方法有GET和PUT，由于REST ful，PUT和DELETE也开始用了起来。\n有些刁钻的面试官会问，GET和POST哪个是幂等的？哪个是安全的？我们丝毫不慌，和他说，GET是幂等和安全的，POST不幂等也不安全（幂等：无论调用几次，结果都一样；安全：请求不会破坏服务器资源）\n\n请求头的字段和值有哪些？\n\nAccept: text/html,image/*   【浏览器告诉服务器，它支持的数据类型】\nAccept-Charset: ISO-8859-1    【浏览器告诉服务器，它支持哪种字符集】\nAccept-Encoding: gzip,compress     【浏览器告诉服务器，它支持的压缩格式】\nAccept-Language: en-us,zh-cn 【浏览器告诉服务器，它的语言环境】\nHost: www.yesyourhighness.github.io 【浏览器告诉服务器，它的想访问哪台主机】\nIf-Modified-Since: Tue, 11 Jul 2000 18:23:51 GMT【浏览器告诉服务器，缓存数据的时间】\nReferer: http://www.yesyourhighness.github.io 【浏览器告诉服务器，客户机是从那个页面来的—反盗链】\nUser-Agent: Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0)【浏览器告诉服务器，浏览器的内核是什么】\nCookie【浏览器告诉服务器，带来的Cookie是什么】\nConnection: close/Keep-Alive 【浏览器告诉服务器，请求完后是断开链接还是保持链接】\nDate: Tue, 11 Jul 2000 18:23:51 GMT【浏览器告诉服务器，请求的时间】\n\n这么多，好慌啊，怎么办呢？\n我把几个重要的标记了一下，其他的先混个脸熟，以后真见到了再看看也不迟\n\n响应报文由这么几个部分组成\n\n响应行：版本 状态码 描述 \n响应头（首部行）：字段 值\n空行：一个空行\n响应体（实体体）\n\n状态码的值有哪些？\n\n1xx  提示信息，表示目前是中间状态还需要后续的操作    \n2xx  成功信息\n200 OK 一切正常，而且非HEAD请求会有body数据\n204 No Content 成功，响应头没有body参数，即服务器没有新数据返回，页面不刷新\n206 Partial Content 分块下载或断电续传，表示返回的body只是一部分\n\n\n3xx 重定向，资源位置变动，需要客户端重新请求\n301 Moved Permanently 请求的资源已分配了新的URI中，URL地址改变了。【永久重定向】\n302 Found 请求的资源临时分配了新的URI中，URL地址没变【转发】会把POST请求变成GET\n303 See other 与302相同的功能，但明确客户端应该采用GET方式来获取资源    \n304 Not Modified 发送了附带请求，但不符合条件【返回未过期的缓存数据】    \n307 Temporary Redirect 与302相同，但不会把POST请求变成GET\n\n\n4xx  客户端错误，请求有误\n400 Bad Request 客户端请求的报文有错误 ，是一个笼统的状态码\n401 Unauthorized  需要认证身份\n403 Forbidden  没有访问权限，服务器禁止访问资源\n404 Not Found  请求的资源在服务器上不存在或未找到\n\n\n5xx  服务器错误，服务器处理出现错误\n500 Internal Server Error 服务器发生错误，笼统状态码\n501 Not Implemented 客户端请求的功能目前还不支持，类似即将开业的意思\n502 Bad Gateway 服务器作为网关或代理返回的错误码\n503 Service Unavailable 服务器当前正忙，暂时无法响应\n505 HTTP Veision Not Surported 服务器不支持请求报文所使用的HTTP协议版本\n\n\n\n响应头的字段和值有哪些？\n\nLocation: http://www.yesyourhighness.github.io 【服务器告诉浏览器要跳转到哪个页面】\nServer:apache tomcat【服务器告诉浏览器，服务器的型号是什么】\nContent-Encoding: gzip 【服务器告诉浏览器数据压缩的格式】\nContent-Length: 80 【服务器告诉浏览器回送数据的长度】\nContent-Language: zh-cn 【服务器告诉浏览器，服务器的语言环境】\nContent-Type: text/html; charset=GB2312 【服务器告诉浏览器，回送数据的类型】\nRefresh: 1;url=http://www.it315.org【服务器告诉浏览器要定时刷新】\nContent-Disposition: attachment; filename=aaa.zip【服务器告诉浏览器以下载方式打开数据】\nTransfer-Encoding: chunked  【服务器告诉浏览器数据以分块方式回送】\nSet-Cookie:SS=Q0=5Lb_nQ; path=/search【服务器告诉浏览器要保存Cookie】\nCache-Control: no-cache      【服务器告诉浏览器不要设置缓存】\nPragma: no-cache       【服务器告诉浏览器不要设置缓存】\nConnection: close/Keep-Alive   【服务器告诉浏览器连接方式】\nDate: Tue, 11 Jul 2000 18:23:51 GMT【服务器告诉浏览器回送数据的时间】\nLast-Modified: Tue, 11 Jul 2000 18:23:51 GMT【服务器告诉浏览器该资源上次更新时间】\n\n除了几个重要的我标记了之外，其他的我们都可以见了再查\n\n现在，知道了请求头和响应体，我们就可以开始调戏百度了，哈哈哈\n（这里我使用的是我的小破服务器，没有服务器可以用Linux的虚拟机）\n我输入：telnet www.baidu.com 80返回给我：Trying 220.181.38.150...\t\tConnected to www.baidu.com.\t\tEscape character is &#x27;^]&#x27;.我再输入：GET /index.html HTTP/1.1\n\n大方的百度给我返回了一大堆，不要急，我们看最前面的东西\nHTTP/1.1 200 OKAccept-Ranges: bytesCache-Control: no-cacheConnection: keep-aliveContent-Length: 14615Content-Type: text/html。。。。省略一大堆&lt;百度的html页面&gt;。。。。&lt;/百度的html页面&gt;\n\n百度响应给我们信息，状态码是喜闻乐见的200，开心\n好了这样我们无情的就调戏了一波百度，走人，程序员的生活就是这么平凡且枯燥\nHTTP(1.0)特性非持续连接如果你是一个程序研制者，你需要使用TCP来完成HTTP报文的传输，那么你会有两种选择\n\n每个请求/响应对使用一个单独的TCP连接发送，这样的程序称为非持续连接\n所有的请求/响应对使用同一个TCP连接发送，这样的程序称为持续连接\n\nHTTP(1.0)是非持续连接的，这意味着服务器每次响应发送的响应体中只能包含一个对象的信息\n假设服务器上有一个HTML资源和十张图片，现在我们要获取这样的资源，我们需要连接几次TCP呢？\n11次（一个html和十张图片），每次我们都要经历TCP的建立和断开\n笨拙的发送请求我们每次只能发送一个请求，只有等待第一个请求响应之后，我们才可以发送第二个请求\n队头阻塞不仅笨，而且假如有一个HTTP请求阻塞，那么他之后的请求都会阻塞\n\n无状态\n兵无常势，水无常形  ——孙武《孙子兵法》\n\nHTTP是一个无状态的协议（stateless protocol），什么是无状态呢？即HTTP没有记忆，或者说服务器不会存储任何关于该用户的信息。\n比如说刚刚我们调戏了百度，但是它根本不会记得我们。。。（是不是该难受）\n这里把它也算做了一个缺点，无状态当然也不是没有好处，由于无状态，服务器的负担就没有那么严重，可以说无状态是把双刃剑吧\n优点\n简单方便\n灵活：由于是应用层协议，它的下层可以任意变化\n应用广泛\n\n缺点明文传输没错，明文传输。肉眼可见，信息裸奔，容易被窃听\nHTTP不会验证身份HTTP建立在双方相信的基础上，他不会去检查你的信息\n不知道是否完整我们无法验证信息的完整性，别人监听了我们的信息，他可以篡改\nHTTP(1.1)提升时代在发展，社会在进步，HTTP也不是一成不变的，HTTP迎来了1.1时代\n持续连接我们上面说到，HTTP是一个非持续连接，这样在请求数据时，我们会经历很多次不必要的TCP建立和断开，于是1.1版本我们变成了持续连接，这样的好处就是，大大提高了传输效率\n请求头内我们有一个字段Connection:Keep-Alive，就是告诉服务器，和我建立连接之后，不要着急断开\n管道网络传输现在我们发送请求，无需等待响应就可以发出第二个\n注意：我们尽管能够发送多个请求而无需等待响应，但是我们的请求是按着顺序来的，服务器会依次响应我们的请求，这意味着，如果其中一个响应出现丢包或是延迟，之后的响应依然会阻塞\nHTTP1.1希望使用此技术解决队头阻塞，但是并没有解决的很完全\n此外，因为接受响应需要按顺序，所以很少浏览器实际使用了这个技术，反而是使用其他一些操作来提高速度：\n\n精灵图：把多个小图标组合起来，作为一个图片发送\nDataURLs：将图片等资源嵌入到文档中作为文字发送，就无需额外请求图片了，比如base64\n域名分片：1.1的串行发送限制是针对域来说的，如果域不同就可以达到并行下载，比如我们有五张图片，给每一个图片设置一个域名，比如image1.img.com、image2.img.com等等，就可以实现并行下载资源（一个比较极端的例子，实际中没有这么夸张）\n\n\n\nDataURLs是一种用于在URL中包含数据的特殊方案。它允许将小型数据嵌入到文档中，而无需单独请求服务器获取数据。\n\nDataURLs的数据格式：\ndata:[&lt;mediatype&gt;][;base64],&lt;data&gt;// &lt;mediatype&gt;表示数据的媒体类型，例如image/png、text/plain等// ;base64 表示数据使用Base64编码// &lt;data&gt; 表示实际的数据内容\n\n优点：减少对服务器的请求，提高页面加载速度，并且适用于一些临时或小规模的数据嵌入需求\n缺点：数据直接嵌入在URL中，会导致URL过长和重复传输相同的数据，增加了页面的大小\nCookie上面我们说我们虽然调戏了百度，但是百度忘记了我们，但其实他是记得我们的。\nCookie是什么？\nCookie是曲奇饼的意思。\n哦不，Cookie是为了解决HTTP无状态的技术\n当我们第一次访问服务器时，服务器看见我们没有带曲奇饼，他就会给我们一个曲奇饼，告诉我们的浏览器，“诶呀，下次来的时候记住带上曲奇饼”，响应完我们的数据之后，他会把对象和曲奇饼一起给我们\n之后，当我们再一次访问服务器时，我们通过曲奇饼，服务器就可以认识我们，“啊，原来是你小子”\n\nCookie技术总共包含四个组件：\n\n响应报文有一个cookie\n请求报文中有一个cookie\n浏览器保存了一个cookie\n后端数据库中也有一个cookie\n\nHTTP1.1已解决的问题\n持续连接的问题\n支持管道网络传输\n\nHTTP1.1仍存在的问题\n请求 / 响应头部（Header）未经压缩就发送，头部信息越多延迟越大。只能压缩 Body 的部分；\n发送冗长的头部。每次互相发送相同的首部造成的浪费较多；\n服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；\n没有请求优先级控制；\n请求只能从客户端开始，服务器只能被动响应\n依然是明文传输，易篡改、窃听、冒充\n\n\nHTTP的缺点还有这么多，但是科技总是会进步的！\n一次完整的HTTP过程我们在浏览器输入 http://www.baidu.com/index.htmlDNS服务将域名转换为主机名\nHTTP客户进程发起一个到服务器www.baidu.com的TCP连接请求（包含四个字段：源IP，源端口，目的IP，目的端口），TCP连接就要经过三次握手\n建立连接后，客户端将HTTP报文发送给服务器端，服务器端OS接收后，将按不同的端口号划分数据给进程（这里就是80端口）。\n服务器端接收到后，分析url，这里即/index.html，在自己的内存中寻找index.html，在寻找到后，将HTML文件封装到响应体中，立马向客户端发送响应报文\n浏览器接收到响应报文之后，根据响应回的Connection字段信息，决定是否关闭TCP连接。如果字段值为close的话，那么开始四次挥手；如果字段值为Keep-Alive的话，那么在发送完html之后依然保持连接状态。\n浏览器根据响应体来进行显示\nHTTPS时代在发展，科技在进步，HTTPS给HTTP的安全性带来了保障\nHTTPS（Hyper Text Transfer Protocol over SecureSocket Layer），明显的字眼SSL\nHTTPS就是在TCP的上层加了SSL（或者是TLS），HTTP的默认端口是80，HTTPS默认端口是443\n\nSSL（Secure Sockets Layer）安全套接层和TLS（Transport Layer Security）传输层安全协议其实是一套东西。\n网景公司在1994年提出HTTPS协议时，使用的是SSL进行加密。后来IETF（Internet Engineering Task Force）互联网工程任务组将SSL进一步标准化，于1999年公布第一版TLS协议文件TLS 1.0。目前最新版的TLS协议是TLS 1.3，于2018年公布。\n\nHTTPS加入了SSL来解决HTTP不安全的问题，主要通过三个手段：\n\n混合加密\n摘要算法\n数字证书\n\n\n混合加密首先我们先了解一下对称加密，和非对称加密\n\n\n对称加密：采用单钥密码系统的加密方法，同一个秘钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单秘钥加密。对称秘钥使用一个秘钥，速度快，但是秘钥必须共享给对方，在这个过程中容易受到攻击\n\n非对称加密：即浏览器和客户端各自持有私钥，不必交换秘钥，安全，但是速度较慢\n\n\n\nHTTPS采用两种办法混合使用的方式：\n\n通信建立前：采用非对称秘钥加密的方式交换会话秘钥，后续就不再使用非对称加密\n通信过程中：全部使用对称加密来加密明文数据\n\n摘要算法客户端在发送明文之前，通过摘要算法算出明文的指纹\n\n指纹：一般地，把对一个信息的摘要称为该消息的指纹或数字签名\n\n发送的时候将明文加指纹一同加密为密文后，一同发送给服务器\n服务器解密后，用相同的摘要算法算出发送过来的明文，通过对比自己得出的指纹和发送过来的指纹做对比，如果比较相同，说明数据是完整的\n数字证书借助第三方权威机构CA（数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构发布），只要证书是可信的，公钥就是可信的。（可信是可信，但是要小钱钱。。。）\n\nSSL/TLS协议建立的过程\n下面是一个旧版的流程，我发现写的有点乱且复杂，所以只看上图即可\n\n\n首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。主要发送的信息       （1）客户端支持的 `SSL/TLS` 协议版本，如 TLS 1.2 版本。\n       （2）客户端生产的**随机数**（Client Random），后面用于生产「会话秘钥」。\n       （3）客户端支持的密码套件列表，如 RSA 加密算法。\n\n\n服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。回应       （1）确认 `SSL/ TLS` 协议版本，如果浏览器不支持，则关闭加密通信。\n       （2）服务器生产的**随机数**（Server Random），后面用于生产「会话秘钥」。\n       （3）确认的密码套件列表，如 RSA 加密算法。\n       （4）**服务器的数字证书**。\n\n\n客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文       发送：\n           （1）一个**随机数**（pre-master key）。该随机数会被服务器**公钥加密**\n           （2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信\n           （3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验\n\n\n服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。\n\n\nHTTP终于解决了不安全的问题，但是他的问题还有很多：\n\n请求 / 响应头部（Header）未经压缩就发送，头部信息越多延迟越大。只能压缩 Body 的部分；\n发送冗长的头部。每次互相发送相同的首部造成的浪费较多；\n服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；\n没有请求优先级控制；\n请求只能从客户端开始，服务器只能被动响应\n\nHTTP2HTTP2优化\n\n头部压缩，如果同时发出的多个请求请求头相同，则会消除重复的部分这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。\n\nHTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式。头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。\n\nHTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。\n\n每个请求或回应的所有数据包，称为一个数据流（Stream）。\n\n每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数        \n\n客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求。\n\n\n\nHTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。\n\n报文含有流标识符，这样解决无序响应的问题\n\n\n服务不再是被动地响应，也可以主动向客户端发送消息。在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。\n\n\n结构如下：\n\nHTTP2缺点​    多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。\n我们发现一个问题（盲生，你发现了华点）：        \n\nHTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了\nHTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。        \n\n归结原因，这是使用TCP协议的弊端\n所以HTTP3直接干掉了TCP，这就是为什么我们说HTTP协议是一个应用层的高层协议，因为它可以灵活的选择底层的结构\nHTTP3HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP\n\n\nUDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。\n大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。    \nQUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。\nTL3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack。\nHTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。\n\n\n\nQUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。\n小结本文从基础的网络知识谈起，从HTTP1.0，谈到了HTTP3.0，\n谈到了他们各自的优点缺点，每一步的发展，每一次出现的错误\n感慨良多，HTTP的发展就像是人类不断探索的过程，发现问题到解决问题，解决问题到又发现问题，值得思考很多很多很多\n参考资料\n《计算机网络 自顶向下方法》\n公众号 小林coding\n 公众号 Java3y\n 敖丙\n\n","categories":["计算机网络","应用层","HTTP"],"tags":["计算机网络","应用层","HTTP"]},{"title":"卷积神经网络CNN","url":"/2022/10/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/PyTorch%E5%AE%9E%E8%B7%B5/","content":"\n引言：卷积神经网络 CNN\n\n\n\n\n\n相关资料：\n\nb站 刘二大人\n\n基本的CNN数据准备以MINST数据为例，搭建CNN并进行测试。\nMINST：入门级的CV数据库，内容全为手写的阿拉伯数字，包含了6w张训练集图片+1w张测试集图片\nimport torchfrom torchvision import transforms # 数据原始处理from torchvision import datasets # datasets包含了MINST数据集from torch.utils.data import DataLoader # 分批量载入数据import torch.nn.functional as F # 激活函数import torch.optim as optim # 优化器\n\n梯度下降存在的问题梯度下降 知乎Link\n\nBatch梯度下降 BGD——遍历所有数据，计算损失函数，计算梯度，更新梯度\n\n计算量大，收敛速度慢，训练的模型一般\n\n随机梯度下降 SGD ——每次从训练集中随机选择一个样本，计算其对应的损失和梯度，进行参数更新，反复迭代\n\n收敛速度比batch还要慢，还遇到鞍点问题；但是训练的模型好。\n\n鞍点saddle point 问题：目标函数在此点的梯度为0，但从该点出发的一个方向存在函数极大值点，而另一个方向是函数的极小值点，在高度非凸空间中，存在大量的鞍点，这使得梯度下降法有时会失灵，虽然不是极小值，但是看起来确是收敛的。 \n\n\n注意：鞍点和局部最优解 local minima不同\n\ncritical point：包括local minima局部最优解 和 saddle point鞍点\n\n\n如何鉴别是鞍点还是局部最优点？\n是否可以逃离：可以逃离的是鞍点，逃不掉的是局部最优解\n这部分可以看这个视频bilibili link：\n根据hessian判断\n\nHessian的所有特征值均大于0：local minima\nHessian的所有特征值均小于0： max minima\nHessian的特征值有时候大于0，有时候小于0：saddle point\n\n\n\n综合两者DataLoader——MINI-Batch\n\n使用MINI-Batch时要使用一个嵌套的循环：\nfor epoch in range(train_epochs):    for i in range(total_batch):        # 每次执行一个MINI-Batch\n\n\n三个重要的概念：：\n\nEpoch：所有样本都经过一个前馈+反馈，就叫一个Epoch\nBatch-size：一个前向+反向所用的样本的数量\nIteration：前+反的次数\n\n\n显然有：Epoch = Batch-size * Iteration\n载入数据的过程在DataSet准备好样本数据后，会经过一个Shuffle过程，将样本数据打乱\n在这之后，在进行分批，每一批就是一个Batch\n\n数据预处理这里关于transform做一个API介绍：这一部分的官方Link\n\nCompose()：将多个转换操作组合在一起\n\nToTensor()：将一个pillow图片或是ndarray转换为一个张量（即将0-255转为0-1）\n\nNormalize：用均值 mean和标准差 std归一化一个浮点张量图像（这个操作只能操作torch的tensor）\n\n参数mean：每个通道的均值序列\n参数std：每个通道的标准差序列\n计算公式：image = (image - mean)/std\n\n\n\nbatch_size = 64# 前部分：将数据从原本的pillow（python处理图片的库）格式转为tensor，即将0-255转为0-1# 后半部分：将每个channel的数据转换为标准高斯分布，两个参数：均值mean、方差std；计算式：transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])# 这里的MIST数据集就一个通道因此只需要传一个值的序列# 没有数据会自动下载train_dataset = datasets.MNIST(root=&#x27;../dataset/mnist/&#x27;, train=True, download=True, transform=transform)train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)test_dataset = datasets.MNIST(root=&#x27;../dataset/mnist/&#x27;, train=False, download=True, transform=transform)test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n\n神经网络模型设计torch.nn官方API：，这里列几个用到的：\n\ntorch.nn.Module：所有神经网络的类的基类\n\ntorch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0...)：二维卷积\n\n参数1in_channels：输入通道\n参数2out_channels：输出通道\n参数3kernel_size：卷积核的大小\n参数4stride：步长\n参数5padding：图形填充0\n\n\ntorch.nn.MaxPool2d(kernel_size)：二维最大值池化\n\n参数kernel_size：核大小\n\n\ntorch.nn.Linear：linear unit线性单元y = xA + b\n\n参数1in_channels：输入通道\n参数2out_channels：输出通道\n参数3bias：默认为True\n\n\ntensor.view()：用来改变tensor的形状，数据不会变\n\n返回的新tensor与原tensor共享内存，意味着你改变一个，另一个也会改变\n当某一维度是-1，会自动计算这一维度的大小\n\n\n\nPyTorch固定的模板就是这样：__init__初始化卷积核、池化、全连接层，forward写神经网络的执行顺序，反馈由Module自动执行无需我们设计\n# 神经网络模型class Net(torch.nn.Module): # 继承nn.Module    def __init__(self):        super(Net, self).__init__()        # Conv2d参数：输入通道、输出通道、核的大小        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)        # 池化2*2        self.pooling = torch.nn.MaxPool2d(2)        # 全连接：输入通道，输出通道，结果为0-9数字        self.fc = torch.nn.Linear(320, 10)            def forward(self, x):        # flatten data from (n,1,28,28) to (n, 784)        batch_size = x.size(0) # 0是x大小第1个参数，自动获取batch大小        # 卷积核1-&gt;池化-&gt;激活-&gt;卷积核2-&gt;池化-&gt;激活        x = F.relu(self.pooling(self.conv1(x)))        x = F.relu(self.pooling(self.conv2(x)))        x = x.view(batch_size, -1) # -1 此处自动算出的是320        # 全连接，拉成一维        x = self.fc(x)        return x# 实例化model = Net()device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)# 如果有GPU使用gpumodel.to(device) # 将model存到显卡\n\n损失与优化# 损失函数：该准则计算输入和目标之间的交叉熵损失criterion = torch.nn.CrossEntropyLoss()# 优化器：负责训练模型，反向传播更新参数：lr是学习率optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n\n损失函数\n损失函数也是Module的子类，他负责计算损失，计算损失的算法有很多种\n\n\nMSELoss：求y与y_hat的差值平方\nCrossEntropyLoss：交叉熵\n\n\n交叉熵：它主要刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近\n\n优化器\n优化器：optim是一个实现了多个优化算法的包，直接调用即可。\n\n构造一个优化器：使用前需要创建一个优化器对象，必须传入一个module的参数对象，并可以配置学习率lr\n\nmodel.parameters()：检查model所有单元的参数，发现有权重就拿走（假如内部有一个线性单元linear unit，就会调用他的linear.parameters()方法，如果还有其他单元，回依次获取）\n\n使用：只要梯度更新（例如backward()），就可以调用优化器方法step()\n训练整个训练过程可以精炼为如下几个步骤：\n\n计算y_hat\n计算损失loss\n反馈backward()（注意：在此之前记得优化器清零zero_grad()）\n更新step()\n\n# 训练及更新def train(epoch):    running_loss = 0.0    for batch_idx, data in enumerate(train_loader, 0):# 指定从零开始        inputs, target = data        # 有GPU使用GPU        inputs, target = inputs.to(device), target.to(device)          # 计算y_hat        outputs = model(inputs)        # 前馈：计算损失        loss = criterion(outputs, target)        # 优化器清零：backward是累积的，因此在backward前记得将所有权重清0        optimizer.zero_grad()        # 反馈：计算梯度        loss.backward()        # 更新：根据梯度和学习率更新        optimizer.step()        # 求和损失        running_loss += loss.item()        # 300次计算一次平均损失        if batch_idx % 300 == 299:            print(&#x27;[%d, %5d] loss: %.3f&#x27; % (epoch+1, batch_idx+1, running_loss/300))            running_loss = 0.0\n\n预测def test():    correct = 0    total = 0    with torch.no_grad(): # 无需计算梯度        for data in test_loader:            images, labels = data            images, labels = images.to(device), labels.to(device)            # 用训练的模型测试images            outputs = model(images)            _, predicted = torch.max(outputs.data, dim=1)            total += labels.size(0)            # 计算正确率            correct += (predicted == labels).sum().item()    print(&#x27;accuracy on test set: %d %% &#x27; % (100*correct/total))\n\n高级的CNNInceptionGoogleNet是一个比较出名的CNN模型\n\nInception：对于比较复杂的结构，会有很多复用的结构，这样的结构就叫做Inception\n\n比如这样的一个Inception结构，优点是：往往并不能确定什么样的卷积核比较好，因此一个Inception就可以带多个卷积核，来比较他们之间的性能，如果其中一条线路的效果较好，那么就增大这条线的权重\n\nConcatnate会将不同通道的tensor合并在一起\n1*1的卷积核\n1*1卷积核的作用：信息融合，以便于降低运算量\n在多通道的情况下，会将每个卷积核的特征融合到一起\n（类比与学校的加权成绩）\n\n\n降低运算量：假设现在有要对192*28*28的张量进行卷积，卷积核为5*5，最后输出32*28*28：\n那么一共要5*5*32*192*28*28=120_422_400\n如果给中间加一步16个卷积1*1，那么运算量会变为1*1*28*28*192*16 + 5*5*28*28*16*32=12_433_648\n可见，降低了1/10的运算量\n代码实现\n设这四条线路分别为A、B、C、D，我们在构建模型时，构造方法就应该写以下代码：\ndef __init__(self, in_channels):    super(InceptionA, self).__init__()    # A     self.branch_pool = nn.Conv2d(in_channels, 24, kernel_size=1)# 1*1的卷积核    # B    self.branch1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)# 1*1的卷积核    # C    self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)    self.branch5x5_2 = nn.Conv2d(16, 24, kernel_size=5, padding=2)    # D    self.branch3x3_1 = nn.Conv2d(in_channels, 16, kernel_size=1)    self.branch3x3_2 = nn.Conv2d(16, 24, kernel_size=3, padding=1)    self.branch3x3_3 = nn.Conv2d(24, 24, kernel_size=3, padding=1)\n\n在初始化后，加入到forward中就可，最后的输出的通道数24*3 + 16 = 88\ndef forward(self, x):    # A    branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)# 平均池化    branch_pool = self.branch_pool(branch_pool)    # B    branch1x1 = self.branch1x1    # C    branch3x3 = self.branch3x3_1(x)    branch3x3 = self.branch3x3_2(branch3x3)     # D    branch5x5 = self.branch5x5_1(x)    branch5x5 = self.branch5x5_2(branch5x5)    # 组合    outputs = [branch1x1, branch5x5, branch3x3, branch_pool]    # cat函数会将各部分组合起来    # 一共有四个dim：b(batch)、c(channel)、w(weight)、h(height)，这里的1就代表c    return torch.cat(outputs, dim=1)\n\nRisidual Net梯度消失在训练过程中可能会遇到梯度消失的问题\n\n梯度消失：我们嵌套的多层卷积层，如果每个算出的值都是十分接近于0的数，在不断的链式乘积后，就会变得更小，导致梯度消失\n\n解决办法：\n【法一】我们可以逐个增加卷积层，去查看哪一层发生了梯度消失\n显然这种方法很麻烦\n【法二】Risidual Net 残差网络\n在基础的NN上，加一个跳连接，如图所示\n\n其中，H(x)= F(x) + x可以保证H&#39;(x) = F&#39;(x) + 1即使F&#39;(x)极小，也可以使梯度变化\n但是这种Net结构得保证经过卷积后的shape与原shape一样，因此在shape发生变化的位置，我们需要单独处理（处理方式：对x也做处理或是根本不做跳连接）\n代码实现class ResidualBlock(nn.Module):\tdef __init__(self, channels):        super (ResidualBlock, self)._init_()        self.channels = channels        # 输入和输出通道需要一样        self.convl = nn. Conv2d(channels, channels, kernel_size=3, padding=1)\t\tself.conv2 = nn. Conv2d (channels, channels, kernel_size=3, padding=1)\tdef forward(self,x):        y = F.relu(self.conv1(x))        y = self.conv2(y)        # 跳连接\t\treturn F.relu(x + y)\n\n循环神经网络RNN出现的原因有时候会遇到类似于根据上一次的数据，去预测下一次的结果的情况。\n比如天气预报，假设我们的数据温度|湿度|光照-&gt;天气，那么我们根据当天的温度和湿度去预测当天的天气是没有意义的。\n\n如何去预测明天的天气呢？\n\n可以将4行记录为一组，3行接在一起作为训练集（温度1|湿度1|光照1|温度2|湿度2|光照2|温度3|湿度3|光照3），用第四天的天气作为验证集；这样就可以使用三天的数据去预测后一天的天气了。\n\n但是这里存在一个问题，如果单个行记录的参数就很多，那么我们拼凑起来的参数会更多，这样我们在之后的卷积、全连接过程中，可能会参数爆炸\n因此为了解决“参数爆炸”的问题，提出了循环神经网络RNN\n\nRNN CellRNN适合去解决数据有序的问题：比如天气预测、比如语言类问题（我|要|去吃饭，语言也有顺序）\nRNN的结构如图所示：\n\n右图是左图的展开式，可以看到，每一次的计算都需要用到上一次的数据，而参数却还使用原来的同一层，这样可以大大减少计算所需要的参数。\n RNN cell的本质就是一个线性层，它的计算式如下：\n\n\n值得注意的是：xt和ht-1看起来做了两次线性变换，其实我们可以把两个矩阵合起来运算，因此其实就是一次线性运算\n比如w1*h + w2*x = [w1, w2]*[h, x]^T\n代码实现PyTorch中提供的对应框架有两个，可以使用RNNCell也可以直接使用RNN\n\nRNNCell\n\ncell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)# 只需要提供参数 input_size 和 hidden_size即可hidden = cell(inputs, hidden)# RNNcell只有一个输出，就是h1-hn\n\n对于inputs要注意的是，他就是输入的序列值，他有三个维度(seq_len, batch_size, input_size)\n对于hidden注意，他也有三个维度(num_layers, batch_size, hidden_size)\n\nRNN\n\ncell = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)# 还需要提供 num_layers 即隐藏层的个数，需要几层的RNNout, hidden = cell(inputs, hidden)# 使用时给inputs：所有的输入序列、hidden即h0# 输出会有两个值 out就是h1-hn；hidden就是hn\n\n比如一个三层的RNN运算时就是这样的：\n\n","categories":["深度学习"],"tags":["神经网络","PyTorch"]},{"title":"RocketMq","url":"/2024/12/29/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMq4/","content":"\n引言：应该是24年最后一篇了，学一下RocketMq\n\n\n\n\nRocketMq4.xRocket的4.x版本，与5版本的区别还是比较大的，4.x的使用更广泛一些，本文介绍4.x的基本使用方式。\n\n本文代码使用：https://github.com/yudaocode/SpringBoot-Labs/tree/master/lab-31\n文章内容参考官网4.0版本以及此篇文章\n\n初期准备mq集群需要搭建一个mq环境，基本的结构要有nameserver和一个broker，我直接使用docker-compose快速搭建：官方文档\n额外创建了一个broker.conf做卷\n# broker 对外提供服务的ip，如果是公网，则公网ip，如果本地测试，则本地机ipbrokerIP1 = 127.0.0.1# Broker 的名称1brokerName = broker-a# 在集群中对 Broker 的唯一标识。值 0 通常表示这是一个主 BrokerbrokerId = 0# 指定什么时候删除旧的提交日志。值 04 表示在每天的凌晨 4 点删除旧日志deleteWhen = 04# 指定提交日志文件的保留时间（以小时为单位）。这里的 48 意味着提交日志会保留 48 小时，然后才会被删除fileReservedTime = 48# 定义 Broker 在集群中的角色。ASYNC_MASTER 表示该 Broker 作为主 Broker，并会将消息异步复制到从 BrokerbrokerRole = ASYNC_MASTER# 定义提交日志的刷新模式。ASYNC_FLUSH 表示数据会异步刷新到磁盘，以提高性能。flushDiskType = ASYNC_FLUSH# 如果设置为 true，则启用消息属性过滤。这允许你除了通过主题和标签过滤消息外，还可以通过消息的属性进行过滤enablePropertyFilter=true# 开启自动创建主题autoCreateTopicEnable=true\n\n用到的compose文件：\nversion: &#x27;3.8&#x27;services:  namesrv:    image: apache/rocketmq:4.9.6    container_name: rmqnamesrv    ports:      - 9876:9876    networks:      - rocketmq    command: sh mqnamesrv  broker:    image: apache/rocketmq:4.9.6    container_name: rmqbroker    ports:      - 10909:10909      - 10911:10911      - 10912:10912    environment:      - NAMESRV_ADDR=rmqnamesrv:9876    volumes:      - ./broker.conf:/home/rocketmq/rocketmq-4.9.6/conf/broker.conf    depends_on:      - namesrv    networks:      - rocketmq    command: sh mqbroker -c /home/rocketmq/rocketmq-4.9.6/conf/broker.confnetworks:  rocketmq:    driver: bridge\n\n\n\nrocket-consolegithub地址，一个mq的看板，这里原本我想也跑到docker上，但是我改掉nameserver的ip也无法访问，因此就拉下来代码跑在宿主机上面了。\n\n工作流程\n\n启动NameServer，NameServer监听端口（默认为9876），等待连接\n启动Broker后，Broker会与所有的NameServer建立长连接，30s心跳一次\n建立Topic，指定该Topic的存储在哪些Broker节点（可选，可以动态指定）\nProducer/Consumer(Client)发送消息前，需要先与NameServer建立连接，获取路由信息（即Topic的queue与broker地址的映射关系，因为消息要发送到一个Topic下的某一个queue上，而queue是存放在某一个broker上的），路由信息会缓存在本地，30s更新一次\n\n\nProducer生产消息、Consumer消费消息\n\n普通消息\n 官网原文\n\n消息有三种发送方式，同步、异步和单向传输，前两种消息类型都有返回，单向传输只发送请求不等待应答\n@Autowiredprivate RocketMQTemplate rocketMQTemplate;public SendResult syncSend(Integer id) &#123;    Demo01Message message = new Demo01Message();// 一个消息类内部定义了TOPIC、ID，无需关注    message.setId(id);    // 同步发送消息，具有返回值SendResult    return rocketMQTemplate.syncSend(Demo01Message.TOPIC, message);&#125;public void asyncSend(Integer id, SendCallback callback) &#123;    Demo01Message message = new Demo01Message();    message.setId(id);    // 异步发送消息，返回值通过回调函数获取SendCallback    rocketMQTemplate.asyncSend(Demo01Message.TOPIC, message, callback);&#125;public void onewaySend(Integer id) &#123;    Demo01Message message = new Demo01Message();    message.setId(id);    // oneway 发送消息，没有返回值    rocketMQTemplate.sendOneWay(Demo01Message.TOPIC, message);&#125;\n\n\nRocketMQTemplate是官方提供的模版类，可以直接使用它发送消息。本质会创建一个 DefaultMQProducer 生产者 producer ，所以RocketMQTemplate后续的各种发送消息的方法，都是使用它。\n\n异步方式的回调函数有两个接口，分别处理成功和失败两种情况：\n\n```javanew SendCallback() {@Override\npublic void onSuccess(SendResult result) &#123;\n    logger.info(&quot;[testASyncSend][发送编号：[&#123;&#125;] 发送成功，结果为：[&#123;&#125;]]&quot;, id, result);\n&#125;\n@Override\npublic void onException(Throwable e) &#123;\n    logger.info(&quot;[testASyncSend][发送编号：[&#123;&#125;] 发送异常]]&quot;, id, e);\n&#125;\n\n}消费一般会使用监听器的方式，而且通常要确保**一个消费者分组，仅消费一个 Topic**```java@Component@RocketMQMessageListener(        topic = Demo01Message.TOPIC,        consumerGroup = &quot;demo01-consumer-group-&quot; + Demo01Message.TOPIC)public class Demo01Consumer implements RocketMQListener&lt;Demo01Message&gt; &#123;    private Logger logger = LoggerFactory.getLogger(getClass());    @Override    public void onMessage(Demo01Message message) &#123;        logger.info(&quot;[onMessage][线程编号:&#123;&#125; 消息内容：&#123;&#125;]&quot;, Thread.currentThread().getId(), message);    &#125;&#125;\n\n\n@RocketMQMessageListener注解用来标记该实例属于哪一个消费组、可以消费哪一个topic\n\n实现RocketMQListener接口，重写onMessage方法来对消息进行操作\n\n\n\n为什么要保证一个消费者分组仅消费一个 Topic？\n\n\n单一职责要求，消费者分组职责单一便于维护与理解\n每个消费者分组独占一个线程池，因此可以让多个Topic隔离在不同的线程池\n\n假设我们让同一个消费者分组消费A、B两个Topic，假设A消费的很慢，执行时间就会长，就导致影响了B的消费（因为同一个线程池去消费A、B）\n批量消息DefaultMQProducer支持批量的生产发送，RocketMQTemplate也实现了批量发送\npublic &lt;T extends Message&gt; SendResult syncSend(String destination, Collection&lt;T&gt; messages, long timeout) &#123;    // ... 省略具体代码实现&#125;\n\n批量发送要注意：\n\n一批消息的Topic需要相同\n批量消息的大小不能超过 1MiB（否则需要自行分割）\n\n聚成一批以后进行发送，可以增加吞吐率，并减少API和网络调用次数。\n批量消息与普通消息的消费是一样的。\n定时消息定时消息（延迟消息）定时消息，指的不是生产定时定点的发往broker，而是定时定点的被消费。\n只有到达要求的时间后，该消息才可以被消费。\n（rocketmq不支持任意时间精度的定时消息，固化了 18 个延迟级别，支持1s到两小时之间的大概延迟时间）\n如果要求高精度的定时消息，可以借助mysql+job，或者是使用DDMQ（单条消息设置精确到秒级的延迟时间）\n\n\n\n延迟级别\n时间\n延迟级别\n时间\n延迟级别\n时间\n\n\n\n1\n1s\n7\n3m\n13\n9m\n\n\n2\n5s\n8\n4m\n14\n10m\n\n\n3\n10s\n9\n5m\n15\n20m\n\n\n4\n30s\n10\n6m\n16\n30m\n\n\n5\n1m\n11\n7m\n17\n1h\n\n\n6\n2m\n12\n8m\n18\n2h\n\n\n生产上的特点就是需要指定延迟级别。\n// 同步rocketMQTemplate.syncSend(Demo03Message.TOPIC, message, 30 * 1000, delayLevel);// 异步rocketMQTemplate.asyncSend(Demo03Message.TOPIC, message, callback, 30 * 1000, delayLevel);\n\n消费时会在规定的级别时间后才可以被消费，比如指定了延迟级别为5，那么这条消息只有1分钟后才会被消费\n消费重试消息消费失败时，Rocketmq会有消费重试机制，重新投递消息给consumer。\n默认情况下达到16次重试次数仍然失败的话，该消息会进入死信队列（Dead-Letter Message Queue）\n\n为什么重试16次？\n\n消费重试是基于定时消息来实现，第一次重试消费按照延迟级别为3（10s）。所以，3~18共有16次。\n注意：只有集群消费模式才有消息重试。\n消息模型集群消费\n一个消费组下的消费者会平均消费一个Topic下的所有消息（这就是集群消费，有点像负载均衡）\n\n（比如1个消费组有2个消费者，那么假设同一个Topic下有10条消息，那么2两个消费者各自消费5个）\n\n订阅同一个Topic的不同消费组会得到所有消息\n\n（比如一个Topic有10个消息，有两个消费组订阅了，那么两个消费组都会得到10条消息）\n比如再创建一个demo01-A，两个消费组都会获得到 Demo01Message.TOPIC的所有消息\n@Component@RocketMQMessageListener(        topic = Demo01Message.TOPIC,    // 这里的消费组与上一个不同        consumerGroup = &quot;demo01-A-consumer-group-&quot; + Demo01Message.TOPIC)public class Demo01AConsumer implements RocketMQListener&lt;MessageExt&gt; &#123;    private Logger logger = LoggerFactory.getLogger(getClass());    @Override    public void onMessage(MessageExt message) &#123;        logger.info(&quot;[onMessage][线程编号:&#123;&#125; 消息内容：&#123;&#125;]&quot;, Thread.currentThread().getId(), message);    &#125;&#125;\n\n这种特性可以让我们对同一个结果展开多个业务，比如一个游戏升级后，A消费组可以专注于增加血量、B消费组可以专注于增加下一次升级所需的阈值等等。\n广播消费同一个消费组group下的每一个实例都会接收到全部的消息\n比如：在应用中，缓存了数据字典等配置表在内存中，可以通过广播消费，实现每个应用节点都消费消息，刷新本地内存的缓存\n@Component@RocketMQMessageListener(        topic = Demo05Message.TOPIC,        consumerGroup = &quot;demo05-consumer-group-&quot; + Demo05Message.TOPIC,        messageModel = MessageModel.BROADCASTING // 设置为广播消费)public class Demo05Consumer implements RocketMQListener&lt;Demo05Message&gt; &#123;    private Logger logger = LoggerFactory.getLogger(getClass());    @Override    public void onMessage(Demo05Message message) &#123;        logger.info(&quot;[onMessage][线程编号:&#123;&#125; 消息内容：&#123;&#125;]&quot;, Thread.currentThread().getId(), message);    &#125;&#125;\n\n这里贴一点@RocketMQMessageListener注解的常用属性：\n// Consumer 所属消费者分组String consumerGroup();// 消费的 TopicString topic();// 选择器类型。默认基于 Message 的 Tag 选择。SelectorType selectorType() default SelectorType.TAG;// 选择器的表达式。String selectorExpression() default &quot;*&quot;;// 消费模式。可选择并发消费，还是顺序消费。 concurrently or orderly.ConsumeMode consumeMode() default ConsumeMode.CONCURRENTLY;// 消息模型。可选择是集群消费，还是广播消费。MessageModel messageModel() default MessageModel.CLUSTERING;// 消费的线程池的最大线程数int consumeThreadMax() default 64;// 消费单条消息的超时时间long consumeTimeout() default 30000L;\n\nRocketMQ 提供了两种顺序级别：\n\n普通顺序消息 ：Producer 将相关联的消息发送到相同的消息队列。\n完全严格顺序 ：在【普通顺序消息】的基础上，Consumer 严格顺序消费。\n\n顺序消息对于一个指定的Topic，消息严格按照先进先出（FIFO）的原则进行消息发布和消费，即先发布的消息先消费，后发布的消息后消费\n但是Rocketmq的实现上分为了生产顺序性和消费顺序性。只有同时满足了生产顺序性和消费顺序性才能达到上述的FIFO效果。\n\n生产顺序性：单个生产者串行发送的消息，如果设置了相同的分区键就会存储在同一个队列中，也就保证了生产顺序性。\n注意要点，要求的是单个生产者，且生产者使用了一个线程发送消息，否则即使设置相同分区键也不能保证顺序。\n\n\n消费顺序性：同一个分区键的消息会被分配到同一个消息队列，消费者会按序消费\n\n\n如图所示，消息1-7依次被生产，有各自的分区键（相同分区键表面属于同一个业务），在分配后，每个消息队列可以保证相同分区键的消息是有序的。\n此外还有其他的称呼方式：\n\n普通顺序性：即生产顺序性\n严格顺序性：生产顺序性+消费顺序性\n\n\n目前已知的应用只有数据库 binlog 同步强依赖严格顺序消息，其他应用绝大部分都可以容忍短暂乱序\n\n代码方面可以使用DefaultMQProducer或者rocketMQTemplate：\n\nDefaultMQProducer使用时要传入一个选择器，规定了相同key消息的分区方式。\n\nMessageQueueSelector的接口如下：\npublic interface MessageQueueSelector &#123;    MessageQueue select(final List&lt;MessageQueue&gt; mqs, final Message msg, final Object arg);    //  mqs 是可以发送的队列，msg是消息，arg是上述send接口中传入的Object对象，也就是key&#125;\n\n生产环境中建议选择最细粒度的分区键进行拆分，例如，将订单ID、用户ID作为分区键关键字，可实现同一终端用户的消息按照顺序处理，不同用户的消息无需保证顺序。\n\n使用rocketMQTemplate比较简单，只需要额外传入一个分区键参数\n\n// 同步rocketMQTemplate.syncSendOrderly(TOPIC, message, 分区键);// 异步rocketMQTemplate.asyncSendOrderly(TOPIC, message, 分区键, callback);// 单向rocketMQTemplate.sendOneWayOrderly(TOPIC, message, 分区键);\n\n\n如果一个Broker掉线，那么此时队列总数是否会发化？\n\n\n如果发生变化，那么同一个 ShardingKey 的消息就会发送到不同的队列上，造成乱序。\n如果不发生变化，那消息将会发送到掉线Broker的队列上，必然是失败的。\n\nRocketMQ 提供了两种模式，如果要保证严格顺序而不是可用性，创建 Topic 是要指定 -o 参数（–order）为true，表示顺序消息\n事务消息事务消息\n事务消息：在普通消息基础上，支持二阶段提交能力\n\n如何实现的？通过半事务消息，如果可以执行完成，就提交，否则就回滚（二阶段思想）\n两个阶段：\n\n\n第一阶段：发送一个半事务消息到broker，同时本地开始执行事务\n半事务消息是指：生产者已经发送到broker上，但是还不能被消费的消息，是否能被消费看后续是提交还是回滚\n\n\n第二阶段：判断两件事情，如果全部成功就标记commit，否则就回滚\n半事务消息是否发送成功\n事务是否执行成功\n\n\n\n详细流程如图所示：\n\n\n生产者将半事务消息发送至 Broker。\n\nBroker 将消息持久化成功之后，向生产者返回 Ack 确认消息\n\n生产者开始执行本地事务\n\n生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：\n\n二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。\n二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。\n\n\n在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查\n\n注意：服务端仅仅会按照参数尝试指定次数，超过次数后事务会强制回滚，因此未决事务的回查时效性非常关键，需要按照业务的实际风险来设置\n\n\n事务消息回查步骤如下： \n\n生产者收到消息回查后，需要检查事务执行的最终结果\n生产者根据最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理\n\n实现rocketMQTemplate实现了该方法\nrocketMQTemplate.sendMessageInTransaction(TX_PRODUCER_GROUP, TOPIC, message, arg);// 四个参数分别是 生产者组name、topic、msg、arg（执行本地事务需要的参数）\n\n事务回查机制\n事务回查机制：RocketMq支持如果应用超过一定时长未 commit 或 rollback 这条事务消息，RocketMQ 会主动回查应用，询问这条事务消息是 commit 还是 rollback ，从而实现事务消息的状态最终能够被 commit 或是 rollback ，达到最终事务的一致性。\n\n通过实现监听器RocketMQLocalTransactionListener：\n\n注解@RocketMQTransactionListener，指定一个生产者组，回查时Broker端如果发现原始生产者已经崩溃，则会联系同一生产者组的其他实例回查\n\nexecuteLocalTransaction 是半事务消息发送成功后，执行本地事务的方法，具体执行完本地事务后，可以在该方法中返回以下三种状态：\n\nLocalTransactionState.COMMIT_MESSAGE：提交事务，允许消费者消费该消息\nLocalTransactionState.ROLLBACK_MESSAGE：回滚事务，消息将被丢弃不允许消费。\nLocalTransactionState.UNKNOW：暂时无法判断状态，等待固定时间以后Broker端根据回查规则向生产者进行消息回查。\n\n\ncheckLocalTransaction是由于二次确认消息没有收到，Broker端回查事务状态的方法。\n\n回查规则：本地事务执行完成后，若Broker端收到的本地事务返回状态为LocalTransactionState.UNKNOW，或生产者应用退出导致本地事务未提交任何状态。则Broker端会向消息生产者发起事务回查，第一次回查后仍未获取到事务状态，则之后每隔一段时间会再次回查。\n\n\n\n@RocketMQTransactionListener(txProducerGroup = TX_PRODUCER_GROUP)// 指定一个生产者组public class TransactionListenerImpl implements RocketMQLocalTransactionListener &#123;    private Logger logger = LoggerFactory.getLogger(getClass());    @Override    public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123;        logger.info(&quot;[executeLocalTransaction][执行本地事务，消息：&#123;&#125; arg：&#123;&#125;]&quot;, msg, arg);        return RocketMQLocalTransactionState.UNKNOWN;    &#125;    @Override    public RocketMQLocalTransactionState checkLocalTransaction(Message msg) &#123;        logger.info(&quot;[checkLocalTransaction][回查消息：&#123;&#125;]&quot;, msg);        return RocketMQLocalTransactionState.COMMIT;    &#125;&#125;\n\n\nRocketMq与其他Mq事务消息的区别\n\nRabbitMQ 和 Kafka 也有事务消息，支持发送事务消息的发送，以及后续的事务消息的 commit提交或 rollbackc 回滚。\n但是要考虑一个极端的情况，在本地数据库事务已经提交的时时候，如果因为网络原因，又或者崩溃等等意外，导致事务消息没有被 commit ，最终导致这条事务消息丢失，分布式事务出现问题。\nRocketMq提供了事务回查机制，可以保证最终一致性\n\n事务回查的一点trick\n\n对于实际的业务，我们可以：\n\n第一步，在 #executeLocalTransaction(...) 方法中，先存储一条 id 为 msg 的事务编号，状态为 UNKNOWN 的记录。\n第二步，调用带有事务的业务 Service 的方法。\n在该 Service 方法中，在逻辑都执行成功的情况下，更新 id 为 msg 的事务编号，状态变更为 COMMIT 。这样，我们就可以伴随这个事务的提交，更新 id 为 msg 的事务编号的记录的状为 COMMIT \n\n\n第三步，要以 try-catch 的方式，调用业务 Service 的方法。如此，如果发生异常，回滚事务的时候，可以在 catch 中，更新 id 为 msg 的事务编号的记录的状态为 RocketMQLocalTransactionState.ROLLBACK 。😭 极端情况下，可能更新失败，则打印 error 日志，告警知道，人工介入。\n如此三步之后，我们在 #executeLocalTransaction(...) 方法中，就可以通过查找数据库，id 为 msg 的事务编号的记录的状态，然后返回。\n\n总结RocketMq的总结：\n\n发送方式：同步、异步、单向传输\n消息类型：普通消息、批量消息、定时消息、顺序消息\n普通消息：最常用的消息类型\n批量消息：将同一个topic下的多个消息打包起来一同发送，注意如果超过1MB需要自行分割\n定时消息：只有指定的时间到后，消息才可以被消费，Rocketmq支持18个级别的消费，不支持高精度消费\n顺序消息：消息可以保证生产顺序性和消费顺序性，一般情况下只保证生产顺序性即可。\n事务消息：普通消息+二阶段提交，RocketMq额外提供事务回查机制\n\n\n消息模型：集群消费和广播消费\n集群消费：\n特点：同一个消费组下的实例之间负载均衡。\n应用：适用于普遍情况，比如一个游戏升级后，A消费组可以专注于增加血量、B消费组可以专注于增加下一次升级所需的阈值等等。\n\n\n广播消费：\n特点：同一个消费组下的每一个实例获取所有消息\n应用：缓存了数据字典等配置表在内存中，可以通过广播消费，实现每个应用节点都消费消息，刷新本地内存的缓存\n\n\n\n\n消费模式：并发消费和顺序消费\n消费重试：消费失败会被重试16次，超过16次进入死信队列\n\n","categories":["消息队列"],"tags":["消息队列"]},{"title":"路由与数据转发","url":"/2023/03/20/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%B7%AF%E7%94%B1%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%BD%AC%E5%8F%91/","content":"\n    引言：感觉计网处在空中楼阁，缺少对于下三层的理解\n\n\n\n路由器相关概念网关网关gateway：是一个连接两个不同网络的设备，使之能够相互通信。\nPS：在早期的计网中，“网关”仅仅表示将不同的网络连接起来，所以当时“网关”常常与“路由器”混用；随着技术发展，网关的作用已不仅仅是连接两个网络了，因此网关已不再单指路由器这一种设备。\n\n1、网关出现的原因：\n\n\n进行不同网络之间的协议转换：由于互联网的发展和演化。在互联网的早期阶段，由于不同类型的网络通信协议不同，网络之间的通信非常困难。（现如今最常用的以太网，在以前并不是这样）\n不同的网络中的地址不同，需要使用网关进行转换\n有的网络需要一个能够对网络流量进行安全检查和管理的设备，防止不安全流量进入网关。\n\n\n2、网关的作用\n\n\n不同类型网络之间通信协议的转换：将局域网中的数据包转换成互联网中的数据包，或将IPv4协议转换成IPv6协议等。\n对网络流量进行安全检查和管理：例如，对数据包进行过滤、拦截、重定向、加密等操作，保护网络中的机密信息和防止网络攻击。\n连接企业内部网络和外部互联网：例如，企业可以通过网关将内部网络和互联网连接起来，实现企业对外部网络的访问和外部网络对企业内部网络的访问。（这样可以保证外部流量不会随意的打入内部，防止信息泄露）\n实现网络地址转换：将内部网络中的私有IP地址转换为公共IP地址，以便内部网络可以访问互联网。\n\n\n3、分布式集群的网关与路由器的网关的概念有所区别\n\n分布式集群中的网关更像是使用了路由器网关的概念——负责与外网进行交流，它的作用有：\n\n负载均衡：将外部流量均匀的打在不同的节点上，保证负载均衡\n安全性：网关可以实现一些安全策略，身份认证、访问控制、数据加密等\n数据转换：网关可以将外部请求转换为集群内部所需的格式，以便集群内部的节点能够处理这些请求。\n监控和日志：网关可以收集集群内部的监控数据和日志信息，并将这些信息发送到监控系统或日志系统中进行处理和分析。\n\n判断两个IP是否处于同一网段比如此时有两个网络：\n\nA：ip地址：192.168.1.1/24\n\nB:  ip地址：192.168.1.3/24\n\n\n子网掩码是/24，即255.255.255.0，判断AB是否处于一个网络很简单：\n只需要使用对方的IP地址，与自己的子网掩码做与&amp;运算，得到网络号，比较网络号是否相同即可。\n对于/24的子网掩码，就是前三个部分，A与B的网络号都是192.168.1.0\nPS：【注意，使用的是对方的子网掩码】判断下面这两个网络：\n\nC: IP 172.33.4.101/16\n\nD: IP 172.33.3.106/24\n\n\n“判断两个IP是否处于同一网段”这个问题其实就是“判断对方处于自己的网络中”\n比如C使用16判断D与自己的网络号都是172.33.0.0；但是D使用24判断C就是172.33.4.0，而自己是172.33.3.0\n\n是否可以通信，与处于同一个子网没有必然的联系：子网的本质是直连路由\n如果两个网络使用了一个交换机（二层互通），那么也可以通信；\n如果两个网络使用了一个路由器（三层互通），即使不在同一个网络也可以通信。\n\nHDLC与PPP两个都是数据链路协议：\n\nHDLC（High-level Data Link Control）：一种数据链路协议，用于在两个点之间传输数据\nPPP（Point-To-Point Protocol）：数据链路协议，HDLC是其基础协议；支持多种网络协议：IPV4、IPV6\n\n\n他们用于点到点的通信，与以太网不同，不需要MAC地址，因为就只有两个人\n\n以最广泛使用的PPP为例，在PPP通信时，需要进行LCP协议（Link Control Protocol）的过程搭建起两人之间的通信，之后使用PPP数据帧包装IP数据包（而不是以太网帧），也就不需要使用MAC地址\nIP与TTL\nTTL（Time To Live），在IP头占一个字节，所以取值在0~255之间\n保活时间，每经过一个路由器就-1，当数字变为0，不再发送该消息，而是向源地址发送一个ICMP的数据报，告知其跃点数超过限制\n\n路由表路由表包含的信息有：\n\n路由的源、管理距离、度量\n网络的详细信息：源信息、网络地址、子网掩码、下一条路由的IP地址\n直连网络：即直接连在当前路由器上的设备\n远程网络连接：连接到了另一个网络\n\n建立路由表三种方式：\n\n直连路由：直接连到设备，在CSICO中使用C（Connect）表示\n静态路由：手动配置的路由表，使用S（static）表示\n动态路由：路由器之间互相学习，不同的算法表示不同I（IGRP）、R（RIP）\n\n在CISCO中可以使用命令：show ip route查看路由表\n静态路由路由表对于静态路由：\n\n使用S表示\n标记出网络地址和子网掩码\n标记出下一跳的IP地址或是出接口\n\n\n静态路由或动态路由使用之前，路由表中必须包含与远程网络相关的直连路由\n\n使用静态路由的条件：\n\n路由器较少\n星型拓扑\n唯一的外连出口（即网络中只有一个出口）\n\n如图配置所示：\n\n三行中：C表示直连、S表示静态路由，表示该路由器通过192.168.2.2连接到外部网络192.168.3.0/24\nFa0/0接口表示FastEthernet，用于局域网中，速度较快；\nS0/0/0表示串口，用于连接远程网络，速度较慢\n动态路由动态路由协议有很多：RIP、IGRP、EIGRP、OSPF\n\n关于动态路由之后详细介绍\n路由表法则路由表三条原则：\n\n每台路由器根据其自身路由表中的信息独立决定发送路线\n一台路由器的路由表中包含某些信息并不表示其它路由器也包含相同的信息\n有关两个网络之间路径的路由信息并不能提供反向路径（即返回路径）的路由信息\n\n有关第1、2条：A发送到B的路线，与B发送到A的路线不一定相同\n有关第3条：即A能发送数据到B，但是B可能发送不到A\n\n路径的确定路由器决定走哪一条线路取决于Metric，其包含很多度量：跳数、带宽、负载、时延、开销\n对于RIP来说，Metric就是跳数；对于IGRP来说，Metric就是带宽、延迟\n\nPS：开销可以由管理员设定，可以表示任意一种度量，或者是几种度量的组合\n\n所以路由器决定走哪一条线路：首先判断优先级；然后对于同种协议判断Metric\n\n一般而言优先级（Preference，也叫管理距离AD）：一般直连&gt;静态&gt;动态，不同厂商对于优先级的定义不同\n对于同一种协议，Metric越小，这条路径越佳\n对于相同的Metric，说明这两条路径是等价的，此时可以进行等价负载均衡（比如A出口发送一半的包，B出口再发一半的包）\n\n对于路由器自己，他需要完成两个任务：\n\n根据优先级以及Metric找到最佳路径\n将数据包送到外出接口\n\n交换\n路由器交换：将数据从一个接口转到另一个接口\n\n一个包传到这个路由器时，它的结构是：二层MAC(三层IP(数据DATA))（因为数据是从上到下包起来的）\n路由器会对收到的数据进行处理：（二层中的数据称为帧，三层中的数据成为包）\n\n对收到的包剥离二层帧头，以便于获取目的IP地址\n根据目的IP地址，查找路由表，选择最佳路径\n将数据重新封装为帧并转发\n\n把路由器看做黑盒，那么数据包输入前后会有如下变化：\n\n源IP和目的IP不会变化\nTTL-1\n二层地址发生变化，并且二层地址不一定总是MAC地址\n\n\n数据包发送的Demo这里放一个Demo：现有一个PC1想要给PC2发送数据包\n1、判断PC2与自己是否处于一个网段\nPC1发现PC2与自己并不是一个网段（如果是同一个网段可以直接二层通信），因此只能走网关，所以需要打一个包发送到路由器R1\n2、查询ARP缓存\n首先PC1会查询自己的ARP缓存，如果没有对应的缓存，那么就进行ARP广播\n广播的过程：\n\nPC1会把自己的IP + MAC地址 + 目的IP（即网关IP）发一个ARP广播\n对应的网关收到后，就给PC1回复网关自己的IP地址 + MAC地址\nPC1收到回复后，缓存到ARP缓存中\n\n\n3、 PC1封装包\n如图所示，PC1将数据封装三层包头与二层包头，通过网卡发送到R1\n这里的目的MAC地址是R1的MAC地址\n4、R1收到包，剥离包头获取IP\nR1收到包后，将包二层拆解以便获取IP地址\n\n5、R1在路由表中寻找目的IP地址\n\n查找目的地址的路由表，查询下一跳的IP\n6、R1用下一跳IP去ARP缓存查询对应的MAC地址，如果没有对应缓存，还是要发ARP广播\n\n\n在更新目的MAC地址后，把对应Fa0/1的MAC地址也封装后发送\n\n对于家用路由器，只有内外网口两个MAC地址；\n如果是思科华为这种路由器，那么每个端口可以配至少一个IP地址，对应至少一个MAC地址\n\n7、同理R2也会进行拆包，获取目的地址的过程\n\n查询到下一跳地址为192.168.3.2，并且对外的接口是S0/0/0，在这之前我们都是使用的以太网，而此时我们切换成了S串口，对应的协议有HDLP、PPP，最广泛的还是PPP\n\n串行链路不同于以太网，因为以太网是一个多路访问的网络，要定位到目的设备需要借助于MAC地址，但串行线路一般的封装协议都是PPP(Point-to-Point Protocol,点到点协议)或HDLC(High-Level Data Link Control,高级数据链路控制协议)封装，这种封装被用于点对点线路，也就是说，一根线缆只连接两台设备，一端发出，另一端肯定可以收到\n\n因为是P2P的，所以此时就不再需要MAC地址了，下图中封装的结构称为PPP数据帧\n\n8、R3接收到后也是拆包、查路由表、查ARP缓存\n\n9、PC2收到数据包后，层层拆解，获取数据\n\n\n至此，包的发送接收过程在二、三层的流程说明清楚了，对于访问一个http网址的问题可以结合DNS、TCP、IP，再结合路由器发送包的关系进行说明\n动态路由与静态路由的区别静态路由管理员手动配置了路由表，所以不需要路由器额外的处理，负载低，但是如果网络发生变化，那么就又得手动更新路由表。\n动态路由可以根据Metric自动更新路由表，选择最佳路径，提高网络性能，有额外负载；\n所以相对于静态路由，动态路由更适合大型的网络拓扑结构\n动态路由的功能\n发现远程网络\n\n维护最新路由信息\n\n选择最佳路径\n\n当前路径无法使用时找出新的最佳路径\n\n\n动态路由的分类\n\n内部网关协议\n距离矢量协议：定期发送路由表信息\n有类：路由信息更新过程中不发送子网掩码信息\n无类：路由信息更新过程中发送子网掩码信息\n\n\n链路状态协议：链路状态改变时，更新链路状态\n\n\n外部网关协议：\n\n\n\n问题1：为什么距离矢量协议要分为有类和无类两种？\n\n\n“有类”的意思是将IP看做网络部分和主机部分，有类协议只根据网络部分进行选择\n\n“无类”就将IP看做一个整体\n\n\n有类的英语是Classul Protocol，因为早期的IP分为A、B、C三类，所以叫有类。\n原因是早期的IP地址没有子网掩码，之后引入了子网掩码后才提出了无类。\n所以可以看到老版本的协议（EGP、RIP、IGRP）是有类的，而新版本的协议是无类的\n\n问题2：距离矢量协议A和链路状态协议B的区别\n\n\n传递的信息不同\nA：邻居之间只传递距离向量（这意味着一个节点并不能知晓整个网络的拓普信息）\nB：发送的信息是整个网络的拓扑结构\n\n\n更新方式不同\nA：定期发送距离向量，收到后更新自己的距离向量表\nB：基于事件触发：当网络中拓扑结构发生变化，网络中广播更新路由信息状态，计算最短路径再更新路由\n\n\n收敛速度：\nA：收敛速度慢（原因是网络中如果存在环，就会出现计数器毒瘤的问题）\nB：收敛速度快\n\n\n资源占用：\nA：占用少，因为只需要存邻居节点的距离向量\nB：占用多，存整个网络的拓扑结构\n\n\n\n\n问题3：RIP协议与IGRP协议的区别\n\n\nIGRP使用时延、带宽来计算路由，比RIP的跳数计算更加能准确的估计网络的运行情况。\nIGRP最大跳数100，RIP最大跳数15\n\n距离矢量协议距离矢量协议的特点\n\n距离矢量：就是路由器之间的跳数；\n对于距离矢量的协议，他们只知道自己与相邻路由器的距离，并不知道整个网络的拓扑\n\n距离矢量协议有：RIP、IGRP几种，他们共同的思想是：每个路由器维护一个距离向量（RIP是跳数，IGRP是带宽和时延），相邻路由器之间周期更新距离矢量表\n相邻路由器之间发送：到达目的节点的最佳输出线路 + 距离向量\n所以与链路状态协议对比：距离矢量协议\n\n优点：占用资源小，简单易实现，维护方便\n缺点：收敛速度慢（甚至形成环），不易扩展（适合小型网络）\n\n对于RIP来说：距离矢量是跳数；最大跳数为15（设置为16代表不可达）；30s更新一次\n对于IGRP来说：距离矢量是时延和带宽；最大跳数为100；90s更新一次且是触发更新的\nRIP路由交换过程初始阶段，如图所示，有三个路由表\n1、路由器对于直连的设备跳数设为0\n\n2、与相邻的路由器通信，交换自己的路由表（发送自己的路由表过去）\n\n3、路由器将自身没有的条目加入，并将跳数+1\n\n4、当网络中所有的路由器的路由表相同时，完成收敛\n\n路由协议的收敛速度由两方面决定：\n\n路由传递更新信息的速度\n路由计算最佳路径的速度\n\n更新方式定时更新：RIP&amp;IGRP\nUpdate Timer：该计时器用于控制路由表的更新频率。当该计时器过期时，路由器将向其邻居发送其完整的路由表。（RIP默认值为30秒；IGRP默认90S）\nInvalid Timer：该计时器用于控制路由表中路由信息的有效性。如果一条路由信息在该计时器过期前没有更新，它将被标记为无效路由。默认值为180秒。(收到新的信息会重新计时)\nHold-Down Timer：当一条路由信息变为无效路由时，该计时器用于防止路由器立即接受来自同一源的任何更新。这是为了避免路由环路的形成。默认值为180秒。\nFlush Timer：该计时器用于删除无效路由。当一条路由信息被标记为无效路由时，该计时器开始计时。当计时器过期时，该路由将从路由表中删除。默认值为240秒。\n\n\n抑制计时器的工作流程：\n\n1、当收到一个路由器发来的更新消息时，启动抑制计数器；在抑制时间内，路由器不会再发送更新消息。\n2、标记该网络为possibly down\n3、如果收到的小于当前值的Metric，就恢复该网络，并删除抑制计时器；如果收到大于当前值的Metric，就忽略这个消息\n注意：路由器仍然会转发目的网络被标记为possibly down的数据包\n限定更新：EIGRPEIGRP是CSICO的独家协议，它的更新对比定时更新有优化：\n\n只有在路由表发生变化时更新\nEIGRP会将自己所知道的网络拓扑信息告诉相邻路由器，加快收敛速度（并不是发送整个路由表）\n\n触发更新对于定时更新的一种优化，在三种情况下更新路由：\n\n路由表中新增了路由\n某条路由进入或退出不可达状态（即无效状态，由无效计时器控制；也有可能是跳数变为16）\n接口开启或关闭\n\n随机抖动加一个随机的参数。是防止大量缓存同时失效的一种办法：比如Redis做缓存时，就可以给每一条缓存加一个随机值。防止热门信息缓存同时失效，导致缓存雪崩。\n对比路由器这里同理，防止网络中同时进行路由更新，导致网络繁忙。\n路由环路\n路由环路：数据包在一系列路由器之间不断传输却始终无法到达其预期目的网络的一种现象。\n\n\n如何出现的？\n\n\n一开始可能只是一个节点从网络中断开，R1刚把对应的条目删掉，但是此时恰好R2发来了更新信息\n\nR3此时发现，这个条目我没有，就会+1；\n依次反复，在R1、R2、R3之间反复传播。\n防止路由形成环路路由环是一种不好的现象，会导致网络中无意义的传输内容：\n\n路由器反复占用链路来确认路由信息，增大网络中的负载\n浪费路由器CPU性能\n影响收敛速度\n路由更新无法到达目的网络\n\n解决路由环路的措施：\n\n定义最大度量（RIP最大跳数是15，变为16就知道出现了环路）\n抑制计时器\n水平分割：从某个接口收到的更新信息不允许再从这个接口发回去，防止生成环路\n\n\n\n路由毒化或毒性反转\n路由毒化：将已经断开的路由的距离通告为无限大。例如路由器设置Fa0/1接口的Metric为16，R2收到就知道该IP已经断开\n毒性反转：收到毒化消息，不遵守水平分割原则，而是将这个毒化消息发给相邻路由器\n\n\n触发更新\n\n","categories":["计算机网络"],"tags":["计算机网络","网络层","路由器"]},{"title":"TCP/UDP协议","url":"/2021/08/20/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%BF%90%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE/","content":"\n引言：TCP/UDP协议（未完成）\n\n\n\nTCP/UDP知识点总结此处仅供复习，省去废话，只有干货！（注意，没有标单位的数，单位将均为字节）\n\n运输层的主要任务：多路复用、多路分解\n多路复用：从不同的数据块接收数据，加首部传递到网络层；多路分解：将报文段数据交付到正确的套接字工作。\nUDP协议的特点：无连接、尽最大努力交付（不保证发送成功）、面向报文（加首部直接传递给下一层）、支持一对一、一对多、多对一、多对多、首部开销小（8字节）\nUDP首部格式：源端口（2）、目的端口（2）、长度（2，包括头部）、检验和（2）\n伪首部：TCP/UDP检验时都会用到，源IP地址（4）、目的IP地址（4）、0（1）、17（1，UDP为17，TCP为6）、UDP长度（2，这里的长度与首部中一样，都不会包含伪首部的长度）\n检验过程：使用伪首部、首部、数据部分、（不为偶数还要填充0）进行求和取反码放入检验和字段，接收端接收时同样对所有数据进行求和取反码，全为1则无错，否则有错，丢弃数据包。\n检验了什么？不仅检查了源端口、目的端口、数据部分、还检查了源IP地址、目的IP地址\nTCP协议的特点：面向连接、只支持一对一、提供可靠交付（无差错、无重复、无丢失、按序到达）、全双工通信、面向字节流（数据报转化为无结构的字节流进行分组发送）\n有关可以保证传输可靠的所有要点：停止等待协议、连续ARQ协议、滑动窗口协议\n停止等待协议：发送一个分组后停止，等待对方确认后再发送下一个分组。\n停止等待协议要点：超时重传、设置等待时间（略大于往返时间RTT）、设置编号（可以明确哪一个丢失）、要保存一个发送的副本（保证可以重发）、自动重传请求ARQ\n自动重传请求ARQ：指重传的请求是自动进行的，接收端无需请求发送端重传某个出错的分组（通过超时重传、确认迟到、确认丢失机制实现）\n确认丢失：指确认信息在返回时丢失了，此时发送方会超时重传，接收端会丢弃重复的包，并再一次返回确认信息\n确认迟到：指确认信息在返回时迟到了，此时发送方会超时重传，接收端会丢弃重复的包，并再一次返回确认信息\n信道利用率：公式为Td / (Td + RTT + Ta)，其中Td为发送分组的时间，RTT是一次往返的事件、Ta是接收分组的时间\n停止等待协议缺点：信道利用率低，效率低，信道绝大部分时间空闲\nTCP报文段格式：源端口（2）、目的端口（2）、序号（4）、确认号（4）、数据偏移（4 bit）、保留（6 bit）、URG（1bit，其后五个也均为1 bit）、ACK、PSH、RST、SYN、FIN、窗口（2）、检验和（2）、紧急指针（2）、选项（可变）、填充（补齐为4的倍数）\nTCP首部长度：固定长度20，可变长度最长为40，即整个首部最短为20，最长为60\n序号（4）：本报文段要发送的第一个字节的序号（TCP按字节编号，此字段标志本次发送的第一个字节的编号）\n确认号（4）：期望收到的下一个字节的编号（确认号为N：代表N-1个数据已经全部收到）\n数据偏移（4 bit）：记录数据起始处 - 首部起始处（其实就是首部长度，单位为 4字节，代表TCP首部最长为 (2^4 -1) * 4 = 60字节，即选项部分最长为40字节）\n保留（6 bit）：今后使用，全为0\nURG：紧急，当此字段为1，TCP会将此报文段优先传送（例如 Control + c 命令），与紧急指针协同使用\n紧急指针（2）：标明紧急的数据在本报文段的末尾位置（如果URG为1，就会把紧急的数据放在报文段最前面；注意：紧急数据后面的数据，属于普通数据，还需要排队）\nACK：确认收到，连接建立后的所有报文段都必须把ACK置为1\nPSH：推送，置为1后，发送方立即创建报文段发送，接收方收到后立即交付进程（不必等到缓存存满再交付）\nRST：复位，表明要断开连接，重新建立\nSYN：同步，建立连接时使用，SYN=1 ACK=0表明这是一个连接请求，SYN=1 ACK=1表明同意连接请求\nFIN：终止，表明发送方数据发送完毕，要求终止连接\n窗口（2）：接收窗口的大小（作为接收方让发送方调节发送窗口的依据）\n检验和（2）：同UDP，要加上伪首部计算\n选项（可变长度）：可以设置MSS、窗口扩大选项、时间戳选项、选择确认选项\nMSS最大报文段长度：仅包括数据部分，默认为536字节（所以默认能接受的报文段长度是536 + 20 = 556字节）\n窗口扩大选项（3）：可以设置更大的接受窗口（首部的窗口只有2字节）\n时间戳（10）：两个作用：用此计算RTT时间；用此区分序号是否重复使用（防止序号绕回）\n防止序号绕回PAWS：序号字段只有4字节，当传输量大时，容易让旧的数据序号与新的数据序号重复，分不清新旧数据，可以在选项中加时间戳选项进行区分\n改用流水线发送分组后，保证可靠性的协议：连续ARQ协议、滑动窗口协议（两个协议是一同使用的）\n发送窗口：位于窗口内的包均可以发送，无需等待确认接收\n连续ARQ协议：规定发送方每收到一个确认请求，就将窗口向前推进一个位置；接收方进行累积确认\n累积确认与回退N：累积确认：对按序到达的最后一个分组发送确认；意味着如果中间丢失了一个分组，需要重新发送其后的所有包，这就是回退N（Go-Back-N）\n滑动窗口协议：TCP通信双方均维护一个发送缓存与接收缓存（实现全双工）\n发送缓存：发送窗口是发送缓存的一部分，存放两部分数据：1 准备发送的数据；2 已经发出但是尚未接收到确认的数据\n接收缓存：接收窗口是接收缓存的一部分，存放两部分数据：1 按序到达，但尚未读取的数据；2 未按序到达的数据\n选择确认SACK：（替代累积确认的方案）当收到不连续的数据时，收下数据，并通知发送方，发送方就无需传递重复的数据\nTCP流量控制：TCP通过滑动窗口来进行流量控制，通过不断的变更窗口的大小，来使信道利用率变高。（目的是为了让接收端来得及接收）\nTCP拥塞控制：通过慢开始、拥塞避免、快重传、快恢复四种算法实现（目的是为了防止网络发生阻塞）\n流量控制与拥塞控制的区别：1 流量控制是为了让接收端来得及接收；拥塞控制是为了防止网络发生阻塞；2 流量控制是一个端到端的控制（发送接收双方的控制）；拥塞控制是一个全局的控制；\n如何判断网络出现了拥塞：只要出现了超时，就发生了拥塞\n拥塞窗口cwnd：发送方维持，只要无拥塞就持续增大，反之亦然。\n慢开始：初始设cwnd为1（但其实是设为几倍的SMSS的大小），每经过一个RTT就翻倍的增加cwnd\n拥塞避免：每经过一个RTT就给cwnd线性增长（比如加1）；注意：拥塞避免只是难以出现拥塞，并不是避免了拥塞\n慢开始门限ssthresh：当cwnd &lt; ssthresh，就用慢开始；当cwnd&gt;ssthresh就用拥塞避免；当cwnd=ssthresh ，二者选其一；如果网络出现了阻塞，会将cwnd置为初始值，重新进行慢开始。\n快重传：发送方只要介绍到三个重复确认，就启动快重传算法。要求接收方不要等到自己发送数据时才捎带进行确认，而是要立即发送确认请求。\n快恢复：快重传启动时执行。调整ssthresh为当前拥塞窗口的一半ssthresh = cwnd / 2\nAIMD算法：拥塞避免时，窗口线性增大（AI，加法增大）；快恢复时，设置慢开始门限为当前拥塞窗口值的一半（MD，乘法减小）；合称AIMD算法\n发送窗口上限值 = Min(rwnd, cwnd)（即接收窗口与拥塞窗口中小的那一个）\n拥塞控制流程总结：设置拥塞窗口初始值；首先慢开始；达到ssthresh，进入拥塞避免；出现拥塞，再次慢开始；如果连续收到3个重复的确认收到请求，开启快重传与快恢复\nTCP三次握手：（A代指客户、B代指服务器）\n初始阶段：均处于CLOSED关闭状态\nB的TCP进程创建传输控制块TCB准备接收请求，处于LISTEN收听状态\nA的TCP进行也创建TCB，并发送SYN=1, seq=x（当SYN=1,ACK=0表示此请求是为建立连接，seq代表序号，初始时序号随机选择）；发送完成后，A进入SYN-SENT同步发送状态\nB接收到请求后，如果同意连接，发送SYN=1, ACK=1, seq=y, ack=x+1（当SYN=1,ACK=1表示同意连接请求，服务器端也随机选一个初始值，并返回确认收到ack，注意ack是x+1），B进入SYN-RCVD同步收到状态\nA收到B的确认后，还要给出确认，发送ACK=1, seq=x+1, ack=y+1，A进入ESTAB-LISHED已建立状态\nB接收到A的确认后，也进入ESTAB-LISHED已建立状态\n\n\nSYN报文段（SYN为1的报文段）不能携带数据，但会消耗掉一个序号\n第三次握手阶段，可以携带数据（第三次握手不是SYN报文段）\n第三次握手的作用：防止已失效的连接请求突然又传到了服务器端\n情景：假如当前为两次握手即建立连接，第一次连接请求在网络中延迟，导致客户端又重传了一次连接请求，第二次连接请求成功连接，然后客户端服务器进行通信且完成后断开，断开后，第一次连接请求又发送到了服务器端，但其实客户端已经没有要发送的数据了，导致服务器端资源白白浪费\n\n\nSYN泛洪攻击：攻击端利用了三次握手协议，伪造IP地址发送连接请求给服务器，服务器确认请求永远发送不到目的地（因为IP是伪造的），以此耗尽服务器资源。（预防措施：设SYN cookie，实现了接收到一个SYN时完全不需要分配空间）\nTCP四次挥手：\n初始阶段：均处于ESTAB-LISHED已建立状态\nA主动关闭连接，发送FIN=1, seq=u的请求，进入FIN-WAIT-1终止等待1阶段\nB收到请求，发送ACK=1, seq=v, ack=u+1，进入CLOSE-WAIT关闭等待状态（此时处于半关闭状态，即A已经没有发送的数据了，但B可能还有）；\nA收到确认请求后，进入FIN-WAIT-2终止等待2阶段\nB传输完数据后，也想关闭连接，发送FIN=1, ACK=1, seq=w, ack=u+1，进入LAST-ACK最后确认状态\nA收到请求后，发送ACK=1, seq=u+1, ack=w+1，进入TIME-WAIT时间等待状态\nB收到请求后，进入CLOSED关闭状态\nA在等待2MSL（MSL最长报文段寿命）后，也进入CLOSED关闭状态\n\n\n为什么要设置TIME-WAIT状态？两个原因\n保证客户端发送的最后一个ACK能到达B\n也是为了防止迟到的连接请求出现\n\n\n如果双方之一出现故障，无法进行四次挥手怎么办？TCP设有保活计时器，每收到一次客户端请求，就重置，在2小时内没收到客户端的数据后，会给客户端每75秒发送一条探测报文，如果连续10个探测报文都未收到响应，就会关闭连接。\n\n运输层（未完成）​        运输层处于应用层与网络层之间，运输层最起码要完成的任务，就是要提供一种复用/分解的服务\n​        在这一层的数据我们使用报文段来进行说明（在RFC中报文段、数据报混合使用，我们这里只使用报文段来阐述）\n多路分解与多路复用\n\n多路分解：\n将运输层报文段中的数据交付到正确的套接字工作作为多路分解\n\n多路复用：\n从不同的套接字中收集数据块，并为每一个数据块封装上首部信息，从而生成报文段，然后将报文段传递到网络层\n\n\n\n\n套接字Socketsocket可以简单理解为 IP + 端口号（这与JavaAPI内的Socket有些区别）\n一台计算机上有很多进程，OS收到数据后，依据端口号来区分哪些信息是传给哪些进程的\n\n端口号：占用2字节，16bit ，大小在0~65535之间\n其中0-1023是周知端口号，自己的APP应避免周知端口号\n\n\nUDP套接字：一个二元组标识，分别是目的IP地址与目的端口号\nTCP套接字：一个四元组标识，除了目的的IP与端口号，还包括源端口号与源IP地址\n\nUDP\nUDP：一种简单的无连接的协议，IP层传来的数据，只进行了简单的封装（只有8个字节）\n\n特点：\n\n无连接：发送端与接收端不必事先连接\n头部简单：只有8个字节\n传输快\n不确保可以发送到\n\n报文段结构UDP封装的头只有四个字段，每个字段占2个字节，一共占8个字节：\n\n源端口号\n目的端口号\n长度\n检验和\n\n检验和为什么UDP还要有差错检验功能？原因是不能保证从源到目的所有链路都有差错检验功能，也就是说，这些链路中可能有一条链路没有使用差错检测的协议\n除此外，报文存储在路由器内存中，也可能有比特差错\n\n检验和的流程检验和的流程简单来说就是：将所有的字段求二进制和，然后取其反码作为检验和这个字段，接收端接收后，将包括检验和的所有字段进行求和，如果每一位都是0，则代表传输过程中没有出现错误\n举例：\n# 发送端：# 有三个字段：分别表示源端口号、目的端口号、长度0110 0110 0110 00000101 0101 0101 01011000 1111 0000 1100--------------------求和，高位溢出不管0100 1010 1100 0010--------------------取反码1011 0101 0011 1101 # 此值作为检验和字段----------------------------------------# 接收端# 将四个字段进行求和0110 0110 0110 00000101 0101 0101 01011000 1111 0000 11001011 0101 0011 1101 # 检验和------------------- # 求和0000 0000 0000 0000\n\n最后的结果全为0，代表没有出错\n如果其中有一个不为0，说明出现了错误\n出错的处理UDP虽然可以检测出数据是否有异常，但是处理异常的过程，非常简单：\n\n将数据丢弃\n给出警告\n\n其他\nUDP只能进行不可靠传输吗？\n\n基于UDP是可以实现可靠传输的，可以在应用程序端自身建立可靠性机制\n\n对于不同源端口号或是源IP地址（不同源），但是具有相同目的端口与IP的报文段的处理\n\nUDP会将这些报文段通过同一个socket传输给对应的进程\n（而TCP会为每一个单独建一个socket）\nTCP\nTCP：运输层的另一个协议，面向连接的传输协议\n\n特点：\n\n面向连接\n可靠\n全双工：连接双方可以互相“说话”\n点对点：一对一\n\n抓包——三次握手在浏览器输入一个IP地址，就会先进行TCP三次握手\n\nB表示浏览器（端口为52085）、S表示服务器（端口为80）\nB中输入127.0.0.1进行访问\n先建立三次握手：\nB给S发建立连接的请求[SYN]\nS给B回应，允许建立连接[SYN, ACK]\nB给S回应，收到[ACK]\n\n\n\n\n\n然后B开始发送GET请求，S收到后回应[ACK]\n然后S开始发送响应，B收到后回应[ACK]\n\n服务端的三次握手一个TCP服务器，需要创建ServerSocket：\n\n先给bind一个端口\n\n然后对这个端口进行监听\n\n\n\n如图所示：\n\n服务器在收到SYN请求后，将客户端的文件描述符FD存放到半连接队列\n服务器再收到ACK请求后，将半连接队列中的文件描述符FD放到全连接队列\n\n之后服务器accept进入阻塞，然后等待客户端的数据。\nTCP“粘包”问题很多人觉得这并不是一个问题，而是一个TCP的特性，关键在于你怎么看待\n\n什么是粘包问题？\n\n\n以接收端来看：因为TCP是面向流的协议，所以不会保持输入数据的边界，导致接收测很可能一下子收到多个应用层报文，需要应用开发者自己分开，有些人觉得这样不合理，就起名为粘包\n以发送端来看：用户数据被TCP发送时，会根据Nagle算法，将小的数据封装在一个报文段发送出去，导致不同的报文段黏在了一起\n\n\n如何解决？\n\n\n发送方可以关闭Nagle算法（设置TCP_NODELAY就能关闭Nagle算法，但我不太认同这种做法）\n接收方对粘包无法处理，只能交给应用层\n应用层：\n格式化数据：每条数据有固定的格式（开始符，结束符），这种方法简单易行（但要确保内容没有开始符与结束符）\n发送长度：发送数据规定一个长度，以便于应用层判断\n\n\n\n拥塞控制首先要知道几个结构：\n\n发送窗口：发送窗口的大小是拥塞窗口和接收窗口的较小值swnd=min(cwnd, rwnd)\n拥塞窗口：拥塞控制的核心组件cwnd\n拥塞窗口门限：在越过这个门限后ssthresh会有不同的操作\n\n其次我们要知道几个控制算法：\n\n慢开始：指cwnd从1开始增长，并且每次翻倍（慢开始指的是起点低，而不是增长速度慢）\n拥塞避免：在超过ssthresh后，进入拥塞避免算法，会让cwnd线性增长\n\n如果出现了拥塞，那么就将ssthresh的值调整为当前cwnd的一半：ssthresh = cwnd / 2，然后重新进入慢开始阶段。\n如果发送端接收到了三个重复的ACK请求（证明当前的网络也不太好，但是也没拥塞那么严重），那么会进入快重传+快恢复阶段\n\n\n快重传：要求接收方立即发送确，\n\n即使收到了失序的报文段，也要立即发出对已收到的报文段的重复确认\n发送确认也不要等缓存区满再发了，加急直接发\n\n\n快恢复：cwnd的初始值不是1了，而是ssthresh\n\n\n\n注意：\n问题1：什么时候会出现ssthresh = cwnd / 2呢？\n\n出现拥塞（即超时）\n收到3个连续的ACK请求\n\n问题2：如何判断出现了拥塞？\n\n丢包\n滑动窗口变小\nACK延迟或是重复出现\n\nCLOSING状态TCP还有一个CLOSING状态：\n在「同时关闭」的情况下出现。\n这里的同时关闭中的「同时」其实并不是时间意义上的同时，而是指的是在发送 FIN 包还未收到确认之前，收到了对端的 FIN 的情况。\n\n所以TCP总共含有11种状态，CLOSING状态之后会进入TIME_WAIT状态\n\n关于CLOSE_WAIT与TIME_WAIT状态\n问题1：CLOSE_WAIT与TIME_WAIT是谁的状态？\n\nTCP是全双工协议，TIME_WAIT是主动关闭者的状态，CLOSE_WAIT是被关闭者的状态，不能简单的认为前者是客户端的，后者是服务器的。\n\n问题2：TIME_WAIT状态的作用？\n\n进入TIME_WAIT状态后，会等待2MSL自动关闭\n1、保证确认关闭的ACK请求发送给了对方\n2、避免历史数据被下一个相同的四元组连接接收到\n\n问题3：如果服务器出现了大量的TIME_WAIT状态，有什么危害？可能是什么原因？\n\n摘自知乎专栏\n如果服务器出现了大量的TIME_WAIT状态，会占用服务器的内存、文件描述符、端口号。\n可能的原因有几点：\n\nHTTP没有使用长连接：\n比如使用的版本是1.0\n请求头Connection:close：这种情况下，无论是谁先主动断开的连接，都会算作服务端主动关闭连接\n\n\nHTTP长连接超时：长连接的超时时间是60s，到时间就会关闭连接\nHTTP长连接的请求数量达到了上限：超过最大限制时，就会主动关闭连接\n\n如何排查呢？\n\n看看是不是都开启了keep-alive，有一个没开启都算服务器主动关闭\n网络是否有问题？\n长连接的请求上限设置的是否合理\n\n\n问题4：如果服务器出现了大量的CLOSE_WAIT状态，可能的原因是什么？\n\n当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接\n（一般都是代码的问题：比如这个link）\n需要对着步骤进行分析：\n\n服务端创建socket，bind、listen\n将socket注册到epoll，epoll_ctl设置关心的操作，并切入内核，将红黑树和双向链表copy过去\nepoll_wait等待事件\n事件发生，调用accept接收连接：\n连接到来时，netty 「忘了」调用 accept 把连接从内核的全连接队列里取走。\n这里的「忘」可能是因为逻辑 bug 或者 netty 忙于其他事情没有时间取走\n\n\n注册新的连接EPOLLIN、EPOLLERR、EPOLLHUP的事件到epoll：\nnetty取走了连接，三次握手真正完成，但是没有注册新连接的后续事件，导致后面收到了 fin 包以后无动于衷\n\n\n继续epoll_wait\n\n","categories":["计算机网络","运输层"],"tags":["计算机网络","运输层","TCP","UDP"]},{"title":"Elasticsearch学习指南","url":"/2025/08/04/Es/Elasticsearch%E5%AE%8C%E5%85%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/","content":" \n学一下ES，另外这篇博客Cursor写的\n\n\n\n\nElasticsearch学习指南目录概览本指南分为五个主要部分，逐步深入Elasticsearch的学习：\n\n基础入门 - ES核心概念与基础操作\n查询分析 - 高级查询与数据分析技术\n系统优化 - 性能优化与集群运维\n高级搜索 - 人性化搜索功能与企业级应用\n核心原理 - 底层机制与性能原理深度剖析\n\n\n第一部分：基础入门什么是Elasticsearch？Elasticsearch是一个基于Apache Lucene构建的分布式搜索和分析引擎，专门用于处理大量数据的实时搜索、分析和可视化。\n核心特性&#123;  &quot;分布式架构&quot;: &quot;多节点集群，自动分片和复制&quot;,  &quot;RESTful API&quot;: &quot;HTTP请求操作，简单易用&quot;,  &quot;JSON文档&quot;: &quot;灵活的数据结构&quot;,  &quot;近实时搜索&quot;: &quot;数据写入后几乎立即可搜索&quot;,  &quot;强大分析&quot;: &quot;支持复杂的聚合查询&quot;&#125;\n\n应用场景\n\n\n场景\n具体应用\n典型案例\n\n\n\n搜索引擎\n全文搜索、商品搜索\n淘宝商品搜索、知乎文章搜索\n\n\n日志分析\n系统监控、错误分析\nELK日志分析平台\n\n\n实时分析\n用户行为、业务指标\n网站访问统计、销售数据分析\n\n\n地理搜索\n位置服务、配送范围\n外卖应用、地图服务\n\n\n核心概念基本术语对比\n\n\nElasticsearch\n关系数据库\n说明\n\n\n\nIndex\nDatabase\n索引，类似数据库\n\n\nDocument\nRow\n文档，JSON格式的数据记录\n\n\nField\nColumn\n字段，文档中的属性\n\n\nMapping\nSchema\n映射，定义字段类型和属性\n\n\n索引与文档的关系索引(Index) = 一个业务领域的数据集合└── 文档(Document) = 具体的数据记录    ├── 字段1: 值1    ├── 字段2: 值2    └── 字段3: 值3\n\n为什么ES中的“数据库”被称为”索引”？ES中的”索引”概念继承自搜索引擎领域，具有双重含义：\n\n数据容器：类似关系数据库的Database，存储相关数据的逻辑集合\n搜索索引：基于倒排索引的快速检索数据结构\n\n这种命名体现了ES作为搜索引擎的本质特征。详细原理请参考第五部分。\nMapping映射详解Mapping是ES的核心概念，定义了文档的结构和字段属性。\n基本语法&#123;  &quot;mappings&quot;: &#123;           // 固定关键字：映射定义    &quot;properties&quot;: &#123;       // 固定关键字：字段容器      &quot;字段名&quot;: &#123;        &quot;type&quot;: &quot;数据类型&quot;,        &quot;其他属性&quot;: &quot;值&quot;      &#125;    &#125;  &#125;&#125;\n\n常用数据类型&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;&#125;,      // 全文搜索      &quot;status&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;,  // 精确匹配      &quot;price&quot;: &#123;&quot;type&quot;: &quot;float&quot;&#125;,     // 浮点数      &quot;count&quot;: &#123;&quot;type&quot;: &quot;integer&quot;&#125;,   // 整数      &quot;published&quot;: &#123;&quot;type&quot;: &quot;date&quot;&#125;,  // 日期      &quot;active&quot;: &#123;&quot;type&quot;: &quot;boolean&quot;&#125;   // 布尔值    &#125;  &#125;&#125;\n\ntext vs keyword的区别核心差异：\n\ntext: 会分词，支持模糊搜索\nkeyword: 不分词，只支持精确匹配\n\n&#123;  &quot;示例对比&quot;: &#123;    &quot;原文&quot;: &quot;计算机科学&quot;,    &quot;text处理&quot;: [&quot;计算机&quot;, &quot;科学&quot;],  // 分词后可搜索&quot;计算机&quot;    &quot;keyword处理&quot;: [&quot;计算机科学&quot;]   // 必须完整匹配&quot;计算机科学&quot;  &#125;&#125;\n\n基础操作实战RESTful API路径规范Elasticsearch遵循RESTful设计，所有操作都通过HTTP请求完成。理解API路径规律是掌握ES的关键。\n基本路径结构http://host:port/&#123;index_name&#125;/&#123;api_type&#125;/&#123;document_id&#125;                  ↑           ↑           ↑                索引名     API类型      文档ID(可选)\n\n常用API路径一览\n\n\n操作类型\nHTTP方法\n路径格式\n说明\n\n\n\n索引管理\n\n\n\n\n\n创建索引\nPUT\n/&#123;index_name&#125;\n创建新索引\n\n\n删除索引\nDELETE\n/&#123;index_name&#125;\n删除整个索引\n\n\n查看索引\nGET\n/&#123;index_name&#125;\n获取索引信息\n\n\n文档操作\n\n\n\n\n\n添加文档(指定ID)\nPUT\n/&#123;index_name&#125;/_doc/&#123;doc_id&#125;\n指定文档ID\n\n\n添加文档(自动ID)\nPOST\n/&#123;index_name&#125;/_doc\n系统自动生成ID\n\n\n更新文档(全量)\nPUT\n/&#123;index_name&#125;/_doc/&#123;doc_id&#125;\n完全替换文档\n\n\n更新文档(部分)\nPOST\n/&#123;index_name&#125;/_update/&#123;doc_id&#125;\n部分字段更新\n\n\n删除文档\nDELETE\n/&#123;index_name&#125;/_doc/&#123;doc_id&#125;\n删除指定文档\n\n\n查询操作\n\n\n\n\n\n根据ID查询\nGET\n/&#123;index_name&#125;/_doc/&#123;doc_id&#125;\n精确ID查询\n\n\n简单搜索\nGET\n/&#123;index_name&#125;/_search\n基础搜索\n\n\n复杂搜索\nPOST\n/&#123;index_name&#125;/_search\n复杂查询条件\n\n\n全库搜索\nGET\n/_search\n搜索所有索引\n\n\n批量操作\n\n\n\n\n\n批量处理\nPOST\n/_bulk\n批量增删改\n\n\n路径参数示例# 示例解析PUT http://localhost:9200/students/_doc/1#    ↑                    ↑        ↑     ↑#   协议://主机:端口      索引名   API类型 文档IDPOST http://localhost:9200/students/_search#                          ↑        ↑#                        索引名   搜索API\n\n补充一些特殊的API路径# 集群管理GET /_cluster/health         # 集群健康状态GET /_cat/indices            # 查看所有索引GET /_cat/nodes              # 查看所有节点# 索引模板和别名GET /_template               # 查看索引模板GET /_alias                  # 查看索引别名# 统计信息GET /_stats                  # 全局统计GET /students/_stats         # 特定索引统计\n\n创建索引demo# 创建学生信息索引curl -X PUT &quot;localhost:9200/students&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;name&quot;: &#123;&quot;type&quot;: &quot;text&quot;&#125;,      &quot;age&quot;: &#123;&quot;type&quot;: &quot;integer&quot;&#125;,      &quot;major&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;,      &quot;gpa&quot;: &#123;&quot;type&quot;: &quot;float&quot;&#125;,      &quot;created_at&quot;: &#123;&quot;type&quot;: &quot;date&quot;&#125;    &#125;  &#125;&#125;&#x27;\n\n添加文档demo# 添加学生记录curl -X PUT &quot;localhost:9200/students/_doc/1&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;name&quot;: &quot;张三&quot;,  &quot;age&quot;: 20,  &quot;major&quot;: &quot;计算机科学&quot;,  &quot;gpa&quot;: 3.8,  &quot;created_at&quot;: &quot;2024-01-15&quot;&#125;&#x27;\n\n基础查询demo# 1. 查询所有文档curl -X GET &quot;localhost:9200/students/_search&quot;# 2. 根据ID查询curl -X GET &quot;localhost:9200/students/_doc/1&quot;# 3. 按名字搜索curl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;&quot;name&quot;: &quot;张三&quot;&#125;  &#125;&#125;&#x27;# 4. 范围查询（GPA &gt; 3.5）curl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;    &quot;range&quot;: &#123;&quot;gpa&quot;: &#123;&quot;gte&quot;: 3.5&#125;&#125;  &#125;&#125;&#x27;\n\n\n第二部分：查询分析复合查询（Bool Query）Bool查询是ES最强大的查询类型，可以组合多个查询条件。\n四种查询条件&#123;  &quot;query&quot;: &#123;    &quot;bool&quot;: &#123;      &quot;must&quot;: [],     // 必须匹配（AND），参与评分      &quot;filter&quot;: [],   // 必须匹配（AND），不参与评分，性能更好      &quot;should&quot;: [],   // 应该匹配（OR）      &quot;must_not&quot;: []  // 必须不匹配（NOT）    &#125;  &#125;&#125;\n\n实战示例# 复杂组合查询：年龄20-25岁，专业为&quot;计算机科学&quot;或&quot;数据科学&quot;，GPA不低于3.0curl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;    &quot;bool&quot;: &#123;      &quot;filter&quot;: [        &#123;&quot;range&quot;: &#123;&quot;age&quot;: &#123;&quot;gte&quot;: 20, &quot;lte&quot;: 25&#125;&#125;&#125;      ],      &quot;should&quot;: [        &#123;&quot;term&quot;: &#123;&quot;major&quot;: &quot;计算机科学&quot;&#125;&#125;,        &#123;&quot;term&quot;: &#123;&quot;major&quot;: &quot;数据科学&quot;&#125;&#125;      ],      &quot;must_not&quot;: [        &#123;&quot;range&quot;: &#123;&quot;gpa&quot;: &#123;&quot;lt&quot;: 3.0&#125;&#125;&#125;      ],      &quot;minimum_should_match&quot;: 1    &#125;  &#125;&#125;&#x27;\n\n聚合分析聚合查询用于数据统计和分析，提供了强大的数据洞察能力。\n聚合分为指标聚合（计算数值）和桶聚合（分组统计），可以灵活组合使用。详细原理请参考第五部分。\n指标聚合# 计算平均GPA和多项统计curl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;aggs&quot;: &#123;    &quot;avg_gpa&quot;: &#123;      &quot;avg&quot;: &#123;&quot;field&quot;: &quot;gpa&quot;&#125;    &#125;,    &quot;gpa_stats&quot;: &#123;      &quot;stats&quot;: &#123;&quot;field&quot;: &quot;gpa&quot;&#125;    &#125;  &#125;,  &quot;size&quot;: 0&#125;&#x27;\n\n桶聚合# 按专业分组统计，并计算每组平均GPAcurl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;aggs&quot;: &#123;    &quot;major_analysis&quot;: &#123;      &quot;terms&quot;: &#123;&quot;field&quot;: &quot;major&quot;&#125;,      &quot;aggs&quot;: &#123;        &quot;avg_gpa&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;gpa&quot;&#125;&#125;      &#125;    &#125;  &#125;,  &quot;size&quot;: 0&#125;&#x27;\n\n排序与分页多字段排序# 按GPA降序，年龄升序排列curl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;,  &quot;sort&quot;: [    &#123;&quot;gpa&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;,    &#123;&quot;age&quot;: &#123;&quot;order&quot;: &quot;asc&quot;&#125;&#125;  ]&#125;&#x27;\n\n分页策略ES提供两种分页方式：from/size适合小数据量，search_after适合大数据量。深分页会导致性能问题，建议大数据量场景使用search_after。详细原理请参考第五部分。\n小数据量：from/size分页\ncurl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;,  &quot;from&quot;: 10,  &quot;size&quot;: 10,  &quot;sort&quot;: [&#123;&quot;gpa&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;]&#125;&#x27;\n\n大数据量：search_after分页（推荐）\ncurl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;,  &quot;size&quot;: 10,  &quot;sort&quot;: [    &#123;&quot;gpa&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;,    &#123;&quot;_id&quot;: &#123;&quot;order&quot;: &quot;asc&quot;&#125;&#125;  ],  &quot;search_after&quot;: [3.8, &quot;student_id_123&quot;]&#125;&#x27;\n\n高亮搜索高亮功能可以在搜索结果中突出显示匹配的关键词。\n# 搜索并高亮姓名字段curl -X POST &quot;localhost:9200/students/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;&quot;name&quot;: &quot;张&quot;&#125;  &#125;,  &quot;highlight&quot;: &#123;    &quot;pre_tags&quot;: [&quot;&lt;mark&gt;&quot;],    &quot;post_tags&quot;: [&quot;&lt;/mark&gt;&quot;],    &quot;fields&quot;: &#123;      &quot;name&quot;: &#123;&#125;    &#125;  &#125;&#125;&#x27;\n\n\n第三部分：系统优化核心参数详解掌握ES的核心参数是进行高级优化的基础，按功能分为以下几类：\n核心参数默认值一览了解参数默认值有助于理解ES的默认行为和优化方向：\n字段级别参数默认值\n\n\n参数名\n默认值\n数据类型适用\n说明\n\n\n\nindex\ntrue\n所有类型\n字段可被搜索\n\n\nstore\nfalse\n所有类型\n不独立存储字段值\n\n\ndoc_values\ntrue\nkeyword, numeric, date等\n支持排序和聚合\n\n\nnorms\ntrue\ntext字段\n启用长度归一化（评分用）\n\n\neager_global_ordinals\nfalse\nkeyword字段\n不预计算聚合\n\n\nfielddata\nfalse\ntext字段\n禁用内存聚合\n\n\nignore_above\n256\nkeyword字段\n超长字符串截断长度\n\n\nnull_value\nnull\n所有类型\n空值不索引\n\n\ncoerce\ntrue\nnumeric字段\n自动类型转换\n\n\nboost\n1.0\n所有类型\n字段权重系数\n\n\n索引级别参数默认值\n\n\n参数名\n默认值\n说明\n\n\n\nrefresh_interval\n1s\n数据刷新间隔\n\n\nnumber_of_shards\n1\n主分片数量\n\n\nnumber_of_replicas\n1\n副本分片数量\n\n\nmax_result_window\n10000\nfrom+size最大值\n\n\nmax_rescore_window\n10000\n重评分窗口大小\n\n\n集群级别参数默认值\n\n\n参数名\n默认值\n说明\n\n\n\ncluster.routing.allocation.disk.watermark.low\n85%\n磁盘使用率低水位线\n\n\ncluster.routing.allocation.disk.watermark.high\n90%\n磁盘使用率高水位线\n\n\nindices.memory.index_buffer_size\n10%\n索引缓冲区大小\n\n\nthread_pool.write.queue_size\n200\n写入队列大小\n\n\n分析器默认值\n\n\n参数名\n默认值\n说明\n\n\n\nanalyzer\nstandard\n默认分析器\n\n\nsearch_analyzer\n同analyzer\n搜索时分析器\n\n\nnormalizer\n无\nkeyword字段标准化器\n\n\n字段索引控制index参数 - 控制字段是否可搜索\n&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;title&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,        &quot;index&quot;: true     // 可搜索      &#125;,      &quot;internal_data&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,         &quot;index&quot;: false    // 只存储，不可搜索，节省空间      &#125;    &#125;  &#125;&#125;\n\nstore参数 - 控制字段独立存储\n&#123;  &quot;summary&quot;: &#123;    &quot;type&quot;: &quot;text&quot;,    &quot;store&quot;: true       // 独立存储，快速访问  &#125;&#125;\n\n分析器配置analyzer和search_analyzer - 分别控制索引和搜索时的分词器\n&#123;  &quot;product_name&quot;: &#123;    &quot;type&quot;: &quot;text&quot;,    &quot;analyzer&quot;: &quot;ik_max_word&quot;,      // 索引时精细分词    &quot;search_analyzer&quot;: &quot;ik_smart&quot;   // 搜索时智能分词  &#125;&#125;\n\n多字段映射fields参数 - 一个字段多种用途\n&#123;  &quot;title&quot;: &#123;    &quot;type&quot;: &quot;text&quot;,               // 主字段：全文搜索    &quot;fields&quot;: &#123;      &quot;keyword&quot;: &#123;                // 子字段：精确匹配        &quot;type&quot;: &quot;keyword&quot;,        &quot;ignore_above&quot;: 256      &#125;,      &quot;suggest&quot;: &#123;                // 子字段：自动补全        &quot;type&quot;: &quot;completion&quot;      &#125;    &#125;  &#125;&#125;\n\n性能优化参数doc_values - 控制列式存储（用于排序、聚合）\n&#123;  &quot;user_id&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;,    &quot;doc_values&quot;: false    // 纯ID字段，禁用节省空间  &#125;&#125;\n\neager_global_ordinals - 预计算聚合性能\n&#123;  &quot;category&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;,    &quot;eager_global_ordinals&quot;: true    // 经常聚合的字段启用  &#125;&#125;\n\n索引优化批量索引配置\n# 临时优化设置（批量导入时）curl -X PUT &quot;localhost:9200/my_index/_settings&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;refresh_interval&quot;: -1,        // 禁用自动刷新  &quot;number_of_replicas&quot;: 0        // 临时移除副本&#125;&#x27;# 批量导入后恢复设置curl -X PUT &quot;localhost:9200/my_index/_settings&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;refresh_interval&quot;: &quot;1s&quot;,  &quot;number_of_replicas&quot;: 1&#125;&#x27;\n\n查询优化filter查询比must查询性能更好，因为filter不计算评分且支持查询缓存。过滤场景优先使用filter，搜索排序场景使用must。详细性能原理请参考第五部分。\n使用filter替代must（性能更好）\n&#123;  &quot;优化前&quot;: &#123;    &quot;query&quot;: &#123;      &quot;bool&quot;: &#123;        &quot;must&quot;: [          &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123;&quot;gte&quot;: 100&#125;&#125;&#125;,          &#123;&quot;term&quot;: &#123;&quot;status&quot;: &quot;active&quot;&#125;&#125;        ]      &#125;    &#125;  &#125;,  &quot;优化后&quot;: &#123;    &quot;query&quot;: &#123;      &quot;bool&quot;: &#123;        &quot;filter&quot;: [          &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123;&quot;gte&quot;: 100&#125;&#125;&#125;,          &#123;&quot;term&quot;: &#123;&quot;status&quot;: &quot;active&quot;&#125;&#125;        ]      &#125;    &#125;  &#125;&#125;\n\n性能优化总结ES性能优化SOP：\n\n 先分析业务场景和数据特征\n再根据读写比例确定优化重点\n最后通过监控验证优化效果\n\n性能优化策略：\n\n存储优化: “禁用不需要的功能（index、doc_values、norms、store）\n查询优化”: “预计算高频操作（eager_global_ordinals）+ 合理缓存\n写入优化”: “批量操作时临时调整refresh_interval和副本数\n集群优化”: “合理分片 + 充足资源 + 监控水位线\n\nES参数汇总表：\n1、存储空间优化参数\n\n\n\n参数名\n级别\n默认值\n优化建议\n性能收益\n使用场景\n\n\n\nindex\n字段级\ntrue\n不需要搜索的字段设为false\n减少20-50%存储空间\n纯展示字段、内部ID\n\n\nstore\n字段级\nfalse\n高频访问字段设为true\n减少30-70%IO开销\n大文档的部分字段查询\n\n\ndoc_values\n字段级\ntrue\n不聚合排序的字段设为false\n减少10-30%存储空间\n纯搜索字段、过滤字段\n\n\nnorms\n字段级\ntrue\n不需要评分的text字段设为false\n减少评分计算开销\nkeyword化的text字段\n\n\nignore_above\n字段级\n256\n根据实际数据调整\n避免超长字符串索引\nURL、描述等长文本字段\n\n\n_source\n索引级\nenabled\n大文档可禁用或过滤\n减少50-80%存储空间\n仅搜索不返回原文档\n\n\n2、查询性能优化参数\n\n\n\n参数名\n级别\n默认值\n优化建议\n性能收益\n使用场景\n\n\n\neager_global_ordinals\n字段级\nfalse\n高频聚合字段设为true\n减少50-90%聚合响应时间\n分类、标签等高频聚合字段\n\n\nfielddata\n字段级\nfalse\n谨慎启用，优先使用keyword\n支持text字段聚合\n无法改为keyword的遗留字段\n\n\nboost\n字段级\n1.0\n设置字段相关性权重\n提升搜索精度\n多字段搜索的权重调优\n\n\nrefresh_interval\n索引级\n1s\n批量导入时设为-1\n提升2-5倍写入性能\n批量数据导入场景\n\n\nmax_result_window\n索引级\n10000\n根据分页需求调整\n控制内存消耗\n深分页业务需求\n\n\n3、集群资源优化参数\n\n\n\n参数名\n级别\n默认值\n优化建议\n性能收益\n使用场景\n\n\n\nnumber_of_shards\n索引级\n1\n数据量(GB) ÷ 30GB\n提升并行查询性能\n大数据量索引\n\n\nnumber_of_replicas\n索引级\n1\n根据可用性需求调整\n平衡性能与可用性\n高可用vs性能权衡\n\n\nindices.memory.index_buffer_size\n集群级\n10%\n写入密集型调至15-20%\n提升写入性能\n高并发写入场景\n\n\nthread_pool.write.queue_size\n集群级\n200\n写入压力大时增加至1000\n减少写入拒绝\n写入峰值处理\n\n\ncluster.routing.allocation.disk.watermark.low/high\n集群级\n85%/90%\n根据磁盘容量规划调整\n避免分片重分布\n磁盘容量管理\n\n\n4、分析器性能参数\n\n\n\n参数名\n级别\n默认值\n优化建议\n性能收益\n使用场景\n\n\n\nanalyzer\n字段级\nstandard\n中文使用ik_max_word\n提升中文搜索效果\n中文内容搜索\n\n\nsearch_analyzer\n字段级\n同analyzer\n索引用ik_max_word，搜索用ik_smart\n平衡索引大小与搜索精度\n中文搜索优化\n\n\nnormalizer\n字段级\n无\nkeyword字段标准化处理\n提升精确匹配准确性\n大小写不敏感匹配\n\n\n集群管理节点角色配置# 主节点 - 负责集群管理node.roles: [master]node.name: master-node-1# 数据节点 - 负责数据存储和查询node.roles: [data, data_content, data_hot, data_warm]node.name: data-node-1# 协调节点 - 负责查询路由和结果聚合node.roles: []node.name: coordinating-node-1\n\n内存配置原则# JVM内存设置-Xms4g-Xmx4g                    # 堆内存不超过系统内存50%，最大32GB-XX:+UseG1GC              # 推荐G1垃圾收集器# ES配置bootstrap.memory_lock: true              # 锁定内存，避免交换indices.memory.index_buffer_size: 10%    # 索引缓冲区大小\n\n分片策略&#123;  &quot;分片设置原则&quot;: &#123;    &quot;分片大小&quot;: &quot;单个分片20-50GB最佳&quot;,    &quot;分片数量&quot;: &quot;数据量(GB) ÷ 30GB&quot;,    &quot;副本数量&quot;: &quot;至少1个副本保证高可用&quot;,    &quot;扩展规划&quot;: &quot;主分片数确定后无法修改，需预留空间&quot;  &#125;&#125;\n\n监控与运维关键监控指标# 集群健康状态curl -X GET &quot;localhost:9200/_cluster/health?pretty&quot;# 节点统计信息curl -X GET &quot;localhost:9200/_nodes/stats?pretty&quot;# 索引统计信息curl -X GET &quot;localhost:9200/_stats?pretty&quot;\n\n故障排查# 查看未分配分片原因curl -X GET &quot;localhost:9200/_cluster/allocation/explain?pretty&quot;# 查看慢查询日志tail -f /var/log/elasticsearch/slowlog.log# 查看热点线程curl -X GET &quot;localhost:9200/_nodes/hot_threads&quot;\n\n\n第四部分：高级搜索人性化搜索功能多字段智能搜索企业级搜索通常需要在多个字段中智能匹配用户输入。\n# 智能产品搜索 - 不同字段不同权重curl -X POST &quot;localhost:9200/products/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;    &quot;multi_match&quot;: &#123;      &quot;query&quot;: &quot;苹果手机&quot;,      &quot;fields&quot;: [        &quot;title^3&quot;,        // 标题权重最高        &quot;brand^2&quot;,        // 品牌权重高        &quot;description&quot;,    // 描述标准权重        &quot;tags^0.5&quot;       // 标签权重低      ],      &quot;type&quot;: &quot;best_fields&quot;,      &quot;minimum_should_match&quot;: &quot;75%&quot;    &#125;  &#125;,  &quot;highlight&quot;: &#123;    &quot;fields&quot;: &#123;      &quot;title&quot;: &#123;&#125;,      &quot;description&quot;: &#123;&quot;fragment_size&quot;: 100&#125;    &#125;  &#125;&#125;&#x27;\n\n容错搜索容错搜索基于编辑距离算法，自动纠正用户的拼写错误，提升搜索体验。详细算法原理请参考第五部分：高级搜索原理。\n# 模糊匹配 - 处理拼写错误curl -X POST &quot;localhost:9200/products/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;    &quot;multi_match&quot;: &#123;      &quot;query&quot;: &quot;iphne&quot;,     // 故意拼错      &quot;fields&quot;: [&quot;title&quot;, &quot;brand&quot;],      &quot;fuzziness&quot;: &quot;AUTO&quot;,  // 自动容错      &quot;prefix_length&quot;: 1,      &quot;max_expansions&quot;: 50    &#125;  &#125;&#125;&#x27;\n\n地理位置搜索地理搜索在O2O、外卖、地图应用中非常重要。\n地理数据建模# 创建餐厅索引curl -X PUT &quot;localhost:9200/restaurants&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;name&quot;: &#123;&quot;type&quot;: &quot;text&quot;&#125;,      &quot;location&quot;: &#123;&quot;type&quot;: &quot;geo_point&quot;&#125;,     // 地理坐标点      &quot;area&quot;: &#123;&quot;type&quot;: &quot;geo_shape&quot;&#125;,        // 地理形状      &quot;cuisine_type&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;,      &quot;rating&quot;: &#123;&quot;type&quot;: &quot;float&quot;&#125;    &#125;  &#125;&#125;&#x27;\n\n距离搜索# 搜索1公里内的餐厅，按距离排序curl -X POST &quot;localhost:9200/restaurants/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;query&quot;: &#123;    &quot;bool&quot;: &#123;      &quot;filter&quot;: &#123;        &quot;geo_distance&quot;: &#123;          &quot;distance&quot;: &quot;1km&quot;,          &quot;location&quot;: &#123;&quot;lat&quot;: 39.9042, &quot;lon&quot;: 116.4074&#125;        &#125;      &#125;    &#125;  &#125;,  &quot;sort&quot;: [    &#123;      &quot;_geo_distance&quot;: &#123;        &quot;location&quot;: &#123;&quot;lat&quot;: 39.9042, &quot;lon&quot;: 116.4074&#125;,        &quot;order&quot;: &quot;asc&quot;,        &quot;unit&quot;: &quot;m&quot;      &#125;    &#125;  ]&#125;&#x27;\n\n智能补全提供优秀搜索体验的关键功能。ES使用FST（有限状态转换器）数据结构实现高效的前缀匹配和补全建议。详细数据结构原理请参考第五部分：高级搜索原理。\n补全索引设计curl -X PUT &quot;localhost:9200/products_v2&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;title&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,        &quot;analyzer&quot;: &quot;ik_max_word&quot;,        &quot;fields&quot;: &#123;          &quot;suggest&quot;: &#123;            &quot;type&quot;: &quot;completion&quot;,    // 补全字段            &quot;analyzer&quot;: &quot;ik_max_word&quot;          &#125;        &#125;      &#125;    &#125;  &#125;&#125;&#x27;\n\n补全查询# 自动补全查询curl -X POST &quot;localhost:9200/products_v2/_search&quot; \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;  &quot;suggest&quot;: &#123;    &quot;title_suggest&quot;: &#123;      &quot;prefix&quot;: &quot;手&quot;,         // 用户输入的前缀      &quot;completion&quot;: &#123;        &quot;field&quot;: &quot;title.suggest&quot;,        &quot;size&quot;: 5,        &quot;skip_duplicates&quot;: true      &#125;    &#125;  &#125;&#125;&#x27;\n\n数据同步方案企业级应用需要保持主数据库与ES的同步。\n同步方案选择\n\n\n方案\n优点\n缺点\n适用场景\n\n\n\n定时全量\n简单可靠\n实时性差，资源消耗大\n小数据量，实时性要求不高\n\n\nMQ异步\n解耦，高可用\n架构复杂，一致性问题\n微服务架构，高并发\n\n\nCDC捕获\n实时性最高，无侵入\n技术门槛高，运维复杂\n企业级，实时性要求极高\n\n\nMQ异步同步实现// 数据同步消息@Datapublic class DataSyncMessage &#123;    private String operation;   // CREATE, UPDATE, DELETE    private String entityType;  // PRODUCT, ORDER, USER    private String entityId;    private Object data;    private Long timestamp;&#125;// 同步监听器@Component@RabbitListener(queues = &quot;product.sync.queue&quot;)@Slf4jpublic class ProductSyncListener &#123;        @Autowired    private ProductSearchService searchService;        @RabbitHandler    public void handleProductSync(DataSyncMessage message) &#123;        try &#123;            log.info(&quot;接收同步消息: &#123;&#125;&quot;, message);                        switch (message.getOperation()) &#123;                case &quot;CREATE&quot;:                case &quot;UPDATE&quot;:                    // 从数据库获取最新数据并同步到ES                    syncProductToES(message.getEntityId());                    break;                case &quot;DELETE&quot;:                    // 从ES删除文档                    searchService.deleteProduct(message.getEntityId());                    break;            &#125;                    &#125; catch (Exception e) &#123;            log.error(&quot;同步失败: &#123;&#125;&quot;, message, e);            throw new SyncException(&quot;数据同步失败&quot;, e);        &#125;    &#125;&#125;\n\n\n第五部分：核心原理理解Elasticsearch的底层原理是掌握高级优化和故障排查的关键。本部分深入剖析ES的核心机制。\nES技术架构与JVM核心技术栈Elasticsearch的技术基础：\n&#123;  &quot;开发语言&quot;: &quot;Java&quot;,  &quot;核心引擎&quot;: &quot;Apache Lucene 9.x&quot;,  &quot;运行环境&quot;: &quot;JVM (Java Virtual Machine)&quot;,  &quot;最低Java版本&quot;: &quot;JDK 11+&quot;,  &quot;推荐Java版本&quot;: &quot;OpenJDK 17 或 Oracle JDK 17&quot;&#125;\n\n为什么选择Java？Java技术栈的优势：\n&#123;  &quot;技术优势&quot;: &#123;    &quot;成熟稳定&quot;: &quot;Java生态成熟，大量企业级应用验证&quot;,    &quot;性能优秀&quot;: &quot;JIT编译器优化，长时间运行性能强劲&quot;,    &quot;内存管理&quot;: &quot;自动垃圾回收，减少内存泄漏风险&quot;,    &quot;跨平台&quot;: &quot;一次编写，到处运行，支持多种操作系统&quot;  &#125;,  &quot;Lucene继承&quot;: &#123;    &quot;历史原因&quot;: &quot;基于Apache Lucene，自然选择Java&quot;,    &quot;技术积累&quot;: &quot;继承Lucene的搜索算法和优化经验&quot;,    &quot;社区支持&quot;: &quot;Java搜索引擎生态完善&quot;  &#125;&#125;\n\n倒排索引原理什么是倒排索引？为什么叫”倒排”索引？传统数据库是”正向”的：文档ID → 包含的词汇倒排索引是”反向”的：词汇 → 包含该词的文档ID列表\n原始的数据会被ES进行分词处理，分词后，词为key，原文件地址为value，这样就形成了反向的映射。\n倒排索引结构：\n&#123;  &quot;原始文档&quot;: &#123;    &quot;doc1&quot;: &quot;我爱北京天安门&quot;,    &quot;doc2&quot;: &quot;北京欢迎你&quot;,     &quot;doc3&quot;: &quot;我爱祖国&quot;  &#125;,  &quot;倒排索引&quot;: &#123;    &quot;我&quot;: [&quot;doc1&quot;, &quot;doc3&quot;],    &quot;爱&quot;: [&quot;doc1&quot;, &quot;doc3&quot;],     &quot;北京&quot;: [&quot;doc1&quot;, &quot;doc2&quot;],    &quot;天安门&quot;: [&quot;doc1&quot;],    &quot;欢迎&quot;: [&quot;doc2&quot;],    &quot;你&quot;: [&quot;doc2&quot;],    &quot;祖国&quot;: [&quot;doc3&quot;]  &#125;&#125;\n\n倒排索引的优势：\n\n快速定位：通过词汇直接找到相关文档\n高效组合：多个词汇的交集、并集运算\n相关性评分：基于词频、逆文档频率等计算相关性\n\n倒排索引存储结构完整的倒排索引包含：\n&#123;  &quot;词汇字典&quot;: &#123;    &quot;作用&quot;: &quot;存储所有不重复的词汇&quot;,    &quot;结构&quot;: &quot;排序的词汇列表，支持快速查找&quot;,    &quot;优化&quot;: &quot;前缀压缩、增量编码&quot;  &#125;,  &quot;倒排列表&quot;: &#123;    &quot;作用&quot;: &quot;存储每个词汇对应的文档列表&quot;,    &quot;内容&quot;: [&quot;文档ID&quot;, &quot;词频TF&quot;, &quot;位置信息&quot;],    &quot;压缩&quot;: &quot;差值编码、变长编码&quot;  &#125;&#125;\n\n分片与副本原理分片设计目的分片（Shard）解决的核心问题：\n&#123;  &quot;分片解决的问题&quot;: &#123;    &quot;水平扩展&quot;: &quot;单机存储容量限制&quot;,    &quot;并行处理&quot;: &quot;多分片并行查询提高性能&quot;,    &quot;故障隔离&quot;: &quot;单分片故障不影响整体服务&quot;  &#125;,  &quot;分片类型&quot;: &#123;    &quot;主分片&quot;: &quot;Primary Shard - 负责写入和读取&quot;,    &quot;副本分片&quot;: &quot;Replica Shard - 主分片的完整副本&quot;  &#125;&#125;\n\n数据分布机制文档路由算法：\n# 文档路由公式shard_id = hash(document_id) % number_of_primary_shards# 示例：3个主分片的路由hash(&quot;doc1&quot;) % 3 = 1  # 文档分配到分片1hash(&quot;doc2&quot;) % 3 = 0  # 文档分配到分片0  hash(&quot;doc3&quot;) % 3 = 2  # 文档分配到分片2\n\n为什么主分片数创建后不能修改？因为文档路由依赖主分片数的哈希计算，修改分片数会导致所有文档路由错乱，必须重建索引。\n近实时搜索原理传统数据库 vs ES的实时性\n\n\n特性\n传统数据库\nElasticsearch\n\n\n\n写入方式\n立即写磁盘\n先写内存，定期刷盘\n\n\n搜索延迟\n无延迟\n1秒内（可配置）\n\n\n性能权衡\n写入慢，查询快\n写入快，微延迟搜索\n\n\nES实时搜索流程三个关键概念：\n&#123;  &quot;Buffer&quot;: &#123;    &quot;作用&quot;: &quot;内存缓冲区，临时存储新文档&quot;,    &quot;特点&quot;: &quot;写入速度快，但不可搜索&quot;  &#125;,  &quot;Refresh&quot;: &#123;    &quot;作用&quot;: &quot;将Buffer内容刷新为可搜索的Segment&quot;,    &quot;频率&quot;: &quot;默认1秒，可配置&quot;,    &quot;结果&quot;: &quot;数据变为可搜索状态&quot;  &#125;,  &quot;Flush&quot;: &#123;    &quot;作用&quot;: &quot;将Segment持久化到磁盘&quot;,    &quot;频率&quot;: &quot;默认30分钟或Translog达到512MB&quot;,    &quot;结果&quot;: &quot;数据永久保存&quot;  &#125;&#125;\n\n完整的写入和搜索流程：\n&#123;  &quot;写入流程&quot;: &#123;    &quot;步骤1&quot;: &quot;文档写入内存Buffer&quot;,    &quot;步骤2&quot;: &quot;同时写入Translog（事务日志）&quot;,    &quot;步骤3&quot;: &quot;每1秒refresh，Buffer → Segment（可搜索）&quot;,    &quot;步骤4&quot;: &quot;定期flush，Segment → 磁盘（持久化）&quot;  &#125;,  &quot;搜索流程&quot;: &#123;    &quot;步骤1&quot;: &quot;查询所有可搜索的Segment&quot;,    &quot;步骤2&quot;: &quot;合并多个Segment的结果&quot;,    &quot;步骤3&quot;: &quot;排序并返回最终结果&quot;  &#125;&#125;\n\n分词器原理分词器组成架构分词器（Analyzer）三层结构：两个filter，肉夹馍结构\n&#123;  &quot;分词器结构&quot;: &#123;    &quot;字符过滤器&quot;: &quot;Character Filter - 预处理文本（去HTML标签等）&quot;,    &quot;分词器&quot;: &quot;Tokenizer - 将文本拆分为词汇单元&quot;,     &quot;词汇过滤器&quot;: &quot;Token Filter - 后处理词汇（小写、停词等）&quot;  &#125;&#125;\n\n标准分词器工作流程处理流程示例：\n&#123;  &quot;示例文本&quot;: &quot;Hello World! ES-Learning.&quot;,  &quot;处理流程&quot;: &#123;    &quot;1. 字符过滤&quot;: &quot;Hello World! ES-Learning. (无变化，字符过滤的是html标签等内容)&quot;,    &quot;2. 分词处理&quot;: [&quot;Hello&quot;, &quot;World&quot;, &quot;ES&quot;, &quot;Learning&quot;],    &quot;3. 词汇过滤&quot;: [&quot;hello&quot;, &quot;world&quot;, &quot;es&quot;, &quot;learning&quot;],    &quot;4. 最终结果&quot;: [&quot;hello&quot;, &quot;world&quot;, &quot;es&quot;, &quot;learning&quot;]  &#125;&#125;\n\n中文分词特殊性中文分词的挑战：\n&#123;  &quot;中文分词挑战&quot;: &#123;    &quot;无明显分隔符&quot;: &quot;中文词汇之间没有空格分隔&quot;,    &quot;语义依赖&quot;: &quot;需要理解上下文确定词汇边界&quot;,    &quot;标准分词器&quot;: &quot;按字符拆分，效果差&quot;,    &quot;专业分词器&quot;: &quot;IK、jieba等，基于词典和算法&quot;  &#125;,  &quot;示例对比&quot;: &#123;    &quot;原文&quot;: &quot;我爱北京天安门&quot;,    &quot;标准分词&quot;: [&quot;我&quot;, &quot;爱&quot;, &quot;北&quot;, &quot;京&quot;, &quot;天&quot;, &quot;安&quot;, &quot;门&quot;],    &quot;IK分词&quot;: [&quot;我&quot;, &quot;爱&quot;, &quot;北京&quot;, &quot;天安门&quot;]  &#125;&#125;\n\n聚合原理聚合类型划分指标聚合（Metric Aggregations）\n\n定义：对一组文档进行数值计算，返回单个或多个数值结果\n特点：输入文档组 → 输出数值\n类型：单值指标（avg、sum、min、max）、多值指标（stats、percentiles）\n\n桶聚合（Bucket Aggregations）\n\n定义：根据条件将文档分组到不同的”桶”中\n特点：输入文档组 → 输出文档桶（可嵌套子聚合）\n类型：terms分组、range范围、date_histogram时间分组\n\n聚合执行原理聚合的执行过程：\n&#123;  &quot;聚合执行流程&quot;: &#123;    &quot;1. 文档收集&quot;: &quot;根据query条件收集匹配的文档&quot;,    &quot;2. 桶分组&quot;: &quot;按照桶聚合条件将文档分到不同桶中&quot;,    &quot;3. 指标计算&quot;: &quot;对每个桶内的文档执行指标聚合&quot;,    &quot;4. 结果合并&quot;: &quot;合并各分片的聚合结果&quot;,    &quot;5. 返回数据&quot;: &quot;返回最终的聚合统计结果&quot;  &#125;&#125;\n\n分页原理深分页问题根本原因from/size分页的性能问题：\n&#123;  &quot;问题分析&quot;: &#123;    &quot;from_size工作原理&quot;: &#123;      &quot;步骤1&quot;: &quot;每个分片都查询 from + size 条数据&quot;,      &quot;步骤2&quot;: &quot;协调节点收集所有分片的结果&quot;,       &quot;步骤3&quot;: &quot;全局排序后取 from 到 from+size 的数据&quot;,      &quot;步骤4&quot;: &quot;丢弃前 from 条数据，返回 size 条数据&quot;    &#125;,    &quot;性能损耗&quot;: &#123;      &quot;内存消耗&quot;: &quot;需要在内存中处理 from + size 条数据&quot;,      &quot;网络传输&quot;: &quot;每个分片传输 from + size 条数据&quot;,      &quot;CPU消耗&quot;: &quot;大量数据的排序和比较操作&quot;    &#125;  &#125;&#125;\n\nsearch_after原理基于游标的分页机制：\n&#123;  &quot;search_after原理&quot;: &#123;    &quot;工作机制&quot;: &#123;      &quot;无需跳过&quot;: &quot;不需要跳过前面的数据&quot;,      &quot;游标定位&quot;: &quot;基于上一页最后一条记录的排序值定位&quot;,      &quot;恒定性能&quot;: &quot;每次查询性能恒定，不随页数增加而降低&quot;    &#125;,    &quot;必要条件&quot;: &#123;      &quot;必须排序&quot;: &quot;query中必须包含sort字段&quot;,      &quot;唯一性保证&quot;: &quot;排序字段组合必须能唯一标识文档&quot;,      &quot;常用方案&quot;: &quot;业务字段 + _id 组合排序&quot;    &#125;  &#125;&#125;\n\n查询优化原理filter vs must 性能差异性能差异的根本原因：\n&#123;  &quot;性能差异分析&quot;: &#123;    &quot;must查询特点&quot;: &#123;      &quot;相关性评分&quot;: &quot;每个匹配的文档都需要计算_score&quot;,      &quot;TF-IDF算法&quot;: &quot;计算词频、逆文档频率、字段长度标准化&quot;,      &quot;排序影响&quot;: &quot;评分结果影响文档排序&quot;,      &quot;无法缓存&quot;: &quot;评分是动态计算的，结果难以缓存&quot;    &#125;,    &quot;filter查询特点&quot;: &#123;      &quot;不计算评分&quot;: &quot;_score始终为0，节省大量计算&quot;,      &quot;布尔判断&quot;: &quot;只判断匹配/不匹配，二进制结果&quot;,      &quot;查询缓存&quot;: &quot;结果可以缓存，重复查询极快&quot;,      &quot;位运算优化&quot;: &quot;内部使用BitSet进行快速位运算&quot;    &#125;  &#125;&#125;\n\n查询缓存机制filter查询的缓存机制：\n&#123;  &quot;filter缓存机制&quot;: &#123;    &quot;缓存对象&quot;: &quot;BitSet位图 - 每个文档一个bit标识匹配状态&quot;,    &quot;缓存条件&quot;: &quot;查询频率高、结果相对稳定的filter&quot;,    &quot;缓存淘汰&quot;: &quot;LRU算法，内存不足时淘汰最少使用的缓存&quot;,    &quot;缓存命中&quot;: &quot;相同filter查询直接返回缓存结果，无需重新计算&quot;,    &quot;缓存大小&quot;: &quot;默认最多缓存10000个filter查询&quot;  &#125;&#125;\n\n容错搜索原理模糊查询（Fuzzy Query）算法基础编辑距离（Levenshtein Distance）算法：\n&#123;  &quot;编辑距离定义&quot;: &#123;    &quot;概念&quot;: &quot;将一个字符串转换为另一个字符串所需的最少编辑操作次数&quot;,    &quot;操作类型&quot;: [&quot;插入字符&quot;, &quot;删除字符&quot;, &quot;替换字符&quot;],    &quot;示例&quot;: &#123;      &quot;cat → bat&quot;: &quot;1次操作（替换c为b）&quot;,      &quot;cat → cats&quot;: &quot;1次操作（插入s）&quot;,       &quot;cat → ca&quot;: &quot;1次操作（删除t）&quot;    &#125;  &#125;&#125;\n\nES模糊查询的工作流程：\n&#123;  &quot;模糊查询流程&quot;: &#123;    &quot;步骤1&quot;: &quot;用户输入查询词（如：&#x27;iphne&#x27;）&quot;,    &quot;步骤2&quot;: &quot;ES根据fuzziness参数确定最大编辑距离&quot;,    &quot;步骤3&quot;: &quot;在倒排索引中查找编辑距离范围内的所有词汇&quot;,    &quot;步骤4&quot;: &quot;计算每个匹配词的相似度得分&quot;,    &quot;步骤5&quot;: &quot;返回按相似度排序的结果&quot;  &#125;&#125;\n\nfuzziness参数详解AUTO模式的智能判断：\n&#123;  &quot;AUTO模式规则&quot;: &#123;    &quot;0-2个字符&quot;: &quot;不允许编辑（fuzziness=0）&quot;,    &quot;3-5个字符&quot;: &quot;允许1次编辑（fuzziness=1）&quot;,     &quot;6+个字符&quot;: &quot;允许2次编辑（fuzziness=2）&quot;  &#125;,  &quot;示例应用&quot;: &#123;    &quot;输入&#x27;go&#x27;&quot;: &quot;fuzziness=0，只匹配精确的&#x27;go&#x27;&quot;,    &quot;输入&#x27;cat&#x27;&quot;: &quot;fuzziness=1，可匹配&#x27;bat&#x27;, &#x27;car&#x27;, &#x27;cats&#x27;等&quot;,    &quot;输入&#x27;iphone&#x27;&quot;: &quot;fuzziness=2，可匹配&#x27;iphne&#x27;, &#x27;ipone&#x27;, &#x27;iphone&#x27;等&quot;  &#125;&#125;\n\n前缀长度和扩展限制prefix_length参数作用：\n&#123;  &quot;前缀长度优化&quot;: &#123;    &quot;目的&quot;: &quot;提高查询性能，减少候选词汇数量&quot;,    &quot;原理&quot;: &quot;要求前N个字符必须精确匹配&quot;,    &quot;示例&quot;: &#123;      &quot;prefix_length=2&quot;: &quot;&#x27;iphone&#x27; → 只考虑以&#x27;ip&#x27;开头的词汇&quot;,      &quot;性能提升&quot;: &quot;大幅减少需要计算编辑距离的词汇数量&quot;    &#125;  &#125;&#125;\n\nmax_expansions参数控制：\n&#123;  &quot;扩展数量限制&quot;: &#123;    &quot;目的&quot;: &quot;防止查询过于消耗资源&quot;,    &quot;默认值&quot;: &quot;50个候选词&quot;,    &quot;工作机制&quot;: &quot;找到50个匹配词后停止搜索&quot;,    &quot;权衡考虑&quot;: &quot;较小值提升性能，较大值提高召回率&quot;  &#125;&#125;\n\n容错搜索的性能优化性能影响因素：\n&#123;  &quot;性能考量&quot;: &#123;    &quot;计算复杂度&quot;: &quot;O(m*n)，m和n分别为两个字符串长度&quot;,    &quot;索引影响&quot;: &quot;需要遍历词汇字典计算编辑距离&quot;,    &quot;优化策略&quot;: &#123;      &quot;使用prefix_length&quot;: &quot;减少候选词数量&quot;,      &quot;控制max_expansions&quot;: &quot;限制计算量&quot;,      &quot;合理设置fuzziness&quot;: &quot;避免过度宽松的匹配&quot;    &#125;  &#125;&#125;\n\n智能补全原理Completion Suggester核心机制Finite State Transducer (FST) 数据结构：\n&#123;  &quot;FST数据结构&quot;: &#123;    &quot;定义&quot;: &quot;有限状态转换器，专门为前缀匹配优化的数据结构&quot;,    &quot;优势&quot;: &#123;      &quot;空间效率&quot;: &quot;相比Trie树节省50-80%内存&quot;,      &quot;查询速度&quot;: &quot;O(k)复杂度，k为前缀长度&quot;,      &quot;共享前缀&quot;: &quot;相同前缀的词汇共享存储路径&quot;    &#125;,    &quot;构建过程&quot;: &#123;      &quot;词汇排序&quot;: &quot;按字典序排列所有补全词汇&quot;,      &quot;路径共享&quot;: &quot;相同前缀合并为同一路径&quot;,      &quot;状态压缩&quot;: &quot;最小化状态数量&quot;    &#125;  &#125;&#125;\n\nFST vs 传统Trie树对比：\n\n\n\n特性\nTrie树\nFST\n\n\n\n内存使用\n高（每个节点独立）\n低（路径共享压缩）\n\n\n查询速度\nO(k)\nO(k)\n\n\n构建复杂度\n简单\n复杂（需排序和最小化）\n\n\n适用场景\n小数据集\n大数据集、生产环境\n\n\n补全查询的执行流程查询处理步骤：\n&#123;  &quot;补全查询流程&quot;: &#123;    &quot;1. 前缀匹配&quot;: &#123;      &quot;输入&quot;: &quot;用户输入前缀（如：&#x27;手&#x27;）&quot;,      &quot;处理&quot;: &quot;在FST中查找以该前缀开始的所有路径&quot;,      &quot;结果&quot;: &quot;获得候选词汇列表&quot;    &#125;,    &quot;2. 权重排序&quot;: &#123;      &quot;输入&quot;: &quot;候选词汇列表&quot;,      &quot;处理&quot;: &quot;根据每个词汇的权重（weight）进行排序&quot;,       &quot;结果&quot;: &quot;按相关性/热度排序的建议列表&quot;    &#125;,    &quot;3. 结果过滤&quot;: &#123;      &quot;输入&quot;: &quot;排序后的建议列表&quot;,      &quot;处理&quot;: &quot;应用size参数限制和skip_duplicates去重&quot;,      &quot;结果&quot;: &quot;最终的补全建议&quot;    &#125;  &#125;&#125;\n\n权重计算策略权重设置的常见策略：\n&#123;  &quot;权重策略&quot;: &#123;    &quot;搜索热度&quot;: &#123;      &quot;数据来源&quot;: &quot;历史搜索统计&quot;,      &quot;计算方式&quot;: &quot;搜索次数的对数值&quot;,      &quot;示例&quot;: &quot;weight = log(search_count + 1)&quot;    &#125;,    &quot;业务重要性&quot;: &#123;      &quot;数据来源&quot;: &quot;业务规则定义&quot;,      &quot;计算方式&quot;: &quot;分类权重 × 基础权重&quot;,      &quot;示例&quot;: &quot;热销商品权重 × 2&quot;    &#125;,    &quot;时间衰减&quot;: &#123;      &quot;数据来源&quot;: &quot;数据的新鲜度&quot;,      &quot;计算方式&quot;: &quot;基础权重 × 时间衰减因子&quot;,      &quot;示例&quot;: &quot;weight = base_weight × 0.9^days_old&quot;    &#125;  &#125;&#125;\n\n补全性能优化内存优化策略：\n&#123;  &quot;内存优化&quot;: &#123;    &quot;FST加载&quot;: &#123;      &quot;机制&quot;: &quot;FST存储在堆外内存（off-heap）&quot;,      &quot;优势&quot;: &quot;不占用JVM堆内存，不影响GC&quot;,      &quot;注意&quot;: &quot;重启节点时需要重新加载&quot;    &#125;,    &quot;数据压缩&quot;: &#123;      &quot;前缀共享&quot;: &quot;相同前缀的词汇共享存储&quot;,      &quot;后缀最小化&quot;: &quot;相同后缀也会合并&quot;,      &quot;压缩比&quot;: &quot;通常可达到50-80%的空间节省&quot;    &#125;  &#125;&#125;\n\n查询性能优化：\n&#123;  &quot;查询优化&quot;: &#123;    &quot;分片级并行&quot;: &quot;每个分片并行处理补全查询&quot;,    &quot;结果合并&quot;: &quot;协调节点合并各分片结果并重新排序&quot;,    &quot;缓存策略&quot;: &quot;频繁查询的前缀结果可被缓存&quot;,    &quot;性能指标&quot;: &quot;通常可达到&lt;10ms的响应时间&quot;  &#125;&#125;\n\n多语言补全支持中文补全的特殊处理：\n&#123;  &quot;中文补全挑战&quot;: &#123;    &quot;拼音支持&quot;: &#123;      &quot;需求&quot;: &quot;支持拼音首字母和全拼输入&quot;,      &quot;实现&quot;: &quot;使用拼音分析器预处理&quot;,      &quot;示例&quot;: &quot;&#x27;手机&#x27; → [&#x27;sj&#x27;, &#x27;shouji&#x27;, &#x27;shou&#x27;, &#x27;ji&#x27;]&quot;    &#125;,    &quot;多输入法&quot;: &#123;      &quot;全拼&quot;: &quot;shouji → 手机&quot;,      &quot;简拼&quot;: &quot;sj → 手机&quot;,       &quot;混合&quot;: &quot;shou机 → 手机&quot;    &#125;,    &quot;同音词处理&quot;: &#123;      &quot;问题&quot;: &quot;拼音相同的词汇竞争&quot;,      &quot;解决&quot;: &quot;结合权重和上下文进行排序&quot;    &#125;  &#125;&#125;\n\n术语概念深度解析为什么ES被称为”索引”？这是很多初学者的疑惑，让我们深入理解ES术语体系的历史演进：\n多重含义解析：\n&#123;  &quot;ES中索引的三重含义&quot;: &#123;    &quot;数据容器层面&quot;: &#123;      &quot;定义&quot;: &quot;Index = Database，存储相关数据的逻辑集合&quot;,      &quot;例子&quot;: &quot;创建students索引存储学生信息&quot;,      &quot;类比&quot;: &quot;MySQL中的database概念&quot;    &#125;,    &quot;搜索引擎层面&quot;: &#123;      &quot;定义&quot;: &quot;Index = 倒排索引，快速检索的数据结构&quot;,       &quot;例子&quot;: &quot;为每个字段构建倒排索引加速搜索&quot;,      &quot;类比&quot;: &quot;图书馆的索引目录&quot;    &#125;,    &quot;历史传承层面&quot;: &#123;      &quot;定义&quot;: &quot;继承Lucene搜索引擎的术语体系&quot;,      &quot;原因&quot;: &quot;ES基于Apache Lucene构建&quot;,      &quot;影响&quot;: &quot;保持与搜索引擎生态的术语一致性&quot;    &#125;  &#125;&#125;\n\n术语对比澄清：\n\n\n\nES术语\n数据库术语\n搜索引擎术语\n实际含义\n\n\n\nIndex\nDatabase\nInverted Index\n数据集合 + 搜索索引\n\n\nDocument\nRow\nDocument\nJSON格式的数据记录\n\n\nField\nColumn\nField\n文档中的属性字段\n\n\nMapping\nSchema\nMapping\n字段类型和属性定义\n\n\n设计哲学体现：\n&#123;  &quot;ES设计理念&quot;: &#123;    &quot;搜索为王&quot;: &quot;一切设计都围绕快速搜索展开&quot;,    &quot;倒排优先&quot;: &quot;每个字段都默认构建倒排索引&quot;,    &quot;近实时&quot;: &quot;数据写入后1秒内即可搜索&quot;,    &quot;分布式&quot;: &quot;天然支持水平扩展和高可用&quot;  &#125;&#125;\n\n这种命名方式强调了ES的核心价值：不仅是数据存储，更是高效的搜索引擎。\n\n实战总结最佳实践索引设计原则\n合理选择字段类型：text用于搜索，keyword用于过滤和聚合\n优化mapping配置：禁用不需要的功能（doc_values、norms等）\n设计合适的分片：单分片20-50GB，分片数=数据量÷30GB\n使用别名管理：便于索引重建和版本切换\n\n查询优化技巧\n优先使用filter：不需要评分的条件用filter，性能更好\n合理设置分页：大数据量使用search_after替代from/size\n控制聚合粒度：避免高基数字段的大量聚合\n启用查询缓存：重复查询使用request_cache\n\n生产环境配置# 关键配置建议cluster.name: production-clusternode.name: es-node-1# 内存设置bootstrap.memory_lock: true-Xms16g-Xmx16g# 性能优化indices.memory.index_buffer_size: 10%thread_pool.write.queue_size: 1000cluster.routing.allocation.disk.watermark.low: 85%cluster.routing.allocation.disk.watermark.high: 90%\n\n常见问题解决集群状态异常# 诊断分片分配问题curl -X GET &quot;localhost:9200/_cluster/allocation/explain?pretty&quot;# 查看未分配分片curl -X GET &quot;localhost:9200/_cat/shards?h=index,shard,state,unassigned.reason&amp;v&quot;\n\n性能问题排查# 查看慢查询tail -f /var/log/elasticsearch/slowlog.log# 分析热点线程curl -X GET &quot;localhost:9200/_nodes/hot_threads&quot;# 检查队列状态curl -X GET &quot;localhost:9200/_nodes/stats/thread_pool?pretty&quot;\n\n\n本指南涵盖了Elasticsearch从入门到精通的完整知识体系，建议收藏备用，在实际项目中遇到问题时可随时查阅。\n","categories":["elasticsearch"],"tags":["elasticsearch"]},{"title":"HTML5(Review)","url":"/2020/12/17/Html/Html(Review)/","content":"\n引言：\n\n马上考试啦、复习一下HTML\n\n\n\n\nHTML5(Review)web标准\nweb标准：W3C和其他标准化组织制定的一系列标准的集合。该标准用来创建和解释基于 Web 的内容，其网页部分的标准通过三部分来描述：结构、表现和行为\n\n\n结构标准：用于对网页元素进行整理和分类，主要包括两个部分：XML和XHTML。\n表现标准：用于设置网页元素的版式、颜色、大小等外观样式，主要指的是CSS。\n行为标准：指网页模型的定义及交互的编写，主要包括两个部分：DOM和ECMAScript\n\nHtml5\nHtml： Hyper Text Markup Language 超文本标记语言\n\n语法基础​        完整的HTML文件包括头部和主体两大部分。其文档结构由&lt;html&gt;、&lt;head&gt;和&lt;body&gt;这三大元素组成。\n\nhtml\nhead\nbody\n\n\n\n&lt;!DOCTYPE html&gt;\t\t// 文档声明类型，通知浏览器按照什么方式进行解析&lt;html&gt;    &lt;head&gt;        &lt;meta charset=&quot;UTF-8&quot;&gt;        &lt;title&gt;Document&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;    &lt;/body&gt;&lt;/html&gt;\n\n标签单标签有：&lt;br&gt;与&lt;hr&gt;与&lt;meta&gt;与&lt;link&gt;与&lt;input&gt;，可以加斜杠如&lt;br /&gt;\n大部分都为双标签\n注释&lt;!-- 这里是注释--&gt;&lt;comment&gt;注释信息&lt;/comment&gt;\n\n编写规范\n以&lt;开始，以&gt;结束\n可以嵌套、不可以交叉使用\n不区分大小写\n\nhead 头部相关标签\n&lt;title&gt;：设置网页标题（标题可以用作默认快捷方式或收藏夹的名称）\n\n一个网页只能有一个标题\n标题名称的长度不超过64个字符数\n标题标记对之间不允许有其它的标签存在\n\n\n&lt;meta&gt;：设置页面元信息\n&lt;meta charset=&quot;UTF-8&quot;&gt;\t设置编码方式&lt;meta http-equiv=&quot;&quot; content=&quot;&quot;&gt;&lt;meta name=&quot;&quot; content=&quot;&quot;&gt;\n\nhttp-equiv与content：设置页面相关属性\n&lt;meta http-equiv=&quot;refresh&quot; content=&quot;3&quot;&gt;\t//3s后刷新页面&lt;meta http-equiv=&quot;expires&quot; content=&quot;Fri,31 Dec 2021 08:00:00 GMT&quot;&gt;\t//设置过期时间&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;Charset=utf-8&quot;&gt;\t//设置文件内容&lt;meta http-equiv =“Set-Cookie” Content=&quot;cookievalue = xxx; expires= Thur,26 Jul 2018 08:00:00 GMT; path=/&quot;&gt;\t//设置cookie\n\nname与content：设置搜索引擎相关内容\n&lt;meta name=&quot;author&quot; content=&quot;dwh&quot;&gt;\t\t\t\t   // 设置作者&lt;meta name=&quot;description&quot; content=&quot;简介&quot;&gt;\t\t\t   //设置内容简介&lt;meta name=&quot;keywords&quot; content=&quot;关键词,时尚,购物&quot;&gt;\t//设置关键词&lt;meta name=&quot;generator&quot; content=&quot;Dreamweaver&quot;&gt;\t //设置编译器类型&lt;meta name=&quot;revised&quot; content=&quot;David,2008/8/8&quot;&gt;\t     //为搜索引擎提供最新版本\n&lt;link&gt;：引用外部文件\n&lt;link href=&quot;&quot; rel=&quot;&quot; type=&quot;&quot; /&gt;\thref：设置url\trel：设置当前文档与引用的外部文档的关系,stylesheet表示定义一个外部样式表\ttype：设置外部文档的类型\n\n&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;style.css&quot;&gt;&lt;link rel=&quot;shortcut icon&quot; type=&quot;image/ico&quot; href=&quot;图标路径&quot;&gt; //可以配置标题旁边的小图标\n&lt;style&gt;：写内联css样式文件\n\n\n基本标签标题段落标签&lt;h1 align=&quot;left&quot;&gt;1&lt;/h1&gt;&lt;h2 align=&quot;center&quot;&gt;2&lt;/h2&gt;&lt;h3 align=&quot;right&quot;&gt;3&lt;/h3&gt;&lt;h4 align=&quot;justify&quot;&gt;4&lt;/h4&gt;&lt;h5&gt;5&lt;/h5&gt;&lt;h6&gt;6&lt;/h6&gt;&lt;p&gt;段落标签&lt;/p&gt;\n\np&#123;    align: left;    align: right;    align: center;    align: justify;&#125;// align一般有四个值，左、右、居中、两端对齐\n\n这里用word表示一下居中和两端对齐的区别：\n\n\n\n\n文本格式标签&lt;br&gt;换行&lt;hr size=&quot;4&quot; width=&quot;100&quot; align=&quot;right&quot; noshade=&quot;noshade&quot; color=&quot;red&quot;&gt;水平线&lt;div&gt;块区域&lt;/div&gt;&lt;span&gt;行内标签&lt;/span&gt;&lt;font size=&quot;10&quot; face=&quot;宋体&quot; align=&quot;left&quot; color=&quot;blue&quot;&gt;设置字体&lt;/font&gt;&lt;b&gt;加粗&lt;/b&gt;&lt;i&gt;斜体&lt;/i&gt;&lt;big&gt;比周围文本大一个尺寸&lt;/big&gt;&lt;small&gt;比周围文本小一个尺寸&lt;/small&gt;&lt;s&gt;加一条删除线&lt;/s&gt;&lt;u&gt;加一条下划线&lt;/u&gt;&lt;sup&gt;上标&lt;/sup&gt;&lt;sub&gt;下标&lt;/sub&gt;&lt;strong&gt;加粗，语义强调&lt;/strong&gt;&lt;mark&gt;带有记号&lt;/mark&gt;\n\nspan与div的区别：\n\nspan是行内元素，不会换行；div是块级元素，会换行\nspan不能包div，反之可以\n\n特殊字符标签：&amp;开始，;结尾\n&amp;gt;\t小于&amp;copy;\t版权号\n\n\n\n图片标签图片格式：\n\nGIF\n\n支持动画\n无损图形格式\n支持透明\n常用于logo、小图标、色彩单一的图像\n\n\nPNG\n\n包括PNG-8和真色彩PNG（PNG-24和PNG-32）\n体积比gif小\n支持透明\n色彩过渡平滑\n不支持动画\n\n\nJPG\n\n色彩显示最全\n有损压缩\n\n\n\n小图片考虑GIF或PNG-8，半透明图像考虑PNG-24，类似照片的图像则考虑JPG\n&lt;!-- 图片标签 --&gt;&lt;img      src=&quot;https://uploadbeta.com/api/pictures/random/?key=BingEverydayWallpaperPicture&quot;      alt=&quot;图片加载中...&quot;      border=&quot;1px solid red&quot;     width=&quot;100&quot;     height=&quot;100&quot;     vspace=&quot;100&quot;     hspace=&quot;100&quot;     title=&quot;图片的说明&quot;     align=&quot;center&quot;      &gt;src：设置图片来源alt：设置加载中的文字title：设置鼠标提示文字width、height：设置图像的宽度与高度vspace、hspace：设置水平、垂直边缘的边距（设置的是margin值）\n\n\n\n超链接标签按链接路径不同分为三种：\n\n内部链接\n锚点链接\n外部链接\n\n链接的组成：\n\n链宿：要跳转的目标\n链源：引起跳转的原因\n\n&lt;!-- 超链接 --&gt;&lt;a    href=&quot;http://www.baidu.com&quot;   name=&quot;top&quot;   title=&quot;提示信息&quot;   target=&quot;_blank&quot;    &gt;链源&lt;/a&gt;&lt;a href=&quot;#top&quot;&gt;锚点链接&lt;/a&gt;href：链宿的路径name：创建文档内的书签（用于标记当前位置）title：提示信息target：指定打开的目标窗口，五个取值\tparent 上一级窗口；\tblank\t新窗口；\tself \t  同一窗口，默认值；       top     整个窗口打开；\tframename-框架名\n\n\n\n表格标签&lt;table border=&quot;1&quot;&gt;    &lt;caption&gt;标题&lt;/caption&gt;    &lt;tr&gt;        &lt;th&gt;表头1&lt;/th&gt;        &lt;td&gt;数据单元&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;        &lt;th&gt;表头2&lt;/th&gt;        &lt;td&gt;数据单元&lt;/td&gt;        &lt;td&gt;数据单元&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;        &lt;td&gt;数据单元&lt;/td&gt;        &lt;td&gt;数据单元&lt;/td&gt;    &lt;/tr&gt;&lt;/table&gt;\n\n\n\n表格样式：\ntable&#123;    border：设置边框    cellspacing：设置单元格与单元格边框之间的空白距离，默认为2px    cellpadding：设置单元格内部padding，默认为1px    width、height：设置表格宽度    align：设置对齐样式    bgcolor：设置表格背景颜色    background：设置背景图像    rules: 设置规定内侧边框的哪个部分是可见的。                none\t没有线条。                groups\t位于行组和列组之间的线条。                rows\t位于行之间的线条。                cols\t位于列之间的线条。                all\t位于行和列之间的线条。     frame: 规定外侧边框的哪个部分是可见的。        \t void\t不显示外侧边框。                above\t显示上部的外侧边框。                below\t显示下部的外侧边框。                hsides\t显示上部和下部的外侧边框。                vsides\t显示左边和右边的外侧边框。                lhs\t显示左边的外侧边框。                rhs\t显示右边的外侧边框。                box\t在所有四个边上显示外侧边框。                border\t在所有四个边上显示外侧边框。&#125;tr&#123;    height：设置行高度    align：设置一行内容的水平对齐方式\t取值left right center    valign：设置垂直方向上的对齐方式 取值 top middle bottom    bgcolor：设置表格背景颜色    background：设置行背景图像&#125;th,td&#123;    width、height：设置单元格宽度、高度    align：设置一行内容的水平对齐方式\t取值left right center    valign：设置垂直方向上的对齐方式 取值 top middle bottom    bgcolor：设置表格背景颜色    background：设置行背景图像    colspan：水平单元格合并，给数字即可    rowspan：垂直单元格合并，给数字即可&#125;\n\n设置表格边框的属性：\n&lt;table  frame=” ” rules=” ”&gt; &lt;/table &gt;\n\n\nHTML5HTML5 通过一些新标签，新功能为开发更加简单、独立、标准的通用Web应用提供了标准。有了新的结构性的标签的标准，可以让HTML文档更加清晰，可阅读性更强，更利于SEO，也更利于视障人士阅读。\n解决了三大问题：\n\n浏览器兼容问题\n解决了文档结构不明确的问题（旧版本的html使用div+自定义的id（例如&lt;div id=&quot;header&quot;&gt;，表示头部，但是语义并不明确），html5提供了新的页面标签）\n解决了Web应用程序功能受限等问题。\n\n结构元素&lt;header&gt;标签用于定义文章的页眉信息&lt;/header&gt;&lt;article&gt;    \t用于表示文档、页面或应用程序中独立的、完整的、可以独自被外部引用的内容，该内容可以是一篇文章、一篇短文、一个帖子或一个评论等&lt;/article&gt;&lt;aside&gt;    \t专门用于定义当前页面或当前文章的附属信息，包括当前页面或当前文章的相关引用、侧边栏、广告以及导航等有别于主体内容的部分&lt;/aside&gt;&lt;footer&gt;用于定义脚注部分，包括文章的版权信息、作者授权等信息。&lt;/footer&gt;&lt;figure&gt;    &lt;figcaption&gt;应该被置于 &quot;figure&quot; 元素的第一个或最后一个子元素的位置。&lt;/figcaption&gt;    \t表示网站制作页面上一块独立的内容，将其从网页上移除后不会对网页上的其他内容产生影响。figure所表示的内容可以是图片、统计图或代码示例。&lt;/figure&gt;\n\n页面节点&lt;!-- html5 页面节点 --&gt;&lt;section&gt;    用于定义文章的节，一般用于成节的内容，会在文档流中开始一个新的节。    它用来表现普通的文档内容或应用区块，通常由内容及其标题组成。&lt;/section&gt;&lt;nav&gt;    代表页面的一个部分，是一个可以作为页面导航的链接组，其中的导航元素链接到其它页面或者当前页面的其它部分，使html代码在语义化方面更加精确，同时对于屏幕阅读器等设备的支持也更好。&lt;/nav&gt;&lt;address&gt;    用于一般被作者用来提供该文档的联系人信息，一般放在一个网页的开头或者结尾，最常用的是和其他内容包含在footer元素内.    如果address元素位于article元素内部，则它表示article元素所包含文章内容的作者的联系信息    如果直接位于body元素内，那么表示该网页的作者的联系信息。&lt;/address&gt;\n\n交互元素progress表示页面中的某个任务完成的进度\n&lt;progress max=&quot;50&quot; value=&quot;25&quot;&gt;&lt;/progress&gt;max： 总数value：当前数量\n\n效果：\nmeter可用于投票系统中候选人各占比例情况及考试分数统计等\n&lt;meter value=&quot;0.6&quot;&gt;60%&lt;/meter&gt;&lt;meter max=&quot;100&quot; min=&quot;0&quot; high=&quot;80&quot; low=&quot;30&quot; value=&quot;10&quot;&gt;&lt;/meter&gt;&lt;meter max=&quot;100&quot; min=&quot;0&quot; high=&quot;80&quot; low=&quot;30&quot; value=&quot;40&quot;&gt;&lt;/meter&gt;&lt;meter max=&quot;100&quot; min=&quot;0&quot; high=&quot;80&quot; low=&quot;30&quot; value=&quot;80&quot;&gt;&lt;/meter&gt;form：规定meter元素所属的一个或多个表单high、low：规定视作高、低的值的范围（必需大于或小于此值才会改变颜色，不能正好等于）max、min：规定最大最小值optimum：规定度量的优化值value：必需的值，规定当前值\n\n效果：\n60%\n\ndetails用于说明文档的详细信息。在特定的浏览器下(如Chrome、 Safari ）能够产生像手风琴一样展开和折叠的交互效果。&lt;summary&gt;元素包含于 &lt; details &gt;元素中，用来说明其的标题。\n&lt;details&gt;    &lt;summary&gt;第二级目录&lt;/summary&gt;    &lt;p&gt;关于HTML5 Summary元素的介绍&lt;/p&gt;&lt;/details&gt;&lt;details draggable=&quot;true&quot; open=&quot;open&quot;&gt;    &lt;summary&gt;第三级目录&lt;/summary&gt;    &lt;p&gt;关于HTML5 Summary元素的介绍&lt;/p&gt;&lt;/details&gt;details属性：open：控制details元素是否显示，默认不可见subject：设置元素对应的项目id号draggable：true、false是否可拖动元素\n\n效果：\n\n    第二级目录\n    关于HTML5 Summary元素的介绍\n\n\n  &lt;details draggable=&quot;true&quot; open=&quot;open&quot;&gt;\n    &lt;summary&gt;第三级目录&lt;/summary&gt;\n    &lt;p&gt;关于HTML5 Summary元素的介绍&lt;/p&gt;\n&lt;/details&gt;\n\nmenu（了解）重新启用的一个旧标记。\n该元素Menu是一系列菜单命令的集合，在一个容器中，Menu元素用于创建上下文、工具栏和弹出菜单。然而，后面的两个功能还没有浏览器实现，包括FireFox\n目前所有主流浏览器都不支持&lt;menu&gt;标签。\n&lt;menu type=&quot;toolbar&quot; id=&quot;myMenu&quot;&gt;    &lt;menuitem label=&quot;单击一下&quot; onclick=&quot;alert(&#x27;您单击了我一下&#x27;)&quot; icon=&quot;&quot;&gt;&lt;/menuitem&gt;&lt;/menu&gt;属性：\tlabel：规定菜单的可见标签\ttype：规定要显示哪种菜单类型\t\tcontext、toolbar、popup\n\ncommand(了解)定义各种类型的命令按钮。\n利用该标记的“url”属性可以添加图片，并且实现图片按钮效果；\n另外，改变标记中的“type”属性值，还可以定义复选框或单选框按钮。\n只有当command 元素位于menu 元素内时，该元素才是可见的。\n没有浏览器支持  标签。\n只有 Internet Explorer 9 （更早或更晚的版本都不支持）支持  标签。\n\n文本层次语义元素&lt;!-- HTML5 文本层次语义元素 --&gt;&lt;em&gt;强调的内容&lt;/em&gt;&lt;strong&gt;语气更强的强调&lt;/strong&gt;&lt;dfn&gt;定义项目&lt;/dfn&gt;&lt;code&gt;int a = 3;&lt;/code&gt;//计算机代码文本&lt;samp&gt;样本文本&lt;/samp&gt;&lt;kbd&gt;CTRL&lt;/kbd&gt;//表示键盘内容&lt;var&gt;a&lt;/var&gt;//定义变量&lt;cite&gt;引用&lt;/cite&gt;&lt;time datetime=&quot;2008-02-14&quot;&gt;情人节&lt;/time&gt; \t两个属性：\t\t1. datetime：规定日期/时间\t\t2. pubdate：指示 time 元素中的日期 / 时间是文档（或 article 元素）的发布日期。\n\n强调的内容语气更强的强调定义项目int a = 3;样本文本CTRLa引用\n情人节 \n分组元素&lt;!-- 分组元素 --&gt;&lt;div&gt;无语义的通用元素&lt;/div&gt;&lt;blockquote&gt;表示摘自另一个源的大段内容&lt;/blockquote&gt;&lt;q&gt;摘自另一个源的小段内容&lt;/q&gt;&lt;pre&gt; 格式 会被   保留&lt;/pre&gt;&lt;ul&gt;无序列表    &lt;li&gt;你&lt;/li&gt;    &lt;li&gt;好&lt;/li&gt;&lt;/ul&gt;&lt;ol&gt;有序列表    &lt;li&gt;你&lt;/li&gt;    &lt;li&gt;好&lt;/li&gt;&lt;/ol&gt;&lt;dl&gt;包含一系列术语和定义说明的列表    &lt;dt&gt;表示术语，充当标题&lt;/dt&gt;    &lt;dd&gt;表示定义，一般是内容&lt;/dd&gt;&lt;/dl&gt;&lt;figure&gt;表示图片    &lt;figcaption&gt;标题&lt;/figcaption&gt;&lt;/figure&gt;\n\n无语义的通用元素\n表示摘自另一个源的大段内容\n摘自另一个源的小段内容\n\n 格式 会被   保留\n\n无序列表\n    你\n    好\n\n有序列表\n    你\n    好\n\n包含一系列术语和定义说明的列表\n    表示术语，充当标题\n    表示定义，一般是内容\n\n表示图片\n    标题\n\n\n\n\nul&lt;!-- ul --&gt;&lt;ul type=&quot;square&quot;&gt;    &lt;li&gt;你&lt;/li&gt;    &lt;li&gt;好&lt;/li&gt;    &lt;li&gt;吗&lt;/li&gt;&lt;/ul&gt;type有三个取值：\t1. disk ：默认，实心小黑点\t2. circle：空心小圆点\t3. square：正方形ul&#123; list-style-type:none;&#125; 去掉前面的小圆点\n\n\n    你\n    好\n    吗\n\n\n\n\nol&lt;ol type=&quot;i&quot; start=&quot;3&quot;&gt;    &lt;li&gt;你&lt;/li&gt;    &lt;li&gt;好&lt;/li&gt;    &lt;li&gt;吗&lt;/li&gt;&lt;/ol&gt;type取值：1、a、A、I、i 分别表示数字、小写字母、大写字母、大写罗马数字、小写罗马数字start：列表初始值\n\n\n    你\n    好\n    吗\n\n\ndl、dt、dd&lt;dl&gt;    &lt;dt&gt;物联网&lt;/dt&gt;&lt;!--定义术语名词--&gt;    &lt;dd&gt;物物相连的互联网&lt;/dd&gt;&lt;!--解释和描述名词--&gt;    &lt;dd&gt;互联网的应用拓展&lt;/dd&gt;    &lt;dd&gt;物品与物品之间进行信息、交换和通信&lt;/dd&gt;&lt;/dl&gt;\n\n  &lt;dl&gt;\n  &lt;dt&gt;物联网&lt;/dt&gt;&lt;!--定义术语名词--&gt;\n  &lt;dd&gt;物物相连的互联网&lt;/dd&gt;&lt;!--解释和描述名词--&gt;\n  &lt;dd&gt;互联网的应用拓展&lt;/dd&gt;\n  &lt;dd&gt;物品与物品之间进行信息、交换和通信&lt;/dd&gt;\n&lt;/dl&gt;\n\n全局属性任何一个标签都是可以使用的属性\n在HTML5中新增了一些全局属性，这些属性可以表达非常丰富的语义，也会额外提供很多实用的功能\naccesskex：规定激活元素的快捷键。class：规定元素的一个或多个类名（引用样式表中的类）contenteditable：规定元素内容是否可编辑。contextmenu：规定元素的上下文菜单。上下文菜单在用户点击元素时显示。data-：用于存储页面或应用程序的私有定制数据。dir：规定元素中内容的文本方向。draggable：规定元素是否可拖动。dropzone：规定在拖动被拖动数据时是否进行复制、移动或链接。hidden：规定元素是否显示id：元素的唯一idlang：元素内容的语言spellcheck：是否对元素进行拼写和语法检查style：规定行内css样式tabindex：规定元素tab键的次序title：有关元素的额外信息translate：是否翻译元素内容\n\n\n\n表单元素form结构：\n\n提示信息\n\n表单控件：包含表单具体功能：如文本输入框、密码输入框、提交按钮\n\n表单域：容纳表单控件和提示信息\n\n\n\n特点：\n\n每个表单都以form开始标签开始，以form标签结束。\n每个表单及其表单控件都有一个 name 属性，用于在提交表单时对表单及数据进行识别\n访问者通过所提供的提交按钮提交表单——触发提交按钮时，填写的数据就会发送至服务器。form开始标签可以有一些属性，其中最重要的就是action和method。\n\n&lt;form action=&quot;url地址&quot; method=&quot;post&quot; name=&quot;表单名称&quot;&gt;&lt;/form&gt;action：用于指定接收并处理表单数据的服务器程序的url地址。method：get 数据将显示在浏览器的地址栏中，保密性差且有数据量的限制。\t\t   post方式的保密性好，并且无数据量的限制，使用method=&quot;post&quot;可以大量的提交数据。name：用于指定表单的名称，以区分同一个页面中的多个表单。\n\ninput常用属性：\ninput&#123;    type: 取值为text、password、radio 、 checkbox 、 button、 submit、 reset、 file、image、 hidden等;    name: 控件的名称;    value: 默认显示文本;    size:  设置显示宽度;    readonly: 设置内容为只读 readonly;    checked: 默认被选中 checked;    disabled: 首次加载时禁用该控件;    maxlength: 允许输入的最多字符数;    // html5 新增的内容    type：search（搜索框）、email、url、Tel（电话号码输入框）、Number、range（滑动条）、color（颜色选择）、date（日期选择）、month、week、time、Datetime-local（日期时间）;    required: 元素必填;    placeholder: 输入提示;    pattern: 验证输入字段;    autofocus: 自动聚焦;&#125;\n\n&lt;!-- 表单元素 --&gt;&lt;form action=&quot;url地址&quot; method=&quot;post&quot; name=&quot;表单名称&quot;&gt;    &lt;input type=&quot;text&quot; placeholder=&quot;文本框&quot;&gt; &lt;br&gt;    &lt;input type=&quot;password&quot; placeholder=&quot;密码&quot; maxlength=&quot;15&quot;&gt; &lt;br&gt;    &lt;input type=&quot;radio&quot;&gt; &lt;br&gt;    &lt;input type=&quot;checkbox&quot;&gt; &lt;br&gt;    &lt;input type=&quot;button&quot; value=&quot;按钮&quot;&gt; &lt;br&gt;    &lt;input type=&quot;submit&quot;&gt; &lt;br&gt;    &lt;input type=&quot;reset&quot;&gt; &lt;br&gt;    &lt;input type=&quot;image&quot;&gt; &lt;br&gt;    &lt;input type=&quot;file&quot;&gt; &lt;br&gt;    &lt;!-- html新type --&gt;    &lt;input type=&quot;range&quot;&gt; &lt;br&gt;    &lt;input type=&quot;color&quot;&gt; &lt;br&gt;    &lt;input type=&quot;search&quot; placeholder=&quot;搜索框&quot;&gt; &lt;br&gt;    &lt;input type=&quot;email&quot; placeholder=&quot;邮件&quot;&gt; &lt;br&gt;    &lt;input type=&quot;tel&quot; placeholder=&quot;电话&quot;&gt; &lt;br&gt;    &lt;input type=&quot;number&quot; placeholder=&quot;数字&quot;&gt; &lt;br&gt;    &lt;input type=&quot;date&quot;&gt; &lt;br&gt;    &lt;input type=&quot;month&quot;&gt; &lt;br&gt;    &lt;input type=&quot;week&quot;&gt; &lt;br&gt;    &lt;input type=&quot;time&quot;&gt; &lt;br&gt;    &lt;input type=&quot;Datetime-local&quot;&gt; &lt;br&gt;    &lt;input type=&quot;datetime&quot;&gt; &lt;br&gt;&lt;/form&gt;\n\n效果演示：\n\n\n\n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n\n\n\n\n\ntextarea控件多行文本输入框\n&lt;textarea name=&quot;&quot; id=&quot;&quot; cols=&quot;30&quot; rows=&quot;10&quot; wrap=&quot;soft&quot;&gt;    文本内容&lt;/textarea&gt;cols与rows表示每行的字符数与显示的行数wrap有两个值：soft与hard，表示在表单中提交时，前者文本不换行（默认值）、后者文本换行（此时必须规定cols属性）\n\n\n    文本内容\n\n\n\n\nselect控件创建选择框，为用户提供一组选项\n&lt;select name=&quot;word&quot; size=&quot;2&quot;&gt;    &lt;option value=&quot;&quot; slected&gt;a&lt;/option&gt;    &lt;option value=&quot;&quot;&gt;b&lt;/option&gt;    &lt;option value=&quot;&quot;&gt;c&lt;/option&gt;&lt;/select&gt;// size表示显示的个数\n\n\n    a\n    b\n    c\n\n\n表单处理三种处理表单的方式：\n\n表单分组：fieldset将相关元素组合在一起\n表单校验：pattern验证输入字段的模式\n添加说明：label为表单组件添加说明\n\n表单分组：fieldset元素使用fieldset元素将相关的元素组合在一起， 使表单更容易理解\n\nfieldset：表单的一个子容器，将所包含的内容以边框环绕方式显示\nlegend：添加子容器的标题\n\n&lt;form action=&quot;&quot;&gt;    &lt;fieldset&gt;        &lt;legend&gt;注册表单&lt;/legend&gt;        &lt;input type=&quot;text&quot; placeholder=&quot;输入用户名&quot;&gt; &lt;br&gt;        &lt;input type=&quot;text&quot; placeholder=&quot;输入密码&quot;&gt;    &lt;/fieldset&gt;    &lt;fieldset&gt;        &lt;legend&gt;下拉框表单&lt;/legend&gt;        &lt;select name=&quot;word&quot; size=&quot;1&quot;&gt;            &lt;option value=&quot;&quot; slected&gt;a&lt;/option&gt;            &lt;option value=&quot;&quot;&gt;b&lt;/option&gt;            &lt;option value=&quot;&quot;&gt;c&lt;/option&gt;        &lt;/select&gt;    &lt;/fieldset&gt;    &lt;fieldset&gt;        &lt;legend&gt;多选表单&lt;/legend&gt;        &lt;input type=&quot;checkbox&quot; name=&quot;choice&quot; value=&quot;cs&quot; checked&gt;计算机 &lt;br&gt;        &lt;input type=&quot;checkbox&quot; name=&quot;choice&quot; value=&quot;physics&quot;&gt;物理 &lt;br&gt;        &lt;input type=&quot;checkbox&quot; name=&quot;choice&quot; value=&quot;chemical&quot;&gt;化学 &lt;br&gt;    &lt;/fieldset&gt;&lt;/form&gt;\n\n效果展示：\n\n    \n        注册表单\n         \n        \n    \n    \n        下拉框表单\n        \n            a\n            b\n            c\n        \n    \n    \n            多选表单\n            计算机 \n            物理 \n            化学 \n    \n\n\n\n\n表单验证：pattern属性在用户提交表单之前，验证用户输入的数据是否合法\nemail/url验证：像html5新增的typeemail/url自带对输入的验证\n&lt;form action=&quot;&quot;&gt;    &lt;input type=&quot;email&quot; value=&quot;email&quot;&gt;    &lt;input type=&quot;url&quot; value=&quot;url&quot;&gt;    &lt;input type=&quot;submit&quot;&gt;&lt;/form&gt;\n\n我们输入不正确的email或是url，点击提交，就会有提示信息：\n\n    \n    \n    \n\n\n\n\npattern验证pattern属性具有对表单中输入字段模式进行验证的功能，pattern内写正则表达式\n&lt;form action=&quot;&quot;&gt;    &lt;input type=&quot;text&quot; pattern=&quot;^[1-9]?[0-9]$&quot; placeholder=&quot;请输入一个0-99的数&quot;&gt;    &lt;input type=&quot;submit&quot;&gt;&lt;/form&gt;常见的正则表达式元字符的含义:    . 表示匹配任意字符    * 匹配0个或多个    + 匹配一个或多个    ? 匹配0个或1个    [...] 匹配方括号内的任意一个字符    [^..]匹配 非 方括号内的内容    ^ 开始    $ 结束    &#123;n&#125;表示前面的元素连续出现n次    &#123;n,&#125;表示至少出现n次    &#123;m,n&#125;表示至少出现m，至多出现n    | 逻辑或例如：^[a-zA-Z0-9]&#123;6,&#125; $表示：只能输入英文或者数字并且至少输入6个字符\n\n\n    \n    \n\n\n\n\n添加说明label标签描述表单字段用途\n\n不会向用户呈现任何特殊效果。\n不过，它为鼠标用户改进了可用性。如果您在 label 元素内点击文本，就会触发此控件。就是说，当用户选择该标签时，浏览器就会自动将焦点转到和标签相关的表单控件上。\n\n相关属性：\nfor： 规定label绑定到哪一个表单元素上，属性值该表单元素的idform：规定label字段所属的一个或多个表单，取值为formid\n\n例如：\n&lt;!-- 表单说明 --&gt;&lt;form action=&quot;&quot; method=&quot;get&quot;&gt; 性别：&lt;br/&gt;     &lt;input name=&quot;sex&quot; id=&quot;man&quot; type=&quot;radio&quot; value=&quot;&quot;/&gt;     &lt;label for=&quot;man&quot;&gt;男&lt;/label&gt;     &lt;input name=&quot;sex&quot; id=&quot;woman&quot; type=&quot;radio&quot; value=&quot;&quot;/&gt;    女 &lt;/form&gt; \n\n你会发现，当你点击“男”这个字的时候，选项会被打钩，但是“女”不行\n\n\n \n性别： \n   \n  男 \n  \n  女 \n \n\n\n\n音频与视频解码器\n音频解码器：\n定义了音频数据流编码和解码的算法。\n其中，编码器主要是对数据流进行编码操作，用于存储和传输。\n音频播放器主要是对音频文件进行解码，然后进行播放操作。目前，使用较多的音频解码器是Vorbis和ACC\n\n音频编解码器\n\nAAC： 这是一种基于MPEG-2的音频编码技术。\n\nOgg Vorbis：这是一种新的音频压缩格式，类似于MP3等的音乐格式。开源，支持多声道\n\n\n\n视频解码器：\n定义了视频数据流编码和解码的算法。\n视频播放器主要是对视频文件进行解码，然后进行播放操作。目前，使用较多的视频解码器是Theora、H.264和VP8 。\n\n视频编解码器\n\n Theora： 这是一种一款由Xiph.org基金会发布的免费且开放的视频压缩编码技术。\n\nH.264：这是一种由国际电信联盟和国际标准化组织联合推出的高性能的。视频编解码技术。\n\nVP8：由 On2 Technologiesis 开发，随后由 Google 发布的视频压缩格式。\n\n\n音频标签&lt;audio src=&quot;&quot; controls=&quot;controls&quot; loop=&quot;loop&quot; autoplay=&quot;autoplay&quot;&gt;    &lt;source src=&quot;1.mp3&quot;&gt;    &lt;source src=&quot;1.wav&quot;&gt;    您的浏览器不支持 audio 标签&lt;/audio&gt;src： 音频地址controls：提供一个播放、暂停、音量的控件autoplay：音频就绪后自动播放loop：音频循环播放preload：音频在页面加载时进行加载，并预备播放，如果有autoplay则忽略本属性source标签可以链接不同的音频文件，浏览器将会使用第一个可以识别的格式\n\n支持三种音频格式：\n\nOgg Vorbis\nMP3\nWAV\n\n效果演示：\n\n视频标签&lt;video src=&quot;&quot; controls=&quot;controls&quot;&gt;    &lt;source src=&quot;1.ogg&quot;&gt;    &lt;source src=&quot;1.mp4&quot;&gt;    &lt;source src=&quot;1.webM&quot;&gt;    您的浏览器不支持 video 标签&lt;/video&gt;标签的属性同audio\n\n支持的三种视频格式：\n\nOgg\nMPEG4\nWebM\n\n\n    您的浏览器不支持 video 标签\n\n\n\n\n音频视频相关的属性与方法（了解即可）相关属性：\n\n\n\n属性\n描述\n\n\n\naudioTracks\n返回表示可用音轨的 AudioTrackList 对象\n\n\nautoplay\n设置或返回是否在加载完成后随即播放音频/视频\n\n\nbuffered\n返回表示音频/视频已缓冲部分的 TimeRanges 对象\n\n\ncontroller\n返回表示音频/视频当前媒体控制器的 MediaController 对象\n\n\ncontrols\n设置或返回音频/视频是否显示控件（比如播放/暂停等）\n\n\ncrossOrigin\n设置或返回音频/视频的 CORS 设置\n\n\ncurrentSrc\n返回当前音频/视频的 URL\n\n\ncurrentTime\n设置或返回音频/视频中的当前播放位置（以秒计）\n\n\ndefaultMuted\n设置或返回音频/视频默认是否静音\n\n\ndefaultPlaybackRate\n设置或返回音频/视频的默认播放速度\n\n\n\n\n\n属性\n描述\n\n\n\nduration\n返回当前音频/视频的长度（以秒计）\n\n\nended\n返回音频/视频的播放是否已结束\n\n\nerror\n返回表示音频/视频错误状态的 MediaError 对象\n\n\nloop\n设置或返回音频/视频是否应在结束时重新播放\n\n\nmediaGroup\n设置或返回音频/视频所属的组合（用于连接多个音频/视频元素）\n\n\nmuted\n设置或返回音频/视频是否静音\n\n\nnetworkState\n返回音频/视频的当前网络状态\n\n\npaused\n设置或返回音频/视频是否暂停\n\n\nplaybackRate\n设置或返回音频/视频播放的速度\n\n\nplayed\n返回表示音频/视频已播放部分的 TimeRanges 对象\n\n\n\n\n\n属性\n描述\n\n\n\npreload\n设置或返回音频/视频是否应该在页面加载后进行加载\n\n\nreadyState\n返回音频/视频当前的就绪状态\n\n\nseekable\n返回表示音频/视频可寻址部分的 TimeRanges 对象\n\n\nseeking\n返回用户是否正在音频/视频中进行查找\n\n\nsrc\n设置或返回音频/视频元素的当前来源\n\n\nstartDate\n返回表示当前时间偏移的 Date 对象\n\n\ntextTracks\n返回表示可用文本轨道的 TextTrackList 对象\n\n\nvideoTracks\n返回表示可用视频轨道的 VideoTrackList 对象\n\n\nvolume\n设置或返回音频/视频的音量\n\n\n相关方法：\n\n\n\n方法\n描述\n\n\n\naddTextTrack()\n向音频/视频添加新的文本轨道\n\n\ncanPlayType()\n检测浏览器是否能播放指定的音频/视频类型\n\n\nload()\n重新加载音频/视频元素\n\n\nplay()\n开始播放音频/视频\n\n\npause()\n暂停当前播放的音频/视频\n\n\n\n\n\n属性\n描述\n\n\n\nabort\n当音频/视频的加载已放弃时\n\n\ncanplay\n当浏览器可以播放音频/视频时\n\n\ncanplaythrough\n当浏览器可在不因缓冲而停顿的情况下进行播放时\n\n\ndurationchange\n当音频/视频的时长已更改时\n\n\nemptied\n当目前的播放列表为空时\n\n\nended\n当目前的播放列表已结束时\n\n\nerror\n当在音频/视频加载期间发生错误时\n\n\nloadeddata\n当浏览器已加载音频/视频的当前帧时\n\n\nloadedmetadata\n当浏览器已加载音频/视频的元数据时\n\n\nloadstart\n当浏览器开始查找音频/视频时\n\n\n\n\n\n属性\n描述\n\n\n\nplay\n当音频/视频已开始或不再暂停时\n\n\nplaying\n当音频/视频在已因缓冲而暂停或停止后已就绪时\n\n\nprogress\n当浏览器正在下载音频/视频时\n\n\nratechange\n当音频/视频的播放速度已更改时\n\n\nseeked\n当用户已移动/跳跃到音频/视频中的新位置时\n\n\nseeking\n当用户开始移动/跳跃到音频/视频中的新位置时\n\n\nstalled\n当浏览器尝试获取媒体数据，但数据不可用时\n\n\nsuspend\n当浏览器刻意不获取媒体数据时\n\n\ntimeupdate\n当目前的播放位置已更改时\n\n\nvolumechange\n当音量已更改时\n\n\n","categories":["前端","HTML"],"tags":["HTML"]},{"title":"JUC实战","url":"/2021/09/04/JUC/JUC%E5%AE%9E%E6%88%98/","content":"\n  引言：JUC实战\n\n\n\n\nJUC实战之前的JUC，感觉也只是入了门；\n在大学不管是做项目、还是做课设，都没有涉及到多线程的开发。\n所以这篇可以更深刻的理解，JUC的由来~\n很重要的前置知识并发编程主要就是三点：分工、同步、互斥\n并发编程要解决的问题（微观）：原子性、可见性、有序性\n并发编程要解决的问题（宏观）：安全性、活跃性、性能\nJava如何解决三个问题：volatile、synchronized、final、八项Happens-Before、锁\n\nhappens before原则\n程序顺序原则（线程内必须串行执行）\n锁规则（解锁必须发生在上锁后）\nvolatile规则（强迫每次的读写都必须刷新到主内存，不能为了省事直接去工作内存读）\n线程启动规则（线程的start()方法先于它的其他操作）\n传递性（A先于B，B先于C，A必先于C）\n线程终止规则\n线程中断规则（线程的所有操作先于线程的终结）\n对象终结规则（构造方法先于finalize()方法）\n\n这八个规则确定的内容，即使没有锁等同步操作，也可以按序执行\n锁模型\n简易的锁模型\n\nlock();// 临界区代码unlock();\n\n\n改进的锁模型：锁和锁要保护的资源是有对应关系的\n\n// 1、 创建保护资源R的锁 LRlock(LR); //2、上锁// 3、 临界区操作Runlock(LR);//4、释放锁\n\n对象头\n加锁的本质，就是在锁对象的对象头写入了当前线程的ID，获得了对Monitor对象的所有权\n\n对象的组成：三大部分\n\n对象头\nMarkword（8字节，64位JVM）\n类型指针（4字节，64位JVM）\n数组长度（数组才有此字段）\n\n\n实例数据\n字节填充\n\nMarkword记录了三方面的信息：哈希值、GC信息、锁信息\n对象头的锁升级过程（细品这篇博客，讲到了锁升级的过程）\n\nsynchronized1. 一把锁保护一个资源// 一把锁保护一个资源的例子public class ALockProtectAResource &#123;    long value = 0;    // 对于long 和 double的读与写操作，JVM是分两步完成的，存在安全问题    synchronized long getValue()&#123;        return value;    &#125;    synchronized void addOne() &#123;        value++;    &#125;    /* syn修饰不同的位置有不同的作用：    * 1. 修饰 普通的方法 锁住的是对象的实例 即 this    * 2. 修饰 静态方法，锁住的是对应的Class对象    * 3. 修饰 同步代码块，锁住的是传入的锁    * */&#125;\n\n2. 多把锁保护多个没有关联的资源场景：有account与password字段。\n对于account可以取款，查账\n对于password可以修改、查看密码\n\n为什么不用syn修饰方法呢？这样不也可以同步吗？\n\n是可以同步，但是发现没有，密码业务与账户业务没有关系。\n如果给方法加了syn，就锁住了this，导致两个业务之间也变为互斥了！降低了我们系统的效率\n// 多把锁保护多个没关系的资源public class LocksProtectNoRelatedResource &#123;    // 密码相关    private String password;    private final Object lockMyPass = new Object();    // 加上final，告诉编译器这是一个不可变对象，尽情的去优化吧    void changePassword(String newPassword)&#123;        synchronized (lockMyPass)&#123;            password = newPassword;        &#125;    &#125;    String getPassword()&#123;        synchronized (lockMyPass)&#123;            return password;        &#125;    &#125;    // 账户相关    private Integer account;    private final Object lockMyMoney = new Object();    // 加上final，告诉编译器这是一个不可变对象，尽情的去优化吧    Integer getAccount()&#123;        synchronized (lockMyMoney)&#123;            return account;        &#125;    &#125;    void takeMoney(Integer money)&#123;        synchronized (lockMyMoney)&#123;            account-=money;        &#125;    &#125;&#125;\n\n3. 多把锁保护多个有关联的资源场景：转账业务\nA的账户需要扣除钱，B的账户需要加上钱（这里A与B是两个资源，而且他们需要同时进行操作）\n实现的核心就是，要保证同一个锁锁住临界区的操作\n\n实现一：错误的示范\n\n// 实现一：这是有问题的实现class Account1 &#123;    private int balance;    // 转账虽然加了syn，锁住了this，但是！我们操作的过程中还操作了B的账户！    synchronized void transfer(Account1 target, int amt) &#123;        if (this.balance &gt; amt) &#123;            this.balance -= amt;            target.balance += amt;        &#125;    &#125;&#125;\n\n\n实现二：必须要传相同的锁\n\n// 实现二：可以实现，但是有点问题class Account2 &#123;    private int balance;    private Object lock;    // 构造时传入一个对象作为锁    Account2(Object lock)&#123;        this.lock = lock;    &#125;    void transfer(Account2 target, int amt) &#123;        // 改变锁的对象，只要A与B两个人构造时传入相同的对象就可以了        // 但是怕就怕两个人传入的锁不同        synchronized (lock) &#123;            if (this.balance &gt; amt) &#123;                this.balance -= amt;                target.balance += amt;            &#125;        &#125;    &#125;&#125;\n\n\n实现三：直接用class对象当锁\n\n这种实现也有问题，就是性能不高；\nA转B、C转D，这两个不需要互斥的操作在这种实现下也变得互斥了\n// 实现三class Account3 &#123;    private int balance;    void transfer(Account3 target, int amt) &#123;        // 改变锁的对象，直接传Class对象        synchronized (Account3.class)&#123;            if (this.balance &gt; amt) &#123;                this.balance -= amt;                target.balance += amt;            &#125;        &#125;    &#125;&#125;\n\n\n实现四：使用N把锁，操作时必须同时取到\n\n对于这个场景：完全可以锁住this与target两个对象\n但是存在死锁问题，设想，A在给B转账的同时，B也在给A转账（看代码中标有记号的位置）    \n// 实现四：使用两把锁，进行两次判断class Account4 &#123;    private int balance;    void transfer(Account4 target, int amt) &#123;        synchronized (this)&#123;            // #这里会死锁#：A执行到这里，B也执行到了这里            // 由于A想拿B的this，B也想拿A的this，导致双方都不能继续进行下去            synchronized (target)&#123;                if (this.balance &gt; amt) &#123;                    this.balance -= amt;                    target.balance += amt;                &#125;            &#125;        &#125;    &#125;&#125;\n\n死锁上一节的实现四，出现了死锁问题\n死锁部分可以看我的另一篇blog\n死锁产生的必要条件\n互斥条件：进程对其所要求的资源进行排它性控制，即一次只有一个进程可以使用一个资源。\n请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求。\n不可剥夺条件：进程所获得的资源在未被释放之前，不能被其它进程强行剥夺。\n环路条件：在发生死锁时，必然存在一个进程资源的循环等待链\n\n其中互斥条件不能被破坏，其他三个都是可以破坏的\n破坏请求和保持条件：有两种方案1、可以将进程所需的所有资源一次性拿走（但是会导致资源浪费、饥饿问题产生）\n2、只获得初期所需资源后，开始运行。运行过程逐步释放已分配、已用完的全部资源，再请求新的所需资源\n对于转账这个业务，第二种方案不好实现，但是第一种方案还是可以实现的\n// 实现5，破坏请求和保持条件// 额外的一个类，帮我们申请资源，防止死锁class Allocater&#123;    // Allocater要保持单例模式，这里使用了饿汉式单例    private Allocater()&#123;&#125;    private final static Allocater allocater = new Allocater();    private List&lt;Object&gt; als = new ArrayList&lt;&gt;();    public static Allocater getAllocater()&#123;        return allocater;    &#125;\t// 申请    synchronized boolean apply(Object a, Object b)&#123;        if(als.contains(a) || als.contains(b))&#123;            return false;        &#125;else &#123;            als.add(a);            als.add(b);            return true;        &#125;    &#125;\t// 释放    synchronized void free(Object a, Object b)&#123;        als.remove(a);        als.remove(b);    &#125;&#125;class Account5&#123;    private int balance;    void transfer(Account5 target, int amt) &#123;        Allocater allocater = Allocater.getAllocater();        while (!allocater.apply(this, target));        // 死循环，保证可以拿到两个资源        try&#123;            synchronized (this)&#123;                synchronized (target)&#123;                    if (this.balance &gt; amt) &#123;                        this.balance -= amt;                        target.balance += amt;                    &#125;                &#125;            &#125;        &#125;finally &#123;            allocater.free(this, target);        &#125;    &#125;&#125;\n\n破坏不可剥夺条件Syn做不到破坏此项，因为Syn锁的申请与释放是JVM帮助我们管理的\n但是Java中的Lock可以做到这一件事情，下面再讲\n破坏环路条件\n做法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反\n编号的原则：较为紧缺的资源给以一个较大的序号\n优点：较前两种策略，资源利用率和系统吞吐量，都有显著的改善。\n问题：\n限制了新设备类型的增加\n发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费，如：某进程先用磁带机，后用打印机，但按系统规定，它应先申请打印机，后申请磁带机，致使打印机长期闲置\n限制了用户简单、自由的编程\n\n\n\n对于这个场景也很简单，给Account加一个id，用来排序\n如果同时出现A转账B，B转账A的情况，由于id小的先申请，所以他们同时先申请同一个资源，不会出现环路，也就避免了死锁。\n// 实现6，破坏环路条件，给资源排序class Account6 &#123;    private int balance;    private int id;    void transfer(Account6 target, int amt) &#123;        Account6 first = this;        Account6 second = target;        // 序号小的先申请        if(target.id &lt; this.id)&#123;            first = target;            second = this;        &#125;        synchronized (first)&#123;            synchronized (second)&#123;                if (this.balance &gt; amt) &#123;                    this.balance -= amt;                    target.balance += amt;                &#125;            &#125;        &#125;    &#125;&#125;\n\nwait-notify 等待通知机制在上面我们解决死锁的时候，使用了\nwhile (!allocater.apply(this, target));\n\n死循环，让CPU自旋，来保证拿到资源，但是这样太耗费CPU了\nwait-notify等待通知是更优的一种方案\nSynchronized与wait-notify配合首先来说明一下api吧：\n他们都是Obejct类的方法\n\nwait()：将当前线程移入等待队列\nnotify()：随机唤醒一个等待队列中的一个线程\nnotifyAll()：唤醒等待队列中的所有线程\n\n\n注意：尽量使用notifyAll！好像notify只唤醒一个线程，是不是会更安全一点呢？但这只是你自己的想象\n\n假如这种情况：\n有资源 A、B、C、D：\n​        线程 1 申请到了 AB；线程 2 申请到了 CD；\n​        此时线程 3 申 请 AB，会进入等待队列；\n​        线程 4 申请 CD 也会进入等待队列；\n现在我们再假设之后线程 1 归还了资源 AB\n​        如果使用notify()来通知 等待队列中的线程，有可能被通知的是线程 4，但线程 4 申请的是 CD，所以此时线程 4 还 是会继续等待，而真正该唤醒的线程 3 就再也没有机会被唤醒了。\n​        所以尽量使用notifyAll()\n\n\n实现代码如下：\nclass AllocaterNew &#123;    // Allocater要保持单例模式，这里使用了饿汉式单例    private AllocaterNew()&#123;&#125;    private final static AllocaterNew allocater = new AllocaterNew();    private List&lt;Object&gt; als = new ArrayList&lt;&gt;();    public static AllocaterNew getAllocater()&#123;        return allocater;    &#125;    synchronized void apply(Object a, Object b)&#123;        while (als.contains(a) || als.contains(b)) &#123;            // 不满足条件，进入等待队列            try &#123;                wait();            &#125; catch (InterruptedException e) &#123;            &#125;        &#125;        als.add(a);        als.add(b);    &#125;    synchronized void free(Object a, Object b)&#123;        als.remove(a);        als.remove(b);        notifyAll();// 唤醒所有线程    &#125;&#125;\n\n安全性、活跃性、性能问题安全性即要保证线程安全，就得保证原子性、有序性、可见性\n\n我们是不是每个对象都得分析它的三性？\n\n只有一种情况我们需要分析：即分析 可变的共享对象 的原子性、安全性、可见性即可\n\n此外有两个专业名词：\n\n数据竞争：指的就是可变的共享对象被抢来抢去\n竞态条件：程序的执行结果依赖于线程的执行顺序\n\n活跃性活跃性：其实也分了三个问题\n\n死锁：前面提到了\n活锁\n饥饿\n\n\n什么是活锁？\n\n活锁就是，类似于线程之间都太客气了，互相谦让对方先使用资源\n就和AB两个人进出同一个门一样，A靠右走让B，B靠左走让A，撞了上去\n\n活锁怎么解决？\n\n尝试等待一个随机的时间就可以了，简单但是很有效\n\n什么是饥饿？\n\n线程因无法访问所需资源而无法执行下去的情况\n对于优先级低的线程，可能永远也得不到自己的资源，而无法执行\n\n饥饿怎么解决？\n\n有三种方案：\n\n保证资源充足\n避免持有锁的线程长时间进行\n公平的分配资源\n\n其中1与2是比较难以实现的，资源不可能充足、持有锁的线程也很难缩短\n所以只有公平的分配资源，比较好实现（类似于Java的公平锁）\n性能问题如果随意的使用锁，会导致性能急剧的下降\n\n阿姆达尔定律：S = 1 / ((1 - P) +  P / n )\nn代表CPU核心线程数；\nP代表并行百分比；\n1-P代表串行百分比；\n\n\n假设我们的串行率(1-P)为5%，那么无论我们cpu有多少核心（n为无穷大）\nS最终也只能为 20%\n也就是说，如果串行率为5%，不管我们如何提高性能，最高也只能提高20%\n\n如何提高性能？\n\n\n使用无锁的数据结构与算法：比如ThreadLocal、CAS、COW、乐观锁\n使用细粒度的锁：分段锁ConcurrentHashMap、读写锁ReadWriteLock\n\n\n性能的指标：\n\n\n吞吐量：单位时间内能处理的请求数\n延迟：从发出请求到响应的时间\n并发量：能同时处理的请求数量\n\n管程synchronized的实现其实是MESA管程模型的简化版\n而JUC包内，LOCK与Condition真正实现了MESA管程模型\n\n管程是什么？\n\n英文为Moniter、Java里面叫监视器（知道是啥了吧）\n管程就是：管理共享变量以及对共享变量的操作过程，让他们支持并发\n\n管程干了什么？\n\n管程通过N个队列来保证线程之间的互斥与同步，入队出队操作由其封装\n\n这种管程模型，条件可以有多个，但在Java的实现中，synchronized只有一个条件变量，也就是为什么说是简化版的synchronized\n\n使用wait的正确姿势（这其实就是MESA模型规定的经典姿势）\n\nwhile(条件不满足)&#123;\twait();&#125;\n\n\nnotify如何使用？\n\n如果你能确定以下三点，就可以使用notify，如果不能请使用notifyAll()\n\n所有线程都拥有相同的等待条件\n等待线程被唤醒后执行相同的操作\n只需要唤醒一个线程\n\nJava线程的状态转换这个图绘制的很好\n\n注意：在OS层面，线程是有五个状态的（新建、就绪、运行、阻塞、终止）\n但是JVM层面，将就绪与运行看做一个状态RUNNABLE（JVM不关心谁被调度了），而将阻塞分为三部分（WAITING、TIMED_WAITING、BLOCKED）\n\nNEW进入RUNNABLE：执行start方法\n\n在OS内部：\n\n就绪进入运行状态：获得时间片\n运行进入就绪状态：yield()方法\n\n\nRUNNABLE与WAITING之间的状态转换：各有三种方式\n\nwait()、join()、LockSupport.park()（LockSupport是Java中实现Lock的基础）\n状态反向：notify()、notifyAll()、LockSupport.unpark(Thread thread)\n\n\nRUNNABLE与TIMED_WATING状态的相互转换\n\n进入超时等待有五种方法wait(long)、 join(long) 、sleep(long)、LockSupport.parkNanos(long)、 LockSupport.parkUntil(long deadline)\n\n\nRUNNABLE与BLOCKED的状态转换：\n\n只有一种方式：就是线程等待synchronized的锁\n\n\n进入TERMINATED状态\n\n可以通过stop，但是这个方法已经不推荐使用了（Stop会立即杀了线程，但是锁不一定会释放（只会释放隐式锁））\n当线程 A 处于 WAITING、TIMED_WAITING 状态时，如果其他线程调用线程 A 的 interrupt() 方法，会使线程 A 返回到 RUNNABLE 状态，同时线程 A 的代码会触发 InterruptedException 异常，只要捕获这个异常我们就可以\n当线程A处于RUNNABLE状态时，可以同步不断的调用isInterrupt()方法，来判断自己是不是被别人叫停了\n\n\n\nSemaphoreSemaphore信号量，主要的api有：\n\nnew Semaphore(int permits , [boolean fair])：创建一个信号量，permits代表资源的数量，fair代表创建一个公平锁还是非公平锁，默认为非公平\nacquire()：会将资源数 -1。如果为0，那么会进入等待状态\nrelease()：将资源数 +1\n\n信号量为1——互斥量当设值信号量为1，就是一个互斥量，和wait notify没有区别\n// 实现加一操作public class SemaphoreX &#123;    // 当设值为1，代表这是一个互斥信号量    static final Semaphore semaphore = new Semaphore(1);    static int count = 0;    static void addOne()&#123;        try &#123;            semaphore.acquire();            // acquire会将信号量的计数器-1            count ++;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;finally &#123;            semaphore.release();            // release会将信号量的计数器+1        &#125;    &#125;&#125;\n\n信号量实现一个对象池对象池，类似于字符串常量池、线程池等等（也可以叫限流器）\n使用池化的思想，先把对象创建出来，然后使用List保存，具体代码如下    \n// 使用信号量实现一个对象池public class ObjPool&lt;T, R&gt; &#123;    // T 代表参数 R 代表返回值    final List&lt;T&gt; pool;    final Semaphore semaphore;    public ObjPool(int size, T t) &#123;        this.pool = new Vector&lt;&gt;(size);        // 这里用了线程安全类Vector        // 不能使用ArrayList，因为信号量允许多个线程进入临界区，可能会导致并发操作List导致错误        for (int i = 0; i &lt; size; i++) &#123;            pool.add(t);        &#125;        this.semaphore = new Semaphore(size);    &#125;    R exec(Function&lt;T,R&gt; func)&#123;        // Function 接口用来根据一个类型的数据得到另一个类型的数据，        // 前者称为前置条件，后者称为后置条件        // 类似于 R apply(T t)        T t = null;        try &#123;            semaphore.acquire();// 获取资源            t = pool.remove(0); // 永远从队列头取            return func.apply(t);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;finally &#123;            pool.add(t);// 使用完要把资源还回来            semaphore.release();        &#125;        return null;    &#125;    public static void main(String[] args) &#123;        ObjPool&lt;Long, String&gt; objPool = new ObjPool&lt;&gt;(10 ,2L);        objPool.exec(t-&gt;&#123;            System.out.println(t);            return t.toString();        &#125;);    &#125;&#125;\n\nReadWriteLock\n读写锁：遵从四个个原则\n\n允许多个线程同时读共享变量\n只允许一个线程写共享变量\n写操作正在执行，那么不能读\n读操作正在执行，那么不能写（悲观读）\n\n\n使用到了实现了ReadWriteLock接口的ReentrantReadWriteLock：\nReadWriteLock的API有：\n\nreadLock()获取读锁\nwriteLock()获取写锁\nlock()上锁\nunlock()释放锁\ntryLock()：非阻塞的获取锁\nlockInterruptibely()：如果线程正在等待获取锁，那么这个线程可以响应中断（别的线程可以使用interrupt()中断其操作）\nnewCondition()：只有写锁支持生成条件\n\n\n\n注意：\ntryLock()和lock()的区别在于：\n\ntryLock()只是”试图”获取锁, 如果锁不可用, 不会导致当前线程等待, 当前线程仍然继续往下执行代码. （不会阻塞）\nlock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行.（阻塞）\n\n读写锁实现缓存下面的实现是一个按需加载的缓存，使用到了ReadLock与WriteLock\npublic class MyCache&lt;K, V&gt; &#123;    final Map&lt;K , V&gt; cache = new HashMap&lt;&gt;();    final ReadWriteLock rwl = new ReentrantReadWriteLock();    final Lock rLock = rwl.readLock();    final Lock wLock = rwl.writeLock();    // 按需加载Cache    V get(K key)&#123;        V value = null;        rLock.lock();        try &#123;            value = cache.get(key);        &#125;finally &#123;            rLock.unlock();        &#125;        if(value != null)&#123;            // 说明缓存内存在直接返回            return value;        &#125;        // 说明缓存内部没，要去数据库读        wLock.lock();        try &#123;            value = cache.get(key);            // 再次检查，防止别的线程也修改数据库，进行没必要的修改            if(value == null)&#123;                // 省略去数据库查询的代码                value = getFromDataBase(key);                cache.put(key, value);            &#125;        &#125;finally &#123;            wLock.unlock();        &#125;        return value;    &#125;    private V getFromDataBase(K key) &#123;        // 省略去数据库查询的代码        return null;    &#125;    void put(K key, V value)&#123;        wLock.lock();        try &#123;            cache.put(key, value);        &#125;finally &#123;            wLock.unlock();        &#125;    &#125;&#125;\n\n读写锁的升级与降级\n升级：就是指，在已经获取到读锁的情况下，继续获取写锁\n降级：就是指，在已经获取到写锁的情况下，或许读锁\n\nReentrantReadWriteLock只支持锁的降级，不支持锁的升级\n意思是，在已经获取到读锁后，获取写锁，是不可以的！会导致写锁永久等待，而且相关线程都会被阻塞\nStampedLockJDK1.8提出的新锁，提供了三种模式：写锁、悲观读锁、乐观读锁\n在ReentrantReadWriteLock中，提供的读锁，是悲观读的，即在读的过程中，不允许写操作\n而StampedLock支持乐观读操作，乐观读就是认为自己读的时候不会发生写的锁，其实就是没有上锁的状态\n核心API：\n\nwriteLock() readLock()：获取写锁、读锁（如果加了try代表非阻塞的尝试获取锁），均会返回一个 stamp（邮戳）\ntryOptimisticRead()：获取乐观读锁，返回stamp；如果当前有写锁占用，那么会返回0\nvalidate(long stamp)：需要传入stamp，如果当前没有写锁占用，会返回true\ntryConvertToWriteLock(long stamp)：尝试锁升级\n如果当前为写锁，返回它的stamp\n如果当前为悲观读，写锁可用，那么释放读锁，返回写锁的stamp\n如果当前为乐观读，仅仅只有写锁当前立即可用的时候，才会返回写锁的stamp\n其他情况stamp全部返回 0\n\n\n\nStampedLock的官方例子class Point &#123;    private double x, y;    private final StampedLock sl = new StampedLock();    // 一个StampedLock    // 一个点进行移动    // 1、写锁的案例：    void move(double deltaX, double deltaY) &#123;        // 写锁是一个排他锁        long stamp = sl.writeLock();        try &#123;            x += deltaX;            y += deltaY;        &#125; finally &#123;            sl.unlockWrite(stamp);        &#125;    &#125;    // 计算与原点的距离    // 2、乐观读的案例    double distanceFromOrigin() &#123;        // 获取了一个乐观锁        long stamp = sl.tryOptimisticRead();        double currentX = x, currentY = y;        // 把当前的位置复制一份，防止其他线程修改        if (!sl.validate(stamp)) &#123;            // 如果当前锁没有被写，那么validate返回为true            // 如果进入这个循环，说明point值已经被修改了，所以要重新获得值            stamp = sl.readLock();// 加悲观读锁            try &#123;                currentX = x;                currentY = y;            &#125; finally &#123;                sl.unlockRead(stamp);            &#125;        &#125;        return Math.sqrt(currentX * currentX + currentY * currentY);    &#125;    // 尝试锁升级的案例    void moveIfAtOrigin(double newX, double newY) &#123; // upgrade        // Could instead start with optimistic, not read mode        long stamp = sl.readLock();        try &#123;            while (x == 0.0 &amp;&amp; y == 0.0) &#123;                long ws = sl.tryConvertToWriteLock(stamp);                // 进行锁升级                if (ws != 0L) &#123;                    // 不为0，代表锁升级成功                    stamp = ws;                    // 如果锁升级成功，要把新的邮戳给了stamp变量，以便后续释放                    x = newX;                    y = newY;                    break;                &#125;                else &#123;                    // 如果没有升级成功，说明当前被写锁占用                    sl.unlockRead(stamp);                    // 释放悲观读锁                    stamp = sl.writeLock();                    // 尝试获取写锁，进入等待                &#125;            &#125;        &#125; finally &#123;            sl.unlock(stamp);        &#125;    &#125;&#125;\n\nStampedLock的读写模板读模板：乐观锁的实现机制，其实就是通过stamp，如果当前被其他线程修改了，stamp的值会变（类似于ABA问题的解决）\nfinal StampedLock sl = new StampedLock();// 乐观读long stamp = sl.tryOptimisticRead();// 读入方法局部变量...// 校验 stampif (!sl.validate(stamp))&#123;    // 如果当前有写锁修改    // 升级为悲观读锁    stamp = sl.readLock();    try &#123;        // 读入方法局部变量        .....    &#125; finally &#123;        // 释放悲观读锁        sl.unlockRead(stamp);    &#125;&#125;// 使用方法局部变量执行业务操作\n\n写模板：\nlong stamp = sl.writeLock();try &#123;    // 写共享变量    ......&#125; finally &#123;    sl.unlockWrite(stamp);&#125;\n\nStampedLock对比ReentrantReadWriteLockStampedLock对比ReentrantReadWriteLock有了如下几点的提升：\n\n支持了乐观读\n支持锁升级\n\n但是StampedLock并不能完全替代ReentrantLock，因为还有以下缺点：\n\n不支持Condition\n不是可重入锁\n使用 StampedLock 一定不要调用中断操作，如果需要支持中断功能，一定使用可中断的悲观读锁 readLockInterruptibly() 和写锁 writeLockInterruptibly()\n\n\n\n\n对比项\nStampedLock\nReentrantReadWriteLock\n\n\n\n模式\n三种：写、悲观读、乐观读\n两种：写、悲观读\n\n\n支持Condition\n不支持\n只有写锁支持生成\n\n\n是否可重入\n不可重入\n可重入\n\n\n锁升级\n支持\n不支持\n\n\n锁降级\n支持\n支持\n\n\nCountDownLatch可以实现让一个线程等待其他线程完成后再执行\n假设我们要实现一个对账系统\n\n使用CountDownLatch我们可以很好的实现这个案例\n核心API：\n\nnew CountDownLatch(int count)：构造一个要等待几个任务的CountDownLatch\ncountDown()：将count值 -1\nawait()：进入阻塞状态，直到count值变为0，才会允许通过\n\nOrder order; // 模拟订单类Bill bill; // 模拟账单类public void check() throws InterruptedException &#123;    Executor executor = Executors.newFixedThreadPool(2);    while(hasBill())&#123;        // 计数器初始化为 2        CountDownLatch latch = new CountDownLatch(2);        // 查询未对账订单        executor.execute(()-&gt; &#123;            bill = getUnCheckedBill();            latch.countDown();        &#125;);        // 查询派送单        executor.execute(()-&gt; &#123;            order = getOrder();            latch.countDown();        &#125;);        // 等待两个查询操作结束        latch.await();        // 执行对账操作        Diff diff = check(order, bill);        // 差异写入差异库        save(diff);    &#125;&#125;\n\n\n如果不用CountDownLatch我们怎么实现这个案例？\n\n可以使用两个线程分别执行查订单，查账单的事情，然后调用join()方法，让主线程等待两个线程完成后再继续执行\nCyclicBarrier类似于CountDownLatch，为了解决其不能重复使用的问题而提出的\n构造方法特别重要，两个参数：第一个就是等待的值，第二个是希望完成后执行的内容（是一个Runnable接口）\n有两个核心API：\n\nawait()：执行完成自动将值减去1\nreset()：不用我们自己调用\n\n任务加载Demopublic class CyclicBarrierDemo &#123;    static class PreTaskThread implements Runnable &#123;        private String task;        private CyclicBarrier cyclicBarrier;        public PreTaskThread(String task, CyclicBarrier cyclicBarrier) &#123;            this.task = task;            this.cyclicBarrier = cyclicBarrier;        &#125;        @Override        public void run() &#123;            // 假设总共三个关卡            for (int i = 1; i &lt; 4; i++) &#123;                try &#123;                    Random random = new Random();                    Thread.sleep(random.nextInt(1000));                    System.out.println(String.format(&quot;关卡%d的任务%s完成&quot;, i, task));                    cyclicBarrier.await();                &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                    e.printStackTrace();                &#125;                //cyclicBarrier.reset();// 重置屏障，不需要我们自己调用，await会自己-1            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        CyclicBarrier cyclicBarrier = new CyclicBarrier(3, () -&gt; &#123;            System.out.println(&quot;本关卡所有前置任务完成，开始游戏...&quot;);        &#125;);        new Thread(new PreTaskThread(&quot;加载地图数据&quot;, cyclicBarrier)).start();        new Thread(new PreTaskThread(&quot;加载人物模型&quot;, cyclicBarrier)).start();        new Thread(new PreTaskThread(&quot;加载背景音乐&quot;, cyclicBarrier)).start();    &#125;&#125;\n\nFutureTask之前说到过，实现Callable接口，实现call方法调用，就可以实现一个有返回值的线程，这个返回值就是一个Future接口对象\n\n先来介绍Future接口：Future接口有五个方法\n\nget()：获取值，如果获取时，线程还没有执行完成，那么会进入阻塞状态\nget(timeout, timeunit)：设置阻塞的超时时间\ncancel()：可以取消任务执行\nisCanceled()：判断任务是否取消\nisDone()：判断任务是否执行结束\n\n而FutureTask就是一个工具类，实现了Future接口，使用看Demo吧\n泡茶Demo\n最优烧开水程序：\n// 实现烧开水程序public class No09FutureTask &#123;    static FutureTask&lt;String&gt; ft1 = new FutureTask&lt;String&gt;(new T1Task());    static FutureTask&lt;String&gt; ft2 = new FutureTask&lt;String&gt;(new T2Task());    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        Thread t1 = new Thread(ft1);        Thread t2 = new Thread(ft2);        t1.start();        t2.start();        System.out.println(ft1.get());    &#125;    static class T1Task implements Callable&lt;String&gt;&#123;        @Override        public String call() throws Exception &#123;            System.out.println(&quot;T1：洗水壶&quot;);            Thread.sleep(1000);            System.out.println(&quot;T1：烧开水&quot;);            Thread.sleep(15000);            String tea = ft2.get();            System.out.println(&quot;T1：拿到茶叶&quot;+ tea);            return &quot;上茶&quot;+tea;        &#125;    &#125;    static class T2Task implements Callable&lt;String&gt;&#123;        @Override        public String call() throws Exception &#123;            System.out.println(&quot;T2：洗茶壶&quot;);            Thread.sleep(1000);            System.out.println(&quot;T2：洗茶杯&quot;);            Thread.sleep(2000);            System.out.println(&quot;T2：拿茶叶&quot;);            Thread.sleep(1000);            return &quot;普洱&quot;;        &#125;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n\n","categories":["JUC"],"tags":["JUC"]},{"title":"深入Java虚拟机GC篇","url":"/2021/07/26/JVM/%E6%B7%B1%E5%85%A5Java%E8%99%9A%E6%8B%9F%E6%9C%BAGC%E7%AF%87/","content":"\n  引言:\n  JVM GC部分\n\n\n\n\n深入Java虚拟机GC篇GC 概述什么是垃圾？什么是GC？（&gt;_&lt;我是垃圾）\n\n垃圾：运行程序没有任何指针指向的对象（游离的对象）\n\n​        GC（Garbage Collection）垃圾回收，程序运行会产生很多垃圾，所以我们需要时不时对垃圾进行回收，回收他们的内存分配给其他对象使用。\n​        相较于传统的C/C++，GC也是Java语言的优势，程序员不必再去考虑内存的释放，加快开发效率。\n​        对于JVM的运行时数据区，GC的主战场是堆和方法区，对于PC、Stack、本地方法栈都没有GC。\nGC相关算法GC可以分为两个阶段：\n\n标记阶段：标记出垃圾\n清除阶段：对1中标记的垃圾进行清除\n\n标记阶段算法标记阶段主要讲两个算法：\n\n引用计数算法\n可达性分析算法\n\n引用计数算法\n引用计数算法：对每一个对象保存一个整型的引用计数器属性，用于记录对象被引用的情况。\n\n一个对象被一个指针引用，那么就会使引用计数器+1，如果去除了这个指针，就会-1，为0时则GC就知道，这个对象可以被清理了。\n优点：实现简单，垃圾对象便于分别；判定效率高，回收没有延迟性\n缺点：\n\n需要额外的字段存储计数器，增加了存储空间的开销\n每次赋值都需要更新计数器，伴随着加法和减法操作，增大了时间开销\n最严重的问题：无法处理循环引用的情况，这个缺陷直接导致JVM没有选择这种算法\n\n循环引用，如下\np -&gt; A -&gt; B -&gt; C     ↑________|\n\n如果我们将P-&gt;null，你会发现ABC的引用计数器还是1，这样GC就永远也不会去去除他们三个。\n可达性分析算法\n可达性分析算法（也叫根搜索算法、追踪性垃圾收集）\n\n思想：\n\n以根集合对象（GC Roots）为起始点，从上至下的方式搜索被根对象集合所连接的目标对象是否可达\n\n根集合对象GC Roots：一组必须活跃的引用\n\n\n存活的对象都会被根节点直接或间接的连接（这条连接的路径叫引用链）\n\n如果对象没有被任何引用链连接，则不可达；不可达，则可以回收\n\n\n\n目前，此算法是Java、C#语言所选择的GC标记算法\n\n\nGC Roots可以是哪些元素？\n\n\nJVM Stack中引用的对象：方法中使用的参数、局部变量等\nJNI（本地方法栈）引用的对象\n方法区中类静态属性引用的对象：静态变量\n方法区中常量引用的对象：字符串常量池的引用\n所有被同步锁synchronized持有的对象\nJVM内部的引用：基本数据类型对应的Class对象、常驻的异常对象（NullPointException、OutOfMemoryError）、系统类加载器\n反应JVM内部情况的JMXBean，JVMTI中注册的回调、本地代码缓存等\n除了这些外，根据用户选用的GC不同、当前回收的内存区域不同，还可能有其他对象“临时性”的加入，共同构成完整的GC Roots集合。比如分代收集和局部回收（Partial GC）\n即：如果是对新生代的回收，那么老年代中有的对象也可以成为GCRoots的元素\n\n\n\n技巧：\n​        如果一个指针，指向堆内的对象，但是自己又不在堆内，那么这就是一个GC Root的元素\n注意：\n\n使用可达性分析算法，分析工作必须在一个可以保障一致性的快照中进行\n这点也是GC时必须STW的原因（即使是CMS收集器（号称不会发生停顿的收集器），在枚举根节点时也是要STW的）\n\n标记阶段的补充：finalization机制finalize()方法Java给对象提供了finalization来让开发人员可以进行对象销毁之前的处理\n当GC回收器发现一个对象可以被回收时，会先去调用fianlize()方法\npublic class Object &#123;    //....\tprotected void finalize() throws Throwable &#123; &#125;&#125;\n\n此方法可以被重写，用于在对象被回收前进行资源释放\n但是注意永远不要主动调用finalize()方法：\n\nfinalize()方法有可能导致对象复活\nfinalize()方法执行时间没有保障，完全由GC线程决定，极端情况下如果不发生GC，那么finalize()方法就没有执行的机会\n一个糟糕的finalize()方法会严重影响GC性能（没错，就是说你写的finalize方法）\n\nfinalize()可能与C++析构函数相似，但是他们有本质的区别，finalize()方法是基于垃圾回收器的自动内存管理机制，不需要主动调用\n对象的三种状态由于finalize()方法的存在，导致对象有三种状态：\n\n可触及的：从根节点开始，这个对象可达，就是可触及的\n可复活的：对象已经不可达，但是有可能在finalize()中复活\n不可触及的：对象的finalize()被调用并且没有复活，就进入此状态；此状态的对象不可能复活，因为finalize()只会调用一次\n\n注意只有不可触及状态的对象，才会被回收！\n对象是否可以回收因为存在三种状态，所以我们要判断一个对象是否可回收，要经历两次标记过程：\n\n是否可达，第一次标记\n是否有必要执行finalize()方法\n没有重写此方法或此方法已调用过：判定为不可触及\n重写了此方法且还未执行：此对象会被插入到F-Queue队列中，由一个虚拟机自动创建的、低优先级的Finalizer线程触发其finalize()方法\nfinalize()方法是最后逃离被回收的机会。稍后GC会对F-Queue的对象进行第二次标记。如果finalize()方法中，此对象建立了引用，那么在第二次标记时，这个对象会被移除出即将回收的集合；如果这个对象之后再次出现不可达的情况，那么会直接变为不可触及状态；（finalize()方法只会被调用一次）\n\n\n\npublic class RebackObject &#123;    public static RebackObject object; // 类变量，属于GCroot    @Override    // 只会调用一次    protected void finalize() throws Throwable&#123;        object = this; // 重新建立引用链    &#125;    public static void main(String[] args) &#123;        try&#123;            object = new RebackObject(); // 建立引用链            object = null; // 失去引用链            System.gc(); // 调用GC            System.out.println(&quot;第一次 GC&quot;);            Thread.sleep(2000); // 等待 finalizer 线程调用finalize方法            if(object == null)&#123;                System.out.println(&quot;object is dead&quot;);            &#125;else &#123;                System.out.println(&quot;object still alive&quot;);            &#125;            // --------------------------------------------            System.out.println(&quot;第二次GC&quot;);            object = null; // 再次失去引用链            System.gc();            Thread.sleep(2000);            if(object == null)&#123;                System.out.println(&quot;object is dead&quot;);            &#125;else &#123;                System.out.println(&quot;object still alive&quot;);            &#125;        &#125;catch (Exception e)&#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n运行结果如下：\n第一次 GCobject still alive第二次GCobject is dead\n\n清除阶段算法JVM常见的三种垃圾回收算法：\n\n标记-清除算法（Mark-Sweep）\n复制算法（Copying）\n标记-压缩算法（Mark-Compact）\n\n还有一些其他的算法：\n\n增量收集算法\n分区算法\n\n标记-清除算法\n一种基础常见的垃圾收集算法。\n提出者——J.McCarthy，应用于Lisp语言\n\n执行过程：\n当有效内存空间（available memory）被耗尽的时候，就会STW，然后进行两项工作：\n\n标记：回收器从根节点开始遍历，标记所有被引用的对象（注意：标记的是可达对象）\n清除：回收器对堆内存从头到尾进行线性遍历，如果发现某个对象在其Header（对象头）中没有标记为可达对象，则将其回收。\n\n缺点：\n\n效率不高\nGC时需要STW，用户体验差\n清理出的空间内存不连续，产生内存碎片，需要维护一个空闲列表\n\n注意：\n清除不需要置空，只需要标记为空闲即可。下次使用直接覆盖。\n复制算法算法思想：\n将活着的内存空间分为两块：每次只使用一块，在GC时将正在使用的内存中存活对象复制到未被使用的内存块中，之后清除正在使用内存块中的所有对象，交换两个内存的角色，最后完成回收。\n优点：\n\n没有标记和清除的过程，实现简单，运行高效\n复制过去以后保证空间的连续性，不会出现碎片问题\n\n缺点：\n\n需要两倍的内存空间\n对于G1这种分拆成为大量rigion的GC回收器，复制而不是移动，意味着GC需要维护region之间对象引用关系，内存占用大，时间开销也大\n不利于非垃圾对象多的情况\n\n应用场景：\n在新生代中，有from区和to区，就应用了这种算法；\n新生代大部分都是垃圾对象，而且新生代也不大，完美的契合这种算法。\n标记-压缩算法复制算法利于新生代，但对于老年代这种大内存，需要使用其他算法。\n但是标记清除算法效率低下还会产生内存碎片，所以对其进行了改进。\n过程：\n\n标记（同标记-清除算法）\n将所有存活的对象，压缩到内存的一端并按顺序排放，之后清理边界外所有的空间。\n\n也可以称为标记-清除-压缩算法，他与标记-清除算法的区别是：是否对对象进行了移动。\n优点：\n\n内存连续（对比标记-清除算法）\n内存不需要加倍（对比复制算法）\n\n缺点：\n\n效率低于复制算法\n移动对象时，如果对象被其他对象引用，还需要调整引用的地址\n移动过程需要STW\n\n三种清除算法的对比\n\n\n\nMark-Sweep\nMark-Compact\nCopying\n\n\n\n速度\n中等\n最慢\n最快\n\n\n空间开销\n少（有内存碎片）\n少\n两倍大小\n\n\n移动对象\n否\n是\n是\n\n\n分代收集算法\n所谓分代收集算法，就是按照不同的代，使用不同的算法。\n\n目前几乎所有的GC都使用了分代收集算法\n\n年轻代\n较小、回收频繁、垃圾多\n适用复制算法\n\n\n老年代\n较大、回收次数少、垃圾少\n一般由标记-清除算法和标记-压缩算法混合实现\n\n\n\n在Hotspot Vm中，CMS回收器采用Mark-Sweep算法，回收效率高。\n对于内存碎片问题，CMS采用Mark-Compact算法的Serial Old回收器作为补偿：当内存回收不佳（碎片导致的Concurrent Mode Failure时），将采用Serial Old 执行Full GC以达到对老年代内存的整理\n增量收集算法上述所有的清除算法，都会出现STW状态，而长时间的STW严重影响用户体验。\n增量收集算法就是为解决STW而提出的一种算法。\n基本思想：\n​        一次性清理所有垃圾，需要长时间的STW，那么可以让垃圾收集线程和应用程序线程交替执行\n​        每次，垃圾收集线程只收集一小片区域的内存空间，接着就切换到应用程序线程，依次反复，直到垃圾收集完成。\n本质上此算法的基础依旧是标记清除算法和复制算法，但是此算法通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作。\n缺点：\n\n线程切换和上下文转换的消耗大，导致垃圾回收的总成本上升，造成系统吞吐量下降。\n\n分区算法​        一般来说，在相同条件下，堆空间越大，一次GC时所需要的时间就越长，有关GC产生的停顿也越长。\n​        为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。​        分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。​        每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。\n三色标记算法分为白、黑、灰三色，分别标记不可达对象、可达对象、尚未遍历完成的对象\n\n初始时，将所有对象标记为白色\n将所有GC roots直接关联的对象标记为灰色\n遍历这些直接关联的对象，如果一个对象没有子引用对象，就标为黑色；如果有子引用对象，标为灰色\n重复第3步\n\n可能会有 浮动垃圾 和 漏标的问题：\n\n浮动垃圾：标记前不是垃圾，标记后变为垃圾，导致没有GC掉\n漏标：标记前是垃圾，但是标记后不是垃圾了，导致被错误的GC掉\n\nGC相关概念System.gc()方法\n程序员可以使用System.gc()来显示的触发Full GC\n这个方法相当于调用Runtime.getRuntime().gc()，实际上System.gc()底层也是这么写的\n只是提醒，无法保证对垃圾回收器的调用\n\ndemo如下：\npublic class GCTest &#123;    public static void main(String[] args) &#123;        new GCTest();        System.gc();    &#125;    @Override    protected void finalize()&#123;        System.out.println(&quot;调用了finalize方法！&quot;);    &#125;&#125;\n\n执行结束，也不会打出“调用了finalize方法！”\n因为重写finalize会被另一个低优先度的线程，以此证明System.gc()方法只是提醒JVM进行GC，但是GC回收器的选择还是由JVM来操作。\n另外JVM有方法System.runFinalization()强制调用失去引用的finalize()方法\n\n还有一些关于GC的demo，便于深入理解GC的时刻\n先来两个简单的demo：\npublic void localVarGC1()&#123;    byte[] buffer = new byte[1024 * 1024 * 5];    //5MB; 注意这里设置太大，有可能直接分配到老年代，然后会被GC掉    System.gc();    //[GC (System.gc()) [PSYoungGen: 10375K-&gt;5864K(76288K)]    //[Full GC (System.gc()) [PSYoungGen: 5864K-&gt;0K(76288K)] ParOldGen: 8K-&gt;5727K(175104K)] 5872K-&gt;5727K(251392K)    //可以看出： young GC 没有回收掉buffer，而是Full GC时，将数据放到了老年代（老年代8K-&gt;5727K，变大了）&#125;public void localVarGC2()&#123;    byte[] buffer = new byte[1024 * 1024 * 5];    buffer = null;    System.gc();    //[GC (System.gc()) [PSYoungGen: 7741K-&gt;128K(76288K)]    //[Full GC (System.gc()) [PSYoungGen: 128K-&gt;0K(76288K)] [ParOldGen: 5727K-&gt;629K(175104K)]    // 可以看出 不可达对象 直接就被YGC了&#125;\n\n可见，正常情况下，有引用链的对象，在Full GC后，会被转移到老年代；而没有引用链的对象，就直接被回收了\nprivate void localVarGC3() &#123;    &#123;        byte[] buffer = new byte[1024 * 1024 * 5];    &#125;    System.gc();    //[GC (System.gc()) [PSYoungGen: 10375K-&gt;5896K(76288K)]    //[Full GC (System.gc()) [PSYoungGen: 5896K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;5728K(175104K)]    // 注意：没有被回收，放在了老年代！是因为buffer还占用着局部变量表的slot槽&#125;private void localVarGC4() &#123;    &#123;        byte[] buffer = new byte[1024 * 1024 * 5];    &#125;    int a = 0; // 把槽占用掉    System.gc();    //[GC (System.gc()) [PSYoungGen: 7741K-&gt;224K(76288K)]    //[Full GC (System.gc()) [PSYoungGen: 224K-&gt;0K(76288K)] [ParOldGen: 5728K-&gt;629K(175104K)]    // 这里就被YGC回收掉了！因为槽被占用&#125;\n\n其中localVarGC3()方法中的对象，在&#123;&#125;中，按理来说应该被回收，但其实没有，因为buffer变量还占用着局部变量表的slot槽；下面的例子将槽复用后，这个对象就被回收掉了\n内存溢出与内存泄露\n内存溢出OOM：\n没有足够的内存使用（即使GC后内存也不够）\n\n造成OOM的原因有两种：\n\nJVM堆内存设置大小不够\n可能存在内存泄露；也可能堆设置的太小了\n\n\n创建了大量大对象，并且GC收集不了\n\n报OOM之前，通常会执行GC\n\n如果内存不够，会自动触发一次GC，如果还不够则会报出OOM异常；\n\n如果想创建一个超大的对象，这个对象的内存大小直接超过了堆大小，那么JVM不会去触发GC，而是直接OOM\n\n\n\n\n内存泄露（Memory Leak）：\n​        严格来说，只有对象不会再被程序用到了，但是GC又不能回收他们的情况，才叫内存泄露。\n​        实际情况中，一些不太好的实践导致对象的生命周期变长甚至OOM，也算宽泛意义上的“内存泄漏”。\n\n​         内存泄露不会立即引起程序崩溃，但是一旦发生内存泄露，程序中的可用内存就会被进一步蚕食，直至耗尽所有内存，最终出现OOM异常（内存泄露有可能导致OOM，但并不一定）\n内存泄露的例子：\n\n单例模式：单例的生命周期和应用程序一样长，所以单例程序中，如果用一个单例的对象关联外部对象的引用的话，那么这个外部对象是不能被回收的，会导致内存泄漏的产生。\n一些提供close的资源未关闭导致内存泄露：数据库连接、网络连接、io连接等必须手动close，否则是不能被回收的。\n\n可能的内存泄漏的原因\n静态的集合类\n\nstatic List&lt;String&gt; list = new ArrayList&lt;&gt;();\n\n类的变量的生命周期很长，类信息被回收的条件比较苛刻，需要满足三个条件：1、没有任何实例。2、子类也没有任何实例。3、加载该类的类加载器已被回收\n注意：类的静态常量一般属于常量池，其实际的位置在堆中，是可以方便回收的。\n\n单例对象\n\n单例对象一般是static修饰的，如果其含有外部引用，那么也不会被回收。\n\n数据库连接、IO、Socket没有关闭\n\n连接如果没有调用close方法关闭，是不会被回收的。\n\nhash值发生变化\n\n使用HashMap等容器，如果存入之后，对象的hash值发生变化，那么也就找不到对应的对象了，也就无法回收。\n（这也是为什么String被设计为不可变类型的原因）\n\nThreadLocal使用不当\n\nThreadLocalMap的Entry是弱引用的，弱引用会在每一次GC时被回收，但是如果创建该线程仍然存活，value还是处于被引用的状态，就不会被回收\nStop The World\nSTW：指GC事件中，整个应用线程被暂停，没有响应的状态。\n\n\n所有的GC回收器都有STW事件\nSTW由JVM在后台自动发起和自动完成，用户不可见。\n\n垃圾回收的并行与并发操作系统的并发并行：\n\n并发：同一个时间段发生；互相抢占资源\n并行：同一个时间点发生；不互相抢占资源\n\n垃圾回收的并行和并发：\n\n并行：多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态\n如：ParNew、Parallel、Scavenge、Parallel Old\n\n\n并发：用户线程和垃圾收集线程同时进行（注意是一个时间段内，这个时间段内，可能用户线程和垃圾收集线程是来回交替的）\n如：CMS、G1\n\n\n\n安全点与安全区域程序运行过程，不是所有的时间点都可以停下进行GC\n\n安全点（Safe Point）：可以停顿下来进行GC的位置\n\n安全点的选择很重要：\n\n太少，GC等待时间太长\n太多，运行时太卡\n\n通常会根据 是否具有让程序长时间执行的特征 为标准选择安全点。\n例如：选择一些执行时间较长的指令，方法调用、循环跳转、异常跳转等\n\n如何确保GC时所有线程都进入安全点了呢？\n\n有两种方法：\n\n抢先式中断：（目前没有虚拟机采用）\n首先中断所有线程，如果线程不再安全点，恢复其线程，让其运行至安全点\n\n\n主动式中断：\n设置一个中断标志，各个线程运行到safe point就主动轮询这个标志，如果中断标志位真，就将自己进行中断挂起\n\n\n\n\n如果线程处于Sleep状态或是Blocked状态，也就无法进入到安全区域\n\n安全区域：\n​        一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置开始GC都是安全的。\n\n我们可以把安全区域看作是被扩展了的安全点\n\n当线程运行到safe Region的代码时，首先**标识已经进入了Safe Region**，如果这段时间内发生GC，JVM会忽略标识为Safe Region状态的线程\n当线程即将离开Safe Region时，会检查JVM是否已经完成GC，如果完成了，则继续运行，否则线程必须等待直到收到可以安全离开Safe Region的信号为止\n\n深入引用JDK1.2后，引用进行了扩展，分为了四种，其强度依次递减\n\n强引用（StrongReference）：强引用下，不会被GC回收；会造成内存泄漏\n软引用（SoftReference）：系统将要发生OOM溢出之前，会将软引用回收，如果回收后依然没有足够的内存，才会抛出OOM\n弱引用（WeakReference）：弱引用关联的对象只能生存到下一次GC之前，无论内存是否充足都会回收弱引用。\n虚引用（PhantomReference）：一个对象是否有虚引用存在，完全不会对其生存时间构成影响，也无法通过虚引用来获得一个对象的实例。虚引用的唯一目的是为了在这个对象被GC时收到一个系统通知\n\n只有强可触及对象不会被GC，软可触及、弱可触及、虚可触及都可以被回收掉\njava.lang.ref包下，有四个引用类对象，还有一个是终结器引用：\njava:\tlang:\t\tref:\t\t\tSoftReference\t\t\tWeakReference\t\t\tPhantomReference\t\t\tFinalReference（终结器引用）\n\n而且终结器引用是包内可见，其他全为public\n下面具体介绍这几个引用：\n\n\n强引用——永不回收\n\n特点：\n\n强引用可以直接访问对象\n强引用指向的对象永远不会被GC，JVM即使抛出OOM，也不会回收强引用对象\n强引用很可能导致内存泄漏\n\n\n软引用——不足才回收\n\n特点：\n\n用来描述一些还有用但是非必须的对象\n只有在即将OOM之前，JVM才会回收这些对象（即使主动调用GC，如果内存还有空闲，就不会清除）\n清理软引用时，可以将引用存放到一个引用队列（可选）\n\n应用：\n\n通常来实现内存敏感的缓存，高速缓存就用到了软引用\n\n可以使用java.lang.ref.SoftReference来实现软引用\n例如：\n// 强引用String str = new String(&quot;nihao1&quot;);// 软引用SoftReference&lt;String&gt; soft = new SoftReference&lt;&gt;(str);// 销毁强引用str = null;//或者直接一行完成SoftReference&lt;String&gt; soft = new SoftReference&lt;&gt;(new String(&quot;nihao1&quot;));\n\n\n弱引用——发现即回收\n\n特点：\n\n只被弱引用关联的对象只能生存到下一次GC发生为止（无论内存是否足够）\n由于垃圾回收线程的优先级很低，所以不一定很快被回收掉；这种情况可以存活较长时间\n\ndemo：\n// 强引用String str = new String(&quot;nihao&quot;);// 弱引用WeakReference&lt;String&gt; weak = new WeakReference&lt;&gt;(str);// 销毁强引用str = null;\n\n\n虚引用——对象回收跟踪\n\n特点：\n\n也称为幽灵引用、幻影引用\n设置虚引用的唯一目的：跟踪垃圾回收进程，在被回收前收到一个系统通知\n虚引用对对象的生命周期没有丝毫影响：一个对象如果只有虚引用，那么和没有引用一样\n虚引用get()方法得不到对象，返回的是一个null\n使用时必须和引用队列一起使用，GC工作时，如果发现对象还有虚引用，那么他会在回收对象后，将这个虚引用加入引用队列，以通知对象回收情况\n虚引用可以跟踪对象回收时间，因此可以将一些资源释放操作放置在虚引用中执行和记录\n\n// 强引用String str = new String(&quot;nihao&quot;);// 虚引用ReferenceQueue&lt;String&gt; queue = new ReferenceQueue&lt;&gt;(); // 必须配合引用队列PhantomReference&lt;String&gt; pf = new PhantomReference&lt;&gt;(str, queue);// 销毁强引用str = null;\n\n\n终结器引用\n\n\n用以实现对象的finalize()方法\n无需手动编码，内部配合引用队列使用\nGC时，终结器引用入队。由Finalize线程通过终结器引用找到被引用的对象并调用他的finalize()方法，第二次GC时才回收该对象。\n\nGC回收器垃圾收集器没有进行太多规范，不同的厂商有不同的定制\n垃圾回收器基本概念垃圾回收器的分类：\n\n按照线程数分\n\n串行垃圾回收器\n并行垃圾回收器\n\n\n按工作模式分\n\n并发式垃圾回收器\n独占式垃圾回收器\n\n\n按碎片处理方式分\n\n压缩式垃圾回收器\n非压缩式垃圾回收器\n\n\n按工作内存区间分\n\n年轻代垃圾回收器\n老年代垃圾回收器\n\n\n\n性能评价指标：（加粗为重点参考指标）\n\n吞吐量：运行用户代码的时间与总运行时间的比例\nT总运行 = T程序 + T内存回收\n\n\n垃圾收集开销：吞吐量的补数，垃圾回收时间与总运行时间的比例\n暂停时间：执行GC时，工作线程被暂停的时间\n收集频率：相对于应用程序的执行，收集操作发生的频率\n内存占用：Java堆区占用的内存大小\n快速：一个对象从诞生到被回收所经历的时间\n\n吞吐量vs暂停时间吞吐量大，程序更多时间处于生产状态；暂停时间短，会让用户感觉交互性好，延迟低。\n但是吞吐量和暂停时间是负相关的，如果以低延迟为优先，那么就要暂停时间短，就要减少GC的时间，但是GC次数更加频繁，从而吞吐量下降；如果以高吞吐量为优先，那么一次GC的时间就会变长，暂停时间就会变大。\n现在的标准：在保证最大吞吐量优先的情况下，降低停顿时间\n不同的垃圾回收器概述经典款：\n\n串行回收器：Serial（第一款GC）、Serial Old\n并行回收器：ParNew（Serial的并行版本）、Parallel Scavenge（JDK8）、Parallel Old（JDK8）\n并发回收器：CMS、G1（JDK9默认GC）\n\n最新款：\n\nZGC、shenandoah GC\n\n本节主要对经典款GC做介绍：\n\n 新生代收集器：Serial、ParNew、Parallel Scavenge\n老年代收集器：Serial Old、Parallel Old、CMS\n整堆收集器：G1\n\n垃圾回收器的配合情况：\n\n关于图的解释：\n\n为什么CMS与Serial Old有连接？\nCMS收集时 可能失败，需要Serial Old做后备方案\n\n\n虚线代表最新版本（截止JDK14）取消的组合；\n红线代表JDK9取消的组合；\n绿线代表JDK14取消的组合\n\n\nCMS用虚线框，代表最新版本JDK14中删除了\n\n查看默认的GC：\n\n-XX:PrintCommandLineFlags查看命令行相关参数，包括使用的GC是什么\n\n-XX:InitialHeapSize=266429440 -XX:MaxHeapSize=4262871040 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC &lt;- JDK8运行：这里写着使用ParallelGC\n\n\njinfo -flag 相关垃圾回收器参数 进程ID\n\nSerial GC——串行回收\nSerial 与 Serial Old\n\n第一款GC收集器，JDK1.3之前新生代的唯一选择\nSerial特点：\n\n是Hotspot中client模式下的默认新生代GC\n采用复制算法、串行回收、STW机制\n与Serial Old搭配使用\n\nSerial Old特点：\n\nSerial Old同样是client模式下的默认老年代GC\n使用标记压缩算法、串行回收、STW机制\n应用有两个：\n与Serial搭配使用\n作为CMS的后备垃圾收集方案\n\n\n\n\n优势：\n\n简单而高效：单线程的GC王\n适用于低配机器：单核CPU机器\n\nParNew——并行回收\nSerial的多线程版本，Par代表Parallel，New代表只能处理新生代\n\n特点：\n\n复制算法、并行回收、STW机制\n能与CMS、Serial Old进行组合\n\n与Serial Old搭配：\n\n新生代GC频繁，使用并发；老年代GC次数少，用串行节省资源\n\nParNew一定比Serial性能高吗？\n\n如果CPU多核、那么是一定的；如果CPU只有一个核，Serial反而发挥更好。\nParallel——吞吐量优先\nParallel Scavenge与Parallel Old：JDK 8 默认GC\n\nParallel Scavenge：\n\n复制算法、并行回收、STW机制\n可以与Serial Old、Parallel Old搭配使用\n吞吐量优先\n自适应策略：\n运行过程会对年轻代大小、Eden与Survivor的比例、晋升老年代对象年龄进行调整\n\n\n\nParallel Old：\n\n标记压缩算法、并行回收、STW机制\n\n\n与ParNew机制一样？是否多此一举？\n\n\n与ParNew不同，Parallel Scavenge目标是为了达到一个可控制的吞吐量，被称为吞吐量优先的垃圾回收器。\n\n而且区别与ParNew，Parallel Scavenge还有自适应调节策略\n\n\nParallel与ParNew对比：\n\n\n\nGC\nParNew\nParallel\n\n\n\n内存占用\n小\n较大\n\n\n吞吐量\n较小\n高\n\n\n因为高吞吐量的优势，所以Parallel Scavenge适合执行交互不多的后台计算任务\n\nCMS——低延迟CMS特点\nCMS：Concurrent Mark Sweep JDK1.5推出的强交互GC，也是第一款并发GC\n\n\n并发GC：用户线程与垃圾收集线程并发执行\n标记清除算法、STW机制\n目的是减少暂停时间，提高交互性\n运行在老年代\n可以与Serial、ParNew进行搭配\nSerial Old是CMS的备选方案\n\n\n为什么不能与Parallel进行搭配？\n\n由于使用的框架不同，导致不能搭配使用\n\nCMS工作原理\nCMS的工作主要分为四个阶段：\n\n初始标记（Initial Mark）：短暂的STW，仅仅只标记出GC Roots能直接关联到的对象\n并发标记（Concurrent-Mark）：从第一步找到的直接关联的对象开始，遍历整个对象图，是整个过程中耗时时间最长的阶段，但是不需要STW\n重新标记（Remark）：确认并发标记期间不能确定是否是垃圾的对象，这部分也需要STW\n并发清除（Concurrent-Sweep）：清除标记阶段判断的依据死亡的对象，释放内存空间\n提前GC：达到阈值就开始GC（JDK6+默认阈值为92%）\n\n注意：\n\n即使是CMS，也有STW，STW发生在初始标记和重新标记两个阶段\n\n另外，由于CMS回收过程中，用户进程依旧在运行，所以要保证有足够的空间使用，因此CMS不能等到老年代满才进行手机，而是达到一定阈值就开始进行回收;\n如果CMS运行期间预留的内存无法满足程序需要，就会出现Concurrent Mode Failure，此时JVM会采用后备方案，临时启用Serial Old收集器来进行老年代的收集\n\n因为CMS为了低延迟与并发，采用标记清除算法，所以会产生内零头（内存碎片），所以CMS只能使用空闲列表的方式进行内存分配，不能使用指针碰撞\n\n\n\n为什么CMS采用标记清除算法而不是标记压缩算法？\n\nCMS主打低延迟与并发，所以如果使用标记压缩算法，除了运行时间会稍长外，最致命的是不能进行并发操作；如果要进行压缩，势必要让对象进行移动，那用户线程就必然不能执行了\nCMS优与劣优势：并发收集、低延迟\n弊端：\n\n产生内存碎片，无法分配大对象时只能进行Full GC\n\n对CPU资源敏感，会因为用户线程占用CPU资源而导致吞吐量降低\n\nCMS无法处理浮动垃圾，而且有可能回收失败\n\n浮动垃圾：在并发标记阶段，用户线程产生的新的垃圾对象\n注意：\n并发标记阶段，有不能确认的对象（这里成为怀疑对象），重新标记阶段就是最终确认怀疑对象是否是垃圾\n而浮动垃圾是并发标记阶段前不是垃圾，而后变为垃圾的垃圾\n\n\n\nG1——区域化分代式产生背景：\n为了进一步的提高吞吐量、降低暂停时间；\nG1基本了解\nG1 （Garbage First）：JDK7引入，JDK9作为默认GC\n\nRegion：\n在G1中，把堆分为一个一个Region，而Region进一步的去组成Eden、Survivor、老年代\nG1可以跟踪每个Region内垃圾堆积的价值（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Regin（G1因此得名）\n\n可见新生代、老年代不再是连续的了\nG1的特点\n采用分区算法，分为一个一个Region，回收的单位是Region\nRegion级别是复制算法\n整体可以看做标记压缩算法\n\n\n兼顾并行与并发\n并行：G1回收期间可以和多个GC线程同时工作（此时STW）\n并发：G1也可以与用户线程交替执行，部分工作可以和应用线程同时执行\n\n\n兼顾老年代与年轻代\n可预测的停顿时间模型\n相较于CMS的一大优势：除了追求低停顿，还能明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒\n不需要全局停顿，只需要回收价值最高的Region\n\n\n对比CMS，G1还不具有压倒性优势\n有更大的内存占用和额外的负载\n\n\n提供三种垃圾回收模式：YoungGC、Mixed GC、Full GC\n\nRegion：化整为零G1将Java堆划分成越2048个大小相同的独立Region块；每个Region的大小由实际情况而定，整体控制在1MB-32MB之间，且为2的幂次\n所有Region的大小是相同的，并且在JVM生命周期内不变\n新生代和老年代由Region组成，但不再是物理隔离的了\nG1中有四种角色，一个Region只能属于一个角色（角色是可以变化的）\n\n对于H角色我们要详细说明：H其实是Old区的一种，如果要存入的对象大于一个Region的一半，就视为一个H区，JVM对待H区等同于Old\n图中Humongous代表矩形对象，是G1新增的内存区域，用来存储大对象，如果超过1.5个Region就存放到H中，如果一个H不够，会去找连续的H进行存储（如果没有连续的H，会触发Full GC）\n原因：在原有的JVM设计下，对于堆中超过新生代的大对象，会直接存放到老年代，但是如果是一个短期的大对象，这样处理显然是不好的，因此划分了H区，H的很多行为都被当做老年代来看待。\nG1的垃圾回收机制垃圾回收过程主要包括三个环节（最后一个环节作为保护方案）：\n\n年轻代GC（Young GC）\n老年代并发标记过程（Concurrent Marking）\n混合回收（Mixed GC）\nFull GC（GC评估失败后的保护机制）\n\n\n在开始细细阐述每一步之前，先来了解一个概念：\n每一个Region不是孤立的，一个Region中的对象很可能被其他任意类型的Region引用。\n那么问题来了：如果一个新生代Region只被一个老年代Region引用，我们是不是得花大力气去遍历所有老年代Region？\n这样太麻烦了，STW时间会很长很长，因此提出了记忆集的概念\n\nRemembered Set（Rset）：记忆集\n\n\n每一个Region都有一个Remembered Set\n每次Reference类型数据写操作时，都会产生一个Write Barrier写屏障暂时中断操作，检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region\n如果不同，通过CardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中（CardTable是记忆集的具体实现）\n\n\nG1垃圾回收器的记忆集的实现实际上是基于哈希表的，key代表的是其他region的起始地址，value是一集合，里面存放了对应区域的卡表的索引，因此G1的region能够通过记忆集知道，当前是哪个region有引用指向了它，并且能知道是哪块区域存在指针指向。（其他GC的收集器就是一个byte数组，只能知道一个区域是否有指针指向，而不能知道是谁指向）\n\n因此当进行垃圾收集时，加入Remember Set就可以保证不进行全局扫描也不会有遗漏\n\n垃圾回收机制，有四种：\n一、年轻代GC当Eden区空间耗尽时，G1会启动一次YGC\n首先STW，G1创建回收集（Collection Set）\n\n回收集是指需要被回收的内存分段的集合\n年轻代回收过程的回收集包含年轻代Eden区和Survivor区所有的内存分段\n\n回收过程：\n\n扫描根\n\n根引用连同RSet记录的外部引用作为扫描存活节点的入口\n\n\n更新RSet\n\n处理dirty card queue中的card，更新RSet\n\n更新完成后，RSet可以准确反映老年代对当前所在内存分段中对象的引用\n\n脏卡表队列：\n对于引用赋值语句，类似于Object obj = object，JVM会在执行这条语句的之前和之后再脏卡表队列中入队一个保存了对象引用信息的Card\n在G1 YGC时，G1会对脏卡表队列中所有的card进行处理，更新RSet\n\n为什么不在引用赋值语句直接更新Rset？\n\n如果着这样做，RSet处理需要考虑线程同步，复杂而且开销大\n\n\n\n\n处理RSet\n\n识别其中指向Eden的对象\n\n\n复制对象\n\n使用复制算法，将存活对象复制到Survivor区的空的内存分段\n如果达到年龄阈值，复制到Old区\n如果Survivor空间不够，直接晋升至老年代\n\n\n处理引用\n\n处理软、虚、最终引用、JNI Weak等各种引用\n清空Eden空间\n\n\n\n二、 并发标记+YGC\n初始标记阶段\nSTW，标记从根直接的可达对象；\n并触发一次YGC\n\n\n根区域扫描\n标记Survivor区直接可达的老年代区域对象，并标记\n必须在YGC之前完成\n\n\n并发标记\n可以与应用线程同时执行\n可能被YGC打断\n如果发现一个Region全是垃圾，那这个Region会被立即回收\n计算每个Region的对象活性（存活对象的比例）\n\n\n再次标记\nSTW：修正并发标记期间的标记结果（同CMS）\n采用比CMS更快的初始快照算法（snapshot-at-the-beginning SATB）\n\n\n独占清理\nSTW；计算每个区域的存活对象和GC的回收比例，进行排序，识别可以混合回收的区域\n并不会实际去做垃圾的收集\n\n\n并发清理\n识别并清理完全空闲的区域\n\n\n\n三、混合回收​        当越来越多的对象晋升到old region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器即Mixed GC（该算法并不是old Gc）\n​        除了回收整个Young Region，还会回收一部分的old Region。\n注意：回收是一部分老年代，而不是全部老年代\n​        由于前一个阶段，对老年代的垃圾回收价值进行了排序，所以排序越靠前，越会被先回收\n​        回收分默认分8次进行（不一定要完全8次，允许一个Region对内存浪费10%），并且只有垃圾占65%时才会对一个Region进行回收\n四、 Full GC\nFull GC是一个可能会被触发的过程，并不是一定会有的过程\n\n是一个单线程过程，运行很慢，STW时间很长\n\n\n导致G1 进行Full GC的原因可能有三个：\n\nEvacuation时没有足够的to区存放晋升的对象\n并发处理过程完成之前空间耗尽\n最大GC停顿时间太短，导致在规定的时间间隔内无法完成垃圾回收，也会导致Full GC\n\nCMS与G1的跨代引用问题\n跨代引用问题：加入有老年代执行新生代的引用，GC时是否需要遍历所有的老年代对象呢？这就是跨代引用问题\n\n首先需要了解几个结构：卡表、写屏障。\n\n卡表：一个字节数组，每一个字节代表一个卡页，卡页是一段内存区域（HotSpot实现中一个卡页代表512字节的内存范围），如果卡的范围内存在至少一个外部引用，那么就会置为为1，表示脏页\n\n\n记忆集：记忆集是专门为了解决跨代引用问题提出的一种理想化的结构，卡表是记忆集的一种具体实现（类似于HashMap与Map的关系）\n\n\n写屏障：是对象引用在被修改时执行的一段代码。（可以理解为一个机器码级别的AOP，会在对象引用发生变化的时候执行，更改卡表为脏）\n\n\nCMS中的卡表是一个字节数组，每一个字节代表一段512字节的区域，如果该区域至少存在一个对象存在外部的引用（CMS只会记录老年代指向新生代），就将该位置的卡表置位1,card_table[this_addr &gt;&gt; 9] = 1（当前地址右移9位，代表地址除以512，就是对应卡表的索引位置）\nG1的卡表是一个hashMap，key存储了外部region的起始地址，value是一个记录卡表索引号的集合，因此G1的这种结构可以找到哪个Region指向了我。\n\n\n\n问题：假设没有记忆集这个结构，该如何进行一次YGC呢？\n\n为了防止年轻代的对象含有老年代的引用，我们需要遍历老年代的所有对象。（成本很大）\nG1的清理步骤\n初始标记（STW）：标记GCRoots可以直接关联的对象\n并发标记：GC线程可以与用户线程同时执行，使用SATB（原始快照算法）扫描的更少\n最终标记（STW）：标记遗留的少部分STAB记录\n筛选回收（STW）：将各个region按可回收价值排序，选择任意个Region组成回收集合，将依然可以存活的对象复制到新的Region，然后清空对应的Region。\n\n与CMS不同的是，G1筛选回收的阶段也需要STW\n\n问题：并发标记阶段，如何保证用户线程和GC线程互不干扰？\n\nCMS使用增量更新的方式，G1使用STAB算法\nG1每一个Region有两个指针TAMS（Top at Mark Start），两个指针之间的空间用来担任回收期间的新对象分配\nCMS对比G1\n回收算法：\nCMS是标记清除算法；\nG1宏观上是标记压缩算法，微观上是标记复制算法\n\n\n卡表的设计：\nCMS是一个简单的字节数组（为什么不是bit数组？操作系统最小的取值单位是字节，bit还需要移位操作，会慢一点），只管老年代指向新生代的跨代引用，对于新生代对老年代的引用，在极端情况下需要遍历所有新生代的对象。\nG1是一个hashmap，key是其他region的起始地址，value是对应卡表的索引，因此G1可以实现双向的指向\n\n\n卡表的大小：\nCMS的卡表全局唯一，且只负责老年代指向新生代的引用\nG1每一个Region有一个卡表\n\n\n内存、CPU占用：\nCMS相较于G1要少一些，G1需要额外10%20%的内存来维持GC，这大约需要68G的堆大小才能安全工作，小内存下，CMS的效果更好\nCMS的额外负载要少于G1\n\n\nSTW：\nCMS只有初始标记、重新标记需要STW\nG1在初始标记、最终标记、筛选回收都需要STW\n\n\n其他特性：\nG1可以实现指定时间内的GC\nG1可以同时完成新生代与老年代的回收，CMS只可以完成老年代的回收。\nG1使用的STAB算法比CMS更快，扫描的内容更少\n\n\n\n文章相关链接\n尚硅谷JVM教程：强推，最强JVM视频教程\n《深入理解Java虚拟机》阅读笔记：省下看书的时间\n《深入理解Java虚拟机》：书还是要看的\n\n","categories":["JVM","GC"],"tags":["JVM","GC"]},{"title":"RequestAndResponse","url":"/2019/10/11/Servlet/RequestAndResponse/","content":"\n引言：\n\nRequest&amp;Response\n\n\n\n\n\nHTTP概述Hiper Text Transfer Protocol 超文本传输协议\n\n传输协议：定义了客户端和服务器端通信时，发送数据的格式\n\n客户端给服务器端发送请求消息\n服务器端解析客户端的请求消息，给客户端发送响应消息\n特点\n基于TCP/IP的高级协议\n默认端口号 80\n基于请求/响应模型的：一次请求对应一次响应\n无状态的：每次请求之间相互独立，不能交互数据\n\n历史版本\n1.0版本：每一个图片，每一个css等配置文件，都是一个请求，每次都会重复申请连接\n1.1版本：复用连接\n\n请求消息数据格式Request格式分为四个部分\n\n请求行\n请求方式 请求url 请求协议/版本\n\n GET /login.html HTTP/1.1\n\n请求方式有七种，常见有两种\nGET:\n请求参数在请求行中\n请求的url长度有限\n不太安全\n\n\nPOST:\n请求参数在请求体中\n请求的url长度没有限制\n相对安全\n\n\n\n\n\n\n请求头\n请求头名称:请求值（键:值）\n\n\n请求空行\n空行,分隔请求头和请求体\n\n\n请求体（正文）\n封装Post请求消息的请求参数\n\n\n\n字符串格式\n//-------------请求行---------------GET /login.html HTTP/1.1//上面为请求行，底下为请求头//-------------请求头---------------Host: localhost//Host:请求主机是localhostUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0//User-Agent:浏览器告诉服务器，访问使用的浏览器版本信息//服务端获取该头信息，解决了浏览器的兼容性问题Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8//支持的响应格式Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2//支持的语言环境Accept-Encoding: gzip, deflate//支持的解析结构Content-Type: application/x-www-form-urlencodedContent-Length: 9Connection: keep-alive//keep-alive 表示连接都是可以复用的Referer: http://localhost/login.html//告诉服务器，当前请求是从哪里发出的//作用：1.防盗链：防止其他网页盗取链接 2.统计工作：获取来源处的某些信息，比如统计广告来源Upgrade-Insecure-Requests: 1//上面为请求头，底下为参数//------------参数----------------username = &quot;输入的内容&quot;\n\n响应消息数据格式Response也分为四个部分\n\n响应行\n组成：协议/版本 响应状态码 状态码的描述\n响应状态码：一个三位数字，分为五类，服务器告诉客户端浏览器本次请求和响应的一个状态\n1xx ：服务器接收客户端消息但没有接收完成，等待一段时间后发送1xx的一个状态码\n2xx ：成功。代表：200(成功)\n3xx ：重定向。代表：302(重定向),304(访问缓存)\n4xx ：客户端错误。代表：404(请求路径为空)，405(请求方式没有对应的doGet等方法)\n5xx ：服务器端错误。代表：500(服务器端出现异常)\n\n\n\n\n响应头\n格式： 头名称:值\n\n\n响应空行\n响应体\n\n字符串格式：\nHTTP/1.1 200 //响应行：协议/版本 响应状态码 状态码的描述Content-Type: text/html;charset=UTF-8//告诉服务器本次响应体的数据格式以及编码格式Content-Length: 90//本次请求的字节数Date: Tue, 08 Oct 2019 13:39:33 GMT//日期Content-disposition://服务器告诉客户端以什么打开响应体数据//值： 1. in-line代表在当前页面打开 2.attachment：以附件形式打开响应体，用于文件下载//--------以上为响应头----------//响应体即传送的数据，内容包括我们可以看懂的HTML的内容，还有其他的一些看不懂的内容\n\n\nRequest&amp;Response重写doGet和doPost方法后，可以接收两个参数Request和Response\npublic class servletDemo extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;doGet方法&quot;);    &#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;doPost方法&quot;);    &#125;&#125;/**    1. tomcat服务器会根据url中的资源路径，创建对应的ServletDemo类的对象    2. tomcat服务器会创建request和response对象，request对象中封装请求消息数据    3. tomcat将request和response两个对象传递给service方法，并且调用service方法    4. 我们可以通过操作request对象来获取请求消息数据，通过response对象设置响应消息数据    5. 服务器在给浏览器做出响应之前，会从response对象中拿出设置的响应消息数据    /\n原理\nrequest对象和response对象是由服务器创建的\nrequest对象来接收消息，response来设置响应消息\n\nRequestRequest对象继承体系结构\nservletRequest  接口\nHTTPServletRequest  （继承上面的接口）\norg.apache.catalina.connector.RequestFacade  （实现了上面的接口） \n\nRequest的功能1. 获取请求消息数据\n获取请求行数据//请求行长这个样子GET /虚拟目录/Servlet路径?id=xxx HTTP/1.1\nrequest的方法：//1. 获取请求方式：GETString getMethod()//2. 获取虚拟目录（重点）String getContextPath()//3. 获取Servlet的路径String getServletPath()//4. 获取get方式的请求参数String getQueryString()//5. 获取请求的URI（重点） 即一次性获取 /虚拟目录/Servlet路径String getRequestURI()获取到/虚拟目录/Servlet路径String getRequestURL()获取到http://localhost/虚拟目录/Servlet路径//6. 获取协议及版本String getProtocol()//7. 获取客户机的IP地址String getRemoteAddr()\nURI: 统一资源定位符：/虚拟目录/Servlet路径\n\nURL：统一资源标识符：http://localhost/虚拟目录/Servlet路径\nURI的范围更大，他们俩的关系类似于 共和国 和 中华人民共和国 的关系\n\n获取请求头数据方法：String getHeader(String name)//1. 通过请求头名称获取请求头的值Enumeration&lt;String&gt; getHeaderNames()//2. 获取所有的请求头,返回一个类似于迭代器的类\n示例代码@Overrideprotected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;    //1. 获取所有请求头    Enumeration&lt;String&gt; headerNames = req.getHeaderNames();    while (headerNames.hasMoreElements())&#123;        String name = headerNames.nextElement();        //2. 据名称获取请求头        String value = req.getHeader(name);        System.out.println(name + &quot;---&quot; + value);    &#125;&#125;\n一般不会使用第二种方法，一般的使用情景如下\n\n1. 判断登录平台@Overrideprotected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;    String agent = req.getHeader(&quot;user-agent&quot;);    // 此处不区分大小写    if (agent.contains(&quot;Firefox&quot;)) &#123;        System.out.println(&quot;火狐登录&quot;);    &#125; else if (agent.contains(&quot;Chrome&quot;) )&#123;        System.out.println(&quot;谷歌登录&quot;);    &#125;&#125; 2. 判断是否盗链@Overrideprotected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;    String referer = req.getHeader(&quot;referer&quot;);    if(referer!=null)&#123;        if(referer.contains(&quot;/来源路径&quot;))&#123;            //正常        &#125;        else &#123;            //盗链，禁止        &#125;    &#125;&#125;\n\n\n\n获取请求体数据\n\n只有POST才有请求体\n步骤：\n//1. 获取流对象BufferedReader getReader()//获取字符输入流，只能操作字符数据ServletInputStream getInputStream()//获取字节输入流，可以操作所有类型数据2. 再从流对象中拿取数据\n示例代码\n@Overrideprotected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;    BufferedReader br = req.getReader();    String line = null;    while ((line=br.readLine())!=null)&#123;        System.out.println(line);    &#125;&#125;\n\n\n\n2. Request的其他功能\n获取请求参数通用方式//这些都是通用方法，适用于post或get//1. 获取请求参数通用方式String getParameter(String name)//根据参数名称获取参数值String[] getParameterValues(String name)//根据参数名称获取参数值的数组 username=2018005761&amp;password=123456getParameterNames()//获取所有请求的参数名称Map&lt;String,String[]&gt; getParameterMap()//获取所有参数的map集合\n//中文乱码的问题：//get方法： Tomcat8.0版本已经解决中文乱码问题//post方法：在获取参数前，设置请求request的编码req.setCharacterEncoding(&quot;utf-8&quot;)\n请求转发//一种在服务器内部资源跳转的方式//步骤：//1. 通过request对象获取请求转发器对象RequestDispatcher getRequestDispatcher(String path)//2. 使用RequestDispatcher对象来进行转发forward(ServletRequest request,ServletResponse response)\n特点：\n\n\n浏览器地址不发生变化\n不能访问服务器外部的其他资源\n转发是一次性的请求//示例代码// demo1 转发demo@WebServlet(&quot;/login&quot;)public class servletDemo extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        RequestDispatcher dispatcher = req.getRequestDispatcher(&quot;/login2&quot;);        dispatcher.forward(req,resp);    &#125;&#125;// demo2 被转发的demo@WebServlet(&quot;/login2&quot;)public class servletDemo2 extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;我被转发调用了&quot;);    &#125;&#125;//这样当访问demo1时，也会自动的访问demo2，而且访问是在同一次的请求完成的\n\n\n共享数据\n\n域对象： 一个有作用范围的对象，可以在范围内共享数据\nrequest域：代表一次请求//方法//1.存储数据void setAttribute(String name,Obejct);//2. 通过键获取值Object getAttribute(String name);//3. 通过键移除键值对void removeAttribute(String name)\n代码示例@WebServlet(&quot;/login&quot;)public class servletDemo extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        //1. 存储信息        req.setAttribute(&quot;msg&quot;,&quot;hello&quot;);        //转发        RequestDispatcher dispatcher = req.getRequestDispatcher(&quot;/login2&quot;);        dispatcher.forward(req,resp);    &#125;&#125;@WebServlet(&quot;/login2&quot;)public class servletDemo2 extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;我被转发调用了&quot;);        //2. 获取数据        System.out.println(req.getAttribute(&quot;msg&quot;));        //3. 删除数据        req.removeAttribute(&quot;msg&quot;);        System.out.println(req.getAttribute(&quot;msg&quot;));    &#125;&#125;\n\n\n获取ServletContext这里先介绍如何获得ServletContext对象\nServletContext servletContext = req.getServletContext();\n\n用户登录案例需求:\n\n编写login.html登录页面\n有username和password两个输入框\n使用Druid数据库连接池技术，操作mysql\n使用JdbcTemplate技术封装JDBC\n登录成功跳转到SuccessServlet展示：登陆成功！用户名，欢迎你\n登录失败跳转到FailServlet展示：登陆失败，用户名或密码错误\n\n代码：\n\n创建JavaEE项目\n\n构建html页面\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt;    &lt;input type=&quot;text&quot; placeholder=&quot;请输入用户名&quot; name=&quot;username&quot;&gt;    &lt;br&gt;    &lt;input type=&quot;password&quot; placeholder=&quot;请输入密码&quot; name=&quot;password&quot;&gt;    &lt;br&gt;    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n引入jar包到web目录下的WEB_INF目录下\n\n创建数据库环境,在src目录下配置druid.properties配置文件\nCREATE DATABASE testlogin;-- 创建数据库USE testlogin;-- 使用此库CREATE TABLE USER(\tid INT PRIMARY KEY AUTO_INCREMENT,\tusername VARCHAR(32) UNIQUE NOT NULL,\tPASSWORD VARCHAR(32) NOT NULL);\n配置文件\ndriverClassName=com.mysql.cj.jdbc.Driverurl=jdbc:mysql://localhost:3306/testlogin?serverTimezone=UTCusername=rootpassword=输入你的密码initialSize=5maxActive=10maxWait=3000filters=stattimeBetweenEvictionRunsMillis=60000minEvictableIdleTimeMillis=300000validationQuery=SELECT 1testWhileIdle=truetestOnBorrow=falsetestOnReturn=falsepoolPreparedStatements=falsemaxPoolPreparedStatementPerConnectionSize=200\nsrc目录下创建包cn.test.domain,创建类User,并补充响应的get,set,toString方法\npackage cn.test.domain;/** * @author BlackKnight * 用户的实体类 */public class User &#123;    private int id;    private String username;    private String password;    @Override    public String toString() &#123;        return &quot;User&#123;&quot; +                &quot;id=&quot; + id +                &quot;, username=&#x27;&quot; + username + &#x27;\\&#x27;&#x27; +                &quot;, password=&#x27;&quot; + password + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;    public int getId() &#123;        return id;    &#125;    public void setId(int id) &#123;        this.id = id;    &#125;    public String getUsername() &#123;        return username;    &#125;    public void setUsername(String username) &#123;        this.username = username;    &#125;    public String getPassword() &#123;        return password;    &#125;    public void setPassword(String password) &#123;        this.password = password;    &#125;&#125;\n创建cn.test.dao包,创建UserDao，提供login方法\npackage cn.test.dao;import cn.test.domain.User;/** * @author BlackKnight * 操作数据库中User表的类 */public class UserDao &#123;    /**     * 登录方法     * @param loginUser 只要用户名和密码     * @return user包含用户全部数据     */    public User login(User loginUser)&#123;        return null;    &#125;&#125;\n创建工具包cn.test.util,创建JDBCUtils工具类\npackage cn.test.util;import com.alibaba.druid.pool.DruidDataSourceFactory;import javax.sql.DataSource;import java.io.IOException;import java.io.InputStream;import java.sql.Connection;import java.sql.SQLException;import java.util.Properties;/** * @author BlackKnight * JDBC工具类 使用Druid连接池 */public class JDBCUtils &#123;    private static DataSource ds;    static &#123;        try &#123;            //1. 加载配置文件            Properties pro = new Properties();            //使用ClassLoader加载配置文件            InputStream is = JDBCUtils.class.getClassLoader().getResourceAsStream(&quot;druid.properties&quot;);            pro.load(is);            //2. 初始化连接池对象            ds = DruidDataSourceFactory.createDataSource(pro);        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    /**     * 获取连接对象     */    public static DataSource getDataSource() &#123;        return ds;    &#125;    /**     * 获取连接Connection对象     */    public static Connection getConnection() throws SQLException &#123;        return ds.getConnection();    &#125;&#125;\n完善UserDao类\npackage cn.test.dao;import cn.test.domain.User;import cn.test.util.JDBCUtils;import org.springframework.dao.DataAccessException;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;/** * @author BlackKnight * 操作数据库中User表的类 */public class UserDao &#123;    //声明JDBCTemplate对象共用    private JdbcTemplate template = new JdbcTemplate(JDBCUtils.getDataSource());    /**     * 登录方法     * @param loginUser 只要用户名和密码     * @return user包含用户全部数据,没有查询到，则返回null     */    public User login(User loginUser)&#123;        try &#123;            //1. 编写sql语句            String sql = &quot;select * from user where username = ? and password =?&quot;;            //2. 调用query方法            User user = template.queryForObject(sql,                    new BeanPropertyRowMapper&lt;User&gt;(User.class),                    loginUser.getUsername(), loginUser.getPassword());            return user;        &#125;catch (DataAccessException e)&#123;            e.printStackTrace();//写入日志            return null;        &#125;    &#125;&#125;\n创建包cn.test.test,创建UserDao类来检测程序\npackage cn.test.test;import cn.test.dao.UserDao;import cn.test.domain.User;import org.junit.jupiter.api.Test;/** * @author BlackKnight * 测试UserDao类 */public class UserDaoTest &#123;    @Test    public void testLogin()&#123;        User loginUser = new User();        loginUser.setUsername(&quot;李白&quot;);        loginUser.setPassword(&quot;456&quot;);        UserDao dao = new UserDao();        User user = dao.login(loginUser);        System.out.println(user);    &#125;&#125;\n编写cn.test.web.servlet.LoginServlet类\npackage cn.test.web.servlet;import cn.test.dao.UserDao;import cn.test.domain.User;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;/** * @author BlackKnight */@WebServlet(&quot;/loginServlet&quot;)public class LoginServlet extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        //1. 设置编码        req.setCharacterEncoding(&quot;utf-8&quot;);        //2. 获取请求参数        String username = req.getParameter(&quot;username&quot;);        String password = req.getParameter(&quot;password&quot;);        //3. 封装user对象        User loginUser = new User();        loginUser.setUsername(username);        loginUser.setPassword(password);        //4. 调用userDao类操作数据库        UserDao userDao = new UserDao();        User user = userDao.login(loginUser);        //5. 判断user        if(user==null)&#123;            //登陆失败            req.getRequestDispatcher(&quot;/failServlet&quot;).forward(req,resp);        &#125;else &#123;            //登录成功            //存储数据            req.setAttribute(&quot;user&quot;,user);            //转发            req.getRequestDispatcher(&quot;/successServlet&quot;).forward(req,resp);        &#125;    &#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        this.doGet(req,resp);    &#125;&#125;\nlogin.html中form表单的action路径的写法\n//虚拟目录 + Servlet的资源路径&lt;form action=&quot;/testLogin/loginServlet&quot; method=&quot;post&quot;&gt;\n设置failServlet与successServlet\npackage cn.test.web.servlet;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;@WebServlet(&quot;/failServlet&quot;)public class FailServlet extends HttpServlet &#123;    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        //给页面写一句话        //设置编码        response.setContentType(&quot;text/html;charset=utf-8&quot;);        //输出        response.getWriter().write(&quot;登录失败,用户名或密码错误&quot;);    &#125;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        this.doPost(request,response);    &#125;&#125;\npackage cn.test.web.servlet;import cn.test.domain.User;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;@WebServlet(&quot;/successServlet&quot;)public class SuccessServlet extends HttpServlet &#123;    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        //获取request域中共享的对象        User user = (User) request.getAttribute(&quot;user&quot;);        if(user!=null)&#123;            //给页面写一句话            //设置编码            response.setContentType(&quot;text/html;charset=utf-8&quot;);            //输出            response.getWriter().write(&quot;登录成功,&quot;+user.getUsername()+&quot;你好!&quot;);        &#125;    &#125;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        this.doPost(request,response);    &#125;&#125;\n完成BeanUtils工具类，简化数据封装\n\n\n\nBeanUtils是用于封装JavaBean的\n\n\n什么是JavaBean？\n  JavaBean是标准的Java类\n\n类必须被public修饰\n必须提供空参的构造器\n成员变量必须使用private修饰\n提供公共的setter和getter方法\n\n\nJavaBean的功能：封装数据\n\n概念的辨析：成员变量 和 属性。\n 大部分情况下成员变量和属性指相同的内容，但某些特例下不相同。\n  例如：getUsername() -&gt; Username -&gt; username 这就是属性，属性是getter和setter方法截取后的产物\n  我们可以给一个成员变量的getter方法取另一个名字，此时成员变量和属性就会不一样了\n  例如：成员变量为gender，而setter方法起名为SetXXX(),此时属性为XXX\n\nBeanUtils的方法\nsetProperty()getProperty()//上面两个接收三个参数： 1. Bean类名 2. 属性名 3. 变量值，相当于给成员变量赋值populate()//接收两个参数，一个是Bean类，一个是map集合//将map集合的键值对信息，封装到对应的JavaBean对象中\n\n使用BeanUtils简化LoginServlet的第二第三步\npackage cn.test.web.servlet;import cn.test.dao.UserDao;import cn.test.domain.User;import org.apache.commons.beanutils.BeanUtils;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.lang.reflect.InvocationTargetException;import java.util.Map;/** * @author BlackKnight */@WebServlet(&quot;/loginServlet&quot;)public class LoginServlet extends HttpServlet &#123;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        //1. 设置编码        req.setCharacterEncoding(&quot;utf-8&quot;);        /*        //2. 获取请求参数        String username = req.getParameter(&quot;username&quot;);        String password = req.getParameter(&quot;password&quot;);        //3. 封装user对象        User loginUser = new User();        loginUser.setUsername(username);        loginUser.setPassword(password);        */        //2. 获取所有的请求参数        Map&lt;String, String[]&gt; map = req.getParameterMap();        //3. 创建User对象        User loginUser = new User();        //3.1 使用BeanUtils封装        try &#123;            BeanUtils.populate(loginUser,map);        &#125; catch (IllegalAccessException e) &#123;            e.printStackTrace();        &#125; catch (InvocationTargetException e) &#123;            e.printStackTrace();        &#125;        //4. 调用userDao类操作数据库        UserDao userDao = new UserDao();        User user = userDao.login(loginUser);        //5. 判断user        if(user==null)&#123;            //登陆失败            req.getRequestDispatcher(&quot;/failServlet&quot;).forward(req,resp);        &#125;else &#123;            //登录成功            //存储数据            req.setAttribute(&quot;user&quot;,user);            //转发            req.getRequestDispatcher(&quot;/successServlet&quot;).forward(req,resp);        &#125;    &#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        this.doGet(req,resp);    &#125;&#125;\n\n\n\nResponse对象功能：设置响应消息\n设置响应行 //1. 格式：HTTP/1.1 200 ok//2. 设置状态码：setStatus(int sc)\n设置响应头 setHeader(String name,String value);sendRedirect()//重定向\n设置响应体 //也是通过流的方式设置响应体1. 获取输出流    * 字符输出流 PrintWriter getWriter()    * 字节输出流 ServletOutputStream getOutputStream()2. 将数据输出到客户端浏览器\n\n实例1：重定向重定向：客户端向A请求数据，A接到数据后告诉客户端另一个地址B以及重定向状态码302，客户端遵循继而转移到B\npackage cn.test.test;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;/** * @author BlackKnight * 重定向demo */@WebServlet(&quot;/responseDemo1&quot;)public class ResponseDemo1 extends HttpServlet &#123;    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        //访问/responseDemo1,自动跳转到/responseDemo2        //1. 设置状态码        response.setStatus(302);        //2. 设置响应头location        response.setHeader(&quot;location&quot;,&quot;/testLogin/responseDemo2&quot;);        //由以上可知 重定向的状态码和响应头的键都是固定的302和location        //所以我们可以使用如下的方法替代上述两种方法,与上述方法二选一即可        response.sendRedirect(&quot;/testLogin/responseDemo2&quot;);    &#125;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        this.doPost(request,response);    &#125;&#125;\n\n转发(forward)的特点：\n\n\n地址栏路径不变\n转发只能访问当前服务器下的资源\n转发是一次请求，可以使用request对象来共享数据\n\n\n重定向(redirect)的特点：\n\n\n地址栏发生变化\n重定向可以访问其他站点的资源\n重定向是两次请求，不能使用request对象共享数据\n\n\n路径的写法：\n\n\n路径分类：\n相对路径：通过相对路径不可以确定唯一资源\n如./index.html\n以.开头的路径\n如&lt;a href=&quot;./responseDemo2&quot;&gt;可以进入同级目录下的其他资源，../进入上一级目录,./可以省略，写为&lt;a href=&quot;responseDemo2&quot;&gt;\n\n\n绝对路径：通过绝对路径可以确定的唯一资源\n如：http://localhost/testLogin/responseDemo1这就是一个完整的绝对路径，我们也要研究不完整的绝对路径/testLogin/responseDemo2\n我们可以简单记为以/开头的路径\n给客户端浏览器访问：需要加虚拟目录(项目的访问路径)\n给服务器端访问：不需要加虚拟目录(例如：转发)\n\n\n\n\n动态获取虚拟目录String contextPath = request.getContextPath();//此方法可以动态的获取路径response.sendRedirect(contextPath+&quot;/responseDemo2&quot;);\n\n实例2：服务器输出字符数据到客户端浏览器步骤：\n\n获取字符输出流\n输出数据package cn.test.test;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;/** * @author BlackKnight * 字符输出到客户端 */@WebServlet(&quot;/responseDemo2&quot;)public class ResponseDemo2 extends HttpServlet &#123;    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        // 1. 设置编码，默认的浏览器解码是GBK,字符输出流的编码是ISO-8859-1编码        response.setCharacterEncoding(&quot;utf-8&quot;);        // 2. 响应头告诉浏览器使用什么编码        response.setHeader(&quot;content-type&quot;,&quot;text/html;charset=utf-8&quot;);        // 这个方法其实可以完全替代掉第一步的设置输出流的方法        // 有一个更简单的方法来设置编码从而省去上述的两步        response.setContentType(&quot;text/html;charset=utf-8&quot;);        // 3. 获取字符输出流        PrintWriter pw = response.getWriter();        // 4. 输出数据        pw.write(&quot;你好&quot;);        //因为此PrintWriter是response提供的，        // 每次请求结束后，response都会被销毁，所以即使是write方法也可以实现print一样的动态刷新页面        pw.write(&quot;&lt;h1&gt;hello&lt;/h1&gt;&quot;);        // 输出的数据可以带标签    &#125;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        this.doPost(request,response);    &#125;&#125;\n\n实例3：服务器输出字节数据到客户端浏览器步骤：\n\n获取字节输出流\n输出数据package cn.test.test;import javax.servlet.Servlet;import javax.servlet.ServletException;import javax.servlet.ServletOutputStream;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;@WebServlet(&quot;/responseDemo3&quot;)public class ResponseDemo3 extends HttpServlet &#123;    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        //0. 设置编码        response.setContentType(&quot;text/html;charset=utf-8&quot;);        //1. 获取字节输出流        ServletOutputStream sos = response.getOutputStream();        //2. 输出,getBytes默认解码GBK，和浏览器相同，但我们仍然要设置一下编码        sos.write(&quot;你好&quot;.getBytes());    &#125;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        this.doPost(request,response);    &#125;&#125;\n\n实例4：验证码本质是一张图片，为的是防止恶意注册\n大多都会动态生成验证码\npackage cn.test.test;import javax.imageio.ImageIO;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.awt.*;import java.awt.image.BufferedImage;import java.io.IOException;import java.util.Random;@WebServlet(&quot;/checkCodeServlet&quot;)public class CheckCodeServlet extends HttpServlet &#123;    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        int width = 100;        int height = 50;        //1. 创建一个对象，在内存中代表一个图片        BufferedImage image = new BufferedImage(width,height,BufferedImage.TYPE_INT_RGB);        //2. 美化图片        //2.1 填充背景色，获取画笔对象        Graphics g = image.getGraphics();//画笔对象        g.setColor(Color.pink);//设置画笔颜色        g.fillRect(0,0,width,height);//填充        //2.2 画边框        g.setColor(Color.blue);        g.drawRect(0,0,width-1,height-1);//画边框        //2.3 写验证码        String str = &quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghigklmnopqrstuvwxyz1234567890&quot;;        Random random = new Random();        for (int i = 1; i &lt;= 5 ; i++) &#123;            int index = random.nextInt(str.length());            char ch = str.charAt(index);            g.drawString(ch+&quot;&quot;,width/5*i,height/2);        &#125;        //2.4 画干扰线        g.setColor(Color.green);        for (int i = 0; i &lt;5 ; i++) &#123;            int x1 = random.nextInt(width);            int y1 = random.nextInt(height);            int x2 = random.nextInt(width);            int y2 = random.nextInt(height);            g.drawLine(x1,y1,x2,y2);        &#125;        //3. 将图片输出到页面展示        ImageIO.write(image,&quot;jpg&quot;,response.getOutputStream());        //三个参数，内存中的图片，图片格式，输出流    &#125;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        this.doPost(request,response);    &#125;&#125;\n\nServletContext对象\n概念：代表整个web应用，可以和程序的容器(服务器)来通信\n获取：两种方法获取的对象是同一个对象\n通过request对象来获取 getServletContext()// 获取ServletContext对象\n通过HTTPServlet获取 this.getServletContext()\n\n\n功能\n获取MIME类型：  MIME (Multipurpose Internet Mail Extensions) 是描述消息内容类型的因特网标准。MIME类型：在互联网通信过程中定义的一种文件数据类型格式： 大类型/小类型例如：text/html  image/jpeg//获取：String getMimeTyppe(String file)\n域对象：共享数据\n获取文件的真实(服务器)路径package cn.test.test;import javax.servlet.ServletContext;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;/** * @author BlackKnight * ServletContext的功能 */@WebServlet(&quot;/servletContextDemo&quot;)public class ServletContextDemo extends HttpServlet &#123;    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        /*        1. 获取MIME类型        2. 域对象        3. 获取文件的真实服务器路径        */        //获取ServletContext对象        ServletContext context = this.getServletContext();        //1. 获取MIME类型        String filename  = &quot;a.jpg&quot;;        String mimeType = context.getMimeType(filename);        System.out.println(mimeType);//image/jpeg        //2. 域对象        //域下设置的属性可以共同享用        context.setAttribute(&quot;msg&quot;,&quot;哈哈哈&quot;);        //context.getAttribute(&quot;msg&quot;);另一个路径下也可以读取到这个属性值        context.removeAttribute(&quot;msg&quot;);        //ServletContext对象的范围：所有用户所有请求的数据        //3. 获取文件的真实服务器路径        String realPath = context.getRealPath(&quot;/a.txt&quot;);//获取web目录下的文件        String realPath1 = context.getRealPath(&quot;/WEB-INF/b.txt&quot;);//获取web-inf目录下的文件        String realPath2 = context.getRealPath(&quot;/WEB-INF/classes/c.txt&quot;);//获取src目录下的文件        System.out.println(realPath);//D:\\testLogin\\out\\artifacts\\testLogin_war_exploded\\a.txt        System.out.println(realPath1);//D:\\testLogin\\out\\artifacts\\testLogin_war_exploded\\WEB-INF\\b.txt        System.out.println(realPath2);//D:\\testLogin\\out\\artifacts\\testLogin_war_exploded\\WEB-INF\\classes\\c.txt    &#125;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        this.doPost(request,response);    &#125;&#125;\n\n\n\n文件下载案例\n页面显示超链接\n点击超链接后弹出下载提示框\n完成图片文件下载\n\n在login.html内加一段代码\n&lt;a href=&quot;/testLogin/downloadDemo?filename=1.jpg&quot;&gt;图片1&lt;/a&gt;&lt;a href=&quot;/testLogin/downloadDemo?filename=2.jpg&quot;&gt;图片2&lt;/a&gt;&lt;!--超链接href属性指向Servlet，传递资源名称filename--&gt;\njava代码如下\npackage cn.test.test;import javax.servlet.ServletContext;import javax.servlet.ServletException;import javax.servlet.ServletOutputStream;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.FileInputStream;import java.io.IOException;@WebServlet(&quot;/downloadDemo&quot;)public class DownloadDemo extends HttpServlet &#123;    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        //1. 获取请求参数，文件名称        String filename = request.getParameter(&quot;filename&quot;);        //2. 使用字节输入流加载文件进内存        //2.1 找到文件的服务器路径        ServletContext context = this.getServletContext();        String realPath = context.getRealPath(&quot;/img/&quot; + filename);        //2.2 使用字节流关联        FileInputStream fis = new FileInputStream(realPath);        //3. 设置response的响应头        //3.1 设置响应头类型        String mimeType = context.getMimeType(filename);//获取文件的MIME类型        response.setHeader(&quot;content-type&quot;, mimeType);        //3.2 设置响应头打开方式        response.setHeader(&quot;content-disposition&quot;, &quot;attachment;filename=&quot; + filename);        //4. 将输入流数据写出到输出流中        ServletOutputStream sos = response.getOutputStream();        byte[] buff = new byte[1024 * 8];        int len = 0;        while ((len = fis.read(buff)) != -1) &#123;            sos.write(buff, 0, len);        &#125;        fis.close();    &#125;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123;        this.doPost(request, response);    &#125;&#125;\n","categories":["后台","Request&Response"],"tags":["Request&Response"]},{"title":"分布式技术","url":"/2022/11/09/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/","content":"\n引言：分布式技术——不要浪费时间去试图为异步分布式系统设计面向任意场景的共识算法\n\n\n\n\n本文相关Link：\n\n《区块链技术》\n极客时间——分布式协议与算法实战\n阿里云——两阶段提交\n思否回答\n\n分布式基本概念一致性问题分布式最核心的问题——一致性问题\n一致性\n一致性Consistency：很多台服务器（分布式集群）对外表现就像是单机环境一样，一直呈现稳定一致的状态\n\n（注意：一致性强调的是系统对外体现一致的状态，并不考虑结果是否正确）\n一致性要求三方面：（这三个概念无需刻意去记，知道一致性要求：有限时间、结果需要共识且合理即可）\n\n可终止性 Termination：有限时间内给出一致的结果（保证能够在一定的时间内提供服务）\n约同性 Agreement：不同节点最终完成决策的结果相同（系统要么不给出结果，要么给出的结果必须是达成共识的）\n合法性 Validity：决策的结果必须是某个结点提出的提案（即A节点认为结果是a，B节点认为结果是b，那么最终结果必须是a或b，不能是c）\n\n\n举个例子：比如售票案例有A、B两个售票口售卖去往北京的机票，还剩最后一张，分别售卖给a与b，而ab几乎同时下单，那么此时该把这张票给谁呢？\n\n分布式系统解决问题的核心秘诀：把不同时空发生的多个事件进行全局唯一排序，而且这个顺序是共识的。\n\n最简单的方法就是，a与b分别有时间戳，我们比较时间戳就可以得到最终谁更快一点（之后我们还会用到比较时间戳的思想）\n但是A如果与B相隔很远，时钟计时可能不准确（即使是Google的分布式数据库Spanner，面对不同的数据库，也有10ms的延迟）因此我们应该对事件排序，而不是一味的追求绝对的时间戳\n这个例子里：在一定时间内返回给a、b谁拿到了票，就是可终止；不同节点在排序后，得到a事件早于b事件的共识，这就是约同性；系统最终将票给了a、b其中之一就是合法性\n一致性的分类一致性根据更新值后是否可以立即读取到分为：\n\n强一致性：写操作后可以立即读到最新数据\n\n顺序一致性（因果一致性）：约束力较强\n\n要求：\n\n所有进程看到的全局执行顺序（total order）一致（否则数据副本就不一致了）；\n\n并且每个进程看自身操作的顺序（local order）跟实际发生顺序一致。\n\n\n\n比如一个进程执行A、B；另一个进程执行C、D；那么所有进程都应该看到A先于B、C先于D（即所有进程都应该看到ABCD、ACDB、CDAB、CADB、CABD、ACDB中的一个 total order）进程内部应该是串行的，进程之间可以并行\n\n线性一致性（原子一致性）：约束力最强，在顺序一致性前提下增加了进程间的操作顺序要求（更新后立即可以读取到最新的值）\n\n\n\n弱一致性：写操作后不能保证立即读到最新数据\n\n最终一致性：即允许出现临时的不一致，但要在一定时间内达到一致\n\n\n\n（PS：对于一致性分类的说法很多版本不一样啊，无非就是把强或弱里面的一种单拿出来，个人认为这里的分类比较好）\n注意一致性的概念有区别\n\n在ACID中的C，指的是状态的一致性，通过二阶段提交来解决\n在CAP中的C，指的是线性一致性，比如Paxos、Raft\n\n所以下文中提到一致性，注意区别指的是哪一个\n共识\n共识 Consensus：特指在分布式系统中多个节点之间对某个提案Proposal达成一致看法的过程\n\n提案：提案的含义在分布式系统中十分宽泛，如多个事件发生的顺序、某个键对应的值、谁是主节点……等等。可以认为任何可以达成一致的信息都是一个提案。\n达成共识需要解决的两个问题：\n\n如何提出提案？\n如何让多个节点达成共识？\n\n\n注意：一致性和共识一样吗？\n\n不一样！很多人把Paxos和Raft看做一致性算法，这是错误的，他们俩是共识算法\n\n共识 Consensus：一致的意见\n一致性 Consistency：根据是否可以立即读到最新数据分为强弱一致性\n\nFLP不可能原理Fischer、Lynch 和 Patterson （FLP）三位科学家于 1985 年发表，该论文后来获得了 Dijkstra（就是发明最短路径算法的那位计算机科学家）奖\n\nFLP 不可能原理：在网络可靠、但允许节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性共识算法\n\n不要浪费时间去试图为异步分布式系统设计面向任意场景的共识算法。\n在分布式系统的同步与异步：\n\n同步：a节点执行完成等待b节点一定时间（分布式系统的时钟误差存在上限）同步情况下，如果b节点超时，那么就能进一步判断其宕机还是网络出现故障\n异步：a节点执行完成后通知b节点（这个时间没有上限）这就造成无法判断某个消息迟迟没有被响应是哪里出了问题\n\n\nFLP不可能原理实际上说明：对于允许节点失效情况下，纯粹异步系统无法确保共识在有限时间内完成\n\nCAP原理\nCAP 原理：分布式系统无法同时确保一致性（Consistency）、可用性（Availability）和分区容忍性（Partition），设计中往往需要弱化对某个特性的需求\n在现实情况中，我们往往在C与A之间取舍\n\n\nC 一致性：线性一致性（可以看第一节），要么读到同一份数据，要么都失败\nA 可用性：系统能在有限时间内完成对操作请求的应答；\nP 分区容忍性：系统中的网络可能发生分区故障（成为多个子网，甚至出现节点上线和下线），即节点之间的通信无法保障。网络故障不应该影响到系统正常服务。\n\nCAP原理认为分布式系统最多只能保证满足其中两种特性：其中AP与CP使用比较多\n\nAP：适合于结果一致性不敏感的应用，允许一段时间后再保持同步。\n网站静态页面、CDN、实时性较弱的查询类数据库\n简单分布式同步协议：Gossip、CouchDB、Cassandra\n设计时，我们对于普通的数据就可以处理为AP\n\n\nCP：适合于结果一致性敏感的应用\nMongoDB、Redis、MapReduce\nPaxos、Raft等共识算法\n设计时，我们对于元数据就应该保证CP\n\n\nAC：网络分区出现概率较小，但很难完全避免，舍弃P意味着放弃分布式系统\n两阶段提交\nZookeeper\n\n\n\nOLTP与OLAPACID与BASE是对不同场景对CAP三者的不同的取舍的结果：\n\n对于OLTP（Online transaction processing）联机事务处理：比如传统的关系型数据库，相关操作主要是CRUD增删查改\n\n对于OLAP（Online analytical processing）联机分析处理：注重数据的分析\n\n\n因为不同的要求，所以OLTP就要求实时性、小数据量、处理事务和查询；而OLAP就要求实时性要求不高，数据量大。\nACID 酸关系型数据库的事务处理基本满足ACID原则。\n\nAtomic 原子性：事务要么成功要么失败\nConsistency 一致性：事务执行前后，对数据库的完整性没有破坏（实体完整性、域完整性、参照完整性）\n实体完整性：主键须唯一\n域完整性：限制字段满足预设类型的值（比如需要是日期或是字符串或是数值）\n参照完整性：父记录存在，子记录才能存在（外键）\n\n\nIsolation 隔离性：不同事物之间互不影响\nDurability 持久性：数据存储后永久存在，除非进行删除操作\n\nBASE 碱BASE是AP的延伸分布式数据库的要求，其实是分布式系统实现ACID成本过高，退而求其次得到BASE要求。\nBASE是AP的延伸拓展，可以理解为BASE放弃了C（最终一致性）\n\nBasic Availability 基本可用：系统内部可能有部分宕机，但是依然可以提供服务\nSoft-state 软状态：系统不要求保持强一致状态\nEventual consistency 最终一致性：系统需要在一段时间后保证数据一致。\n\n软状态只是描述系统的一个特点，对于基本可用与最终一致性我们来讨论一下具体实现：\n如何保证BA如何保证BA基本可用？一套组合拳\n\n削峰填谷：（削峰）分不同时间段售卖，比如8点抢深圳的票、9点抢北京的票；（填谷）比如在QPS较少的时间段开放此类高并发服务\n延迟响应：自己提交的请求会排队等待处理，可能推迟几分钟\n体验降级：\n比如用较为模糊的图片替代高清图片\n保证核心功能可以使用，停止提供非核心功能\n\n\n过载保护：请求限流，消息队列满载之后，拒绝之后的请求或是清空一部分请求\n\n这部分和Redis防止缓存雪崩、缓存击穿、缓存穿透异曲同工\n如何保证E一般有三种方法保证最终一致\n\n读时修复：在读取数据的时候检测数据是否一致\n写时修复：在写入数据的时候，监测数据是否一致，写失败就缓存数据，定时重传（对系统的消耗最小，不需要额外的判断）\n异步修复：最常用的方式，定时对账，保证数据副本一致\n\n多阶段提交在mysql介绍过两阶段提交，当时记录了mysql先写redo log后写bin log，这个思想来源于分布式事务的多阶段提交方法。\n这一部分的相关资料：\n\n阿里云——两阶段提交\n思否回答\n\n二阶段提交既然在分布式场景下，直接提交事务可能出现各种故障和冲突，那么可将其分解为预提交和正式提交两个阶段，规避风险。\n\n二阶段提交协议（Two-phase Commit Protocol，简称 2PC）是分布式事务的核心协议：\n定义了一个事务管理器 TM（Transaction Manager）与一个资源管理器RM（Resource Manager），所有RM向TM汇报自身活动状态，由TM根据各RM汇报的状态（完成准备或准备失败）来决定各RM是“提交”事务还是进行“回滚”操作。\n\n协议分成了两个阶段：（TM与RM也有称为协调者与参与者）\n\nphase1：预提交（也有称投票阶段）：\nTM通知各RM执行事务\n各RM执行事务，但是不提交\nRM将执行情况汇报给TM\nRM阻塞等待TM的指令\n\n\nphase2：正式提交：\n如果所有RM均执行完成：通知所有的RM进行提交\n如果有一个RM执行失败：通知所有的RM进行回滚\n\n\n\n两阶段提交存在的问题：\n\n同步阻塞：各RM执行事务后会阻塞，等待TM指示\n单点故障：非常依赖TM这一个点，如果TM宕机，其他RM会一直等待\n数据可能不一致：比如在第二阶段，TM告知RM可以提交后，有RM没有收到或是宕机\n\n三阶段提交为了弥补二阶段存在的问题，三阶段提交将二阶段的第一个阶段拆为了两个部分，变成了三阶段：\n\nphase1：询问提交（注意这个阶段不执行事务，因此这个阶段不会阻塞）\nTM询问RM是否可以进行提交操作\nRM根据自身状况回复一个预估值：是或否\n\n\nphase2：预提交（如果事务开始执行，那么执行完成后他们会阻塞）\nTM检查所有收到的答复，根据不同情况返回不同请求\n全部为是：TM对RM发起执行事务的请求\n一个或多个返回否或等待超时：TM对RM发送abort请求，RM收到后中断事务\n\n\n\n\nphase3：正式提交\n如果所有RM均执行事务成功：\nTM向所有RM发送commit请求\n所有RM进行提交操作，释放相关资源\nRM返回给TM其提交结果\n\n\n如果一个或多个失败或等待超时：\nTM向所有RM发送回滚指令\nRM执行回滚\n返回回滚操作\n\n\n\n\n\n如果phase3中，RM迟迟接收不到TM的commit或rollback请求，将在等待超时后继续commit（二阶段中如果出现这种情况会一直阻塞）\n三阶段提交存在的问题：\n三阶段提交解决了阻塞问题和单点故障问题，但是还是会有数据不一致的情况（比如TM发送rollback请求，但是有的RM没有收到这个消息，在等待超时后，他们依然会commit）\n\n两阶段提交协议中所存在的长时间阻塞状态发生的几率还是非常低的，所以虽然三阶段提交协议相对于两阶段提交协议对于数据强一致性更有保障，但是因为效率问题，两阶段提交协议在实际系统中反而更加受宠。\n\nXA协议2PC的传统方案是在数据库层面实现的，如Oracle、MySQL都支持2PC协议\n为了统一标准减少行业内不必要的对接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织Open Group定义分布式事务处理模型DTP（Distributed Transaction Processing Reference Model）\nDTP模型定义TM和RM之间通讯的接口规范叫XA，简单理解为数据库提供的2PC接口协议，基于数据库的XA协议来实现2PC又称为XA方案。\n一句话就是：XA接口方案实现了2PC（比如Mysql XA）\nTCC\nTry-Confirm-Cancel 预留-确认-撤销：\n可以将TCC理解为是业务层的二阶段提交，而二阶段提交是处理数据库层的事务的\n\n\nTry：对应二阶段提交phase1，对业务系统做检测及资源预留\nComfirm：对应二阶段提交的phase2的commit，一般Try成功都能Confirm成功\nCancel：对应二阶段提交的phase2的rollback，业务执行出错，那么就进行回滚\n\n在需要分布式事务能力时，优先考虑现成的事务型数据库（比如 MySQL XA），当现有的事务型数据库不能满足业务的需求时，再考虑基于 TCC 实现分布式事务。\n拜占庭将军问题\n拜占庭是古代东罗马帝国的首都，现土耳其君士坦丁堡（后改名为伊斯坦布尔）\n所谓的拜占庭将军问题就是：一组拜占庭将军分别各率领一支军队共同围困一座城市，他们商量进攻还是撤退，而且将军中可能出现叛徒\n\n二忠一叛难题：\n假设现有A、B、C三个将军商量进攻，要求必须至少有两个将军一起进攻才能胜利：\n此时假如C是间谍，那么如果A告诉B、C进攻，B告诉A、C撤退，此时进攻撤退比为1:1，而间谍C给A发送进攻，给B发送撤退。\n那么A看到2:1，会进攻，最后全军覆没；B看到1:2会撤退\n\n那么如果你是指挥，你会如何破局呢？\n\nLeslie Lamport莱斯利·兰伯特（Paxos算法创始人、LaTeX的La、图灵奖得主，大佬）提出了两个解决这个问题的办法：\n\n口信消息型：多轮交互\n\n签名消息型：给消息加密\n\n\n口信消息型\n前提：n个将军，最多容忍m = (n-1)/3位叛徒，最多需要m+1次交互\n（推到过程参考大佬的论文，我们只需要记住结论）\n\n比如上面的二忠一叛问题，就需要再加一个将军D（4个人，个叛徒）就可以防止叛徒捣乱。\n我们规定首先发出指令的为指挥官，其余的为副官，当忠诚将军首先发出指令时：\n\nA向B、C、D发送进攻的指示（如果没有收到信息默认是撤退）\n副官B、C、D之间互相发送作战信息\nB、D之间互相发送进攻的消息；B与C、D与C发送进攻，此时叛徒C无论给B与D发送撤退，影响不了局面（进攻与撤退比：D收到2:1、B收到2:1）\n\n当叛徒首先发出指令时：\n\nC告诉A进攻，告诉B、D撤退\nA、B、D之间相互交流，发现撤退2大于进攻1，于是都不会进攻\n\n签名消息型\n使用签名保证，最多需要m+1次交互\n\n忠诚将军签名无法伪造\n任何人都能验证消息真伪\n\n这样就可以不增加人数而达到共识\n\n比如还是A、B、C：\n\nA通知B、C：A要进攻\nB通知C：A、B要进攻\nC是叛徒，通知B：A、C撤退\n\n此时B就能判断出C叛变了，从而忽略他的消息，参与进攻\n（如果叛徒C先发出消息也将这样）\n\n签名消息就是带有数字签名的消息，假设现在bob要给alice发送消息“我爱你”，为了防止被人篡改，我们使用非对称加密算法比如（RSA）\nbob发送时：\n\n将消息“我爱你”先进行数字摘要（比如MD5），生成一个摘要Digest\n然后使用私钥对Digest加密，生成签名Signature1\n发送时发送：消息+Signature（两个都要发送）\n\nAlice接收时：\n\nAlice接收到的消息是“我不爱你”，对这个消息也进行摘要，生成Signature2\nAlice使用公钥对Signature进行解密，得到Signature1\n对比Signature1与Signature2，Alice就知道消息被篡改了\n\n共识算法\n拜占庭错误 Byzantine Fault：指存在故意伪造恶意信息的节点引发的错误\n非拜占庭错误Non-Byzantine Fault：指断电、网络拥塞等等故障（Crash或Fail-Stop）引发的错误\n\n针对解决不同的错误场景有不同的共识算法：\n\n解决非拜占庭错误——CFT（Crash Fault Tolerance）\nPoxos（1990年）\nRaft及其变种（2014年）\n\n\n解决拜占庭错误——BFT（Byzantine Fault Tolerance）\n确定性系列算法：一旦达成共识就不可逆转，即共识是最终结果\nPBFT（Practical Byzantine Fault Tolerance，1999）\n\n\n概率算法：指共识结果则是临时的，随着时间推移或某种强化，共识结果被推翻的概率越来越小，最终成为事实上结果（比如比特币出现两个链时，会由下一个区块决定哪一个是最长链）\nPoW（Proof of Work，1997）\n\n\n\n\n\n近几年还有其他的算法：\n\nXFT（Cross Fault Tolerance，2015 年）：提供类似 CFT 的处理响应速度，并能在大多数节点正常工作时提供 BFT 保障\nAlgorand（2017年）：基于 PBFT 进行改进，通过引入可验证随机函数解决了提案选择的问题，理论上可以在容忍拜占庭错误的前提下实现更好的性能\n\n可靠性指标\n可靠性（Availability），或者说可用性，是描述系统可以提供服务能力的重要指标\n\n几个9指标\n几个9表示：每年允许服务出现不可用时间的参考值。\n\n\n单点的服务器系统至少应能满足两个 9（99%，每年允许87.6h不可用）；\n普通企业信息系统应能满足三个 9（99.9%，每年允许8.76h不可用）；\n少数领先企业（如亚马逊、甲骨文）产品能实现四个9甚至更多（99.99%，每年允许52min不可用）。\n大型金融和电信系统指标是五个9（99.999%，每年允许5min不可用）。\n五个 9 以上的系统十分罕见，要实现往往意味着极高的成本。\n\nMTBF与MTTR描述系统出现故障的可能性和故障出现后的恢复能力\n\nMTBF：Mean Time Between Failures 平均故障间隔时间，即系统可以无故障运行的预期时间（越大越好）\nMTTR：Mean Time To Repair，平均修复时间，即发生故障后，系统可以恢复到正常运行的预期时间（越小越好）\n\n分布式算法PaxosPaxos无论将数据分为几个阶段进行提交，都避免不了出现数据不一致的问题，直到出现第一个共识算法\n\nPaxos：第一个共识算法，解决非拜占庭问题\n论文中为了描述问题编造了一个虚构故事：在古代爱琴海的Paxos岛，议会如何通过表决来达成共识。议员们通过信使传递消息来对议案进行表决。但议员可能离开，信使可能走丢，甚至重复传递消息。\n\n兰伯特的Paxos包括两部分：\n\nBasic Paxos：多节点如何就一个值达成共识\nMulti-Paxos：多节点如何对一系列值达成共识\n\n三种角色算法提到了三种角色：\n\n提案者Proposer：提出一个提案，等待大家批准chosen为决议value；\nclient承担这个角色（但其实，接收到client请求的节点才是提案者）\n负责接入与协调：接入client的请求，协调发起二阶段提交\n\n\n接受者Acceptor：对提案进行投票\nserver承担这个角色\n负责协商和存储数据：参与二阶段提交，存储最终达成共识的数据\n\n\n学习者Learner：获取共识结果，不参与投票过程\n可以是client也可以是server\n学习者一般是为了备份数据，被动接受数据，不参与共识过程\n负责存储数据：接收达成共识的值\n\n\n\nPaxos算法基本过程很类似于二阶段提交\nBasic-Paxos现在假设我们实现了一个分布式集群，提供只读KV存储服务，有两个客户端，一个要修改x为3，另一个要修改为7：\nPhase1：如图所示，我们用[n, v]来表示一个提案，n表示提案的id，v表示提案的值；图中有两个提案者，proposer1的提案为x=3，proposer2的提案为x=7；图中有三个接收者，他们之前均没有共识过任何提案\n\n\nproposer1发出提案[1, ]（注意：第一个阶段并不需要指定提议的值）；\nAcceptor1接收到请求[1, ]，承诺之后将拒绝所有小于1的请求；Acceptor2同理\nproposer2发出提案[5, ]\nAcceptor1接收到请求[5, ]，承诺之后将拒绝所有小于5的请求，由于之前没有共识过任何提案，所以返回给提案者一个空值[,]；Acceptor2、Acceptor3同理（如果之前共识过，那么应该返回提案者曾经共识的提案的id）\nAcceptor3接收到请求[1, ]，由于1&lt;5，因此拒绝响应这个请求\nproposer1接收到来自于Acceptor1、Acceptor2的响应，开始进入第二阶段（注意：接受者有3个，只需要接收到&gt;2个的响应，就可以进入第二阶段）\nproposer2接收到来自于Acceptor1、Acceptor2的响应，开始进入第二阶段\n\n\nPhase2：\n\nproposer1决定设置x为3，发出请求[1, 3]\nproposer2决定设置x为7，发出请求[5, 7]\n由于1&lt;5，Acceptor1、Acceptor2、Acceptor3均拒绝响应\nproposer2的请求，得到了共识，于是设置x的值为7\n\n假设，如果Acceptor3第二阶段收到信息延迟了，而新的提案者Proposer3提议要把x改为6，如图所示\n\n\nproposer3发出提议[9, ]\nAcceptor1、Acceptor2将更新接收到的最大编号为9，返回曾经共识过的提案信息[5, 7]\nAcceptor3将更新接收到的最大编号为9，因为曾经没有共识过，所以返回空值[,]\nproposer3收到两个值，但是提示说这个值已经共识过了，所以会把自己的请求由[9, 6]改为[9, 7]\nAcceptor1、Acceptor2、Acceptor3接收到并更新自己的值为7（其实没有发生变化）\n\n下面对Paxos的两阶段提交做一个总结：\n阶段1Prepare阶段：\n\n提案者向接受者发送计划提交的提案编号n的Request，不需要指定设定的值，只需要发送提案编号\n接受者收到n，检查回复过的提案的最大编号M\n如果n &gt; M：发送ACCEPT的Response，并且携带上上一个共识的编号P，且更新M_i的值为n，不再接受小于n的提案\n如果n &lt; M：拒绝响应\n\n\n\n阶段二Commit阶段：\n\n某个提案者如果收到大多数接受者的回复（表示大部分人收到了 n），则准备发出带有n与值v的提交消息\n还是比较n与M\n如果n &gt;= M则更新值（注意这里包括=这个选择）\nn &lt; m则忽略\n\n\n\n\n1、如果只有Acceptor1共识了值，Acceptor2、3都没有的话，出现proposer3要设置为6的情况，那么结果会是7还是6呢？\n\n有可能是6，也有可能是7，取决于谁先共识（由于网络的不稳定，无法判断是哪一个值）\n\n2、题目设计的是一个只读的KV服务器，如果是一个可读写的KV服务器，是不是就能改变值了？\n\n不能。Basic Paxos是一个共识算法：通过提案的值就不会改变了！！\nBasic Paxos只能就单值达成共识，属于一个基础算法；Multi-Paxos，才能在实际场景中落地。\n\n3、怎么保证提案号不会重复呢？\n\n提案号可以利用时间戳+分区的办法，比如给Acceptor1分配1-5，Acceptor2分配6-10等等，再加上时间戳标记，就可以保证既是递增，也不会冲突\nMulti PaxosBasic Paxos 只能就单个值（Value）达成共识，一旦遇到为一系列的值实现共识的时候，它就不管用了\n\n兰伯特提到的 Multi-Paxos 是一种思想，不是算法：Multi-Paxos 算法是一个统称，通过多个 Basic Paxos 实例实现一系列值的共识的算法\n\nMulti-Paxos的想法就是多次执行Basic-Paxos实例，但是这么做存在几个问题：\n\n可能因为提案者的编号冲突，导致没有一个提案能得到大多数准备响应，协商失败需要重新协商。（比如五个接受者，同时出现三个提案，得票为1:2:2）\n2轮RPC通讯（二阶段）往返消息多，耗费性能。\n\n如何解决这两个问题？有两个方案：引入领导者Leader和优化Basic Paxos（个人理解优化Basic Paxos是引入领导者后才有的优化，因此方案可以理解为引入领导者一个）\n引入Leader后：\n\n将提案者缩减为一个，这样就不存在出现同时提案导致协商失败的情况。（Multi-Paxos没有说明如何选取领导者，不同的算法有自己的实现）\n可以省略掉阶段一，直接进行阶段二，提升了效率\n\n但是同样的，引入了Leader也带来了几个问题：\n\n增加了选举Leader的复杂度\n只有Leader可以写，分布式系统中容易出现性能瓶颈\n存在单点故障问题\n\nChubby的Multi-Paxos的实现简单了解\nChubby是谷歌提供的经典的分布式锁服务，提供了粗粒度的分布式锁、对于小数据的可靠存储、关注可靠性一致性扩展性而不是性能\n\nChubby实现了单提案者，它的选举机制是：通过执行Basic Paxos算法投票选举产生的，并且在运行过程中，主节点会通过不断续租的方式来延长租期（Lease）。\n​        比如在实际场景中，几天内都是同一个节点作为主节点。如果主节点故障了，那么其他的节点又会投票选举出新的主节点，也就是说主节点是一直存在的，而且是唯一的。\nChubby是谷歌基于Multi-Paxos的落地实现\nRaft共识算法Raft 算法属于 Multi-Paxos 算法，是Multi-Paxos的落地实现。\n\nRaft算法：通过一切以领导者为准的方式，实现一系列的共识和各节点日志的一致\n\nRaft的角色身份角色身份即服务器的节点状态，Raft有三种状态：\n\n领导者（Leader）：负责三个任务，处理写请求、管理日志复制、不断发送HeartBeat信息\n跟随者（Follower）：接收处理Leader的信息，如果Leader心跳超时，就会变成Candidate\n候选人（Candidate）：向其他节点发送请求投票的RPC消息，赢得多数选票的就晋升为Leader\n\nLeader的选举机制\nRaft给每一个Follower都随机了一个超时时间，时间到期就会变为Candidate，然后给其他的节点发送请求投票的消息，获得多票者晋升为Leader\n\n每个Follower初始化时都有两个值：\n\n任期编号：一个自增的值\n超时时间：（这个值是随机的）\n\n假设现在有A(0, 150ms)、B(0, 200ms)、C(0, 300ms)三个Follower，要选出一个Leader，这里用X(a,b,c)分别代表任期编号、超时时间、选票数\n\n系统中没有Leader，因此没有任何的HeartBeat信息\n由于随机到的A的超时时间最短，到期后，A就变为了Candidate\nA给B、C发送请求投票 RPC 消息，请它们选举自己为领导者，然后A的任期编号加1，自己再给自己投一票，变为A(1, 150ms, 1)\nB、C收到A的请求后，投票给A节点，而且发现自己的任期编号0&lt;1，更新一下任期编号：B(1, 200ms)、C(1, 300ms)\nA收到B、C的投票，变为A(1, 150ms, 3)\nA获得了大部分的选票，A变为了Leader，向B、C发送心跳机制（告诉他们已有Leader，不要篡权）\n\n注意下面几个问题：\n\n1、节点之间如何通讯？\n\n节点之间联络通过RPC：选举过程有两类RPC\n\nRequestVote 请求投票RPC：请求投票。Candidate发起投票，晋升Leader。\nAppendEntries 日志复制RPC：只能Leader发起。用来复制日志，提供心跳信息。（注意：心跳信息包含在此一起发送）\n\n\n2、什么是任期？\n\nLeader是有任期的，任期到期，需要重新选举Leader，在选举过程中，主要会有以下几个事件变化任期：\n\n心跳超时：Follower在HeartBeat信息超时后，变为Candidate，增加自己的任期编号\n交流后发现自己编号小：节点发现自己的任期编号比其他节点的小，就会更新自己的任期编号为较大的编号值\n\n这个任期编号有什么用？\n\nCandidate或Leader发现自己的编号小于其他节点的编号，会变为Follower\n节点接收到小于自己编号的请求，会直接拒绝\n\n\n3、选举有哪些规则？\n\n对于Leader来说：\n\nLeader会周期性的给Follower发送心跳信息（即不带日志的AppendEntries）\n一个任期有多久？直到Leader出现故障，否则Leader一直是Leader\n\n对于Follower与Candidate：\n\nFollower超时时间内没有得到心跳信息，就会变为Candidate，发起选举\n获得大多数选票的Candidate晋升为Leader\n一个Follower只能投一次票，先来的先投；之后的将无票可投\n节点接收到小于自己编号的请求，会直接拒绝\n日志完整度高的Follower拒绝投票给日志完整性低的Candidate（因为日志完整度高代表：最后一条日志项对应的任期编号值更大）\n\n\n4、随机超时时间是什么？\n\nRaft设计超时时间，避免同时的出现很多个Candidate，造成网络堵塞\n在Raft随机超时时间有两个：\n\nFollower等待成为Candidate的超时时间\nCandidate在一个随机时间内没有获得半数以上的票，那么此选举无效\n\nRaft的日志复制\n日志是什么？**日志(Log)由日志项(Log entries)**组成\n一个日志项由三部分组成：也就是指令（Command）、索引值（Log index）、任期编号（Term）\n比如log entries1：(1, 3, x&lt;-3)就是一个日志项，前后分别代表索引值、任期编号、指令\n\n如图所示（图片来自极客时间，分布式协议与算法实战）：\n\n图中可以看到，Leader的日志是最新的，而且注意到，索引值是连续的\n\n具体的日志复制的流程是这样的：\n\n\n客户端请求，比如将x设置为3\nLeader接收到之后，创建一个新的日志项(index+1, 9, x&lt;-3)，通过日志复制（AppendEntries）RPC 消息，将日志项复制到集群其他节点上（二阶段优化为了一个阶段）\n如果大多数节点返回成功，那么就提交日志，并且返回给客户端成功\n如果没有收到大多数节点返回的成功，那么就返回错误\n\n\nFollower接收到RPC消息，如果Leader已经提交，那么他们也会提交\n\n\n理想情况下是这样的，如果出现了宕机崩溃，那么Leader会强制让Follower复制自己的日志项：\n​        Leader通过AppendEntries的一致性检查，找到Follower与自己相同的最后的索引值（说明之后的都不一致）\n举个例子：\n\n如图所示，Follower的日志与领导者发生了区别（7号索引位置），图中还引入了两个值：\n\nPrevLogEntry：上一个entry的索引值，图中为7\nPrevLogItem：上一个entry的任期编号，图中为4\n\n\nLeader通过AppendEntries，发送最新日志给Follower（发送的内容包括：心跳、新的日志项、PrevLogEntry、PrevLogItem）\nFollower发现找不到PrevLogEntry=7&amp;&amp;PrevLogItem=4的记录，说明与Leader不一致，那么跟随者就会拒绝接收新的日志项，并返回失败信息给领导者\nLeader会递减要复制的日志项的索引值，并发送新的日志项到跟随者（PrevLogEntry=6, PrevLogTerm=3）\nFollower找到了此条日志，那么返回成功，这样Leader就知道Follower在什么位置之后与自己发生了分歧\n领导者通过AppendEntries，复制并更新覆盖该索引值之后的日志项，实现了集群各节点日志的一致\n\nRaft成员变更在分布式系统中，经常会有节点的加入和退出，有可能会引发脑裂问题（出现了新旧两个配置的Leader）\n\n脑裂问题：Raft集群分裂，出现了两个Leader。\n配置 configuration：即集群是哪些节点组成的，比如ABC组成的集群，那么集群的配置就是[A, B, C]的集合\n\n比如现在有配置[A, B, C]要加入D、E两个节点，如果在加入的时候，AB与C发生了分区，导致[A, B]推举了A为Leader，[C, D, E]推举C为Leader，集群中就出现了两个Leader\n\n如何解决脑裂问题？\n\n联合共识 Joint Consensus：但这个方法实现起来很难\n单节点变更 single-server changes：即每次都只添加一个节点进入集群\n\n\n还是刚才那个问题，[A, B, C]要加入D、E两个节点，第一次只加入D这个节点，\n\nLeader A向新节点D同步数据\nLeader A将新配置[A, B, C, D]作为一个新的日志项，复制到新配置中所有节点（节点 A、B、C、D）上，然后将新配置的日志项应用（Apply）到本地状态机，完成单节点变更。\n重复1-2步骤，添加节点E\n\nPBFTPaxos和Raft都是解决非拜占庭问题CFT的，如果遇到故意使坏的节点，那么他们将不能发挥作用，因此本节介绍最出名的BFT算法，PBFT（Practical Byzantine Fault Tolerance）\n口信消息型与签名消息型在上一章介绍解决拜占庭问题的两种办法：口信消息与签名消息\n实际中，口信消息无法落地，其需要进行叛军数量f+1轮循环，如果有n个将军的话，那么就会系统中就会有O(n^(f+1))条消息，指数级别爆炸；而签名消息型也存在这个消息指数爆炸的问题\n所以实际中这两个办法都是理论化的办法，无法落地\nPBFT共识如图所示，以该图为例串一下PBFT的过程：\n这里例子里面有一个客户端Client以及四个node节点，假设node1是Master，而其中node4是叛徒节点\n\nPBFT的实现需要保证 N &gt;= 3*F + 1\n\nF代表叛徒节点\nN代表节点总数\n\n所以实现PBFT至少需要4个节点（1个为叛徒）\n\n\n\n系统先通过轮换或随机算法选出某个节点为主节点Master，此后只要主节点不切换，则称为一个视图（View），如图node1就被选中了作为Master\nClient请求发送给Master（如果发送给了从节点Slave，那么Slave会发送到Master）请求的内容是&lt;REQUEST,op,timestamp,client&gt;\nop表示具体的操作，timestamp代表当前时间戳，client表示客户端\n\n\nMaster接收到Client的消息，将消息发送给所有的Slave（开启一个三阶段提交过程）\nPhase1 Pre-Prepare：Master发送&lt;&lt;PRE-PREPARE,view,n,digest&gt;,msg&gt;给Slave（View代表视图，n代表Master给此请求分配的序号，digest是摘要，msg表示客户端的消息）\n注意：这里有摘要信息，表示其他节点不能伪造该节点的信息\n\n\nPhase2 Prepare：收到消息的Slave，发送&lt;PREPARE,view,n,digest,id&gt;给其他的节点\n此处的digest是对应节点自己的摘要，id代表自己\n发送的对象是除自己以外的节点（包括Master）\nnode4节点是叛徒，因此他不准备回应任何消息\n\n\nPhase3 Commit：如果节点收到了至少2F+1个消息（本例中即为3）则认为验证通过\n注意：这个2F+1需要包含自己，如图中node1准备reply，因为收到了node2和node3的消息，再加上自己的，正好3票，因此可以回应Client\nnode4节点是叛徒，虽然他收到了3票（不算自己），他依然不会去回复Client\n\n\n\n\n如果节点收到了至少2F+1个消息，就可以回复Client；Client如果收到了至少f+1个不同节点的相同结果，就达成共识，作为最后的结果\n\n\n1、叛徒节点为什么不伪造其他人的信息？\n\n信息中有签名，如果node4要发送完全不一样的消息给node1，那么node1在受到来自Master和node4的消息后，验证签名发现不一致，就发现了node4是叛徒\n\n2、如果Master节点是叛徒怎么办？\n\n图中我们举的例子是Slave为叛徒节点，那么如果Master是叛徒，Slave会发现其为叛徒，并且会以“轮流上岗”方式，推举新的主节点。\n轮流上岗：(v + 1)mod|R|，其中v为当前视图的值，|R|为节点数\n\n3、PBFT对签名型消息的优化：\n\nPBFT将消息复杂度从 O(n^(f+1)) 降低为 O(n^2)\n\n4、一个动态集群怎么确定f的值？\n\n最坏打算f=(n-1)/3\n\n5、为什么Client为什么需要f+1个回复而不是2f+1？\n\n假设f个全是叛徒发的错误讯息，那么多一个讯息就能让Client确认有问题\nMaster是叛徒\n如何切换主节点？\n\n视图变更，使用轮流上岗的形式：(v + 1)mod|R|，其中v为当前视图的值，|R|为节点数\n\n如果Master是坏蛋怎么办？\n\n如果Master是叛徒，那么他的作恶手段无非三种：\n\n接收到Client请求，不作任何处理\n这种情况下：Client在一段时间得不到回应后，会给所有的节点发送消息，各节点然后给Master发消息，如果Master没音讯，那么就发起视图变更\n\n\n接收到Client请求，给不同的预准备请求分配不同的序号\n达不成共识，最后触发视图变更\n\n\n接收到Client请求，主节点只给部分节点发送预准备消息\n达不成共识，最后触发视图变更\n\n\n\nPBFT存在的问题\n消息量还是很多，适合用在中小型分布式系统中（比如联盟链）\n\n虽然PBFT能在实际场景中落地，但是消息还是比较多的\n比如n=13, f=4的情况下：(f=(n-1)/3)\n\n请求消息：1\n预准备消息：n-1 = 3*f =12（Master给其他节点发消息）\n准备消息：(n-1-f)*(n-1)= (3*f - f)*3f = 8*12 = 96（除Master与叛徒节点外，节点给其他节点发消息）\n提交消息：(n-1)*(n-f) = 3f*(2f+1) = 108\n回复消息：n - f = 2f + 1 = 9\n\nGossip\n此部分参考周志明的凤凰架构\n以及参考极客时间——分布式协议与算法实战\n知乎专栏\n\n\nGossip是一个较为底层的协议，他并不是共识算法\n本质是一个异步的图广度优先算法\n\n这句话的意思是：\n\n对于Paxos、Raft算法，如果我们把它看做黑盒，那么我们每次输入得到的最后输出是一致的\n\n但是对于Gossip来说，前一个时刻的输入和后一个时刻的输入得到的输出可能会不同\n\n\n这两种协议内部都可能存在很多种结果（不同的节点认为的可能不同），但是对于Paxos、Raft他们会得到共识后输出，但是Gossip不会\nGossip的使用场景\n是一种：用于分布式数据库在多节点间复制同步数据的算法\n\n比如在区块链网络中：Gossip用它来在各个分布式节点中互相同步区块头和区块体的信息，这是整个网络能够正常交换信息的基础（但并不能称作共识）\nGossip协议的目的也很简单就是保证高鲁棒性下（即使只剩一个节点依然能正常工作）传递消息\nGossip的三个核心要义\nGossip三个核心要义：\n\n直接邮寄 Direct Mail\n反熵 Anti-entropy\n谣传 Rumor mongering\n\n\nDirectMailGossip的基本机制：\n如果有一个节点想要传输数据（源节点）\n\n源节点每过一个定时的周期，传输到与他相连接的K个节点上\n节点收到消息后，如果该消息是其未收到过的消息，那么就传播给除源节点外的节点\n\n有点像流行病毒传播，而最初它是被称作“流行病算法”（Epidemic Algorithm）\n\n（图片来源）\n这种机制下我们可以看到Gossip的优点与缺点十分明显：\n优点：\n\n极高的鲁棒性：对网络节点的连通性和稳定性几乎没有任何要求，网络中可以随意新增节点或是删除节点\n\n缺点：\n\n达到最终一致（指网络中的所有数据变为相同的状态）的时间不确定\n冗余消息量大（每个节点可能会重复收到好几次消息）\n\n而这两个缺点，是相互对立的\n\n达到一致性耗费的时间与网络传播中消息冗余量这两个缺点存在一定对立，如果要改善其中一个，就会恶化另外一个\n\n因此Gossip还涉及了反熵和谣传两种模式来供选择\n反熵\n熵是指事物的混乱程度\n反熵也就是反混乱，降低混乱程度，尽量达成同步\n反熵下：集群中的节点每隔一段时间就会随机选择某个节点与其交换数据\n\n交换方式有三种：\n\n推：将本节点消息推给另一个节点，修复对方的熵\n拉：同理，修复自己的熵\n推拉：修复双方的熵\n\n反熵的效果：缩减达到一致性耗费时间，增加了冗余消息量\n谣传\n谣传：当节点有了新数据，此节点变为活跃状态，周期性的联系给其他节点发送新的数据，直到所有的节点都包含此新数据\n注意：谣传只发送新数据，因此冗余数据量少\n\n比如A向B、C发送新数据，B与C得到新数据后变为活跃节点，给其他没有新数据的节点（即不是活跃状态的节点）发送新数据\n反熵与谣传的对比\n\n\n模式\n特点\n适用于\n\n\n\n反熵\n更快的一致性，但是冗余数据量大\n节点已知，基本固定不变\n\n\n谣传\n一致较慢，但是冗余量少\n节点动态变化的分布式系统\n\n\nGossip总结优点：\n\n扩展性强：允许节点任意增加减少\n高容错：网络中节点宕机重启不会影响Gossip消息传播\n去中心化：节点之间相互平等，不存在任何中心节点\n一致性收敛：整个网络会很快的收敛一致，消息传播速度达到了 logN。\n\n缺点：\n\n冗余消息多\n消息延迟，不适合要求实时性的场景\n\n雪花算法雪花算法，分布式环境下生成64bit的有序ID\n\n\n0：第一bit固定不使用\n41bit：表示时间戳，可以表示69年的时间\n10bit：机器ID，还可以细分，前5bit为机房，后5bit为机器号\n12bit：自增序列，最多表示4096\n\n这意味着，雪花算法可以在一毫秒一台机器上生成4096个有序的不重复ID，并且由于机器ID号很多，同一毫秒可以生成机器数*4096个ID号。\n具体的生成算法如下：\n// 生成唯一IDpublic synchronized long nextId() &#123;    long timestamp = System.currentTimeMillis();    // 如果当前时间小于上次生成ID的时间戳，说明系统时钟倒退过，抛出异常    if (timestamp &lt; lastTimestamp) &#123;        throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp));    &#125;    // 如果是同一时间生成的，则进行毫秒内序列    if (lastTimestamp == timestamp) &#123;        sequence = (sequence + 1) &amp; sequenceMask;        if (sequence == 0) // 如果超过4096个，则阻塞到下一毫秒, 获取新的时间戳            timestamp = tilNextMillis(lastTimestamp);    &#125; else &#123;        sequence = 0L;    &#125;    lastTimestamp = timestamp;    // 移位并通过或运算拼到一起组成64位的ID    return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) |        (datacenterId &lt;&lt; datacenterIdShift) |        (workerId &lt;&lt; workerIdShift) |        sequence;&#125;// 阻塞到下一个毫秒，直到获得新的时间戳protected long tilNextMillis(long lastTimestamp) &#123;    long timestamp = System.currentTimeMillis();    while (timestamp &lt;= lastTimestamp) &#123;        timestamp = System.currentTimeMillis();    &#125;    return timestamp;&#125;\n\n\n\n\n\n\n\n","categories":["分布式"],"tags":["分布式","raft","paxos","pbft","gossip","雪花算法"]},{"title":"设计模式","url":"/2022/02/14/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fplus/","content":"\n    引言：设计模式（未完）\n\n\n\n\n设计模式设计基本原则\n封装变化\n针对接口编程，而不是针对实现编程\n多用组合，少用继承\nOP原则：对扩展开放，对修改关闭\n\nOOP面向对象软件开发的三个阶段\nOOA：面向对象分析\nOOD：面向对象设计\nOOP：面向对象编程。一种编程范式或是编程风格。\n\n\n什么是OOP？\n\n一句话：以类和对象作为基本单元，将封装、继承、抽象、多态四个特性作为代码设计和实现的基石。\n\n如何判断一个语言是否是面向对象的？\n\n只要看这个语言是否实现了四大特性（不一定全都要实现，放宽要求的话，只要具有类、对象这两个概念，这个语言就可以是OO的了）\n\n四大特性的意义：\n\n\n封装：\n保证系统运行的安全性，防止意外的更改数据\n提高易用性（减少不必要的额外操作提高易用性，比方说一个电视机，有很多配置，这需要很大的学习成本，但是如果只有开机、关机、切换频道三个按钮，就很容易上手）\n\n\n抽象：\n关注大逻辑，忽略小细节\n\n\n继承：\n代码复用\n\n\n多态：\n可扩展性\n复用性\n\n\n\n\nJava如何实现四大特性：\n\n\n封装：通过访问权限控制（private、protected、default、public）\n抽象：抽象类与接口类\n继承：类之间的继承\n多态：父类可以引用子类对象；重写；重载\n\nJava抽象类\nJava 抽象类\n\n\n抽象类不能被实例化（如果被实例化，就会报错，编译无法通过）\n抽象类中不一定包含抽象方法，但是有抽象方法的类必定是抽象类。\n抽象类中的抽象方法只是声明，不包含方法体，就是不给出方法的具体实现也就是方法的具体功能。\n构造方法，类方法（用 static 修饰的方法）不能声明为抽象方法。\n抽象类的子类必须给出抽象类中的抽象方法的具体实现，除非该子类也是抽象类。\n抽象类可以有具体的方法\n\n\n如何决定使用接口还是抽象类？\n\n\n如果我们要表示一种 is-a 的关系，并且是为了解决代码复用的问题，我们就用抽象类\n如果我们要表示一种 has-a 关系，并且是为了解决抽象而非代码复用的问题，那我们就可以使用接口\n\n创建型\n创建型：阐述如何优雅的创建一个对象\n\n单例模式单例模式的适用场景\n单例模式：一个类只创建一个实例\n\n\n防止资源的访问冲突\n解决资源访问冲突的方法很多：分布式锁、使用并发类、而使用单例模式是最简单的一种解决方法\n\n\n表示全局唯一\n有时候业务上要表示系统全局唯一的类，比如配置文件\n\n\n\n单例模式的实现要点要实现一个单例模式，有很多种方式：\n\n将构造方法设为private【必选】\n是否懒加载\n保证创建时的线程安全（用volatile）\n考虑是否会被反射破坏单例性\n\n实现单例模式的5种方式饥饿式特点：private构造方法、实例是由private static final修饰\n\n线程安全（类成员，而且有final）\n初始化时就会被加载\n\npublic class Hungary &#123;    private static final Hungary hungary = new Hungary();    private Hungary()&#123;&#125;    public Hungary getInstance()&#123;        return hungary;    &#125;&#125;\n\n其中初始化时就加载是饥饿式单例一直被诟病的一点\n\n缺点：初始化时就加载，延长了启动时间，占用了内存（万一没有使用此单例，相当于白白浪费了内存）\n\n\n但是这几个缺点真的很致命吗？\n\n\n对于延长了启动时间：如果将启动时间延迟到第一次使用时，那么不就延长了第一次使用时的响应时间吗？\n对于占用了内存：按照fail-fast（有问题及早暴露）这一观点，提早创建，如果内存不够，可以提早出现OOM，便于去修复\n\n所以饥饿式的两个缺点其实也不是很致命（所以不该对于饥饿式的态度好像有点谈虎色变的感觉）\n懒汉式特点：将创建延迟到第一次使用时\n\n线程安全：为保证线程安全，对static方法添加了synchronized关键字，相当于给类对象Lazy.class加锁\n第一次使用时才会被加载\n\npublic class Lazy &#123;    private static Lazy lazy;    private Lazy()&#123;&#125;    public static synchronized Lazy getInstance()&#123;        if(lazy == null)&#123;            lazy = new Lazy();        &#125;        return lazy;    &#125;&#125;\n\n懒汉式的缺点很明显，使用synchronized这种重量级锁，会大大降低并发性（几乎和串行没有区别）\n使用要注意：\n\n如果频繁地用到，那频繁加锁、释放锁及并发度低 等问题，会导致性能瓶颈\n\n如果使用并不频繁，懒汉式也是一种比较好的实现方式\n\n\nDCL双重检查懒汉式（Double Check Lazy）\n特点：解决懒汉式的并发程度太低的问题\n\n线程安全：使用两次if保证速度，使用volatile保证创建对象安全\n\npublic class DCL &#123;    private volatile static DCL dcl;    private DCL()&#123;&#125;    public static DCL getInstance()&#123;        if(dcl == null)&#123;            synchronized (DCL.class)&#123;                if(dcl == null)&#123;                    dcl = new DCL();                &#125;            &#125;        &#125;        return dcl;    &#125;&#125;\n\n\n为什么要加volatile？\n\n因为new创建一个对象，其实有三个阶段：\n\n分配内存\n初始化\n指向引用\n\n其中CPU判断2与3并不存在先后执行关系，所以有可能指向引用之后，依然没能初始化，但是对象已经可以拿到了（因为有了引用），所以线程会把它拿回工作内存\n因此要加volatile，避免重排序\n\n为什么要两次判断是否为空？\n\n第二次判断很好理解，为什么要加第一重判断？\n如果没有第一重的判断，那么多个线程会为了获取DCL.class锁而进入等待，而且也没有办法唤醒\n如果有第一重判断，那么会让没拿到锁的线程先去做其他事，提高并发度\n静态内部类静态内部类的特点：外部类被加载，内部类不会被加载\n\n懒加载：内部类的特点\n线程安全：static final\n\npublic class StaticInnerClass &#123;    static class InnerClass&#123;        private static final StaticInnerClass innerClass = new StaticInnerClass();    &#125;    private StaticInnerClass()&#123;&#125;    public StaticInnerClass getInstance()&#123;        return InnerClass.innerClass;    &#125;&#125;\n\n枚举枚举可以做到真正的单例（不会被反射创建新的对象）\npublic enum SingleEnum &#123;    SingleEnum;    public static SingleEnum getInstance()&#123;        return SingleEnum;    &#125;&#125;\n\n\n为什么反射创建不了枚举对象？\n\nJDK源码如下：\nif ((clazz.getModifiers() &amp; Modifier.ENUM) != 0)            throw new IllegalArgumentException(&quot;Cannot reflectively create enum objects&quot;);\n\n如果发现类型是Enum，就会抛出异常\n如果是其他的枚举类，可以通过反射获取构造器，设置许可为true的方式创建对象，如下:\nDCL instance1 = DCL.getInstance();Constructor&lt;DCL&gt; constructor = DCL.class.getDeclaredConstructor();constructor.setAccessible(true);DCL instance2 = constructor.newInstance();System.out.println(instance1); // @28a418fc 哈希值不同，说明创建了两个对象，破坏了单例System.out.println(instance2); // @5305068a\n\n但如果枚举类这么做就会报错\n不同情况下的单例模式\n进程内唯一的单例模式：在多个线程（一个进程的多个线程）内，保证单例（上述的五种单例模式都是进程唯一的单例模式）\n集群唯一的单例模式：在多个进程间，保证单例\n\n\n如何在进群内保证一个对象是单例？\n\n\n需要把共享的对象，序列化到外部一个共享区域；\n使用时上锁，反序列化后使用；\n使用完后，并将对象序列化回该区域，释放锁；\n\n多例模式\n所谓多例模式：\n\n可以理解为创建的对象的个数是有限的\n也可以理解为同一类的对象为单例，不同类之间创建的对象不同\n\n\n1、可以创建的对象个数有限\npublic class MultiCaseMode1 &#123;    private static final int size = 3;    private static final Map&lt;Integer, InetSocketAddress&gt; server = new ConcurrentHashMap&lt;&gt;();    static &#123;        server.put(0, new InetSocketAddress(&quot;127.0.0.1&quot;, 8080));        server.put(1, new InetSocketAddress(&quot;127.0.0.1&quot;, 8081));        server.put(2, new InetSocketAddress(&quot;127.0.0.1&quot;, 8082));    &#125;    private MultiCaseMode()&#123;&#125;    public static InetSocketAddress getInstance()&#123;        Random random = new Random();        return server.get(random.nextInt(size));    &#125;&#125;\n\n这样每次getInstance返回的就是三个对象之一\n2、同一类创建的对象个数有限\npublic class MultiCaseMode2 &#123;    private static final ConcurrentHashMap&lt;String, Object&gt; instance = new ConcurrentHashMap&lt;&gt;();    private MultiCaseMode2()&#123;&#125;    public static Object getInstance(String key)&#123;        instance.putIfAbsent(key, new Object());        return instance.get(key);    &#125;&#125;\n\n这样，对于同一类（即相同key）的对象，会获得相同的对象。\n工厂模式\n工厂模式：实现了创建者和调用者的分离\n\n普通的对象，我们可以直接new来创建，但是当创建的操作比较复杂时，就会考虑使用工厂模式，将创建者和调用者分离，简化调用者的操作。\n普通的方式：\n// 张三开五菱去上班Car car = new Wulin();zhangSan.drive(car);// 后来张三996挣钱了，换成了宝马车Car car = new BMW();zhangSan.dirve(car);// 再后来张三30岁了，被裁员，只能骑共享单车了Car car = new HaLuo();zhangSan.dirve(car);\n\n简单工厂模式（静态工厂模式）简单工厂就是提供一个静态方法，直接返回对象实例。\n使用简单工厂方式是这样的：\nzhangSan.drive(CarFactory.getCar(&quot;别克&quot;));\n\npublic class CarFactory&#123;    public static Car getCar(String carName)&#123;        if(carName == &quot;BMW&quot;)&#123;            return new BMW;        &#125;else if(...)&#123;            ...        &#125;\t&#125;&#125;\n\n工厂模式原则：当创建逻辑比较复杂的时候使用工厂模式，其余使用简单工厂模式即可\n什么算创建复杂的逻辑？\n\n涉及到对不同的类型，创建了不同的对象（往往有很多个if-else嵌套）\n创建涉及到很多个对象\n\n工厂模式相比于简单工厂，就是定义了详细的接口，更加规范：\n\n产品接口\n产品实现接口\n工厂接口\n工厂实现接口\n\n对应的接口都需要有实现类，比如下面的例子：\npublic static void main(String[] args) &#123;    TruckCarFactory factory = new TruckCarFactory();    Car car = factory.createCar();    car.fire();    car.stop();&#125;\n\n产品接口及其产品实现接口：\npublic interface Car &#123;    public void fire();    public void stop();&#125;public class TruckCar implements Car&#123;    @Override    public void fire() &#123;    &#125;    @Override    public void stop() &#123;    &#125;&#125;\n\n工厂接口及其工厂实现接口：\npublic interface CarFactory &#123;    Car createCar();&#125;public class TruckCarFactory implements CarFactory&#123;    @Override    public Car createCar() &#123;        return new TruckCar();    &#125;&#125;\n\n建造者模式\n建造者模式解决什么问题？\n\n创建一个对象时，往往使用它的构造方法与set方法去创建这个对象，但是这样存在几个问题：\n\n如果需要设置的成员很多，那么会导致构造函数的参数很多\n\n导致代码可读性、易用性变差\n调用时可能会搞错参数的顺序\n\n\n如果参数之间存在依赖关系（比如A参数必须大于B参数等），校验逻辑放在构造函数内也不够优雅\n\n避免对象存在无效状态\nRectangle r = new Rectangle();// 创建了长方形对象(无效状态)r.setWidth(2); // 设置了宽，但是只有宽的长方形也是不能用的(无效状态)r.setHeight(3);// 宽、高都有(有效状态)\n\n建造者模式可以避免处于无效状态的对象被别的地方使用导致出错。\n\n\n例如这个例子:\npublic class Rectangle &#123;    private int length;    private int width;    public Rectangle(int length, int width) &#123;        this.length = length;        this.width = width;    &#125;    static class Builder&#123;        // 给默认值        private int length = 2;        private int width = 1;        public Rectangle.Builder length(int length) &#123;            this.length = length;            return this;        &#125;        public Rectangle.Builder width(int length) &#123;            this.length = length;            return this;        &#125;        public Rectangle build()&#123;            // 加判断逻辑，防止无效状态            if(length &lt;= 0 || width &lt;= 0)&#123;                throw new IllegalArgumentException(&quot;Wrong length or width&quot;);            &#125;            return new Rectangle(this.length, this.width);        &#125;    &#125;&#125;\n\n如果我们要创建一个长方形：\npublic static void main(String[] args) &#123;    Rectangle.Builder builder = new Rectangle.Builder();    Rectangle rec = builder.length(10).width(10).build();&#125;\n\n这样，即使是我们给的长给了负数，在最后build()时，也会抛出异常，这样就避免了无效状态。\n\n建造者模式的缺点\n\n代码重复，发现建造者中有原对象的成员（代码冗余度高）\n\n建造者模式与工厂模式的区别\n\n生活的例子：顾客走进一家餐馆点餐，我们利用工厂模式，根据用户不同的选择，来制作不同的食物，比如披萨、汉堡、沙拉。\n对于披萨来说，用户又有各种配料可以定制，比如奶酪、西红柿、起司，我们通过建造者模式根据用户选择的不同配料来制作披萨\n\n工厂模式：创建不同但是相关类型的对象\n建造者模式：创建一种逻辑复杂的对象\n\n\nLombok有注解@Builder就是建造者模式的使用\n\n（关于此注解可以看此篇博客）\n原型模式\n原型模式：利用对已有对象（原型）进行复制（或者叫拷贝）的方式，来创建新对象，以达到节省创建时间的目的。\n\n原型模式有两种实现方法：\n\n深拷贝：一份完完全全独立的对象\n浅拷贝：复制对象中基本数据类型数据和引用对象的内存地址，不会递归地复制引用对象，以及引用对象的引用对象\n\n可以通过改写clone方法来实现原型模式：\n\n继承Cloneable接口\n重写clone方法\n\n@Datapublic class User implements Cloneable&#123;    private String name;    private ArrayList list;    @Override    protected Object clone() throws CloneNotSupportedException &#123;        return super.clone(); // 浅拷贝    &#125;&#125;public class Test &#123;    public static void main(String[] args) throws CloneNotSupportedException &#123;        User fengQiang = new User();        fengQiang.setName(&quot;小明&quot;);        ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;();        list.add(1);        fengQiang.setList(list);        // 克隆一份，然后使用克隆的再添加一个元素        User clone = (User)fengQiang.clone();        clone.getList().add(2);        System.out.println(fengQiang);        System.out.println(clone);    &#125;&#125;// 输出结果为：//User(name=小明, list=[1, 2])//User(name=小明, list=[1, 2])\n\n浅拷贝，两个对象地址一样\n改写clone为深拷贝\n@Overrideprotected Object clone() throws CloneNotSupportedException &#123;    User clone = (User) super.clone();    clone.setList((ArrayList) clone.list.clone());    return clone;&#125;\n\n结构型结构型：总结了一些类或对象组合在一起的经典结构\n代理模式\n代理模式在不改变原始类接口的条件下，为原始类定义一个代理类，主要目的是控制访问，而非加强功能，这是它跟装饰器模式最大的不同\n\n代理模式常用在业务系统中开发一些非功能性需求，比如：监控、统计、鉴权、限流、事务、幂等、日志。\n分为：\n\n静态代理\n动态代理\n\n静态代理模式静态代理模式中有 真实对象、代理对象\n\n真实对象与代理对象要实现同一个接口\n代理对象要代理真实的角色\n\n优点：\n\n静态代理模式可以帮助我们处理一些其他的事情，真实对象可以专注于做本职任务\n如果业务发生扩展，方便集中管理\n\n例如：租客与房东之间，租客需要一个中介（代理对象），中介负责去找房东（真实对象）\n在Java中，Thread就是一个静态代理的例子，自定义Thread类要实现Runnable接口，而Thread类也实现了Runnable接口，此时自定义Thread类就是真实对象，而Thread类就是代理对象\n除此外，在RPC（远程方法调用）中，客户端与服务端连接，具体的连接过程都由一个代理类来完成，这也是代理模式\n动态代理静态代理模式还存在一些问题，需要给每一个类都创建一个代理类，工作量直接翻倍\n对于这种情况就出现了动态代理\n\n其他概念与静态代理相同，只不过代理类是动态生成的，而不是我们直接写好的\n\n\n基于接口的动态代理：JDK Proxy\n\n基于类的动态代理：CGLIB\n\n字节码实现：Javasist（不是重点，实现在JBoss服务器）\n\n\nJDK Proxy此动态代理模式用到两个类：Proxy与InvocationHandler\nProxy主要了解此方法newProxyInstance：\npublic static Object newProxyInstance(ClassLoader loader,// 类加载器， 通常会选择使用动态代理类本身的类加载器                                      Class&lt;?&gt;[] interfaces,// 通过真实对象可以获取到它所实现的所有接口                                      InvocationHandler h// 实现动态代理的类本身                                     )\n\nInvocationHandler是一个接口，他有一个方法：\nObject invoke(Object proxy,// 生成的代理对象              Method method,// 调用的方法              Object[] args)// 方法的参数       throws Throwable\n\n在JDK动态代理中，真实对象必须实现接口，代理对象才可以对其进行代理，原理如下面这个demo：\n// 接口；在静态代理中，这个就是我们要实现的业务，代理与真实对象都要实现public interface UserService &#123;    public void sayHi();&#125;// 真实对象public class UserServiceImpl implements UserService &#123;    @Override    public void sayHi() &#123;        System.out.println(&quot;hi&quot;);    &#125;&#125;// 动态代理生成处理器public class ProxyInvocationHandler implements InvocationHandler &#123;    private Object target;    public void setTarget(Object target) &#123;        this.target = target;    &#125;    // 获得代理类    public Object getProxy()&#123;        return Proxy.newProxyInstance(                this.getClass().getClassLoader(),                target.getClass().getInterfaces(),// 这个参数注意！其必须要有实现接口                this        );    &#125;    @Override    // 处理代理实例，返回对象    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        System.out.println(&quot;其他操作...&quot;);// 可以进行其他操作，比如记录日志等等        Object invoke = method.invoke(target, args);// 实现真实对象想要实现的功能        System.out.println(&quot;其他操作...&quot;);        return invoke;    &#125;&#125;public class Test &#123;    public static void main(String[] args) &#123;        UserServiceImpl impl = new UserServiceImpl();        // 创建代理对象        ProxyInvocationHandler pih = new ProxyInvocationHandler();        pih.setTarget(impl);        UserService proxy = (UserService) pih.getProxy();        // 代理对象通过invoke调用方法        proxy.sayHi();    &#125;&#125;\n\n运行结果：\n其他操作...hi其他操作...\n\n这也是Spring AOP的实现原理\nCGLibJDK动态代理中，被代理的对象必须实现接口，而CGlib就不需要\n桥接模式\n什么是桥接模式？\n抽象部分与实现部分解耦，可以理解为接口与实现类都属于桥接模式\n\n\n抽象和实现解耦\n组合优于继承\n\n装饰者模式模式概念\n装饰者模式解决的问题：\n\n当一个类的子类很多时，如果我们想给父类扩展一个功能，那么所有的子类都会发生变化（类爆炸）\n\n什么是装饰者模式？\n\n动态的将责任附加到对象上，若要扩展功能，装饰者提供了比继承更有弹性的替代方案\n具体实现上，装饰者类会继承同一个类（其实就是使用多态的特性实现对功能的增强），然后内部含有一个父类对象的引用（下面的InputStream就是例子）\n\n装饰者模式与代理模式的区别\n\n\n体现的特性不同：\n装饰者模式体现多态性\n代理模式体现封装性\n\n\n要实现的目的不同：\n装饰者模式是为了增强功能\n代理模式是为了实现不属于自己的功能\n\n\n\n重要的例子这里以InputStream类来说明：\nInputStream是一个抽象类，他有几个方法：\npublic abstract class InputStream implements Closeable &#123;\tpublic abstract int read() throws IOException;    // 省略 skip()等方法    public void close() throws IOException &#123;&#125;&#125;\n\n他有很多个子类，其中有一个子类FilterInputStream，该类也有子类BufferedInputStream、DataInputStream\n\nBufferedInputStream：为流提供了缓冲区\nDataInputStream：为流提供了读取基本类型的方法（例如：readInt、readLong不需要思考具体的读取细节）\n\n这个例子中，BufferedInputStream、DataInputStream就是装饰类，他们继承了InputStream，使用的时候可以这么用：\nInputStream in = new FileInputStream(&quot;/test.txt&quot;);BufferedInputStream bs = new BufferedInputStream(in);while (bs.read() != -1)&#123;    // ...&#125;\n\n\n为什么此处使用装饰者模式？\n\n如果我们想实现缓冲区、读取单个基本类型的字节等等这样的功能，如果直接在父类InputStream类实现这个功能，那么会导致其所有子类都会有这个功能，这非我本意\n\n为什么需要有一个中间类FilterInputStream，而不是直接使用BufferedInputStream继承InputStream？（此处比较难理解）\n\n假设BufferedInputStream直接继承了InputStream，那么对于InputStream的抽象方法（比如说read方法），我们需要重写：\npublic class BufferedInputStream extends InputStream &#123;    // 假设直接继承了 InputStream    protected volatile InputStream in;    protected BufferedInputStream(InputStream in) &#123;        this.in = in;    &#125;    // 下面这个方法需要重写    public int read()&#123;        in.read();    &#125;    // 其他。。。&#125;\n\n同理，对于DataInputStream，我们也需要这样实现一遍，代码冗余度很高，因此抽出来FilterInputStream这个方法\n因此如果看JDK源码就是这样：\npublic class FilterInputStream extends InputStream &#123;    protected volatile InputStream in;        public int read() throws IOException &#123;        return in.read();    &#125;\t// 其他方法&#125;\n\n适配器模式\n将不兼容的接口转换为可兼容的接口\n\n一种补偿措施，补救设计缺陷：\n\n有缺陷的接口：参数过多、命名不规范\n替换依赖的外部系统\n兼容老版本接口\n适配不同格式的数据\n\n门面模式\n什么是门面模式\n\n门面模式为子系统提供一组统一的接口，定义一组高层接口让子系统更易用\n（我的理解：即封装+抽象，封装难用方法，抽象出一个简洁好用的方法）\n\n门面模式与适配器模式的区别\n\n\n门面模式：解决多接口整合的问题\n适配器模式：解决接口过时或无法使用的问题\n\n\n遇到什么问题可以使用门面模式呢？\n\n解决性能问题：\n    假设客户端与服务器之间通信，服务器暴露了3个接口A、B、C，某业务需要客户端请求A、B、C三个接口。\n\n    但是客户端是APP，App 和服务器之间是通过移动网络通信的，网络通信耗时比较多 \n\n    因此我们可以将A、B、C封装在一个D接口中（门面接口），让客户端直接请求门面接口即可，这样就将网络通信的次数减少到1次\n\n\n注意：\n\n门面接口如果数量少，可以直接和普通的接口放在一起，如果比较多的门面接口的话，还是专门给门面接口放一个包比较好\n\n组合模式对于具有树结构的数据有奇效，比如:\n\n文件与目录\n员工与部门\n\n一个目录下可以有目录也可以有文件，常有的操作是统计一个目录包含的文件数量，及一个目录的大小\n如果不使用设计模式，我们可能会设计成：\npublic class FileSystemNode &#123;    private String path;    private boolean isFile;    private List&lt;FileSystemNode&gt; subNodes = new ArrayList&lt;&gt;();\t// 省去一些方法&#125;\n\n而使用组合模式的话：\n三个类：文件类与目录类继承文件系统类\npublic abstract class FileSystemNode &#123;    protected String path;    public FileSystemNode(String path) &#123;        this.path = path;    &#125;    public abstract int countNumOfFiles(); // 统计文件数量    public abstract long countSizeOfFiles(); // 统计文件大小    public String getPath() &#123;        return path;    &#125;&#125;\n\n文件类：\npublic class File extends FileSystemNode&#123;    java.io.File file;    public File(String path) &#123;        super(path);        this.file = new java.io.File(path);    &#125;    @Override    public int countNumOfFiles() &#123;        return 1;    &#125;    @Override    public long countSizeOfFiles() &#123;        if(!file.exists())&#123;            return 0;        &#125;        return file.length();    &#125;&#125;\n\n目录类：\npublic class Directory extends FileSystemNode &#123;    private List&lt;FileSystemNode&gt; subNodes = new ArrayList&lt;&gt;();    public Directory(String path) &#123;        super(path);    &#125;    @Override    public int countNumOfFiles() &#123;        int num = 0;        for (FileSystemNode subNode : subNodes) &#123;            num += subNode.countNumOfFiles();        &#125;        return num;    &#125;    @Override    public long countSizeOfFiles() &#123;        int size = 0;        for (FileSystemNode subNode : subNodes) &#123;            size += subNode.countSizeOfFiles();        &#125;        return size;    &#125;    public void addSubNode(FileSystemNode fileOrDir) &#123;        subNodes.add(fileOrDir);    &#125;    public void removeNode(FileSystemNode fileOrDir) &#123;        int size = subNodes.size();        int i = 0;        for (; i &lt; size; ++i) &#123;            if (subNodes.get(i).getPath().equalsIgnoreCase(fileOrDir.getPath())) &#123;                break;            &#125;        &#125;        if (i &lt; size) &#123;            subNodes.remove(i);        &#125;    &#125;&#125;\n\n享元模式\n所谓享元模式，就是共享元数据。\n使用享元模式的目的只有一个，就是为了节省内存\n\n比如有一个在线象棋项目，每一个房间都有一个牌局，有几十万个房间，每个房间都有一副象棋。\n一个象棋类，需要记录 颜色、位置、棋的种类\n但其实，对于每一个房间来说，只有棋的位置是不同的，其他元素都是相同的，因此对于除位置外的元素我们都可以抽为一个类，使用享元模式进行共享，节约内存\npublic class ChessPieceUnit &#123;    // 棋子样式    private int id;    private String text;    private Color color;&#125;public class ChessPiece &#123;    // 棋子类    private ChessPieceUnit chessPieceUnit;    private int positionX;    private int positionY;&#125;\n\n\nJava中的享元模式\n\n比如Integer的整型池、字符串常量池都属于享元模式的实现\n\n享元模式与单例模式、缓存、对象池的区别\n\n\n享元模式与单例模式区别\n享元模式：一个类可以有多个对象（类似于多例模式，但是目的是为了节省内存，而不是限制对象个数）\n单例模式：一个类只能创建一个对象\n\n\n享元模式与缓存与对象池的区别\n享元模式：为了节省内存\n缓存：为了提高访问效率\n对象池：为了节省对象的创建时间\n\n\n\n行为型观察者模式概念介绍观察者模式（即pub/sub模式）\n\npub出版者即主题Subject\nsub订阅者改称为观察者Observe\n\n观察者模式=主题+观察者\n\n观察者模式：\n定义了对象之间的一对多依赖（主题:观察者=1:n），这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新\n\nJava中的观察者模式Java自带了观察者模式（Observe接口（sub）与Observable类（pub）），但是存在一些问题\n\nObservable是一个类，这意味着在单继承的Java中，使用不是很方便\nObservable的API中，setChange()是protected修饰的，违反了多用组合、少用继承的原则\n\n因此掌握其设计思想才是重要的！\npublic interface Observer &#123;    void update(Observable o, Object arg);&#125;\n\npublic class Observable &#123;    private boolean changed = false;     // 让更新不再那么敏感（即我们可以实现隔一段时间后，设置changed为true，才让其接收通知）    )    private Vector&lt;Observer&gt; obs; // 使用了线程安全的Vector    public Observable() &#123;        obs = new Vector&lt;&gt;();    &#125;    public synchronized void addObserver(Observer o) &#123;        if (o == null)            throw new NullPointerException();        if (!obs.contains(o)) &#123;            obs.addElement(o);        &#125;    &#125;    public synchronized void deleteObserver(Observer o) &#123;        obs.removeElement(o);    &#125;    public void notifyObservers() &#123;        notifyObservers(null);    &#125;    public void notifyObservers(Object arg) &#123;        /*         * 一个临时的对象数组，作为当前Observe状态的一个快照         */        Object[] arrLocal;        synchronized (this) &#123;            /* 这里需要加锁，不加锁可能导致的结果             * 1、新增加的Observe接收不到通知             * 2、删除的Observe错误的接收到通知             */            if (!changed)                return;            arrLocal = obs.toArray();            clearChanged();        &#125;        for (int i = arrLocal.length-1; i&gt;=0; i--)            ((Observer)arrLocal[i]).update(this, arg);    &#125;    public synchronized void deleteObservers() &#123;        obs.removeAllElements();    &#125;    protected synchronized void setChanged() &#123;        changed = true;    &#125;    protected synchronized void clearChanged() &#123;        changed = false;    &#125;    public synchronized boolean hasChanged() &#123;        return changed;    &#125;    public synchronized int countObservers() &#123;        return obs.size();    &#125;&#125;\n\n简单的Demo这里以一个报纸公司与其订阅读报者的例子演示观察者模式：\n观察者的接口：只需要做自己需要做的事情即可\npublic interface MyObserve &#123;    public void updateData();&#125;\n\n主题的接口：一般都有三个方法分别为注册、移除、通知\npublic interface MySubject&lt;E&gt; &#123;    public void registerObserve(E e);    public void removeObserve(E e);    public void notifyObserve();&#125;\n\n报纸出版公司：\npublic class PaperCom implements MySubject&lt;PaperSub&gt;&#123;    List&lt;PaperSub&gt; notifyGroup;    public PaperCom(List&lt;PaperSub&gt; notifyGroup) &#123;        this.notifyGroup = notifyGroup;    &#125;    @Override    public void registerObserve(PaperSub sub) &#123;        notifyGroup.add(sub);    &#125;    @Override    public void removeObserve(PaperSub sub) &#123;        notifyGroup.remove(sub);    &#125;    @Override    public void notifyObserve() &#123;        for (int i = 0; i &lt; notifyGroup.size(); i++) &#123;            PaperSub paperSub = notifyGroup.get(i);            paperSub.updateData();        &#125;    &#125;&#125;\n\n报纸订阅者：\npublic class PaperSub implements MyObserve&#123;    @Override    public void updateData() &#123;        System.out.println(&quot;读最新的报纸&quot;);    &#125;&#125;\n\n模板模式策略模式定义\n策略模式：\n定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户端\n\n实际上就是解耦了策略的定义、创建、使用的三个过程\nJDK线程池的拒绝策略JDK线程池有四种拒绝策略，他们都实现了此接口：\npublic interface RejectedExecutionHandler &#123;    void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125;\n\n实现类在ThreadPoolExecutor内部，作为静态内部类实现，比如\npublic static class AbortPolicy implements RejectedExecutionHandler &#123;        public AbortPolicy() &#123; &#125;    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        throw new RejectedExecutionException(&quot;Task &quot; + r.toString() +                                             &quot; rejected from &quot; +                                             e.toString());    &#125;&#125;\n\n策略模式的使用开发中可能会遇到很多if-else的逻辑\npublic class OrderService &#123;    public double discount(Order order) &#123;        double discount = 0.0;        if(order.equals(Order.NORMAL))&#123;            // ...        &#125;else if(order.equals(Order.GROUP))&#123;            // ...        &#125; else if (order.equals(Order.PROMOTION)) &#123;            // ...        &#125;        return discount;    &#125;&#125;\n\n使用策略模式+工厂模式我们就可以避免if-else嵌套\n\n一个策略接口+不同的策略实现\n一个工厂类，用key代表类型，value存放不同的策略实现\n\n这样就可以避免重复的判断逻辑\n职责链模式定义：\n\n将请求的发送和接收解耦，让多个接收对象都有机会处理这个请求。\n将这些接收对象串成一条链，并沿着这条链传递这个请求，直到链上的某个接收对象能够处理它为止。\n\n翻译一下的话，就是：多个处理器依次处理同一个请求。一个请求先经过 A 处理器处理，然后再把请求传递给B处理器，B 处理器处理完后再 传递给 C 处理器，以此类推，形成一个链条。\n链条上的每个处理器各自承担各自的处理职责，所以叫作职责链模式。 \n\n\n比如Spring MVC的处理逻辑，就是一个职责链模式\n对一些UGC应用（用户生成内容），需要过滤敏感词，这也可以用到职责链模式\n\n状态模式迭代器模式访问者模式备忘录模式命令模式解释器模式中介模式","categories":["设计模式"],"tags":["设计模式"]},{"title":"NIO","url":"/2021/09/18/Netty/NIO/","content":"\n引言：NIO 非阻塞I/O模型；给Netty的学习打基础！\n\n\n\nJava NIONIONIO：可以叫做Non-Blocking IO，也可以称为New IO，个人觉得第二种比较合适，因为非阻塞只是NIO的特点之一\n（但是非阻塞确实是核心中的核心，所以怎么叫都是可以的）\n\n\n1、在没有NIO下，如何实现一个服务器？\n\n【法一】使用多线程开发\n\n特点：一个Socket连接，使用一个线程来进行管理\n优点：一对一的服务，适合于连接数少的场景\n缺点：\n内存占用高（一个Socket需要一个线程，如果很多连接同时进入，那么就会占用很多的内存）\n线程上下文切换成本高\n\n\n\n【法二】使用线程池\n\n特点：使用线程池思想，控制线程数量\n优点：避免了创建大量的线程导致内存占用过高的问题，适合短连接场景\n缺点：属于阻塞模式（即一个线程同时只能给一个socket连接提供服务），线程的利用率不高\n\n【法三】使用NIO的Selector\n\n特点：用一个线程管理Selector，Selector去管理注册在此的通道（下面会详细介绍）\n优点：适合连接数多，但是流量低的场景（low traffic）\n\n\n\n2、JavaNIO由三个核心组件构成：\n\n\nChannel\nBuffer\nSelector\n\n除了这三个还有其他组件，如Pipe、FileLock等等\n\n3、NIO与BIO的对比：\n\n\nBIO是面向流的；NIO面向缓冲区\nBIO只能向后读，不能向前读；NIO可以向前也可以向后读\nBIO是单向的，一端要么读要么写；NIO中通道是双向的，一端可读可写\nBIO是阻塞的；NIO是非阻塞的\n\n\n4、程序在NIO中的读取数据过程如图：\n\n\nBuffer\nBuffer 缓冲区：可以理解为一个数组，通道必须与Buffer一起使用\n\n具体的实现类有：\nByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer分别对应除了boolean之外的八种基本数据类型\nBuffer常用API具体的实现类有：\nByteBuffer、CharBuffer 、ShortBuffer 、IntBuffer 、LongBuffer 、FloatBuffer 、DoubleBuffer分别对应除了boolean之外的八种基本数据类型（常用的是ByteBuffer与CharBuffer）\n核心API：\n\nput(value)：将value写入缓存（从当前的position开始写入，并增加position的值，即相对位置的写入）\nget(arr[])：读取position位置下的数据到一个数组中（如果不传参数，默认读取一个字符）\nhasRemaining()：判断position与limit之间的距离，如果还有数据可以处理，那么就返回true\nclear() ：清空缓冲区（清空的原理并不是真的清空了，只是将position的位置为0，limit设置为capacity，即切换回写模式）\nflip()：可以将缓冲区由写模式切换到读模式（将limit设为position的位置，再将position设置为0）\ncompact()：压缩，将未读取的数据（即position与limit之间的数据）向前移动，然后position指向最后一个未读取的数据之后，然后limit指向capacity\n\n\n其他API：\n\ncapacity(); limit() ; position()：返回当前capacity/limit/position的值\n\nmark()：标记当前position的位置，当调用reset方法时，会重置到mark标记过的位置（只能在 0-position之前）\n\nremaining()：返回position与limit之间的距离\n\nreset()：重置position到mark标记过的位置\n\nrewind()：将position设置为0（即让position回到初始的位置），取消mark标记位\n\n\n创建buffer\nallocate(long)：创建一个指定大小的缓冲区；是一个静态方法；（注意：buffer对象不能new，只能通过allocate分配）\nwarp()：把已存在的数组包装为一个Buffer对象（无论操作两者中的哪一个，另一个也会变化，因为就是同一个数组）\n\n注意：\n这两种创建方式，都是间接的创建了一个缓冲区（间接：是指这个缓冲区在JVM堆中）\n\n\n如何将一个字符串转换为一个ByteBuffer数组？\n\n有三种方式：\n1、使用ByteBuffer的wrap方法\n2、使用Charset\n3、创建ByteBuffer再put字符串的字节数组\nString str = &quot;hello&quot;;//1、使用ByteBuffer的wrapByteBuffer bf1 = ByteBuffer.wrap(str.getBytes());//2、使用CharsetByteBuffer bf2 = StandardCharsets.UTF_8.encode(str);//3、创建ByteBuffer再放入ByteBuffer bf3 = ByteBuffer.allocate(16);bf3.put(str.getBytes());\n\n\n\nBuffer的属性及属性的变化过程Buffer有四个重要的属性：\n\ncapacity：表示当前Buffer的容量大小；创建时指定，创建后不能修改；如果写满了capacity，那么需要等清空后才能写入数据\nposition：表示当前的位置，初始时为0，每读写一个数据，position就+1，最大为capacity-1\nlimit：指第一个不能被读或写的位置（即可以表示只能读取或写入多少个数据）\nmark：设置一个标记位，当进行reset时，会将position的值变为mark原本标记的值\n\n四个属性有这样的大小关系：0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity\n下面有个图，可以清晰的表示整个过程\n\n理解了这样的变化过程，再来看读取数据时的代码，就懂了：\nwhile (true) &#123;    int len = fc.read(bf);    if (len == -1) &#123;        break;    &#125;    bf.flip();     //1、转换为读模式！将limit设为position，再将position设置为0    while (bf.hasRemaining())&#123;        byte b = bf.get();        //2、每读取一个字节，就将position+1        System.out.print((char) b);    &#125;    bf.clear();    //3、转换为写模式！将position的位置为0，limit设置为capacity&#125;\n\n直接缓冲区首先要明确一个概念：只有byteBuffer才有资格参与IO操作，因为数据全为01，只有byteBuffer存储的才是01二进制，所以只有它才能IO操作\n\n为什么要用直接缓冲区？\n\n使用非直接缓冲区可能会导致性能损耗（多一次拷贝过程）\n假设给一个通道传入了一个非直接缓冲区，那么通道会先创建一个临时的直接缓冲区，将非直接缓冲区的数据复制到临时的直接缓冲区，使用这个临时的直接缓冲区去执行IO操作（多一次拷贝，增大了开销）\n\n直接缓存区存在的问题：\n\n\n直接缓存区绕过了JVM的堆栈，不受JVM控制，所以有可能我们创建的直接缓存区代价会更高\n直接缓存区分配会较慢，因为Java需要调用OS的函数进行分配，所以会较慢\n\n\n如何创建一块直接缓冲区？\n\n调用ByteBuffer.allocateDirect(1024)即可\n分散读与集中写\n这主要是两种思想\n分散读就是把原本的数据一次读到多个buffer中，集中写就是将多个buffer的内容一次性写入\n\n这两种思想分别有两个接口代表：ScatteringByteChannel（有read方法）、GatheringByteChannel（有write方法）\n都可以传入一个ByteBuffer的数组\nByteBuffer bf1 = ByteBuffer.allocate(5);ByteBuffer bf2 = ByteBuffer.allocate(5);ByteBuffer bf3 = ByteBuffer.allocate(5);//分散读try (FileChannel fc = new RandomAccessFile(&quot;D:\\\\temp.txt&quot;, &quot;r&quot;).getChannel()) &#123;    fc.read(new ByteBuffer[]&#123;bf1, bf2, bf3&#125;);    // 这个read方法传入的是一个ByteBuffer数组    // 可以将数据分别读入三个缓冲区中&#125; catch (IOException e) &#123;&#125;\n\n集中写同理\nTCP的粘包问题很多人觉得这并不是一个问题，而是一个TCP的特性，关键在于你怎么看待\n\n什么是粘包问题？\n\n\n以接收端来看：因为TCP是面向流的协议，所以不会保持输入数据的边界，导致接收端很可能一下子收到多个应用层报文，需要应用开发者自己分开，有些人觉得这样不合理，就起名为粘包\n以发送端来看：用户数据被TCP发送时，会根据Nagle算法，将小的数据封装在一个报文段发送出去，导致不同的报文段黏在了一起\n\n\n如何解决？\n\n\n发送方可以关闭Nagle算法\n\n设置TCP_NODELAY就能关闭Nagle算法\n但我不太认同这种做法，最好不要使用这种方法\n\n\n接收方对粘包无法处理，只能交给应用层：\n\n固定消息长度：一条消息就发送一个固定大小的数据，然后填充空白\n\n缺点：浪费带宽\n\n\n格式化数据：每条数据有固定的格式（开始符，结束符），这种方法简单易行\n\n缺点：但是这种方法需要保证传输的字符中没有该开始符与结束符，而且因为需要挨个遍历，传输速度不是很快\n\n\nTLV格式：即Type类型、Length长度、Value数据，在类型和长度已知的情况下就可以方便的知道消息大小，分配合适的buffer\n\n缺点：buffer需要提前分配，如果分配过大，影响server的吞吐量\nHTTP1.1是TLV格式（先传输类型）\nHTTP2.0是LTV格式（先传输长度）\n\n\n\n\n\n\n此处举一个例子：（这里属于格式化数据的一种方式，使用到\\n作为分隔符）\n\n​        网络上有多条数据发送给服务端。数据之间使用\\n进行分隔，但由于某种原因这些数据在接收时，被进行了重新组合。\n例如原始数据有3条为\nHello,world\\nI&quot;m zhangsan\\nHow are you?\\n\n\n变成了下面的两个 byteBuffer(黏包，半包)\nHello,world\\nI&quot; m zhangsan\\nHow are you?\\n\n\n如何解决？（但这种方法需要对字节挨个遍历，所以效率不是很高）\npublic static void main(String[] args) &#123;    ByteBuffer source = ByteBuffer.allocate(32);    // 模拟粘包    source.put(&quot;Hello,world\\nI&#x27; m zhangsan\\nHo&quot;.getBytes());    spilt(source);    source.put(&quot;w are you?\\n&quot;.getBytes());    spilt(source);&#125;// 处理粘包private static void spilt(ByteBuffer source) &#123;    source.flip();    for (int i = 0; i &lt; source.limit(); i++) &#123;        if(source.get(i) == &#x27;\\n&#x27;)&#123;// 带索引的get方法不会改变position的值            int len = i + 1 - source.position();            // 计算要分配的缓冲长度            ByteBuffer target = ByteBuffer.allocate(len);            for (int j = 0; j &lt; len; j++) &#123;                target.put(source.get());            &#125;        &#125;    &#125;    source.compact();    // 注意这里不能用clear&#125;\n\n\n\nChannel\nChannel：通道，类似于IO流，但是与流不同的是Channel是双向的（流是单向的）\n\nIO流：如InputStream、OutputStream要么输入（读），要么输出（写）\n但是Channel是双向的，实现类如下\n\nFileChannel：从文件中读写数据\nDatagramChannel：通过UDP读写网络数据\nSocketChannel：通过TCP读写网络数据\nServerSocketChannel：可以监听新进来的TCP连接，就像Web服务器一样，对每一个新连接都会建立一个SocketChannel\n\n特点：\n\n通道的操作是双向的（可以只读、可以只写、还可以读写）\n通道可以操作的数据种类很多（可以是文件IO、网络Socket都可以操作）\n通道的操作是异步的\n不能直接访问通道，需要与Buffer合作（通道读必须从一个Buffer读、通道写必须写到一个Buffer内）\n通道不能复用！关闭了就没了\n\n具体在Java中，就是一个接口，有两个方法\npublic interface Channel extends Closeable &#123;    /**     * 检测通道当前是否打开     */    public boolean isOpen();    /**     * 关闭这个通道：（如果通道关闭了，那么对这个通道的操作，     \t都会抛出ClosedChannelException异常）     */    public void close() throws IOException;&#125;\n\nChannel全家福\n\n可以注意到FileChannel没有继承SelectableChannel类（**FileChannel是阻塞的**）\n除ServerSocketChannel外，均实现了ScatteringByteChannel与GatheringByteChannel接口\n\nFileChannel用来对文件进行操作的通道\n\n1、获取FileChannel的方式：（不能new来获取，有三种获取方式）\n\n\n获取FileChannel可以使用RandomAccessFile这个类\n也可以使用InputStream（这样创建的FileChannel只能读）\n也可以使用OutputStream（这样创建的FileChannel只能写）\n\n\n2、FileChannel读取数据到Buffer中\n\n\n通道的read()方法，必须读入到一个缓存中，而且会返回读取到的字节数（或者说是，缓冲区中的字节数有多少）\n需要在缓冲的buffer.hasRemaining()的循环中使用\n如果读完，会返回-1\n\nDemo如下：\n// 此文件有21字节，设置模式为读写均可RandomAccessFile rw = new RandomAccessFile(&quot;D:\\\\temp.txt&quot;, &quot;rw&quot;);// 使用RandomAccessFile类的getChannel方法获得此文件的通道FileChannel channel = rw.getChannel();// 关于buffer的内容先不做介绍，此处为分配一个大小为10字节的缓存ByteBuffer buffer = ByteBuffer.allocate(10);// 通道的read方法会返回读取到的字节数，因为我的文件21字节，所以需要读三次// 第一次：10字节、第二次10字节、第三次1字节int read = channel.read(buffer);// 这一步是不会阻塞的！会继续向下执行while (read != -1)&#123;    System.out.println(&quot;读取了：&quot;+ read);    buffer.flip();    while (buffer.hasRemaining())&#123;        System.out.println((char)buffer.get());    &#125;    buffer.clear();    read = channel.read(buffer);&#125;rw.close();channel.close();\n\n下面精炼一下读文件的Demo，可以记下来：\ntry (RandomAccessFile rw = new RandomAccessFile(&quot;D:\\\\temp.txt&quot;, &quot;rw&quot;))&#123;    // JDK7 新特性    //在 try 的后边可以增加一个 ()，在括号中可以定义流对象，    //那么这个流对象的作用域就在 try 有效，try 中的代码执行完毕，会把流对象自动释放，不用写 finally    FileChannel fc = rw.getChannel();    ByteBuffer bf = ByteBuffer.allocate(10);    while (true) &#123;        int len = fc.read(bf);        if (len == -1) &#123;            break;        &#125;        bf.flip();        while (bf.hasRemaining())&#123;            byte b = bf.get();            System.out.print((char) b);        &#125;        bf.clear();    &#125;&#125; catch (IOException e) &#123;    e.printStackTrace();&#125;\n\n\n3、写数据到Buffer中\n\n\nwrite方法，需要传入缓冲\n需要在缓冲的buffer.hasRemaining()的循环中使用\n\nRandomAccessFile rw = new RandomAccessFile(&quot;D:\\\\temp.txt&quot;, &quot;rw&quot;);FileChannel channel = rw.getChannel();ByteBuffer buffer = ByteBuffer.allocate(15);buffer.clear();byte[] bytes = &quot;I love you too&quot;.getBytes();System.out.println(bytes.length);buffer.put(bytes);buffer.flip();while (buffer.hasRemaining())&#123;    int write = channel.write(buffer);    // 返回写入的字节，与读取一样，并不能确定一次会写入多少字节    // 所以需要在循环内执行write方法，并且要用hasRemaining方法判断是否有剩余    System.out.println(write);&#125;// 关闭channel.close();\n\n\n4、其他方法\n\n\npositon()：返回从文件开头位置到当前位置的字节数\nposition(long)：设置当前位置（注意：如果指定的位置超过了文件当前的位置，然后进行了写入，会导致文件中间部分没有被写（文件空洞））\nsize()：返回文件大小\ntruncate(long)：截取前指定大小的数据，后面的数据将会被删除\n\nRandomAccessFile rw = new RandomAccessFile(&quot;D:\\\\temp.txt&quot;, &quot;rw&quot;);FileChannel channel = rw.getChannel();long pos = channel.position();// 初始位置为 0long size = channel.size();System.out.println(size);channel.position(pos+size);// 指定从什么位置开始，这里指定了当前位置+文件大小，就是文件的末尾开始写ByteBuffer buffer = ByteBuffer.allocate(30);buffer.put(&quot; but she don&#x27;t fond of me&quot;.getBytes());buffer.flip();while (buffer.hasRemaining())&#123;    channel.write(buffer);&#125;rw.close();channel.close();\n\n\n5、force方法与RandomAccessFile的模式\n\n\nforce(boolean)方法：\n\n此方法是为了保证对文件的所有更新操作都写回磁盘\n参数为false表示只写回文件内容\n参数为true表示既要写回文件内容，又要写回元数据信息（即文件的权限信息等）\n\n\nRandomAccessFile(fileName, mode)：传入一个文件的路径以及一个模式，此处的模式有四种\n\nr：只读，如果调用write会抛出异常\nrw：可读可写；如果文件不存在，将会被创建\nrws：可读可写，并且所有的更新操作每次都会被同步的写入磁盘，会写入文件内容以及元数据（即带有force(true)的rw模式）\nrwd：可读可写，并且所有的更新操作每次都会被同步的写入磁盘，会写入文件内容（即带有force(false)的rw模式）\n\n\n\n\n6、通道间通信：transferFrom与transferTo\n\n通道之间可以传输数据，这两个方法仅仅是方向不同而已\n（通道之间传输数据没有用到缓存，不知道底层实现是否用到了缓存）\n\ntransferFrom(ReadableByteChannel src, long position, long count)：三个参数，第一个传入另外一个通道，第二个为起始位置，第三个传入想要传输的字节数\n\nRandomAccessFile rw1 = new RandomAccessFile(&quot;d:\\\\temp.txt&quot;, &quot;rw&quot;);FileChannel channelFrom = rw1.getChannel();RandomAccessFile rw2 = new RandomAccessFile(&quot;d:\\\\temp2.txt&quot;, &quot;rw&quot;);FileChannel channelTo = rw2.getChannel();// 这样就将temp的文件写入到了temp2channelTo.transferFrom(channelFrom, 0, channelFrom.size());// channelFrom.transferTo(0, channelFrom.size(), channelTo);// 也可以这么实现，两个方法只不过是方向反了一下channelFrom.close();channelTo.close();\n\n注意：transferTo方法是有上限的（最大为2G，超过这个范围，那么只会传输2g的内容，剩下的数据就不会再传输了）\n可以这样实现传输大于2g的内容：\ntry (    FileChannel fc1 = new RandomAccessFile(&quot;D:\\\\temp.txt&quot;, &quot;r&quot;).getChannel();    FileChannel fc2 = new RandomAccessFile(&quot;D:\\\\temp1.txt&quot;, &quot;rw&quot;).getChannel()) &#123;    // 重点在这里：    long size = fc1.size();    for (long left = size; left &gt; 0 ;) &#123;        left -= fc1.transferTo(size-left, left, fc2);    &#125;&#125; catch (IOException e) &#123;&#125;\n\n\n\n\n\nSocket通道此处的Socket通道泛指了三个实现了AbstractSelectableChannel的类：SocketChannel、DatagramChannel、ServerSocketChannel\n（注意：SocketChannel我会专门提到他的名词，如果提到Socket通道，泛指的是三个类）\n\n\n已经有了Socket，为什么要引入Socket通道？\n\n传统的Socket会为每个Socket连接创建一个线程，但是Socket通道仅仅只开辟一个或几个线程就可以提供成百上千的服务，大大提高了性能！\n好处：\n1、节省了线程切换的上下文开销\n2、便于管理！\n\nSocket通道的特点\n\n\nServerSocketChannel只负责： （不负责读写）\n监听传入的连接\n创建SocketChannel对象\n\n\nDatagramChannel与SocketChannel负责真正的读写操作\nSocket通道可以被重复使用\n\n\nSocket通道可以设置为非阻塞模式\n\nServerSocketChannel\nServerSocketChannel：可以理解为一个实现了非阻塞模式的ServerSocket\n\n特点：\n\nsocket()：可以获得ServerSocket对象，然后调用其bind()方法去绑定一个端口（注意：ServerSocketChannel本身没有bind方法！！（JDK1.7有了bind方法，默认绑定本地地址））\nServerSocketChannel有accept()方法，会返回一个SocketChannel对象；但是使用ServerSocket的accept()方法就还是阻塞的\n如果返回的对象为null，说明当前没有连接\n\n\n因为继承了AbstractSelectableChannel类，所以可以设置为非阻塞模式\n\n\nServerSocketChannel对象的创建：\n\n不能new，需要调用ServerSocketChannel的静态方法open()\n\n核心API\n\n\naccepct()：方法是阻塞方法（如果不设置为非阻塞）\nbind()：绑定一个端口\nconfigureBlocking(boolean)：默认为true（阻塞模式）\n\n\n使用单线程+Channel实现服务器：\n\n// 0. byteBufferByteBuffer bf = ByteBuffer.allocate(16);// 1. 创建服务器ServerSocketChannel ssc = ServerSocketChannel.open();ssc.configureBlocking(false);// 设置为非阻塞模式// 2. 绑定端口ssc.bind(new InetSocketAddress(8080));// 3. 连接集合ArrayList&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;();while (true) &#123;    // 4. SSC建立与客户端的连接，sc与客户端通信    SocketChannel sc = ssc.accept();// 设置为非阻塞，不会再阻塞运行    if (sc != null) &#123;        log.debug(&quot;connected... &#123;&#125;&quot;, sc);        sc.configureBlocking(false);// sc也设置为非阻塞        channels.add(sc);    &#125;    // 5. 遍历集合处理请求    for (SocketChannel channel : channels) &#123;        int read = channel.read(bf);// 设置为非阻塞        if (read &gt; 0) &#123;            bf.flip();            readBuffer(bf);// 此方法简单的输出了一下buffer（模拟实际操作）            bf.clear();            log.debug(&quot;after read...&quot;);        &#125;    &#125;&#125;\n\n缺点：我们使用了死循环来一次次判断连接情况（这样也会浪费CPU的资源）\n因此有了Selector来解决这个问题（使用Seletor后，代码的逻辑会发生变化，具体看下一节）\nSocketChannel\nSocketChannel：一个用来连接到TCP套接字的通道\n\n特点：\n\n实现了可选择通道，可以被多路复用\n基于TCP传输协议\n支持两种模式：阻塞与非阻塞（同样也是通过configureBlocking调节）\n\n\n如何创建SocketChannel\n\n\nServerSocket对象的accept方法会返回SocketChannel对象\n直接使用SocketChannel.open()也可以创建SocketChannel对象\n\n\n核心API\n\n\nconfigureBlocking(boolean)：默认为true（阻塞模式）\nread(ByteBuffer)：读\nwrite(ByteBuffer)：写\n\nDatagramChannelSelector\nSelector ：选择器提供了一种选择执行已经就绪的任务的能力\n\n允许单线程处理多个通道，大大提高了效率\nSelector选择的原理1、每一个Channel都需要在Selector上注册\n2、注册后会返回一个选择键，选择键代表了当前通道是否已经就绪的信息\n3、每执行一次select方法，都会更新所有的选择键，然后选择一个已经就绪的通道\n\n注意：\n\n这些Channel必须是SelectableChannel的子类（比如：FileChannel就不是其子类，也就不能被选择）\n\nSelector有关的三个类\nSelector：选择器类负责管理在此注册的通道的集合信息以及他们的就绪状态\n\nSelectableChannel：可选择通道，是一个抽象类，继承这个类的类为可以进行选择的类（FileChannel就没有继承这个类）\n\nSelectionKey：选择键类，封装了通道与选择器之间的注册关系，含有两个比特集（一个代表注册关系所关心的通道操作，一个代表通道已经就绪的操作）\n\n\nSelector\n如何建立一个Selector系统？\n\n1、创建Selector：不能new，需要调用Selector.open()方法\n2、设置通道为非阻塞（只有非阻塞的通道才能注册到选择器）\n3、通道注册：调用register(selector, OP)进行注册，两个参数，第一个为选择器，第二个参数为想让选择器关心的操作，会返回一个SelectionKey对象\n此处可以设置的关心的操作OP有：\nSelectionKey.OP_READ = 1&lt;&lt;0; // 是否有可读的通道就绪SelectionKey.OP_WRITE = 1&lt;&lt;2; // 是否有可写的通道就绪SelectionKey.OP_CONNECT = 1&lt;&lt;2; // 是否有新的通道连接到服务器SelectionKey.OP_ACCEPT = 1&lt;&lt;3; // 是否有新的连接（只有ServerSocketChannel有这个操作）\n\n如果我们想要关心多个操作，可以通过|位或运算符将OP连接起来\nchannel.register(selector, SelectionKey.OP_READ | SelectionKey.OP_WRITE)\n\n4、select()轮询：查看是否有就绪的通道，会返回当前就绪通道的数量\nSelector维护的三个集合\nSelector维护了三个集合：keys集合、selectedKeys集合、cancel集合\n\n\nkeys()：此集合保存已注册的键（此集合不能修改！）\nselectedKeys()：此集合保存关心事件发生的键，此集合我们只能移除，不能添加（添加是自动进行的）\n注意这个集合的特点：会自动添加集合，但是不会自动删除集合\n因此我们在处理完成后要主动remove掉，要不然会报异常\n\n\n已取消键的集合，使用cancel()方法后的键都会放在这里\n\n\nSelector的核心就是select方法，它的执行过程为：\n\n\n检查已取消集合：如果集合非空，就将集合内所有的键从另外两个集合中移除，然后注销其相关的通道\n检查selectedKeys集合：确定每个通道所关心的操作是否已经就绪\n返回值：返回上一次调用select后进入就绪状态的通道的数量\n\nSelectionKey\n选择键： 表示通道与Selector之间的注册关系，注册一个通道就会返回一个SelectionKey\n\n相关API：\n\nchannel：返回对应的通道\n\nselector：返回通道注册的选择器\n\ncancel：取消注册关系\n\nisValid()：判断注册关系是否有效\n\ninterestOps()：以整数的形式，返回所关心操作的bit掩码，可以用此来判断选择器是否关心通道的某个操作\nBoolean isAccept = interestOps &amp; SelectionKey.OP_ACCEPT == SelectionKey.OP_ACCEPT;// 判断一下与的结果是否与Accept相等\nisAccept()等操作：上面的这种方式判断太麻烦了，API直接就有相关判断方法\n\n\nselector的要点辨析\n1、select方法什么时候会不阻塞，向下执行？\n\n总共用如下几种情况：\n\n发生事件时\n客户端发起连接请求，触发accept事件\n客户端发送数据、正常关闭、异常关闭都会触发read事件\n如果要发送的数据大于缓冲区，会触发多次read事件\nchannel可写，触发write事件\n在Linux下nio bug发生时\n\n\n调用selector.wakeup()\n调用selector.close()\nselector所在线程interrupt\n\n\n2、事件可以不进行处理吗？\n\n不可以，事件要么就remove，要么就cancel，不可以不进行处理\n如果不进行处理，select每次都会返回这个事件，白白浪费CPU的资源\n\n3、用完key为什么要remove？\n\n​        Selector维护的集合SelectedKeys添加是自动的，删除需要我们手动进行，一旦有我们关心的事件发生，那么Selector就会将此key添加到这个集合内\n​        如果我们用完key，没有remove，那么此集合内就还会存在这个key，在使用这个key进行操作的时候，就可能会出现异常（比如空指针异常）\n注意：remove只是将这个集合内的该键删除了，如果对应的事件还会继续发生，那么这里光删除集合内的key是没有用的，应该cancel掉对应的事件\n\n4、处理read事件要注意的事情\n\n【一】处理好客户端的正常与异常断开\n正常断开依靠read方法返回值\n异常断开依靠catch抓住异常后，将此key取消掉\ntry&#123;    SocketChannel channel = (SocketChannel) key.channel();    ByteBuffer buffer = ByteBuffer.allocate(16);    int read = channel.read(buffer);//如果客户端正常断开，这里会返回-1    // 【处理客户端正常断开】    if(read == -1)&#123;        key.cancel();    &#125;else &#123;        ...    &#125;&#125;catch (IOException e)&#123;    e.printStackTrace();    // 【处理客户端异常断开】    key.cancel();&#125;\n\n【二】处理好消息边界\n例如我们开辟一块buffer为4字节的缓冲区，客户端传输两个汉字“中国”，默认字符集UTF-8对于1个汉字占用3个字节，就要处理好消息边界的问题！\n（如何解决消息边界问题下一节详细介绍）\n\n5、处理write事件要注意的事情\n\n我们发送的数据可能不是一次性发送的！\nByteBuffer buffer = Charset.defaultCharset().encode(sb.toString());//【1】 write不能保证一次性就将所有的数据写入，有一个返回值，表示实际写入的字节数while (buffer.hasRemaining())&#123;    // 【2】返回值代表一次性可以发送的位数    // 这里一次性可以发送多少，涉及到了OS对于TCP的发送缓存与接收缓存的实现    int write = sc.write(buffer);    System.out.println(write);&#125;\n\n这样处理虽然可以保证数据全部发完，但是不符合NIO非阻塞的思想\n好的处理方式应该是，如果我们一次性发不完，可以先去处理其他事情（避免一直发送导致发送缓冲区满，导致轮询）\n完整代码如下：\nwhile (true)&#123;    selector.select();    Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator();    while (iterator.hasNext()) &#123;        SelectionKey key = iterator.next();        iterator.remove();        if (key.isAcceptable()) &#123;            SocketChannel sc = ssc.accept();            sc.configureBlocking(false);            SelectionKey scKey = sc.register(selector, 0, null);            // 向客户端发送消息            StringBuilder sb = new StringBuilder();            for (int i = 0; i &lt; 30000; i++) &#123;                sb.append(&quot;a&quot;);            &#125;            ByteBuffer buffer = Charset.defaultCharset().encode(sb.toString());            sc.write(buffer);            //【1】 一次发送完最好            if (buffer.hasRemaining())&#123;                //【2】 如果发送不完，就关注写事件                // 注意：要拿到原本关注的事件再|上此事件（+ |都可以）                scKey.interestOps(scKey.interestOps() | SelectionKey.OP_WRITE);                //【3】把没有写完的数据写回，利用附件的形式                scKey.attach(buffer);            &#125;        &#125;else if(key.isWritable()) &#123;            // 【4】从附件取出，继续写            ByteBuffer buffer = (ByteBuffer) key.attachment();            SocketChannel sc = (SocketChannel) key.channel();            sc.write(buffer);            // 【5】如果此次还没有写完，由于我们已经关注了可写事件，所以下一次会继续写            // 【6】清理操作            if(!buffer.hasRemaining())&#123;                // 清掉附件                key.attach(null);                // 去掉关注的事件                key.interestOps(key.interestOps() - SelectionKey.OP_WRITE);            &#125;        &#125;    &#125;&#125;\n\n\n\n处理消息边界​        在Buffer一节，介绍过什么是TCP粘包，这里因为read操作涉及到了粘包，所以我们要对其进行处理！\n消息发送的异常情况\n消息边界：发送一个消息可能有三种异常情况\n\n\nbuffer的大小不足以放下一个完整的消息。\n这种情况下，只能将buffer扩容\n\n\nbuffer空间足够，但是只放了1.5个消息，剩下的半个消息我们需要进行拼接（在Buffer一节，我们介绍了一个利用\\n来截断消息的步骤）\n\n\n如果buffer空间不足（即一条消息的大小就超过了buffer），nio是如何进行处理的呢？\n\n例如：buffer空间为8字节，传输一条10字节的消息\n服务器收到read事件，将数据读到8字节的缓存中，然后打印输出\n然后，服务器会再次收到read事件，将剩下2个字节读入，打印输出\n（即：服务器会变为多次read事件读取消息，因此对于这种情况我们需要扩容）\n如何给buffer扩容\nbuffer不能是局部变量\n\n最开始我们的代码是这样的，但是如果我们想要给一个buffer扩容，buffer就不能是一个局部变量\n//收到read事件try &#123;    SocketChannel channel = (SocketChannel) key.channel();    ByteBuffer buffer = ByteBuffer.allocate(16);    // 注意这里的buffer是局部变量    int read = channel.read(buffer);    if (read == -1) &#123;        key.cancel();    &#125; else &#123;        //         spilt(buffer);    &#125;&#125; catch (IOException e) &#123;    e.printStackTrace();    key.cancel();&#125;\n\n\n那么，不能是局部变量，我提到最外面可以不可以呢？\n\n不可以，我们要保证一个线程的buffer是私有的，如果我们提到最外面，那么多个线程操控一个buffer，这就乱套了（线程不安全）\n因此我们要借助附件attachment\n\n注意：附件可以保证每一个线程间是私有的\n\nregiser()传入的第三个参数就是附件，如果要获取附件，可以调用key的attachment()方法\n if (key.isAcceptable()) &#123;    //6.1、accept事件    ServerSocketChannel channel = (ServerSocketChannel) key.channel();    SocketChannel sc = channel.accept();    sc.configureBlocking(false);    ByteBuffer buffer = ByteBuffer.allocate(16);    // 【1】将buffer以附件的形式存放到key中    SelectionKey scKey = sc.register(selector, 0, buffer);    scKey.interestOps(SelectionKey.OP_READ);    log.debug(&quot;sc: &#123;&#125;&quot;, sc);&#125; else if (key.isReadable()) &#123;    //6.2、read事件    try &#123;        SocketChannel channel = (SocketChannel) key.channel();        // 【2】从附件中获取buffer        ByteBuffer byteBuffer = (ByteBuffer) key.attachment();        int read = channel.read(byteBuffer);        if (read == -1) &#123;            key.cancel();        &#125; else &#123;            spilt(byteBuffer);            byteBuffer.flip();            readBuffer(byteBuffer);        &#125;    &#125; catch (IOException e) &#123;        e.printStackTrace();        key.cancel();    &#125;&#125;\n\n\n什么时候进行扩容呢？\n\n当然是buffer空间不够的时候，之前我们自己实现的split()方法最后是使用的compact()方法去完成拼接\n如果一个消息大于buffer，那么他的\\n的索引依然会大于limit\n比如：\nbuffer大小8字节传输一个数据：0123456789\\n（11字节）-----------------&gt;执行spilt()方法，最后buffer内的数据为01234567，此时position为8，limit也为8\n\n因此，扩容的时机就是position==limit\nSocketChannel channel = (SocketChannel) key.channel();// 从附件中获取bufferByteBuffer byteBuffer = (ByteBuffer) key.attachment();int read = channel.read(byteBuffer);if (read == -1) &#123;    key.cancel();&#125; else &#123;    System.out.println(byteBuffer);    // 【1】判断是否需要扩容    if(byteBuffer.position() == byteBuffer.limit())&#123;        //【2】 分配一个double容量的buffer        ByteBuffer newByteBuffer = ByteBuffer.allocate(byteBuffer.capacity() * 2);        byteBuffer.flip();        newByteBuffer.put(byteBuffer);//【3】 copy        key.attach(newByteBuffer);// 【4】替换原有的byteBuffer    &#125;&#125;\n\n这样两次read事件，就能把消息拼接到一起了！\nbuffer大小8字节传输一个数据：0123456789\\n（11字节）---------解释---------【第一次read事件】：执行spilt()方法buffer1内的数据：01234567此时position=8, limit = 8 因此创建buffer2，容量为8*2字节，并放入附件中【第二次read事件】：buffer2数据为：01234567spilt()将89\\n拼接到buffer2此时buffer2数据为：0123456789\\n\n\n此处我们的扩容简单的进行了翻倍扩容，这是比较简单的实现，在Netty中，就设计的比较优秀了，此处我们只是抛砖引玉\n\nbuffer大小如何抉择有两种思路：\n\nByteBuffer需要设计为可变的buffer：\n\n思路一：首先分配一个较小的buffer，如果不够用，再分配一个更大的buffer，并将原本的buffer数据copy到新buffer内\n优点：消息连续好处理\n缺点：数据copy消耗性能\n\n\n思路二：用多个数组组成buffer，一个数组不够，就将多出来的内容写入新的数组\n优点：避免了copy消耗性能\n\n\n\nNIO服务器的完整DEMO此DEMO是上述样例的完整品（没有write的处理部分），仅供参考使用\n@Slf4jpublic class Server &#123;    public static void main(String[] args) throws IOException &#123;        //1、创建Selector对象        Selector selector = Selector.open();        ByteBuffer bf = ByteBuffer.allocate(16);        ServerSocketChannel ssc = ServerSocketChannel.open();        ssc.configureBlocking(false);        ssc.bind(new InetSocketAddress(8080));        //2、注册ssc，返回SelectionKey对应关系        SelectionKey sscKey = ssc.register(selector, 0, null);        //3、SelectionKey设置关心的操作        sscKey.interestOps(SelectionKey.OP_ACCEPT);// 这个键只关心其ACCEPT事件        while (true) &#123;            //4、调用select方法，如果没有事件发生，是阻塞的！如果有事件才会恢复执行            selector.select();            //5、处理事件（因为我们涉及到删除，所以要用迭代器遍历）            //   注意：事件必须要处理，要么remove要么cancel，要不然select会一直有这个事件，浪费CPU资源            Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator();            while (iterator.hasNext()) &#123;                SelectionKey key = iterator.next();                log.debug(&quot;key: &#123;&#125;&quot;, key);                // 7、要记得删除此事件！可以一开始就删，也可以最后再删除                // 这里一开始就删除了，特别强调！！一定要删除                iterator.remove();                // 6、区分时间类型进行处理                if (key.isAcceptable()) &#123;                    //6.1、accept事件                    ServerSocketChannel channel = (ServerSocketChannel) key.channel();                    SocketChannel sc = channel.accept();                    sc.configureBlocking(false);                    ByteBuffer buffer = ByteBuffer.allocate(16);                    // 将buffer以附件的形式存放到key中                    SelectionKey scKey = sc.register(selector, 0, buffer);                    scKey.interestOps(SelectionKey.OP_READ);                    log.debug(&quot;sc: &#123;&#125;&quot;, sc);                &#125; else if (key.isReadable()) &#123;                    //6.2、read事件                    try &#123;                        SocketChannel channel = (SocketChannel) key.channel();                        // 从附件中获取buffer                        ByteBuffer byteBuffer = (ByteBuffer) key.attachment();                        int read = channel.read(byteBuffer);                        if (read == -1) &#123;                            key.cancel();                        &#125; else &#123;                            System.out.println(byteBuffer);                            // 判断是否需要扩容                            if(byteBuffer.position() == byteBuffer.limit())&#123;                                // 分配一个double容量的buffer                                ByteBuffer newByteBuffer = ByteBuffer.allocate(byteBuffer.capacity() * 2);                                byteBuffer.flip();                                newByteBuffer.put(byteBuffer);// copy                                key.attach(newByteBuffer);// 替换原有的byteBuffer                            &#125;                        &#125;                    &#125; catch (IOException e) &#123;                        e.printStackTrace();                        key.cancel();                    &#125;                &#125; else if (key.isWritable()) &#123;                    //6.3、write事件                &#125;            &#125;        &#125;    &#125;    private static void readBuffer(ByteBuffer bf) &#123;        for (int i = bf.position(); i &lt; bf.limit(); i++) &#123;            System.out.print((char) bf.get());        &#125;        System.out.println();    &#125;    private static void spilt(ByteBuffer source) &#123;        source.flip();        for (int i = 0; i &lt; source.limit(); i++) &#123;            if (source.get(i) == &#x27;\\n&#x27;) &#123;// 带索引的get方法不会改变position的值                int len = i + 1 - source.position();                // 计算要分配的缓冲长度                ByteBuffer target = ByteBuffer.allocate(len);                for (int j = 0; j &lt; len; j++) &#123;                    target.put(source.get());                &#125;            &#125;        &#125;        source.compact();        // 注意这里不能用clear    &#125;&#125;\n\n\n\n多线程优化如何优化前面我们都是使用单线程，即将所有的事件全部放在一个线程内进行操作，不能发挥多线程的优势\n所以我们可以进行多线程优化：（这也是Netty的实现原则）\n\n优化的手段\n\n可以将ACCEPT请求与读写请求分开，如图：\n\n有两类线程：\n\nboss线程：专门负责处理ACCEPT事件\nworker线程：处理READ与WRITE事件\n\nboss线程只有一个，而worker线程可以根据服务器的CPU核心数来确定，并且可以加入负载均衡策略，让每一个worker线程一起出力。\n\n优化手段总结：\n\n1、按事件分类，分给不同的线程执行\n2、worker间实现负载均衡\n实现逻辑boss线程一开始就有，worker线程是慢慢创建的，具体的逻辑如下\n\n值得注意的是：要让select与注册全让worker线程来执行，通过消息队列+wakeup()方法来进行传输消息（即我标为黄色的部分）\n这样可以避免出现执行顺序不正确带来的顺序问题。\n实现代码@Slf4jpublic class MultiThreadServer &#123;    public static void main(String[] args) throws IOException &#123;        // boss负责管理连接事件        Thread.currentThread().setName(&quot;boss&quot;);        ServerSocketChannel ssc = ServerSocketChannel.open();        ssc.configureBlocking(false);        Selector boss = Selector.open();        SelectionKey bossKey = ssc.register(boss, 0, null);        bossKey.interestOps(SelectionKey.OP_ACCEPT);        ssc.bind(new InetSocketAddress(8888));        // 1、创建固定数量的worker并初始化        Worker[] workers = new Worker[Runtime.getRuntime().availableProcessors()];        for (int i = 0; i &lt; workers.length; i++) &#123;            workers[i] = new Worker(&quot;worker-&quot; + i);        &#125;        AtomicInteger index = new AtomicInteger();        while (true) &#123;            boss.select();            Iterator&lt;SelectionKey&gt; iterator = boss.selectedKeys().iterator();            while (iterator.hasNext()) &#123;                SelectionKey key = iterator.next();                iterator.remove();                // ACCEPT事件                if (key.isAcceptable()) &#123;                    SocketChannel sc = ssc.accept();                    log.debug(&quot;connected...&#123;&#125;&quot;, sc.getRemoteAddress());                    sc.configureBlocking(false);                    //2、关联selector                    // 轮流使用worker，达到负载均衡                    workers[index.getAndIncrement() % workers.length].initial(sc);                &#125;            &#125;        &#125;    &#125;    /**     * Worker类负责读写操作     */    static class Worker implements Runnable &#123;        private Thread thread;        private Selector selector;        private String name;        private volatile boolean start = false;//保证只创建一个        // 作为消息队列，让boss线程给worker线程传消息        private ConcurrentLinkedQueue&lt;Runnable&gt; queue = new ConcurrentLinkedQueue&lt;&gt;();        public Worker(String name) &#123;            this.name = name;        &#125;        // 初始化线程和selector        public void initial(SocketChannel sc) throws IOException &#123;            if (!start) &#123;                thread = new Thread(this, name);                selector = Selector.open();                start = true;                thread.start();            &#125;            queue.add(() -&gt; &#123;                try &#123;                    sc.register(selector, SelectionKey.OP_READ, null);                &#125; catch (ClosedChannelException e) &#123;                    e.printStackTrace();                &#125;            &#125;);            selector.wakeup();            // 唤醒selector，让其可以将READ事件注册        &#125;        @Override        public void run() &#123;            while (true) &#123;                try &#123;                    selector.select(); // 阻塞                    Runnable task = queue.poll();                    if (task != null) &#123;                        task.run();                        // 真正是在这里执行了注册方法  sc.register(selector, SelectionKey.OP_READ, null);                    &#125;                    Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator();                    while (iterator.hasNext()) &#123;                        SelectionKey key = iterator.next();                        iterator.remove();                        if (key.isReadable()) &#123;                            ByteBuffer buffer = ByteBuffer.allocate(16);                            SocketChannel channel = (SocketChannel) key.channel();                            int read = channel.read(buffer);                            if(read == -1)&#123;                                key.cancel();                            &#125;                            buffer.flip();                            log.debug(&quot;&#123;&#125; executing...&quot;, name);                            while (buffer.hasRemaining()) &#123;                                System.out.print((char) buffer.get());                            &#125;                            buffer.clear();                        &#125;                    &#125;                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;&#125;\n\n零拷贝传统IO例子：服务器从磁盘读取一个文件，然后用socket写回给客户端\n代码如下：\nFile f = new File(&quot;helloworld/data.txt&quot;);RandomAccessFile file = new RandomAccessFile(f, &quot;r&quot;);byte[] buff = new byte[(int)file.length()];file.read(buf);Socket socket = ...;socket.getOutputStream().write(buf);\n\n从磁盘读入文件并发送，整个过程内部工作流程如下：\n\n\nJava代码调用read方法去读取文件，由用户态陷入内核态，将文件读入到内核缓冲区内（期间Copy使用DMA技术，无需CPU参与）\n全部读入到内核缓冲区后，由内核态回到用户态，将内核缓冲区的数据写入到用户缓冲区（即buff字节数组中）（期间Copy使用CPU）\n调用write方法，将数据从用户缓冲区写入到socket缓冲区（CPU参与拷贝）\n向网卡写数据，由用户态陷入内核态，（DMA实现数据Copy，CPU不会参与）\n发送完毕后，再从内核态返回到用户态\n\n所以我们可以知道，简单的一个过程发生了：\n\n2次用户态与内核态的转换\n4次数据Copy\n\n效率十分低下\nNIO优化NIO可以分配直接缓存，直接缓存的特点是OS与Java都可以访问的一块内存（Java可以使用DirectByteBuffer将堆外内存映射到JVM内存中使用）因此减少了一次copy\n\n现在有：\n\n2次用户态与内核态的转换\n3次数据Copy\n\nLinux2.1提供sendFile进一步优化Linux2.1后，提出了sendFile方法，对应到Java就是通道的transferTo与transferFrom实现了拷贝数据（即不需要再将数据复制到用户态的缓冲区内）\n此时可以直接将内核缓冲区拷贝到socket缓冲区\n\n\nJava调用transferTo，陷入内核态（使用DMA将数据读入内核缓冲区）\n数据从内核缓冲区传输到socket缓冲区（CPU参与拷贝）\n最后使用DMA将socket缓冲区的数据写入网卡，不会使用CPU\n\n现在有：\n\n1次用户态与内核态的转换\n3次数据Copy\n\nLinux2.4再进一步优化Linux2.4后，再进一步优化，可以直接将数据传输到网卡\n\n\nJava调用transferTo，陷入内核态（使用DMA将数据读入内核缓冲区）\n直将一些offset和length拷贝到socket缓冲区，几乎无消耗\n将数据从内核缓冲区直接写入到网卡（DMA）\n\n现在有：\n\n1次用户态与内核态的转换\n2次数据Copy\n\n\n这也就是所谓的零拷贝\n\n零拷贝：并不是真正意义的无拷贝，而是不会拷贝重复的数据到JVM内存中，因此成为零拷贝\n\n零拷贝的优点：\n\n更少的用户态与内核态转换\n不利用CPU\n适合小型文件传输\n\n","categories":["Java","NIO"],"tags":["Java","NIO"]},{"title":"Docker","url":"/2021/11/16/docker/Docker/","content":"\n引言：Build, Ship and Run Any App, Anywhere!\n\n\n\n\nDocker因为有了Docker，运维与开发的界限越来越模糊，甚至现在的研发的定位就是DevOps\n走进Docker\n1、什么是Docker？\n\nDocker是基于Go的开源容器项目：可以将Docker容器理解为一种轻量级的虚拟机\n\n2、Docker有什么作用？\n\n\n解耦应用程序与运行平台，可以保证快速的分发与部署；\n\n实际中的应用比如：开发与运维交互，运维需要安装一系列前置环境（mysql、redis、kafka等等），并且对他们的版本也有要求，之前的安装配置方式费时费力；再比如需要对mysql服务集群进行快速的扩容和缩容；\n\n3、Docker与虚拟机的区别\n\n\n\n\n特性\nDocker容器\n虚拟机\n\n\n\n启动速度\n秒级\n分钟级\n\n\n内存使用\n很少\n较多\n\n\n迁移性\n优秀\n一般\n\n\n\n4、Docker容器与传统虚拟化技术的区别\n\nDocker技术是操作系统级别的虚拟化，虚拟机是硬件级别的虚拟化\n\n比方说Centos7是一个镜像文件，我们可以将其安装在VMWare上，这样就模拟了一个Linux操作系统；\n现在Docker会将一个项目：包括运行文档、配置环境、运行环境统统打包为一个镜像，直接跑在我们的OS上（Docker相当于VMWare，项目镜像相当于Centos镜像）\n\n实际上：Docker需要基本的Linux内核环境，所谓的操作系统级别的虚拟化，其实只是将APP所需要使用到的Linux内核支持拿了出来单独使用，这样做到的更小更快（Centos与Ubantu提出来的内核仅仅170M左右）。\n所以实际上Docker是需要Linux的内核支持的，因此如果我们使用Windows去跑Docker，其实Docker也是先模拟了一个mini的Linux环境，然后在此之上运行程序的\nDocker三大核心概念镜像Image可以理解为一个只读的模板（类似于Java的类模板）\n（一个镜像包含我们需要运行程序的必要环境）\n容器ContainerDocker利用容器来运行应用（类似于Java对象实例）\n\n容器是从镜像创建的应用运行实例\n容器之间相互隔离\n\n注意：镜像本身是只读的，容器从镜像启动的时候，会在镜像的最上层创建一个可写层\n仓库Repository类似于代码仓库（Github、码云），存放镜像的场所\n\n注册服务器是存放仓库的地方（比如一个注册服务器下，会有Ubantu的仓库、CentoOs的仓库等等）\n\nDocker的简易架构如图所示，Docker的运行由三个构成：\n\n\nClient：发起Docker命令\nDocker Host：docker安装的宿主机，运行着Docker这个后台进程（Docker是一个守护进程Daemon），宿主机内部有镜像（本地镜像）、容器\nRegister：远程仓库，对于宿主机没有的本地镜像需要从远程仓库下载\n\nDocker相关命令启动相关命令# 启动Dockersystemctl start docker# 重启systemctl restart docker# 关闭systemctl stop docker# 查看docker状态systemctl status docker# 开机启动Dockersystemctl enable docker\n\n镜像相关命令1、获取镜像我们可以去仓库下载镜像（类似于Git的操作）\ndocker pull name:[tag]# name 即要下载的应用名称，tag为标签# 如果不选择的话，默认是`lastest`，也就是最新版本的（所以我们一定要指定标签）# 严格来说，如果没有指定仓库，所以默认会从registry.hub.docker.com下载，即此命令相当于：docker pull registry.hub.docker.com/name:[tag]# 如果需要安装非官方仓库的镜像的话，那么需要加上仓库名\n\ndemo：这里使用该命令下载nginx作为一个示例：\n[root@slave1 ~]# docker pull nginx:1.20.11.20.1: Pulling from library/nginxb380bbd43752: Already exists 83acae5e2daa: Pull complete 33715b419f9b: Pull complete eb08b4d557d8: Pull complete 74d5bdecd955: Pull complete 0820d7f25141: Pull complete Digest: sha256:a98c2360dcfe44e9987ed09d59421bb654cb6c4abe50a92ec9c912f252461483Status: Downloaded newer image for nginx:1.20.1docker.io/library/nginx:1.20.1\n\n可以看到，镜像文件由很多层layer构成，前面的一串b380bbd43752表示这一层的唯一ID，当不同的镜像包括相同的层时，本地仅存储层的一份内容，减小了需要的存储空间。\n2、查看镜像查看镜像的命令有如下几个：\n\n查看下载的镜像\n\ndocker images# -a 显示所有镜像，包括临时镜像# --no-trunc 此参数可以完全显示镜像信息（默认情况下会截断显示内容）# -q 仅输出ID信息\n\ndemo：此处做示例\n[root@slave1 ~]# docker images --no-truncREPOSITORY   TAG       IMAGE ID                                                                  CREATED       SIZEmysql        5.7       sha256:938b57d64674c4a123bf8bed384e5e057be77db934303b3023d9be331398b761   4 weeks ago   448MBnginx        1.20.1    sha256:c8d03f6b8b915209c54fc8ead682f7a5709d11226f6b81185850199f18b277a2   5 weeks ago   133MB\n\n可见，Image Id是很长的串，只不过可以用前几位代替完整的ID\n\n给镜像添加自定义名称\n\n命令：\ndocker tag name:[tag] my-name# my-tag：表示自己可以自定义的名称\n\ndemo：下面是一个示例\n[root@slave1 ~]# docker imagesREPOSITORY   TAG       IMAGE ID       CREATED       SIZEmysql        5.7       938b57d64674   4 weeks ago   448MBnginx        1.20.1    c8d03f6b8b91   5 weeks ago   133MB[root@slave1 ~]# docker tag nginx:1.20.1 my-nginx[root@slave1 ~]# docker imagesREPOSITORY   TAG       IMAGE ID       CREATED       SIZEmysql        5.7       938b57d64674   4 weeks ago   448MBmy-nginx     latest    c8d03f6b8b91   5 weeks ago   133MBnginx        1.20.1    c8d03f6b8b91   5 weeks ago   133MB\n\n可以看到，my-nginx与nginx两个的ID值一样，说明两个指向同一个镜像，我们自定义的标签只是一个软连接而已\n\n查看镜像详细信息\n\ndocker inspect name:tag\n\n会返回一个json串，如果我们只想查看其中的部分数据可以加-f参数，例如这样（记着加.）\ndocker inspect my-nginx -f &#123;&#123;&quot;.Metadata&quot;&#125;&#125;\n\n3、搜索镜像docker search name# -f 可以指定额外的参数# -f stars=100 显示star数大于100的镜像# --limit 5 只显示5条信息\n\ndemo：显示所有stars大于100的并且可以自动装配的nginx镜像\n[root@slave1 ~]# docker search -f stars=100 nginxNAME                          DESCRIPTION                                     STARS     OFFICIAL   AUTOMATEDjwilder/nginx-proxy           Automated Nginx reverse proxy for docker con…   2094                 [OK]richarvey/nginx-php-fpm       Container running Nginx + PHP-FPM capable of…   818                  [OK]tiangolo/nginx-rtmp           Docker image with Nginx using the nginx-rtmp…   145                  [OK]jlesage/nginx-proxy-manager   Docker container for Nginx Proxy Manager        143                  [OK]alfg/nginx-rtmp               NGINX, nginx-rtmp-module and FFmpeg from sou…   110                  [OK]\n\n4、删除镜像docker rmi tag|id# -f 强制删除，即使当前镜像已经启动了一些容器\n\n注意：\n\n如果参数指定为一个tag，那么此命令只会删除该镜像的一个标签而已（如果这个镜像只有一个标签，那么会被立即删除）\n\n参数指定为image id的话，会先删除该镜像的所有标签，然后删除该镜像本身\n\n\n示例：\n[root@slave1 ~]# docker imagesREPOSITORY   TAG       IMAGE ID       CREATED       SIZEmysql        5.7       938b57d64674   4 weeks ago   448MBmy-nginx     latest    c8d03f6b8b91   5 weeks ago   133MBnginx        1.20.1    c8d03f6b8b91   5 weeks ago   133MB[root@slave1 ~]# docker rmi my-nginxUntagged: my-nginx:latest[root@slave1 ~]# docker imagesREPOSITORY   TAG       IMAGE ID       CREATED       SIZEmysql        5.7       938b57d64674   4 weeks ago   448MBnginx        1.20.1    c8d03f6b8b91   5 weeks ago   133MB[root@slave1 ~]# docker rmi nginx:1.20.1Untagged: nginx:1.20.1Untagged: nginx@sha256:a98c2360dcfe44e9987ed09d59421bb654cb6c4abe50a92ec9c912f252461483Deleted: sha256:67a7407724b6c71e2355fc2236b5be27d1f03bf9cbdffdfbb97c1d2a326ccf94...// 真正删除了所有的镜像[root@slave1 ~]# docker imagesREPOSITORY   TAG       IMAGE ID       CREATED       SIZEmysql        5.7       938b57d64674   4 weeks ago   448MB\n\n5、查看镜像的占用空间docker system df\n\n输出docker目前占用的大小内容：\nhynis@hynisVM:~$ docker system dfTYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLEImages          14        1         2.612GB   2.612GB (99%)Containers      2         0         0B        0BLocal Volumes   3         0         9.208kB   9.208kB (100%)Build Cache     0         0         0B        0B\n\n容器相关命令1、创建与运行容器\n创建容器（基于一个镜像，创建一个容器）\n\ndocker create [参数] name:tag# 会返回一个容器的ID Container ID\n\n\n启动容器\n\ndocker start id\n\n\n【推荐】创建并启动容器（建议直接使用run命令，等同于上述创建并启动容器）\n\ndocker run [options] image# 其中`options`可选的参数很多，下面介绍几个常用的：--name # 指定此容器的名字-i # 让容器的标准输入保持打开（交互式模式运行容器），通常与-t一起使用-t # 分配一个伪终端并绑定到容器的标准输出上-d # 后台运行（守护态运行）-P # 容器内随机映射一个端口-p # 指定端口映射，比如 -p 3306:3306 就指定主机的3306端口与容器的3306端口进行映射，此时访问主机的3306端口，相当于访问容器的3306端口\n\ndemo：启动一个交互式的Ubuntu系统：\nhynis@hynisVM:~$ docker run -it ubuntu /bin/bash# 此处命令的意思是 run -it + 一个OS + shell# 此处的61a30a155427就是容器号，想要退出使用命令exitroot@61a30a155427:/# exitexit\n\n想要退出当前容器，可以输入exit也可以直接按ctrl + p + q（注意：此按键并不会关闭容器）\n\nPS：补充run命令的执行顺序\n\n当利用docker run来创建并启动容器时，Docker在后台运行的标准操作包括：\n\n检查本地是否存在指定的镜像，不存在就从公有仓库下载；\n利用镜像创建一个容器，并启动该容器；\n分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层；\n从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中；\n从网桥的地址池配置一个IP地址给容器；\n执行用户指定的应用程序；\n执行完毕后容器被自动终止。\n\n2、查看容器\n查看所有的容器\n\ndocker ps -l# -a 可以显示所有的容器，包括没有在运行的容器# -l 显示最近创建的容器# -n 显示最近n个创建的容器# -q 静默模式，只显示容器编号\n\n\n查看容器的日志\n\ndocker logs [id]\n\n3、进入容器进入存活的容器有两个命令：\n# 进入正在进行的容器docker attach [id]docker exec -it [id] /bin/bash\n\n两个有一些区别：\n\nattach直接进入容器启动命令的终端，不会启动新的进程，用exit会直接退出\nexec是在容器中打开新的终端，用exit不会退出【推荐】\n\n4、终止、重启与删除容器\n终止容器\n\n首先向容器发送SIGTERM信号，等待一段超时时间（默认为10秒）后，再发送SIGKILL信号来终止容器\ndocker stop id# -t 可以指定终止的时间# 对于已经终止的容器 可以使用start命令docker start id\n\n\n如果想要重启一个容器\n\ndocker restart id\n\n\n强制终止一个容器\n\n会直接发送SIGKILL信号\ndocker kill id\n\n\n删除容器\n\n只能删除非运行态的容器，除非加参数-f\ndocker rm id# -f 强制删除\n\n拷贝、导入与导出1、从容器拷贝文件到主机\ndocker cp 容器ID:容器内路径 目的主机路径# 在宿主机上敲此命令# hynis@hynisVM:~$ docker cp d0367f6fb6c4:/a.txt ./\n\n2、如果想要所有的数据，那么可以使用导出命令：导出容器的内容作为一个tar归档\ndocker export [id] &gt; xxx.tar# 将id为d0367f6fb6c4的容器的数据导出到当前目录下，并且打包为ubuntu1.tardocker export d0367f6fb6c4 &gt; ubuntu1.tar\n\n3、导入一个tar归档文件\ncat 归档.tar | docker import - 镜像用户/镜像:版本号# 注意命令里有一个-# 镜像用户就是包名\n\n比如下面这个例子：我们使用第二步导出的数据恢复一个容器\nhynis@hynisVM:~$ cat ubuntu1.tar | docker import hynis/ubuntu:latestopen hynis/ubuntu:latest: no such file or directoryhynis@hynisVM:~$ cat ubuntu1.tar | docker import - hynis/ubuntu:latestsha256:95fad8b97bceb4cdb159d62694fe7f4f906729e61bc8528f00a9495b2287061ahynis@hynisVM:~$ docker imagesREPOSITORY                   TAG       IMAGE ID       CREATED         SIZEhynis/ubuntu                 latest    95fad8b97bce   3 seconds ago   77.8MB\n\n镜像的深入理解镜像包括不同的层次，当不同的镜像包括相同的层时，本地仅存储层的一份内容，减小了需要的存储空间。其本质需要了解一下联合文件系统\n联合文件系统Unionfs 是2004年在stony brook大学开始的，它是一个可叠放的联合文件系统，它能够联合多个目录（因此可称为分支）同时独立地保持它们的物理内容。\n所谓联合的意思是：联合在不同磁盘上的不同的文件系统到一个目录，或者把几张cd合并成一个统一的归档镜像。\n允许任何ro（只读）和rw（可读可写）分支的 结合，同时允许在分支中修改和删除不使用的分支，（即具有复制可写功能的unionfs可以用来把ro和rw的文件系统合并起来），并且可以允许修改只读文件系统并把这些修改保存在可写文件系统。\nDocker镜像的加载原理比如Docker上安装Ubuntu和CentOS，这是两种发行版，（如果我们使用VMWare安装，我们就需要这两者的镜像）他们都是Linux的操作系统，其实Linux操作系统由两部分构成：\n\nBootFS：Boot与Loader部分，Boot在主板的bios内，当电脑启动后，bios载入Boot程序，Boot载入Loader程序，loader程序将Linux内核载入到内存中，操作系统启动完毕。\nRootFS：rootfs则包含了一般系统上的常见目录结构，类似于/dev, /proc, /bin等等以及一些基本的文件和命令。发行版的区别在于此，即Ubuntu和Centos的区别在于此；\n\n\nDocker的镜像加载原理就是基于UnionFS，复用同一套内核（即使用宿主机的bootfs），对不同的发行版再去下载不同的rootfs，这样不仅节省内存空间，还加快了速度。\n注意：镜像层都是只读的，只有容器层是可写的\nDocker的容器启动时，一个新的可写层会被加载到镜像的顶部，如下图所示。\n\nCommit命令docker commit可以提交容器副本使之成为一个新的镜像\ndocker commit -m=&#x27;提交的描述信息&#x27; -a=&#x27;作者&#x27; 容器ID 新的镜像名:[标签名]\n\n比如我们现在给基础的Ubuntu系统加一个Vim程序，然后使用Commit命令后，这个新的镜像一运行就可以直接使用vim命令\n\n本地镜像推入私有库\n如果不想让敏感数据存入阿里云或是Dockerhub，公司可以搭建自己的私有库Docker Registry\n1、Docker拉取Docker Registry\ndocker pull registry\n\n2、启动：此处用到了容器数据卷\ndocker run -d -p 5000:5000  -v /zzyyuse/myregistry/:/tmp/registry --privileged=true registry# -d 后台运行# -p 5000:5000 将本地的5000端口映射到5000端口# -v 容器数据卷# --privileged=true 特权模式开启：如果不开启特权模式可能会出现权限问题\n\nDocker挂载主机目录访问如果出现cannot open directory .: Permission denied，记住加参数--privileged=true\n3、可以查看以下本地的私有Docker库是否含有数据\nhynis@hynisVM:~$ curl -XGET http://192.168.235.151:5000/v2/_catalog&#123;&quot;repositories&quot;:[]&#125;\n\n4、开启http传输\n# 修改daemon.json文件sudo vim /etc/docker/daemon.json# 加入以下内容，Docker的镜像配置也在这里，此处没有配置&#123;  &quot;insecure-registries&quot;: [&quot;192.168.235.151:5000&quot;]&#125;\n\n注意：更改完成后，需要重启一下Docker，并重新跑一下Registry\n5、将我们想要的一个镜像传输到本地私有库\n# 更改一下tagdocker tag hynitu:1.0 192.168.235.151:5000/hynitu:1.0# pushdocker push 192.168.235.151:5000/hynitu:1.0\n\nhynis@hynisVM:~$ docker push 192.168.235.151:5000/hynitu:1.0The push refers to repository [192.168.235.151:5000/hynitu]e3b19c432d29: Pushed b93c1bd012ab: Pushed 1.0: digest: sha256:29f871c91b95fa69e13ebcc0013046ffbf32a7fc89ae2dee4e655f3ffa6281d9 size: 741hynis@hynisVM:~$ curl -XGET http://192.168.235.151:5000/v2/_catalog&#123;&quot;repositories&quot;:[&quot;hynitu&quot;]&#125;\n\n6、拉取到本地运行\ndocker pull 192.168.235.151:5000/hynitu:1.0\n\nhynis@hynisVM:~$ docker pull 192.168.235.151:5000/hynitu:1.01.0: Pulling from hynituDigest: sha256:29f871c91b95fa69e13ebcc0013046ffbf32a7fc89ae2dee4e655f3ffa6281d9Status: Image is up to date for 192.168.235.151:5000/hynitu:1.0192.168.235.151:5000/hynitu:1.0\n\n容器数据卷数据卷在上一章我们使用Registry，将本地的镜像上传到了本地的私有仓库，使用到了如下命令\ndocker run -d -p 5000:5000 -v /zzyyuse/myregistry/:/tmp/registry --privileged=true registry\n\n此处-v参数就添加了容器数据卷，这条命令的意思是，将宿主机的目录的/zzyyuse/myregistry/映射到容器内的/tmp/registry，两个目录资源共享\n\n数据卷：就是文件或目录，脱离于Docker容器的生命周期之外的，因此Docker不会在容器删除时删除其挂载的数据卷\n\n数据卷本来的作用就是做数据备份或是资源共享的\n\n数据备份：将容器数据备份到本地目录，防止Docker容器挂掉数据丢失\n资源共享：数据卷可以在容器之间共享或重用数据\n\n注意：对于数据卷的修改不会包含在镜像的更新中\n相关命令1、添加数据卷\ndocker run -it --privileged=true -v 宿主机目录:容器内目录[:权限] ubuntu# 权限部分可以不写，默认即为rw即可读可写# 权限部分有: rw 与 ro# 如果为 ro 则容器不能对此目录进行修改，而宿主机可以\n\n2、查看是否设置数据卷成功\ndocker inspect 容器ID# 可以查看到Mount下有        &quot;Mounts&quot;: [            &#123;                &quot;Type&quot;: &quot;bind&quot;,                &quot;Source&quot;: &quot;/tmp/temphynisdata&quot;,                &quot;Destination&quot;: &quot;/tmp/tempdockerdata&quot;,                &quot;Mode&quot;: &quot;&quot;,                &quot;RW&quot;: true,                &quot;Propagation&quot;: &quot;rprivate&quot;            &#125;        ],\n\n3、此时目录/tmp/temphynisdata与/tmp/tempdockerdata关联，双向绑定\n\n提问：如果此时将容器关掉，将数据卷位置的数据进行修改，再将容器重启动，那么容器内的数据卷会发生变化吗？\n\n答案是会的，所以可以理解到，宿主机和容器的数据卷并不是双向同步，而是共享同一片地址\n4、容器卷可以进行继承，假设现在我们需要另外一个容器，和之前的容器的规则相同，那么可以进行继承\n#额外的参数，这样新建的容器就会继承父容器的卷规则--volumes-from 父容器\n\nDocker实战Docker实现Mysql主从同步1、Docker安装mysql5.7版本\ndocker pull mysql:5.7\n\n2、先建立主mysql，需要run一主一从\n# 主docker run -p 3307:3306 --name mysql-master -v /mydata/mysql-master/log:/var/log/mysql -v /mydata/mysql-master/data:/var/lib/mysql -v /mydata/mysql-master/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7# -p 主3307 从3308# -d 后台运行# --name 命名# -v 配置数据卷\n\n需要在/mydata/mysql-master/conf下创建一个配置文件my.cnf内容为以下：\n[mysqld]## 设置server_id，同一局域网中需要唯一server_id=101## 指定不需要同步的数据库名称binlog-ignore-db=mysql## 开启二进制日志功能log-bin=mall-mysql-bin## 设置二进制日志使用内存大小（事务）binlog_cache_size=1M## 设置使用的二进制日志格式（mixed,statement,row）binlog_format=mixed## 二进制日志过期清理时间。默认值为0，表示不自动清理。expire_logs_days=7## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致slave_skip_errors=1062\n\n配置完成后重启mysql服务，还需要配置数据同步用户\n# 重启mysql-masterdocker restart mysql-master# 进入master容器docker exec -it mysql-master /bin/bash# 在bash键入mysql -uroot -proot# 创建数据同步用户CREATE USER &#x27;slave&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27;;# 授予REPLICATION权限GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#x27;slave&#x27;@&#x27;%&#x27;;\n\n3、建立从mysql\n# 从docker run -p 3308:3306 --name mysql-slave -v /mydata/mysql-slave/log:/var/log/mysql -v /mydata/mysql-slave/data:/var/lib/mysql -v /mydata/mysql-slave/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7\n\n需要在/mydata/mysql-slave/conf下创建一个配置文件my.cnf内容为以下：\n[mysqld]## 设置server_id，同一局域网中需要唯一server_id=102## 指定不需要同步的数据库名称binlog-ignore-db=mysql## 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用log-bin=mall-mysql-slave1-bin## 设置二进制日志使用内存大小（事务）binlog_cache_size=1M## 设置使用的二进制日志格式（mixed,statement,row）binlog_format=mixed## 二进制日志过期清理时间。默认值为0，表示不自动清理。expire_logs_days=7## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致slave_skip_errors=1062## relay_log配置中继日志relay_log=mall-mysql-relay-bin## log_slave_updates表示slave将复制事件写进自己的二进制日志log_slave_updates=1## slave设置为只读（具有super权限的用户除外）read_only=1\n\n配置完成后同样重启容器\ndocker restart mysql-slave\n\n4、注意下面的操作需要区分主从了，不要键入错误\n主mysql先看一下状态show master status;\n主mysql&gt; show master status;# 主要看一下bin从哪里开始，这里是000004+-----------------------+----------+--------------+------------------+-------------------+| File                  | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-----------------------+----------+--------------+------------------+-------------------+| mall-mysql-bin.000004 |      617 |              | mysql            |                   |+-----------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec)\n\n在从mysql中配置主从复制\n# 命令根据自己的配置进行更改change master to master_host=&#x27;宿主机ip&#x27;, master_user=&#x27;slave&#x27;, master_password=&#x27;123456&#x27;, master_port=3307, master_log_file=&#x27;mall-mysql-bin.000001&#x27;, master_log_pos=617, master_connect_retry=30;\n\n从mysql&gt; change master to master_host=&#x27;192.168.235.151&#x27;, master_user=&#x27;slave&#x27;, master_password=&#x27;123456&#x27;, master_port=3307, master_log_file=&#x27;mall-mysql-bin.000004&#x27;, master_log_pos=617, master_connect_retry=30;Query OK, 0 rows affected, 2 warnings (0.01 sec)\n\n顺便查看以下从机的主从复制配置show slave status \\G;\nmysql&gt; show slave status \\G; # \\G 让结果以列展示*************************** 1. row ***************************               Slave_IO_State:                   Master_Host: 192.168.235.151                  Master_User: slave                  Master_Port: 3307                Connect_Retry: 30              Master_Log_File: mall-mysql-bin.000004          Read_Master_Log_Pos: 617               Relay_Log_File: mall-mysql-relay-bin.000001                Relay_Log_Pos: 4        Relay_Master_Log_File: mall-mysql-bin.000004             Slave_IO_Running: No # 主要看此处，主从复制还没开始            Slave_SQL_Running: No # 主要看此处，主从复制还没开始\n\n从mysql启动主从同步start slave\nmysql&gt; start slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; show slave status \\G;*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.235.151                  Master_User: slave                  Master_Port: 3307                Connect_Retry: 30              Master_Log_File: mall-mysql-bin.000004          Read_Master_Log_Pos: 1235               Relay_Log_File: mall-mysql-relay-bin.000003                Relay_Log_Pos: 325        Relay_Master_Log_File: mall-mysql-bin.000004             Slave_IO_Running: Yes # 此处已连接            Slave_SQL_Running: Yes # 此处已连接\n\n然后我们可以在主Mysql新建一个表，建一些数据测试一下，从数据库会得到同步\n\n排错提示：我在第一次尝试的过程中，遇到的问题是Slave_IO_Running: Connecting，再确认其他配置正确的情况下，反复尝试，都是错误，关闭防火墙后重试，变为Yes\n# 查看防火墙状态sudo ufw status# 关闭防火墙sudo ufw disable\n\n之后在从节点处输入命令，重启一下slave\nstop slave;start slave;\n\n运行后查到双Yes\n\n如何存储1~2亿的缓存数据？\n现在我们有1~2亿条数据需要缓存，请问如何设计？\n\n如此大量的数据我们单击Redis肯定完成不了，需要进行分布式存储\n哈希取余分区最简单的实现，就是模以N，来对用户的读写操作实现负载均衡\n\n优点：简单易实现，流量会均匀打到各个节点上\n缺点：当集群某一台挂掉，会导致一定的混乱。\n比如说现在有三台机器，之前的读写操作都%3，分别打到0、1、2三台机器上，但是现在出现了一点问题，第三台机器挂了，那么此时读写操作%2，此时的流量会分别打到0、1上。\n即使是没有机器宕机，Redis集群的扩容缩容也会存在，每次更改都会导致映射关系进行重新计算\n一致性哈希算法1997年，麻省理工提出的一致性哈希算法。\n\n一致性哈希算法：为了当服务器个数发生变化的时候，尽量减少影响客户端到服务器的映射关系。\n\n算法思想由三步骤组成：\n\n构造一个环，从0~2^32-1（哈希取余是根据服务器台数，此处是int的范围）\n对于不同的Redis服务器，对IP进行取余，分别落在这个环上的不同点\n当流量打入到环上后，会按顺时针的方向，落在第一个遇到的服务器上。\n\n\n如图所示，环由0~2^32-1个点构成，有三台Redis服务器，按照hash(IP)后，分布在环上的各个节点上。此时用户流量打入：User1的操作会按顺时针分别流入Redis1、Redis3，User2的操作会打入Redis2，User3的操作会打入Redis3。\n\n【可容错】假如此时Redis2宕机会发生什么？\n\nUser2的流量会打入Redis3，所以整个环路中，出现某个结点挂机，只会影响两个节点（宕机的节点和宕机节点的下一个节点）的流量分布。\n\n【可扩展】假如Redis2又恢复了，又会发生什么？\n\n只需要将Redis1到Redis2之间的数据转移到Redis2即可，其他部分不受影响。\n\n【可能出现数据倾斜】当节点较少的时候，或者数据hash高度一致的时候会有什么影响？\n\n假如我们的节点很少（可以假设Redis2宕机，我们此时只有两个节点）那么可以看到Redis1到Redis3的距离，与Redis3到Redis1的距离差距很多，这样会导致大部分的数据打入到Redis3，Redis3可能会高度负载，而Redis2却没有负载。\n所以总结一下：一致性哈希算法适合使用在Redis数量很多，流量也很多的情况下。\n哈希槽分区目前的绝对主流的使用方法。\n\n哈希槽：本质是一个大小为2^14-1(即16384个)的数组\n在数据和服务器节点之间又加入了一层，把这层称为哈希槽（slot），用于处理数据和节点之间的关系。\n\n\n如图所示，将哈希槽分为了4段，用不同的颜色表示。当流量打入时，会进行这样的运算：slot = CRC16(key) % 16384，先对数据求循环冗余码CRC，然后对循环冗余码模以16384，这样数据就会打入不同的Redis上。\n如果某个节点出现了宕机，那么宕机节点应该承受的流量会由其他正常节点共同承担。（一致性哈希算法就出现了数据倾斜，哈希槽避免了这个问题）\n\n为什么是16384个，也就是2^14-1个槽位？\n\n如果槽位是65535个，那么Redis的心跳信息的消息头将会有8k，较为庞大。而且Redis集群中的主节点数不可能超过1000个，因此16384个完全够用了。\nDocker实现Redis三主三从Reids集群搭建1、下载Redis镜像\ndocker pull redis:6.0.8\n\n2、启动6个Redis容器，搭建一个三主三从的架构\ndocker run -d --name redis-node-1 --net host --privileged=true -v /data/redis/share/redis-node-1:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6381docker run -d --name redis-node-2 --net host --privileged=true -v /data/redis/share/redis-node-2:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6382docker run -d --name redis-node-3 --net host --privileged=true -v /data/redis/share/redis-node-3:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6383docker run -d --name redis-node-4 --net host --privileged=true -v /data/redis/share/redis-node-4:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6384docker run -d --name redis-node-5 --net host --privileged=true -v /data/redis/share/redis-node-5:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6385docker run -d --name redis-node-6 --net host --privileged=true -v /data/redis/share/redis-node-6:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6386# --net host 使用宿主的IP和端口# --cluster-enabled yes 开启Redis集群# --appendonly yes 开启持久化\n\n3、配置主从结构\n任意进入一个Redis容器\n# 进入节点1docker exec -it redis-node-1 /bin/bash# 配置一主一从redis-cli --cluster create 192.168.235.151:6381 192.168.235.151:6382 192.168.235.151:6383 192.168.235.151:6384 192.168.235.151:6385 192.168.235.151:6386 --cluster-replicas 1# --cluster-replicas 1 表示为每个master创建一个slave节点\n\nRedis会自动进行分配，比如我的运行结果就是：\n&gt;&gt;&gt; Performing hash slots allocation on 6 nodes... # 正在为6个节点分配哈希槽，分配情况如下面三行Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.235.151:6385 to 192.168.235.151:6381Adding replica 192.168.235.151:6386 to 192.168.235.151:6382Adding replica 192.168.235.151:6384 to 192.168.235.151:6383&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: 910039156a5be3bd6798de420c6cb3771cccedd9 192.168.235.151:6381   slots:[0-5460] (5461 slots) masterM: 68ddc85b453fc7f28933740f62a1b5721d1c606e 192.168.235.151:6382   slots:[5461-10922] (5462 slots) masterM: 337571ef1e1d861189bcd3c72fb6f33b8cba64e0 192.168.235.151:6383   slots:[10923-16383] (5461 slots) masterS: 2fb166b3d74833b37bc792fcb0810feac86c244e 192.168.235.151:6384   replicates 337571ef1e1d861189bcd3c72fb6f33b8cba64e0S: d57408e2bc1f968dae58cc155edcf0a326970bde 192.168.235.151:6385   replicates 910039156a5be3bd6798de420c6cb3771cccedd9S: 7278e520806f2f3b3c6fa25685a1d9c1e60a0e70 192.168.235.151:6386   replicates 68ddc85b453fc7f28933740f62a1b5721d1c606eCan I set the above configuration? (type &#x27;yes&#x27; to accept): yes\n\n可以看到，系统自己将6381、6382、6383三台机器作为Master，6385、6386、6384依次作为前者的Slave\n4、进入Redis内部，查看集群信息\n# 查看集群信息root@hynisVM:/data# redis-cli -p 6381127.0.0.1:6381&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:278cluster_stats_messages_pong_sent:305cluster_stats_messages_sent:583cluster_stats_messages_ping_received:300cluster_stats_messages_pong_received:278cluster_stats_messages_meet_received:5cluster_stats_messages_received:583\n\n# 查看节点信息127.0.0.1:6381&gt; cluster nodes7278e520806f2f3b3c6fa25685a1d9c1e60a0e70 192.168.235.151:6386@16386 slave 68ddc85b453fc7f28933740f62a1b5721d1c606e 0 1681213675552 2 connected2fb166b3d74833b37bc792fcb0810feac86c244e 192.168.235.151:6384@16384 slave 337571ef1e1d861189bcd3c72fb6f33b8cba64e0 0 1681213675000 3 connected68ddc85b453fc7f28933740f62a1b5721d1c606e 192.168.235.151:6382@16382 master - 0 1681213676000 2 connected 5461-10922337571ef1e1d861189bcd3c72fb6f33b8cba64e0 192.168.235.151:6383@16383 master - 0 1681213677574 3 connected 10923-16383910039156a5be3bd6798de420c6cb3771cccedd9 192.168.235.151:6381@16381 myself,master - 0 1681213674000 1 connected 0-5460d57408e2bc1f968dae58cc155edcf0a326970bde 192.168.235.151:6385@16385 slave 910039156a5be3bd6798de420c6cb3771cccedd9 0 1681213677000 1 connected\n\n根据以上信息，我们可以构建下图：\n\nRedis集群的使用如果我们进入随便一个主Redis，比如进入6381\nroot@hynisVM:/data# redis-cli -p 6381127.0.0.1:6381&gt; set k1 v1 # 存一个k1:v1的数据(error) MOVED 12706 192.168.235.151:6383\n\n报错了，这是因为key值k1经过运算后的hash值为12706，这不属于6381的范畴，所以报错，提示你应该在6383存入，可以使用参数-c来重定向\nroot@hynisVM:/data# redis-cli -p 6381 -c127.0.0.1:6381&gt; set k1 v1-&gt; Redirected to slot [12706] located at 192.168.235.151:6383OK192.168.235.151:6383&gt; # 可以看到我们被自动切换到了6383\n\n可以看到此时将12706重定向到6383上\n此外，可以使用以下命令查看集群状态\nredis-cli --cluster check 192.168.235.151:6381# 出现以下信息root@hynisVM:/data# redis-cli --cluster check 192.168.235.151:6381192.168.235.151:6381 (91003915...) -&gt; 1 keys | 5461 slots | 1 slaves.192.168.235.151:6382 (68ddc85b...) -&gt; 0 keys | 5462 slots | 1 slaves.192.168.235.151:6383 (337571ef...) -&gt; 1 keys | 5461 slots | 1 slaves.[OK] 2 keys in 3 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.235.151:6381)M: 910039156a5be3bd6798de420c6cb3771cccedd9 192.168.235.151:6381   slots:[0-5460] (5461 slots) master   1 additional replica(s)S: 7278e520806f2f3b3c6fa25685a1d9c1e60a0e70 192.168.235.151:6386   slots: (0 slots) slave   replicates 68ddc85b453fc7f28933740f62a1b5721d1c606eS: 2fb166b3d74833b37bc792fcb0810feac86c244e 192.168.235.151:6384   slots: (0 slots) slave   replicates 337571ef1e1d861189bcd3c72fb6f33b8cba64e0M: 68ddc85b453fc7f28933740f62a1b5721d1c606e 192.168.235.151:6382   slots:[5461-10922] (5462 slots) master   1 additional replica(s)M: 337571ef1e1d861189bcd3c72fb6f33b8cba64e0 192.168.235.151:6383   slots:[10923-16383] (5461 slots) master   1 additional replica(s)S: d57408e2bc1f968dae58cc155edcf0a326970bde 192.168.235.151:6385   slots: (0 slots) slave   replicates 910039156a5be3bd6798de420c6cb3771cccedd9[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.\n\nRedis容灾主从切换假如此时我们将6381号停掉，那么他的slave应该会自动切换为master\n# 关闭1号容器docker stop redis-node-1# 进入6382docker exec -it redis-node-2 /bin/bash\n\nroot@hynisVM:/data# redis-cli --cluster check 192.168.235.151:6382Could not connect to Redis at 192.168.235.151:6381: Connection refused192.168.235.151:6382 (68ddc85b...) -&gt; 0 keys | 5462 slots | 1 slaves.192.168.235.151:6383 (337571ef...) -&gt; 1 keys | 5461 slots | 1 slaves.192.168.235.151:6385 (d57408e2...) -&gt; 1 keys | 5461 slots | 0 slaves.[OK] 2 keys in 3 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.235.151:6382)M: 68ddc85b453fc7f28933740f62a1b5721d1c606e 192.168.235.151:6382   slots:[5461-10922] (5462 slots) master   1 additional replica(s)S: 2fb166b3d74833b37bc792fcb0810feac86c244e 192.168.235.151:6384   slots: (0 slots) slave   replicates 337571ef1e1d861189bcd3c72fb6f33b8cba64e0S: 7278e520806f2f3b3c6fa25685a1d9c1e60a0e70 192.168.235.151:6386   slots: (0 slots) slave   replicates 68ddc85b453fc7f28933740f62a1b5721d1c606eM: 337571ef1e1d861189bcd3c72fb6f33b8cba64e0 192.168.235.151:6383   slots:[10923-16383] (5461 slots) master   1 additional replica(s# 关键看这里，6385,变为了masterM: d57408e2bc1f968dae58cc155edcf0a326970bde 192.168.235.151:6385   slots:[0-5460] (5461 slots) master [OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.\n\n即使我们现在将容器1恢复，也不会发生主从切换。\n（为了之后叙述方便，我们将容器5再次stop、start，将Master换回容器1）\nRedis主从扩容现在我们给系统中再加入一个Master-Slave，使之变成4主4从\n1、 首先创建新的两个容器\ndocker run -d --name redis-node-7 --net host --privileged=true -v /data/redis/share/redis-node-7:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6387docker run -d --name redis-node-8 --net host --privileged=true -v /data/redis/share/redis-node-8:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6388\n\n2、进入6387容器节点内部\ndocker exec -it redis-node-7 /bin/bash\n\n3、加入集群\nredis-cli --cluster add-node 192.168.235.151:6387 192.168.235.151:6381# 6387 就是将要作为master新增节点# 6381 就是原来集群节点里面的领路人，相当于6387想进入组织需要一个介绍人\n\n4、此时我们查看集群的情况：发现6387没有任何的插槽！\noot@hynisVM:/data# redis-cli --cluster check 192.168.235.151:6382192.168.235.151:6382 (68ddc85b...) -&gt; 0 keys | 5462 slots | 1 slaves.# 主要看这里！！发现6387没有任何的插槽！192.168.235.151:6387 (3e431906...) -&gt; 0 keys | 0 slots | 0 slaves.192.168.235.151:6383 (337571ef...) -&gt; 1 keys | 5461 slots | 1 slaves.192.168.235.151:6381 (91003915...) -&gt; 1 keys | 5461 slots | 1 slaves.[OK] 2 keys in 4 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.235.151:6382)M: 68ddc85b453fc7f28933740f62a1b5721d1c606e 192.168.235.151:6382   slots:[5461-10922] (5462 slots) master   1 additional replica(s)S: 2fb166b3d74833b37bc792fcb0810feac86c244e 192.168.235.151:6384   slots: (0 slots) slave   replicates 337571ef1e1d861189bcd3c72fb6f33b8cba64e0M: 3e4319061f2943b3335406dbe369cc7e5cc1d9a5 192.168.235.151:6387   slots: (0 slots) masterS: 7278e520806f2f3b3c6fa25685a1d9c1e60a0e70 192.168.235.151:6386   slots: (0 slots) slave   replicates 68ddc85b453fc7f28933740f62a1b5721d1c606eM: 337571ef1e1d861189bcd3c72fb6f33b8cba64e0 192.168.235.151:6383   slots:[10923-16383] (5461 slots) master   1 additional replica(s)S: d57408e2bc1f968dae58cc155edcf0a326970bde 192.168.235.151:6385   slots: (0 slots) slave   replicates 910039156a5be3bd6798de420c6cb3771cccedd9M: 910039156a5be3bd6798de420c6cb3771cccedd9 192.168.235.151:6381   slots:[0-5460] (5461 slots) master   1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.\n\n5、重新分配hash槽位\nredis-cli --cluster reshard 192.168.235.151:6381\n\n\n因为现在新加入了一台Master，所以16384/4=4096，我们输入4096个。并将插槽分配给6387\n6、再次查看\nroot@hynisVM:/data# redis-cli --cluster check 192.168.235.151:6382192.168.235.151:6382 (68ddc85b...) -&gt; 0 keys | 4096 slots | 1 slaves.192.168.235.151:6387 (3e431906...) -&gt; 1 keys | 4096 slots | 0 slaves.192.168.235.151:6383 (337571ef...) -&gt; 1 keys | 4096 slots | 1 slaves.192.168.235.151:6381 (91003915...) -&gt; 0 keys | 4096 slots | 1 slaves.[OK] 2 keys in 4 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.235.151:6382)M: 68ddc85b453fc7f28933740f62a1b5721d1c606e 192.168.235.151:6382   slots:[6827-10922] (4096 slots) master   1 additional replica(s)S: 2fb166b3d74833b37bc792fcb0810feac86c244e 192.168.235.151:6384   slots: (0 slots) slave   replicates 337571ef1e1d861189bcd3c72fb6f33b8cba64e0# 主要看这里！！！可以看到6387的槽位不是均匀的M: 3e4319061f2943b3335406dbe369cc7e5cc1d9a5 192.168.235.151:6387   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) masterS: 7278e520806f2f3b3c6fa25685a1d9c1e60a0e70 192.168.235.151:6386   slots: (0 slots) slave   replicates 68ddc85b453fc7f28933740f62a1b5721d1c606eM: 337571ef1e1d861189bcd3c72fb6f33b8cba64e0 192.168.235.151:6383   slots:[12288-16383] (4096 slots) master   1 additional replica(s)S: d57408e2bc1f968dae58cc155edcf0a326970bde 192.168.235.151:6385   slots: (0 slots) slave   replicates 910039156a5be3bd6798de420c6cb3771cccedd9M: 910039156a5be3bd6798de420c6cb3771cccedd9 192.168.235.151:6381   slots:[1365-5460] (4096 slots) master   1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.\n\n6387的槽位是slots:[0-1364],[5461-6826],[10923-12287] ，说明rehash的规则是从每一个Master的插槽，分出一部分给6387，使之凑成4096个！\n7、为6387配置slave\nredis-cli --cluster add-node 192.168.235.151:6388 192.168.235.151:6387 --cluster-slave --cluster-master-id 3e4319061f2943b3335406dbe369cc7e5cc1d9a5# redis-cli --cluster add-node ip:新slave端口 ip:新master端口 --cluster-slave --cluster-master-id 新主机节点ID(此处即为6387的id)\n\n此时我们就实现了4主4从的redis分布式集群，如下图所示：\n\n可以与之前的图对比查看\nRedis主从缩容主从缩容与扩容同理，只不过在重新分配槽位的时候，如果想要槽位原路返回，那么需要分配三次，此处为了省事直接将6387的所有槽位分配给6381。\n注意：缩容一定要先将slave删掉！\n1、将slave节点删除\n# 命令redis-cli --cluster del-node 192.168.235.151:6388 2a7586688a28e8227d23f21c2c8c9575f00d5bfe# 输出结果如下root@hynisVM:/data# redis-cli --cluster del-node 192.168.235.151:6388 2a7586688a28e8227d23f21c2c8c9575f00d5bfe&gt;&gt;&gt; Removing node 2a7586688a28e8227d23f21c2c8c9575f00d5bfe from cluster 192.168.235.151:6388&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; Sending CLUSTER RESET SOFT to the deleted node.\n\n2、将Master的所有槽位分配给其他Master\nredis-cli --cluster reshard 192.168.235.151:6381\n\n\n将6387的所有槽位分配给6381\n3、删除节点6381\nredis-cli --cluster del-node 192.168.235.151:6387 3e4319061f2943b3335406dbe369cc7e5cc1d9a5\n\n4、查看集群状态\nroot@hynisVM:/data# redis-cli --cluster check 192.168.235.151:6382192.168.235.151:6382 (68ddc85b...) -&gt; 0 keys | 4096 slots | 1 slaves.192.168.235.151:6383 (337571ef...) -&gt; 1 keys | 4096 slots | 1 slaves.192.168.235.151:6381 (91003915...) -&gt; 1 keys | 8192 slots | 1 slaves.[OK] 2 keys in 3 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.235.151:6382)M: 68ddc85b453fc7f28933740f62a1b5721d1c606e 192.168.235.151:6382   slots:[6827-10922] (4096 slots) master   1 additional replica(s)S: 2fb166b3d74833b37bc792fcb0810feac86c244e 192.168.235.151:6384   slots: (0 slots) slave   replicates 337571ef1e1d861189bcd3c72fb6f33b8cba64e0S: 7278e520806f2f3b3c6fa25685a1d9c1e60a0e70 192.168.235.151:6386   slots: (0 slots) slave   replicates 68ddc85b453fc7f28933740f62a1b5721d1c606eM: 337571ef1e1d861189bcd3c72fb6f33b8cba64e0 192.168.235.151:6383   slots:[12288-16383] (4096 slots) master   1 additional replica(s)S: d57408e2bc1f968dae58cc155edcf0a326970bde 192.168.235.151:6385   slots: (0 slots) slave   replicates 910039156a5be3bd6798de420c6cb3771cccedd9# 主要看这里！！6381的槽位M: 910039156a5be3bd6798de420c6cb3771cccedd9 192.168.235.151:6381   slots:[0-6826],[10923-12287] (8192 slots) master   1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.\n\n6381的槽位发生了变化，可以看到将原本6387的槽位全部合并到了6381\n\nDockerFileDockerFile\nDockerFile就是Docker的脚本文件：DockerFile的执行流程就相当于我们对镜像进行修改后，commit，然后不断重复这个过程。\n\n对于其中的关键字可以查看官网\n常见关键字：\n\nFROM：从哪一个源镜像构建而来，Dockerfile文件第一行就需要时FROM\nMAINTAINER：镜像维护者的姓名和邮箱地址\nRUN：在docker build时执行命令，有两种格式\nshell格式：RUN &lt;命令&gt;\nexec格式：exec [命令, 参数, 参数]\n\n\nEXPOSE：对外暴露出端口\nWORKDIR：创建容器后，终端默认登录进来的工作目录\nUSER：以什么样的用户去执行命令，默认为root\nENV：在构建镜像过程中设置环境变量\nENV指定的环境变量，在RUN指令中可以使用\n\n\nADD：将宿主机目录下的文件拷贝进镜像而且会自动处理URL和解压tar压缩包。\nCOPY：与ADD相似，拷贝文件到目录。ADD=COPY+解压\nVOLUME：数据卷\nCMD：指定容器启动后要执行的命令，格式与RUN一样\n注意：Dockerfile可以有多个CMD指令，但是只有最后一个会生效，CMD会被docker run指令之后的参数替换\n与RUN的区别在于：RUN在docker build时执行；CMD在docker run时执行\n\n\nENTRYPOINT：用来指定一个容器启动时要执行的命令\n注意：Dockerfile可以有多个ENTRYPOINT指令，但是只有最后一个会生效\n搭配CMD命令使用的话，CMD命令可以给ENTRYPOINT传递参数\n\n\n\n这里举一个小例子：\n假设已通过Dockerfile构建了nginx:test\nFROM nginxENTRYPOINT [&quot;nginx&quot;, &quot;-c&quot;]CMD [&quot;/etc/nginx/nginx.conf&quot;]\n\n如果要运行上述的dockerfile文件的话，输入\ndocker run nginx:test# 实际上执行的命令是nginx -c /etc/nginx/nginx.conf# 如果在执行中自己指定了参数docker run nginx:test -c /etc/nginx/temp.conf# 那么实际上会替换原有的参数nginx -c /etc/nginx/temp.conf\n\n一个Dockerfile的实例现在使用Dockerfile构建一个可以使用vim + ifconfig + JDK8的ubuntu镜像\n1、创建一个Dockerfile文件\nFROM ubuntuMAINTAINER hynis ENV MYPATH /usr/localWORKDIR $MYPATH#更新索引RUN apt-get update#安装vim编辑器RUN apt-get install -y vim#安装ifconfig命令查看网络IPRUN apt-get install -y net-tools#安装java8及lib库#RUN apt-get install -y  glibc.i686RUN mkdir /usr/local/java#ADD 是相对路径jar,把jdk-8u171-linux-x64.tar.gz添加到容器中,安装包必须要和Dockerfile文件在同一位置ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/#配置java环境变量ENV JAVA_HOME /usr/local/java/jdk1.8.0_171ENV JRE_HOME $JAVA_HOME/jreENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHENV PATH $JAVA_HOME/bin:$PATHEXPOSE 80CMD echo $MYPATHCMD echo &quot;success--------------ok&quot;CMD /bin/bash\n\n2、build镜像\ndocker build -t hynix:1.0 .\n\n3、进入镜像查看软件是否安装成功\ndocker run -it hynix:1.0\n\n虚悬镜像\n什么是虚悬镜像？\n\n虚悬镜像指：仓库名、标签都是&lt;none&gt;的镜像，英文名为dangling image\nDocker在拉取镜像的时候可能会出错，虚悬镜像没有任何用处，可以删除\nDocker网络\n在Docker启动后，Linux系统中会多一个docker0的地址，这个docker0就是Docker自己配置的一个网络\n\nVMware的网络配置在介绍Docker的网络配置前，有必要先介绍一下VMware中的模式：\n可以参考此篇知乎\n\n桥接模式：虚拟机的虚拟网卡与主机的物理网卡直接交接；直白一点的说法是，网络中出现了一台可以完全独立的计算机，他可以与网络中的其他终端进行交互。\nNAT模式：网络地址转换（Network Address Translation），主机会给所有的虚拟机建一个网络，虚拟机内部可以直接交互，虚拟机向外部的通信需要通过主机转发\n仅主机模式：一种比NAT模式更加封闭的的网络连接模式，它将创建完全包含在主机中的专用网络。仅主机模式的虚拟网络适配器仅对主机可见，并在虚拟机和主机系统之间提供网络连接\n\nDocker的网络模式此处略微介绍，下面会详细阐述\n\nbridge：为一个容器分配、设置IP，并将容器连接到一个docker0\nhost：容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口\nnone：【了解】容器有独立的Network namespace，但并没有对其进行任何的网络设置\ncontainer：【了解】新创建的容器不会创建自己的网卡和配置自己的IP，而是和一个指定的容器共享IP、端口范围。\n\n启动容器时，使用参数--net就可以指定模式，例如启动一个host容器\ndocker run -it --net host hynix:1.0 /bin/bash\n\n我们可以通过docker inspect 容器ID来查看这个容器的网络状况：\n&quot;Networks&quot;: &#123;    &quot;bridge&quot;: &#123;        &quot;IPAMConfig&quot;: null,        &quot;Links&quot;: null,        &quot;Aliases&quot;: null,        &quot;NetworkID&quot;: &quot;e9a47bb319e6523eb731752a4be2a495e757aa8d22e8ed46e7c0e3039fc373a0&quot;,        &quot;EndpointID&quot;: &quot;e9b47c4014b839ac36b2197ebbda365314451acf7742c58363efd1fe3df954ec&quot;,        &quot;Gateway&quot;: &quot;172.17.0.1&quot;,        &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,        &quot;IPPrefixLen&quot;: 16,        &quot;IPv6Gateway&quot;: &quot;&quot;,        &quot;GlobalIPv6Address&quot;: &quot;&quot;,        &quot;GlobalIPv6PrefixLen&quot;: 0,        &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,        &quot;DriverOpts&quot;: null    &#125;&#125;\n\n可以看到我们的网络模式是bridge的，并且我们的IP地址和网关都有分配\n注意：容器的IP可能是会变化的\nbridge模式为一个容器分配、设置IP，并将容器连接到一个docker0\nDocker服务默认会创建一个 docker0网桥（其上有一个 docker0 内部接口），该桥接网络的名称为docker0，它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。\nDocker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信。\n如图所示：\n\n\n宿主机网卡eth0（即网卡ens33）\nDocker运行后，默认构建一个桥接的网络docker0，其上有很多接口veth（虚拟eth）\nDocker会给每一个容器分配一个docker0网段内的IP地址（称为container_ip），而且每个容器都有网卡eth0与veth相互配对（这样的一对称为veth pair）\ndocker0就相当于一个交换机，所有容器通过docker0进行通信\n宿主机与容器的交互也需要通过docker0\n\n使用ip addr就可以看到docker0的信息\ndocker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default # BROADCAST 网卡可以发广播包# MULTICAST 网卡可以发多播包# UP 表示网卡处于启动状态# LOWER_UP L1处于启动状态（L1指第一层，即物理层，即插着网线）    link/ether 02:42:71:5f:92:b8 brd ff:ff:ff:ff:ff:ff\t# link/ether MAC地址\t# IPv4地址    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    # IPv6地址    inet6 fe80::42:71ff:fe5f:92b8/64 scope link        valid_lft forever preferred_lft forever\n\n我们也可以启动一个容器，来验证：\n# 容器 ip addr查询# 注意看下面 if3635: eth0@if36: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default     link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever\n\n# 宿主机 ip addr查询36: vethf7d2553@if35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default     link/ether 5e:f8:66:59:05:e4 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet6 fe80::5cf8:66ff:fe59:5e4/64 scope link \n\n可以看到宿主机提供了veth@if35 与容器内的veth@if36配对，达成内部通信\nhost模式容器使用宿主机的IP与端口\n\n如果启动一个容器以--net host的方式启动，那么它的IP与端口就与宿主机的是同一份\nnone模式【不常用】此种模式将只有lo回环地址，需要自己进行配置\ncontainer模式此种模式的容器将会与一个指定的容器的IP与端口一致，如图所示：\n\n可以看到有一个容器没有创建自己的网卡，而是直接使用另一个容器的网卡。\n自定义网络模式前面我们说到：容器的IP可能是会变化的\n这意味着，容器上面的服务如果我们使用IP去连接的话，有时候会出现错误，此时我们可以进行自定义网络，保证服务调用正常\n1、创建docker网络\ndocker network create hynisNet# 此时的网络默认驱动还是bridge模式\n\n2、将容器使用该网络进行创建\ndocker run -d -p 8081:8080 --network hynisNet --name service1 hynixdocker run -d -p 8082:8080 --network hynisNet --name service2 hynix\n\n使用--network就可以在指定网络中创建容器了\n3、测试使用域名访问服务，是可以相互ping通的\nping service1ping service2\n\n\n为什么默认的桥接模式IP和主机名关系有时候会改变，但是自定义模式却能维护呢？\n\n因为自定义网络自身维护好了IP与主机名的对应关系\nDocker整体的网络架构如图所示：\n\nDocker 是一个 C/S 模式的架构，运行的基本流程为：\n\n 用户使用Docker Client与Docker Daemon建立通信\nDocker Daemon 作为 Docker 架构中的主体部分，首先提供 Docker Server 的功能使其可以接受 Docker Client 的请求。\nDocker Engine 执行 Docker 内部的一系列工作Job\nJob 的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动Graph driver将下载镜像以Graph的形式存储。\n当需要为 Docker 创建网络环境时，通过网络管理驱动 Network driver 创建并配置 Docker 容器网络环境。\n当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 Execdriver来完成。\nLibcontainer是一项独立的容器管理包，Network driver以及Execdriver都是通过Libcontainer来实现具体对容器进行的操作。\n\nDocker-composeDocker-compose类似于最近很流行的k8s，是docker官方提供的容器编排工具，适用于对大量的容器进行管理。\nCompose允许用户通过一个单独的docker-compose.yml模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）\n一个简单的docker-compose.yml文件如下：这个文件，我们构建了搭建微服务的基本结构，首先我们启动了redis、mysql、以及测试的项目，并将三个容器放在了hynisNet网络中，只需要使用docker-compose up就可以一键启动整个微服务项目\nversion: &quot;3&quot;services:  microService:    image: dockerTest:1.6    container_name: ms01    ports:      - &quot;6001:6001&quot;    volumes:      - /app/microService:/data    networks:       - atguigu_net     depends_on: # 此处依赖了redis与mysql      - redis      - mysql  redis:    image: redis:6.0.8    ports:      - &quot;6379:6379&quot;    volumes:      - /app/redis/redis.conf:/etc/redis/redis.conf      - /app/redis/data:/data    networks:       - hynisNet    command: redis-server /etc/redis/redis.conf  mysql:    image: mysql:5.7    environment:      MYSQL_ROOT_PASSWORD: &#x27;123456&#x27;      MYSQL_ALLOW_EMPTY_PASSWORD: &#x27;no&#x27;      MYSQL_DATABASE: &#x27;db2021&#x27;      MYSQL_USER: &#x27;zzyy&#x27;      MYSQL_PASSWORD: &#x27;zzyy123&#x27;    ports:       - &quot;3306:3306&quot;    volumes:       - /app/mysql/db:/var/lib/mysql       - /app/mysql/conf/my.cnf:/etc/my.cnf       - /app/mysql/init:/docker-entrypoint-initdb.d    networks:      - hynisNet    command: --default-authentication-plugin=mysql_native_password #解决外部无法访问networks:    hynisNet: \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","categories":["Docker"],"tags":["Docker"]},{"title":"Redis","url":"/2020/01/11/Redis/Redis/","content":"\n引言：\nredis：一个非关系型高性能键值对数据库\n\n\n\n\nRedis核心内容总结\n支持的数据结构有：字符串、列表、字典（哈希）、集合、有序集合\n字符串的底层数据结构：SDS简单动态字符串（三个字段：指针、free剩余的空间大小、len长度）\n使用SDS替代C原本字符串的优点：\n获取字符串长度为O(1)级别（C中需要遍历一遍O(n)）\n实现了空间预分配（扩大时会扩的更大一点）、惰性空间释放（缩小时不会立即缩小）\n二进制安全（使用len来判断字符串结尾，而不是C中的使用/0来判断）\n\n\n列表的底层数据结构：数据少用压缩列表；数据多用双向链表\n什么时候用压缩列表？满足两个条件：\n每个数据的长度不超过64\n数据总个数不超过512\n\n\n哈希的底层数据结构：数据少用压缩列表；数据多用散列表\n散列表的使用细节：\n解决哈希冲突：拉链法\n维护一个装载因子：装载因子大于1.0，就翻2倍左右；小于0.1，就缩小2倍左右\n\n\n集合的底层数据结构：数据少用有序数组；数据多用散列表\n什么时候用有序数组？满足两个条件：\n存储的数据全为数字\n总个数不超过512\n\n\n有序集合的底层数据结构：数据少用压缩列表；数据多用跳表\n跳表的实现细节：\n给链表隔一个元素建一个索引，在给索引隔一个建一个索引，直到最顶层建了两个索引为止\n插入、删除、查询都很快\n**时间复杂度：O(log n)**（再细一点，如果是隔一个建立一个索引，那么时间复杂度是O(3 log n)）\n通过一个随机函数来保持平衡（随机函数的选择很重要，但是不需要深究）\n\n\n为什么使用跳表而不是红黑树？两个原因：\n跳表实现相对来说简单\n红黑树的范围查询性能没有跳表好\n\n\n数据的持久化：\nRDB：默认的方式，隔一段时间，就将当前redis库内的所有元素写入磁盘\nAOF：日志记录的方式\n\n\n各类数据结构的应用场景：\n字符串：可以统计网站人数、可以实现分布式锁（用setnx）\n列表：可以实现栈、实现队列、实现消息队列\n哈希：可以实现一个购物车\n集合：可以实现社交领域发现共同好友、发现用户共同兴趣等\n有序集合：可以实现一个直播的动态排行榜\n\n\n\nNOSQL随着互联网web2.0网站的兴起，传统的关系数据库在处理web2.0网站，特别是超大规模和高并发的SNS类型的web2.0纯动态网站已经显得力不从心，出现了很多难以克服的问题\nredis作为非关系型数据库的一员，在web2.0的交互中展露枝头\n关系型数据库例如：\n\nOracle\nMySQL\n\n是指采用了关系模型来组织数据的数据库，其以行和列的形式存储数据，以便于用户理解，关系型数据库这一系列的行和列被称为表，一组表组成了数据库。\n特点：\n\n数据之间有关联关系\n数据存储在硬盘的文件上\n表现为一个个的表格\n\n非关系型数据库(NOSQL)例如：\n\nredis\nhbase\nmongdb\n\n区别于关系数据库，它们不保证关系数据的ACID特性。（ACID指关系型数据库的原子性，一致性，隔离性，持久性）相对于铺天盖地的关系型数据库运用，这一概念无疑是一种全新的思维的注入。\n但是一个共同的特点都是去掉关系数据库的关系型特性。NoSQL有如下优点：易扩展，NoSQL数据库种类繁多\n特点：\n\n数据之间没有关系\n数据存储在内存中\n表现为key:value的形式\n\nNOSQL与关系型数据库的比较优点：\n\n成本：NOSQL数据库简单易部署，基本都是开源软件，相比关系型数据库成本低廉\n查询速度：NOSQL存储在缓存当中，查询速度非常快\n存储格式为：key:value形式，文档形式，图片形式等，所以可以基础类型以及对象或是集合等格式，而关系型数据库只能存储基础类型\n\n缺点：\n\n维护的工具和资料有限：因为NOSQL属于新的技术，而关系型数据库已经有十几年的技术\n不提供对SQL的支持：不支持SQL这样的工业标准，将产生一定用户的学习和使用成本，例如redis与hbase差别很大，而Oracle与mysql差别就很小\n不提供关系型数据库对事务的处理\n\n我们一般将数据存储在关系型数据库中，在NOSQL数据库中备份存储关系型数据库的数据\nRedis初识Redis\nRedis：Remote Dictionary Server 远程字典服务\nredis是一款高性能的NOSQL系列的非关系型数据库\n\nredis是用c语言开发的高性能键值对数据库\n常见的应用场景：\n\n缓存（数据查询，短连接，新闻内容，商品内容等等）\n聊天室的在线好友列表\n任务队列（秒杀、抢购、12306等）\n应用排行榜\n网站访问统计\n数据过期处理\n分布式集群架构中的session分离\n\n两大维度、三大主线三大主线：高性能、高可靠、高可扩展\n两大维度：应用维度、系统维度\n\nredis不同数据的操作本节是关于Redis的命令操作\nredis数据库操作ping //测试一个连接是否还可用，如果不加任何内容返回pong，加了内容返回它本身select [index] // 切换数据库[1-15]dbsize //查看当前数据库大小keys * // 查看所有的keyflushdb // 清除当前数据库flushall // 清除全部数据库的内容exist key // 是否存在这个keyexpire key [n] // 设置过期时间(默认为秒)ttl key // 查看key的过期时间type key //查看当前key的类型\n\nredis的数据结构支持的五大数据结构：\n\n字符串类型 string\n哈希类型 hash\n列表类型 list\n集合类型 set\n有序集合类型 sortedset (Zset)\n\n另外还能存储几种特殊数据结构：\n\nHyperLogLogs：省内存的去统计各种计数，比如注册 IP 数、每日访问 IP 数的页面实时UV、在线用户数，共同好友数等\nBitmap：两个状态的，都可以使用 Bitmap，比如登录未登录、性别\ngeospatial ：推算地理位置的信息: 两地之间的距离, 方圆几里的人；底层是Zset，有序列表\nstream：用于消息队列和发布/订阅模式\n\n字符串类型Redis中的字符串\nstring类型是二进制安全的，意思是 Redis 的 string 可以包含任何数据（图片、对象等等）\nkey最大可以是512Mb\n\n基本的操作\nset key value // 存储get key //查找del key //删除\n\n追加与长度获取\nappend key xxx // 给一个key追加字符串strlen key // 查看这个key的长度\n\n自增与自减（可以使用这个来进行计数，比如统计系统在线人数）\nincr key // 给一个key的值+1（必须是数值）decr key // 给一个key的值-1incrby key n // 步长为n +ndecrby key n // 步长为n -n\n\n获取子串\ngetrange key [start] [end] //返回子串[start,end]，如果end是-1，代表末尾setrange key [index] [newStr] // 将从index开始用newStr替换原来的字符串\n\nex与nx（setnx可以实现分布式锁）\nsetex key [second] [value] // 设置值附带过期时间setnx key value// 如果不存在此key，则设置；存在则不设置（分布式设置乐观锁）\n批量操作（原子操作，但注意，Redis单线程，如果一次传输数据太多，会导致Redis阻塞或者网络拥塞）\nmset key1 value1 k2 v2 k3 v3 // 批量创建mget k1 k2 k3 k4 //批量获取msetnx // 不存在则设置也支持批量\n\n存放对象\nmset user:1:name zhangsan user:1:age 3 // mset 对象:&#123;id&#125;:field value\n\ngetset\ngetset //设置新值，返回旧值\n\n总结：表格来自于\n\n\n\n命令\n描述\n用法\n\n\n\nSET\n（1）将字符串值Value关联到Key（2）Key已关联则覆盖，无视类型（3）原本Key带有生存时间TTL，那么TTL被清除\nSET key value [EX seconds] [PX milliseconds] [NX|XX]\n\n\nGET\n（1）返回key关联的字符串值（2）Key不存在返回nil（3）Key存储的不是字符串，返回错误，因为GET只用于处理字符串\nGET key\n\n\nMSET\n（1）同时设置一个或多个Key-Value键值对（2）某个给定Key已经存在，那么MSET新值会覆盖旧值（3）如果上面的覆盖不是希望的，那么使用MSETNX命令，所有Key都不存在才会进行覆盖（4）MSET是一个原子性操作，所有Key都会在同一时间被设置，不会存在有些更新有些没更新的情况\nMSET key value [key value …]\n\n\nMGET\n（1）返回一个或多个给定Key对应的Value（2）某个Key不存在那么这个Key返回nil\nMGET key [key …]\n\n\nSETEX\n（1）将Value关联到Key（2）设置Key生存时间为seconds，单位为秒（3）如果Key对应的Value已经存在，则覆盖旧值（4）SET也可以设置失效时间，但是不同在于SETNX是一个原子操作，即关联值与设置生存时间同一时间完成\nSETEX key seconds value\n\n\nSETNX\n（1）将Key的值设置为Value，当且仅当Key不存在（2）若给定的Key已经存在，SEXNX不做任何动作\nSETNX key value\n\n\nRedis字符串的应用应用场景：\nRedis单线程，不需要考虑并发\n\nsetnx来设置分布式锁\nincrby进行计数、统计网站人数\n\n哈希类型以Java来理解，Redis的哈希类型就是Map&lt;String, Map&lt;String, Object&gt;&gt;\nhset key field value // 存储hget key field //获取对应的valuehgetall key  //获取所有的键和值hdel key field //删除\nredis-cli示例\n//设置127.0.0.1:6379&gt; hset person name zhangsan(integer) 1127.0.0.1:6379&gt; hset person user lisi(integer) 1//获取127.0.0.1:6379&gt; hget person name&quot;zhangsan&quot;127.0.0.1:6379&gt; hget person user&quot;lisi&quot;//获取所有127.0.0.1:6379&gt; hgetall person1) &quot;name&quot;2) &quot;zhangsan&quot;3) &quot;user&quot;4) &quot;lisi&quot;//删除127.0.0.1:6379&gt; del person name(integer) 1127.0.0.1:6379&gt; del person user(integer) 0127.0.0.1:6379&gt; hgetall person(empty list or set)\n\n列表类型Redis中的listredis内的列表是一个横向的列表，可以添加到左边或者右边\nredis列表是一个有序的列表，而且可以重复\n//添加lpush key value //将元素加入列表左边rpush key value //将元素加入列表右边//获取lrange key start end //范围获取,从0开始//删除lpop key //删除列表最左边的元素，并将元素返回rpop key //删除列表最右边的元素，并将元素返回\nredis-cli示例\n//添加到list127.0.0.1:6379&gt;  lpush list a(integer) 1127.0.0.1:6379&gt; lpush list b(integer) 2127.0.0.1:6379&gt; rpush list c(integer) 3127.0.0.1:6379&gt; lrange list 0 -1 //end为-1代表查找所有1) &quot;b&quot;2) &quot;a&quot;3) &quot;c&quot;127.0.0.1:6379&gt; lpop list&quot;b&quot;127.0.0.1:6379&gt; rpop list&quot;c&quot;\n\nRedis列表的应用Redis的列表特点：有左右、有序、可重复\n\n实现栈（lpush、lpop）\n实现队列（lpush、rpop）\n实现消息队列（lpush、brpop）\n\n\nbrpop命令：移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n\n集合类型Redis集合类型特点：\n\n不允许重复\n\n无序\n\n\n//存储sadd key value//获取smembers key//删除srem key\nredis示例\n 127.0.0.1:6379&gt; sadd myset a b c d e f g(integer) 7127.0.0.1:6379&gt; smembers myset1) &quot;d&quot;2) &quot;b&quot;3) &quot;g&quot;4) &quot;c&quot;5) &quot;a&quot;6) &quot;e&quot;7) &quot;f&quot;127.0.0.1:6379&gt; srem myset g(integer) 1127.0.0.1:6379&gt; sadd myset a a b b(integer) 0127.0.0.1:6379&gt; smembers myset1) &quot;c&quot;2) &quot;a&quot;3) &quot;d&quot;4) &quot;e&quot;5) &quot;b&quot;6) &quot;f&quot;127.0.0.1:6379&gt;\n\nRedis集合的应用可以利用集合的并、交特性，在社交领域，可以求共同好友、发现用户共同兴趣等\n有序集合类型Redis有序集合Zset特点：\n\n不允许重复\n有序\n\n//存储,存储数据以及数据对应的值zadd key score value //获取zrange key start end//删除 zrem key value\nredis示例\n127.0.0.1:6379&gt;  zadd mysort 60 zhangsan(integer) 1127.0.0.1:6379&gt; zadd mysort 50 lisi(integer) 1127.0.0.1:6379&gt; zadd mysort 80 wangwu(integer) 1127.0.0.1:6379&gt; zrange mysort(error) ERR wrong number of arguments for &#x27;zrange&#x27; command127.0.0.1:6379&gt; zrange mysort 0 -11) &quot;lisi&quot;2) &quot;zhangsan&quot;3) &quot;wangwu&quot;127.0.0.1:6379&gt; zrange mysort 0 -1 withscores//带上withscore会显示分数1) &quot;lisi&quot;2) &quot;50&quot;3) &quot;zhangsan&quot;4) &quot;60&quot;5) &quot;wangwu&quot;6) &quot;80&quot;\n\nRedis有序集合的应用可以做排行榜、也可以用于社交领域\nRedis底层数据结构Redis的底层数据结构，支持了上一节五大基本结构的使用\n\n\nString：简单动态字符串（注意：String也有第二个数据结构：当你保存的是一个64位有符号整数时，String会保存为一个8字节的Long类型整数，这也叫int编码方式）\nList：压缩列表；双向链表\nHash：压缩列表；散列表\nSet：整数数组；散列表\nSorted Set：压缩列表；跳表\n\nOBJECT ENCODING [key] # 此命令可以查看底层的数据结构 \n\nSDS简单动态字符串使用自己构建的名为SDS(Simple  dynamic string)简单动态字符串\nstruct sdshdr&#123;     int len; //记录字符串长度     int free; // 记录未使用的字节数     char buf[];//字节数组，用于保存字符串&#125;\n\n使用如此的结构，极大的提高了性能：\n\n\nO(1)级别获取字符串长度；在C中，需要进行遍历，为O(n)\n杜绝缓冲区溢出；C中，进行strcat等字符串操作，如果没有分配足够长度空间，容易导致缓冲区溢出；而对于SDS数据类型，字符串修改会首先根据len属性检查内存是否符合要求\n减少修改字符串的内存重新分配次数；SDS可以进行空间预分配与惰性空间释放\n空间预分配：当字符串扩展时，会扩展更大的空间\n惰性释放：当字符串缩小，会增大free的值，但是空间不一定会跟着变化\n\n\n二进制安全：C中使用/0空字符作为字符串结束位，但是对于图片等二进制文件，内容可能有空字符，因此SDS用len来判断字符串是否结束\n兼容部分C字符串函数：使用C语言实现，可以兼容部分C的API\n\n压缩列表\n压缩列表：\n​        通过一片连续的内存空间来存储数据（类似于C的数组）\n​        但是和数组的区别是，存放的数据大小允许不同\n\n压缩列表的特点：\n\n压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。\n如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段 的长度直接定位，**复杂度是 O(1)**。\n而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。\n\n优点：\n\n允许存储不同类型的数据\n节省空间\n\n\nRedis什么时候使用压缩列表的实现？\n\n在数据量小的时候才会使用，需要同时满足：\n\n保存的单个数据小于64字节\n列表中的数据总个数小于512个\n\n双向链表\n双向循环链表：\n​        Redis的list结构体额外定义一个list的结构体\n\n链表节点：（这与基本的双向列表一样）\ntypedef  struct listNode&#123;       //前置节点       struct listNode *prev;       //后置节点       struct listNode *next;       //节点的值       void *value;  &#125;listNode\n\n双向链表：（额外定义list的结构体）\ntypedef struct list&#123;     //表头节点     listNode *head;     //表尾节点     listNode *tail;     //链表所包含的节点数量     unsigned long len;     //节点值复制函数     void (*free) (void *ptr);     //节点值释放函数     void (*free) (void *ptr);     //节点值对比函数     int (*match) (void *ptr,void *key);&#125;list;\n\n特点：\n\n双端：双向链表，获取头尾元素均为O(1)\n无环：头尾均指向NULL\n带链表长度计数器：获取链表长度为O(1)\n多态：链表节点使用void*指针，可以保存不同元素\n\n散列表散列表\n哈希算法：Redis 使用 MurmurHash2这种运行速度快、随机性好的哈希算法作为哈希函数\n哈希冲突解决：拉链法\n当数据动态增加之后，散列表的装载因子会不停地变大。为了避免散列表性能的下降：\n装载因子 = 已存储元素数量 / 哈希表大小\n\n当装载因子大于 1 的时候，Redis 会触发扩容，将散列表扩大为原来大小的 2 倍左右\n\n为了节省内存，当装载因子小于 0.1 的时候，Redis 就会触发缩容， 缩小为字典中数据个数的大约 2 倍大小\n\n\n（2倍左右，是估计值！）\n有序数组\n什么时候使用有序数组？\n\n\n存储的数据都是整数\n存储的数据元素个数不超过512个\n\n在集合中如果不满足这些，就用散列表实现集合\n\n整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它 们作为底层数据结构呢？\n\n虽然没有什么时间复杂度的优势，但是胜在其使用数组，有两个特点：\n\n节省空间\n没有内存碎片\n\n跳表\n跳表：一个链表，为了提高它的查询速度，隔一个设置一个索引，用来加快查找，为了加快索引的搜索，再对索引隔一个设置一个索引\n每一层索引都是一个链表，这样构成的数据结构就是跳表\n\n\n特点：\n\n由很多层结构组成；\n每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点\n最底层的链表包含了所有的元素；\n如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；\n链表中的每个节点都包含两个指针\n一个指向同一层的下一个链表节点\n另一个指向下一层的同一个链表节点；\n\n\n插入、删除、查询都很快\n通过随机函数来维护自平衡\n\n\n有多快？\n\n如果总共有 n个 节点\n那么会建立log2N的高度的节点\n查询一个数据的时间复杂度为O(m*log n)\nm 是多少？ m=3，因为每一层最多遍历三个节点（因为索引是隔一个抽一个建立起来的）\n\n如何维护自平衡？通过一个随机函数\n\n比如随机函数生成了值 K，那我们就将这个结点添加到第一级到第 K 级这 K 级索引中。\n随机函数的选择比较重要，这也比较复杂，我们无需研究。\n\n为什么选跳表不用红黑树？\n\n\n按照区间来查找数据这个操作，红黑树的效率没有跳表高（虽然增删查的时间复杂度一样）\n跳表更容易实现（相比较而言简单）\n\n为什么SortedSet用跳表？跳表的数据结构可以看做：\npublic class Node &#123;    private int data = -1;    // 存放跳转的索引    private Node[] forwards = new Node[MAX_LEVEL];    private int maxLevel = 0;&#125;\n\n跳表式依赖于概率算法的：比如现在要新加入一个节点，需要决定该节点的层级\n理论上来讲，一级索引应该占50%，二级索引占25%，三级索引占12.5%等等以此类推\n决定当前节点层级是通过随机来决定的，晋升的概率为1/2。\nprivate static final float PROB = 0.5 f;private int randomLevel() &#123;    int level = 1;    // 如果随机数大于0.5，就允许晋升    while (Math.random() &gt; PROB &amp;&amp; level &lt; MAX_LEVEL) &#123;        ++level;    &#125;    return level;&#125;\n\n对于有序Set来说，一般需要支持的操作有：\n\n增\n删\n查一个数据\n查区间数据\n\n红黑树与跳表比较来说，对于前三个操作基本一致，但是查区间数据会慢一些，且实现要比跳表难一些。\n\n为什么跳表范围查询比红黑树快？\n\n红黑树是老老实实一级一级查的，但是跳表是顺序和跳跃的结合，这使得跳表可以快速跳跃到目标区间的起点，而一旦找到起点后，可以直接顺序遍历底层链表。\n深入Redis数据结构占内存的String前面说了String的底层，由SDS构成，但其实，String类有很深的门道，这节我们来说一下\n\nString有三种编码方式：\n\nint编码：在保存64位有符号整数时\nembstr编码：在保存的字符串小于44字节时\nraw编码：大于44字节时\n\n下图是RedisObejct的示意图\n\n可见，三种编码方式，在内存中的实现是不一样的，int编码的数据就直接在指针里放着，节省内存；embstr的SDS在内存中与RedisObejct紧挨着（这样可以避免内存碎片）\n\n这里额外补充一下：\n\nRedisObejct是记录数据是什么类型的结构体，由两部分组成，元数据与类型指针\n\n对于全局哈希表，它的每一项都是一个DictEntry结构体，这个结构体存放三个数据（下一节）：key、value、next\n\n\n内存结构是这么存的：\n\n\n假如我们用String保存2个10位的数，会消耗多少内存呢？\n\n由于存10的数字，所以会直接占用指针的8个字节，元数据用8个字节，共有两个会占用32字节；\nDictEntry占24字节，但是Redis 使用的内存分配库 jemalloc只会分配2的幂次的大小，所以分配32字节\n所以占用了64字节，但是有效的信息，只有16字节，所以说String的开销很大！利用率不高\n使用压缩列表String消耗内存很多，当存的数据只是简单的数字时，越多String消耗的空间越大，但实际上根本没有利用多少\n压缩列表就是一个很节省内存的例子\n\n压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束\n压缩列表的每一个entry，由四个部分构成：prev_len、encoding、len、content\n\nprev_len：表示前一个entry的长度，只有两种取值情况，要么占1B、要么占5B\n如果上一个entry小于254字节，那么就取1B；否则取5B\n\n\nencoding：编码方式，1B\nlen：表示自身长度，占4B\ncontent：保存实际数据\n\n\n用一个RedisObejct，就可以存一堆数，这可比存一个数就要一个RedisObejct的String要省内存多了\n\nRedis什么时候使用压缩列表的实现？\n\n在数据量小的时候才会使用，需要同时满足：\n\n保存的单个数据小于64字节\n列表中的数据总个数小于512个\n\n这两个参数都可以调节\n全局哈希表Redis使用了两个全局哈希表\n\n全局哈希表：如图，value为一个一个节点，节点才会去存真正的数据类型\n\n\n这个全局的哈希表中，每一项是一个dictEntry节点，这个dictEntry结构体包含三个部分（图中只画了两个）：key、value、next（指向下一个dictEntry）\n那么这里有几个问题，带着问题来思考\n\n全局哈希表如何解决哈希碰撞？\n\n是使用拉链法来解决哈希冲突的\n\n如果拉链变的十分长，导致查询速度下降，那么Redis是怎么保证高性能呢？\n\n​        当Redis发现存放的数据达到一定程度，就会进行rehash，使用两个哈希表来进行交替，这样即使在rehash过程中，也不会无法进行服务\n\nrehash的过程\n\n\n给哈希表2分配更大的空间（比如是哈希表1的两倍）\n将哈希表1的数据重新映射并拷贝到哈希表2中\n释放哈希表1的空间\n\n如果哈希表2再满了，那么再次重复这个过程\n\n渐进式rehash\n\n如果真的采用上面的rehash过程，那么在2步过程中，由于copy浪费的时间，将导致redis不能进行服务\n所以Redis是渐进式rehash的（即每次的请求，都捎带着copy一个桶上的索引）\n\n可以保证在copy过程中，也能继续保持服务\n单线程数据库Redis\nRedis是单线程的吗？\n\n严格意义上来说，Redis不是单线程的；\n常说的Redis是单线程，是指其提供的网络IO 和 键值对读写是由一个线程来完成的\n\n为什么使用单线程？\n\n多线程其实并不会快很多，对于一些共享数据，多线程需要加锁进行操作，这种情况下，多线程的性能不会比单线程高，只会让设计上更加复杂\n\n为什么使用单线程，Redis还这么快？\n\n几方面原因：\n\n处理方面：redis是单线程的，单线程无需考虑并发操作，无需加锁\n内存方面：redis的底层数据结构比较快，比如跳表\n持久化方面：有AOF这种快速的日志机制。\n网络方面：使用epoll网络编程模型\n\n多路复用机制以一个Redis的GET请求为例，基本的IO模型如图\n\n整个过程如下\n\nRedis要先监听客户端请求（bind/listen）\n建立连接（accept）\n读取请求（recv）\n解析客户端发送的请求（parse）\n从数据库获取数据（get）\n返回发送给客户端（send）\n\n其中2与3是阻塞点\n（2：redis监听到连接请求，但是一直未能成功连接，导致其他客户端无法与redis连接；3：读取的数据如果一直没有到达，也会造成阻塞）\n\n如何解决基本的网络IO带来的阻塞？\n\nSocket网络模型支持非阻塞模式\n\n非阻塞：即在遇到阻塞后，不在原地等待，而是先去执行其他操作，隔段时间再来观察是否还阻塞\n\nSocket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上：\n\n\n\n调用方法\n返回套接字类型\n非阻塞模式\n效果\n\n\n\nsocket()\n主动套接字\n\n\n\n\nlisten()\n监听套接字\n可设置\naccept()非阻塞\n\n\naccept()\n已连接套接字\n可设置\nsend()/recv()非阻塞\n\n\n\nsocket()方法会返回主动套接字\n\n然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求\n\n调用 accept() 方法接收到达的客户端连接，并返回已连接套接字\n\n\n因为可以设置非阻塞，所以Redis在accept()或recv()迟迟没有得到反映，就可以先进行其他操作\n\n虽然Redis可以不继续等待，但是总得有机制在监听套接字上等待，这就用到了Linux的IO多路复用机制\n\n多路复用机制：\n​        IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制\n\n\nselect/epoll 机制：可以快速看一下这篇blog，图画的非常nice，一眼就懂了\n\n这里贴一下图，图源在上面已经说了\n\nselect：\n处理所有的fd，进行挨个询问\n水平触发：如果不处理，下次会继续通知\n\n\nepoll：\n所只处理那些就绪的fd\n支持水平触发与边缘触发：只通知一次，如果我没有处理，只有到下次状态发生实际变化才会通知\n\n\n\n\n\nRedis中的高性能IO模型\n\n\n回调机制：\n​        select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数\n\n​        这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。\n​        这样一来， Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。\nAOF详解redis是一个内存数据库，储存在内存当中，关闭后数据会丢失，但是Redis提供了两种持久化方式：RDB、AOF\n\n\nAOF (Append Only File)： 日志记录的方式，可以记录每一条命令的操作，可以每一次命令操作后，持久化数据\n\nAOF日志的工作比较特殊，不同于传统的WAL，他是先执行操作，再写数据\n\n为什么AOF日志要先执行操作，后写入日志呢？\n\n好处有两个：\n\n避免检查语法错误：因为只有执行成功，才会被写入日志\n命令执行后再写，不会阻塞当前的操作\n\n不过有两个潜在的风险：\n\n如果操作执行完，宕机，会导致日志上并没有记录（数据会丢失，不再可以使用日志进行恢复）\n虽然避免了阻塞当前操作，但可能会阻塞下一个操作（因为写日志是需要操作磁盘的！）\n\n如果我们可以找好时机写入磁盘，那么这两个风险会好一点：Redis提供了三种写回策略\n三种写回策略AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值：\n\nAlways：每一个操作都写回日志\nEverysec：每秒写回，先写在缓冲区，每隔一秒写回一次\nNo：先写在缓冲区，操作系统控制何时写回\n\n\n\n\n配置项\n写回时机\n优点\n缺点\n\n\n\nAlways\n同步写回\n可靠性好，数据基本不丢失\n影响性能\n\n\nEverysec\n每秒写回\n性能适中\n宕机丢失1s数据\n\n\nNo\n操作系统控制写回\n性能好\n宕机丢失数据较多\n\n\n不管哪一种写回方式，随着日志越写越多，终究会导致性能问题，所以AOF还提供了重写机制\nAOF重写机制\n重写：就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件\n\n这个文件会比原来的小很多，因为它只记录结果！\n\n并且 和AOF 日志由主线程写回不同，重写过程是由后台线程 bgrewriteaof 来完成的\n重写的过程：一个拷贝、两个日志\n​        一个拷贝：主线程fork出后台线程bgrewriteaof（注意：fork这一操作的过程是阻塞了主线程的！）\n​        fork操作会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据（也就是说，如果主线程的内存越大，这个拷贝的时间也会越长）\n两个日志：\n\n正常使用的AOF日志\nAOF重写日志\n\n\nRDB详解另一种Redis的持久化方式\n\nRDB (Redis DataBase) ： 默认方式，不需要进行配置，默认就使用这种机制，一定时间间隔，检测key的变化情况，然后持久化存储\n\n类似于快照，会将当前内存所处的状态，生成一个RDB文件\n和AOF比，RDB 记录的是某一时刻的数据，并不是操作\n所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复\nRDB快照Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave：\n\nsave：在主线程中执行，会导致阻塞； \nbgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置\n\n\n在进行快照时，数据可以改变吗？\n\n可以改变，Redis采用COW（写时复制）的思想来实现备份时也可以服务\n\n如果是读操作：（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响\n如果是写操作：（例如图中的键值对 C）， 那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据\n\n\nRDB的缺点虽然RDB可以快速的进行恢复，而且也可以在备份时继续服务\n但是隔多久进行一次快照并不好把控\n\n隔得时间短，影响性能\n隔得时间长，如果宕机会丢失很多数据\n\nRedis提出了增量快照\n\n增量快照：即在一次全量快照后，之后的更改只记录修改的部分\n\nRedis4.0混合AOF与RDBRedis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。\n简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作\n这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势\nRedis主从复制为了保证数据故障恢复时也可以进行服务（Redis为了可以提供服务操碎了心）Redis也有主从机制\n主从库模式Redis主从库承担了不同的任务，采用读写分离的方式\n\n主库：负责读操作、写操作\n从库：只负责读操作\n\n写操作只可以对主库进行\n\n\n为什么要采用读写分离的方式？\n\n可以避免主从库之间进行数据协调，只需要让主库同步从库即可（如果都可以进行写操作，那么会很混乱）\n第一次同步从库如何成为主库的从库？\n一行代码即可：\n# 现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5）# 实例2键入replicaof 172.16.19.3 6379# 实例2就变为了实例1的从库# Redis 5.0之前用 slaveof命令\n\n第一次同步有三个阶段：\n\n\n从库发起连接请求（psync a b包含两个参数，a为主库的runId，由于不知道主库runID，所以为?；b为复制进度，第一次复制为-1）；主库收到后，会使用FULLRESYNC命令，表示这是一次全量复制\n\n主库将所有数据同步（即一个RDB块）给从库。从库收到数据后，清除原本的数据，并在本地完成数据加载\n（主库发送RDB后会在内存中用专门的 replication buffer，记录 收到新的写操作）\n\n主库会把第二阶段执行过程中新收到的写命令，再发送给从库\n\n\n主从级联模式如果主库频繁的从库创建RDB、发送RDB\n这会影响主库的性能（因为fork会阻塞主线程，而且越大，fork所需要的时间会越长）\n所以为了解决这个问题，有了主 - 从 - 从模式\n即部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置 较高的从库），用于级联其他的从库\n这个从库就可以帮主库分担压力\n\n网络闪断与repl_backlog_buffer缓存\n网络闪断：即网络不好，短短续续\n\n如果在Redis2.8版本之前，出现了网络闪断，在重新连接后，会重新进行一次全量复制，开销极大\nRedis2.8版本之后，网络断了之后，主从库会采用增量复制的方式继续同步\n​        当主从库断连后，主库会把断连期间收到的写操作命令，写入replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer这个缓冲区\nrepl_backlog_buffer是一个环形缓冲区，随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置\n这个缓存有两个指针：如图，分别为主库读的指针、从库读的指针\n\n连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库\n主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距，只用把master_repl_offset和 slave_repl_offset 之间的命令操作同步给从库就行\n哨兵机制主库提供了所有的写服务，如果主库挂掉，那么整个系统将陷入瘫痪\nRedis使用哨兵机制，来解决这个问题\n\nRedis哨兵机制：在主库挂掉后，将从从库中选出一个作为新的主库\n\n哨兵\n哨兵：即运行在特殊模式下的Redis进程\n\n哨兵有三个任务：\n\n监控：周期性的给主库发送PING，检测主库是否在运行\n选择主库：从众多的从库中筛选一个作为主库\n通知：把新主库的连接信息发送给从库\n\n其实这三个功能都是围绕着一个流程来进行的\n监控——主观下线与客观下线\n哨兵如何判断一个主库已经挂掉了呢？\n\n哨兵会周期性给主库、从库发送PING请求，如果主从库没有在规定时间内回应：\n\n从库没有回应：标记为主观下线\n主库没有回应：有可能主库真的下线了（此时会进行主从切换），也有可能是哨兵误判了\n\n所以需要有很多哨兵来进行对主库是否下线的判断，这就称为哨兵集群\n所以，当多数的哨兵都认为主库已经下线，那么此时主库就会被认定为客观下线\n客观下线的标准就是：当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”\n\n监控的具体流程：\n\n当一个哨兵判断主库主观下线后，就会给其他哨兵发送is-master-down-by-addr\n其他的哨兵会根据自己的判断，投出Y/N（即赞成票和不赞成票）\n当赞成票大于quorum参数时，就会认为主库客观下线\n\n\n\n主库挂掉，哪一个哨兵来执行主从切换的任务呢？\n\n是由Leader来执行，leader也是由投票选举产生的：\n在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：\n\n拿到半数以上的赞成票\n拿到的票数同时还需要大于等于哨兵配置文件中的 quorum值\n\n\n哨兵是如何确定Leader投票是投是还是否呢？\n\n它会给第一个向它发送投票请求的哨兵回复 Y，给后续再发送投票请求的哨兵回复 N\n选主——选择新主库\n哨兵如何选择主库？\n\n整个过程分为两步：筛选 + 打分\n​        简单来说，我们在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则， 给剩下的从库逐个打分，将得分最高的从库选为新主库\n（从库都在卷~）\n筛选条件：除了要检查从库的当前在线状态，还要判断它之前的网络连接状态（通过配置一个最大连接时长，默认如果发生断连的次数超过10次，就认为这个从库的网络状况不好，就被miss掉了）\n打分规则：别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号\n三轮打分过程：\n\n优先级最高的从库得分高（不同的从库可以设置不同的优先级，一般给内存大的从库设定一个高的优先级）\n和旧主库同步程度最近的从库得分高（通过repl_backlog_buff缓存中的指针，详情见上一节）\nID号小的从库得分高：默认的规定，在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库\n\n通知——发布/订阅机制\n哨兵之间是如何进行交流的？\n\n要弄清楚这个问题，首先得知道如何设置一个哨兵：\nsentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;# 需要主库的ip、端口号\n\n此时哨兵之间是不知道彼此的\n哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅 机制\n\n发布订阅机制：订阅了同一个频道的应用，可以通过发布的消息进行信息交换\n\n频道有很多：\n\n哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）\n同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。\n举个例子，具体说明一下。\n在下图中，哨兵 1 把自己的 IP（172.16.19.3）和端口 （26579）发布到“__sentinel__:hello”频道上，哨兵 2 和 3 订阅了该频道。那么此时，哨兵 2 和 3 就可以从这个频道直接获取哨兵 1 的 IP 地址和端口号。\n\n\n哨兵是如何知道从库的IP的？\n\n哨兵向主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵\nRedis缓存缓存处理请求的两种情况缓存接收请求后，无非两种情况：\n\n缓存命中：缓存中有数据，可以直接读\n缓存缺失：缓存中没有数据，必须要去数据库中读取；而且读取完成后，还必须把这个数据再加载到缓存中\n\n注意：缓存缺失后，除了要访问数据库，还要把新的数据写到缓存内（缓存更新）\nRedis的缓存类型Redis中缓存由两种类型，我们可以根据业务的不同来选择不同的缓存：\n\n只读缓存：只读缓存只接受读请求，对于写请求直接交给数据库处理\n读写缓存：读写请求接收读、写请求\n\n只读缓存对于不同的请求：\n\n写请求：只读缓存会删除当前缓存\n读请求：如果读不到，会发生缓存缺失，在读完数据库后进行缓存更新\n\n\n读写缓存对于不同的请求的处理：\n\n读请求：与只读缓存一样\n写请求：直接在缓存中进行更改\n\n在读写缓存中，由于写请求在缓存中就进行了处理，所以必须要写回磁盘，这时就有两种不同的写回磁盘的策略：\n\n同步直写：服务器向缓存和数据库同时发起请求，缓存处理完成后，需要等待数据库也处理完成后，才会返回响应\n异步写回：缓存处理完数据后直接返回，而且数据只有在被淘汰出缓存时才会写回磁盘\n\n\n\n\n\n对比\n同步直写\n异步写回\n\n\n\n优点\n即使缓存发生故障，数据也不会丢失\n访问快速\n\n\n缺点\n等待数据库，降低了缓存的访问性能\n缓存发生故障会导致数据直接丢失\n\n\nRedis的缓存淘汰机制Redis有两种淘汰策略：\n\n惰性删除：redis不主动删除过期键，而是处理每一个请求时，判断是否过期，如果过期就删除。\n定期删除：每隔一段时间（默认100ms）随机抽查一部分键，根据不同的策略淘汰键。\n\nRedis4.0定期删除有 8 种淘汰策略：\n\n\nnoeviction：不会淘汰数据，如果缓存满了，将不再提供服务（默认策略）\nvolatile开头的淘汰策略：代表淘汰的选择源是所有有时间限制的数据，不会淘汰那些无时间限制的数据（即只淘汰那些设置EXPIRE的数据）\nallkeys开头的淘汰策略：淘汰的选择源是所有数据\nLRU：基于LRU算法进行淘汰\nLFU：基于LFU算法进行淘汰\nrandom：随机进行淘汰\nvolatile-ttl：淘汰最早的请求（通过TTL判断）\n\n\n如何选择？\n\n\n优先使用allkeys-lru策略：可以充分利用 LRU 这一经典缓存算法的优势，把最 近最常访问的数据留在缓存中\n\n如果你的业务中有类似置顶的需求（比如置顶新闻、置顶视频）：可以使用 volatile-lru 策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选\n\n\n\n淘汰的数据如何处理？\n\n一般来讲，对于干净页直接删除，但是对于脏页要写回数据库后再删除。\n但是在Redis中，不管干不干净，只要认定淘汰，就会直接删除\nRedis中的LRU算法由于LRU需要借助链表，而且涉及到了链表的很多断开、连接的操作\n所以如果缓存中的数据很多，那么直接使用LRU算法，显然会造成很大负担\nLRU算法就不介绍了，在Redis中的特殊处理，要说一下\n\n首先要知道Redis在RedisObejct中，保存了lru字段记录最近一次的访问时间戳\n\n第一次LRU淘汰：随机选出N个数据，把他们作为一个候选集合，接下来，Redis会比较这N个数据的lru字段，将数值最小的（也就是好久没有访问的）淘汰\n\n之后的每一次淘汰：挑选一些数据进入候选集合，挑选的标准是该数据的lru字段的值比候选集合里最小的lru还要小，然后淘汰lru字段最小的数据\n\n\n经过这样的特殊处理，Redis就既实现了LRU，也提高了缓存的性能\n缓存一致性问题由于Redis有两种缓存，所以缓存不一致问题，我们分开来讨论：\n\n对于读写缓存\n\n只能采用同步直写的方式避免，涉及到Redis的事务\n\n对于只读缓存\n\n\n新增数据时：数据在写入数据库后，加载到内存，不存在不一致问题\n删改数据时：只读缓存只接受读请求，所以如果你改了数据库中的数据，假设此时还没来得及删掉缓存中的数据，那么此时有请求来读，读到的将是旧的数据（存在不一致问题）\n\n解决措施：删除缓存中的数据，并且将数据库中的数据修改\n\n但是！这个解决措施并不一定能完全成功：（我们还需要保障措施保证这两步能完成！）\n下面我们看删改数据时都会有哪些情况，可以导致数据不一致的发生\n情况一：删改数据后，由于删缓存数据的操作失败而导致的缓存不一致\n情况二：删改数据后，由于多线程，还没来得及删缓存数据，而导致的缓存不一致\n如何解决？\n对于情况一：采用重试机制\n对于情况二：采用延迟双删\n\n重试机制\n\n可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）\n当删除缓存数据操作失败后，可以从消息队列中重新读取这些值，然后再次进行删除或更新\n\n\n延迟双删\n\n在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间，再进行一次缓存删除操作\n（线程 A sleep 的时间，就需要大于线程 B 读取数据再写入缓存的时间）\n之所以要加上 sleep 的这段时间，就是为了让线程 B 能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程 A 再进行删除\n# 伪代码redis.delKey(X)db.update(X)Thread.sleep(N)redis.delKey(X)# 第二次删除\n\n\n使用延迟双删+消息队列方式解决缓存一致性会有什么弊端吗？\n\n\n对业务代码的侵入比较大\n延迟时间不好控制，时间短可能导致双删没有作用；时间太长可能会降低系统并发度\n\n因此可以使用异步缓存更新机制：使用canal订阅binlog日志文件，在有数据更新后触发缓存更新重试机制。\n\n缓存雪崩\n缓存雪崩：指大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增\n\n导致缓存雪崩的原因：\n\n缓存中有大量的数据同时过期\nRedis缓存发生故障宕机\n\n解决措施：\n对于情况1，有两种解决办法：\n\n避免给大量的数据设置相同的过期时间（可以给EXPIRE设置时间时加一个1-3分钟的随机值）\n服务降级\n\n\n服务降级：\n对于非核心数据，暂停缓存服务，让其直接返回预定义的信息或者空值\n对于核心数据，继续提供服务\n\n对于情况2，也有两种解决办法：\n\n服务熔断或请求限流机制\n使用主从Redis集群，切换主库（比较好的办法）\n\n\n服务熔断：\n为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问\n\n服务熔断会终止所有的缓存服务，这当然是不好的\n\n请求限流机制：\n在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请 求被发送到数据库\n\n比如请求入口前端允许每秒进入系统的请求是 1 万个，其中，9000 个请求都能在缓存系统中进行处理，只有 1000 个请求会被应用发送到数据库进行处理\n缓存击穿\n缓存击穿：针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，导致访问该数据的大量请求，一下子都发送到了后端数据库\n\n解决办法：\n热点数据不要设置过期时间，让其能对热点数据持续提供服务\n缓存穿透\n缓存穿透：要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据\n\n发生缓存穿透的原因：\n\n业务层误操作：业务层不慎删除了缓存的数据和数据库的数据\n恶意攻击：专门访问数据库没有的数据\n\n解决措施：\n\n缓存空值或缺省值\n使用布隆过滤器快速判断是否存在，减轻数据库压力\n在前端的请求入口进行检测，把恶意的请求直接过滤掉\n\n布隆过滤器\n布隆过滤器：\n是由初值都为0的bit数组与N个哈希函数组合，可以快速判断数据是否存在\n\n如果一个数据被写入数据库，那么需要在布隆过滤器上标记它的存在：\n\n使用N个哈希函数分别计算这个数据的哈希值，得到N个哈希值\n\n将哈希值对bit数组的长度取模，得到每个哈希值在数组中的对应位置\n\n将对应的bit位置为1\n\n\n如果想要查一个数据是否存在：\n\n同样使用N个哈希函数计算其哈希值\n去对应位置查看bit数组对应位是否为1\n只要有一个不为1，那么这个数据就不存在\n\n缓存异常总结\n缓存污染\n缓存污染：指缓存中存放了很多访问次数很少，甚至只会被访问一次的数据，白白占用缓存的空间\n\n如何解决缓存污染？\n\nLRU可以解决缓存污染问题吗？\n\nLRU的确可以有效的留存最近访问的数据，但是在出现扫描式单次查询操作时，LRU策略显得无能为力\n\n扫描式单词查询：应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访 问过，所以 lru 字段值都很大\n\nRedis中的LFU算法LFU（least frequently used）可以看做LRU算法的一种优化，它会从两个值来判断将什么数据淘汰：\n\n数据访问的时效性（即访问时间到当前时间的长度）\n数据被访问的次数\n\nLFU判断依据：\n​        LFU算法会先根据数据被访问的次数进行筛选，如果访问次数相同，那么才会去比较访问的时效性，将访问更久的数据淘汰。\n这两个数据也存放在RedisObejct中，RedisObejct中的lru字段占用了3B（24b），将这个字段分开：\n\nldt值：lru字段的前16bit，表示数据的访问时间戳\ncounter值：lru字段的后8bit，表示数据的访问次数\n\n注意：\ncounter的值并不是每访问一次就增加1\n它的加1过程很复杂：\n\ncounter计数规则是：\n​        每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；\n​        把这个 p 值和一个取值范围在（0，1）间的随机数r值比大小，只有p值大于 r 值时，计数器才加 1\n\n我们不需要记住这个计数规则，官方给我们一个lfu_log_factor值取不同数据时，counter值的变化情况：\n\n可见，一般的项目，我们可以设置为10，就可以保证在1M点击的情况下也能保证区分度\n\n除此外，Redis还规定了counter的衰减机制：\n\nLFU 策略使用衰减因子配置项lfu_decay_time 来控制访问次数的衰减。\nLFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。 \n然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。\n\n热key问题\n热key指在缓存系统中，某些缓存key访问过于频繁，导致对于这些key需要额外进行性能处理的情况。\n\n一般处理热key问题的解决手段有三种：\n\n缓存预热：在系统启动或者业务低峰，主动缓存热门数据\n一致性hash：使用哈希环，将键散列在整个环上，可以使请求更均匀的分布在各个redis节点。\n数据分片：按照业务某个键分片，拆分缓存在不同的缓存节点上，减轻单个节点的压力。\n\n但是在实际应用中，热key可能是可预知的，也可能不可预知：\n\n可预知的热key：比如秒杀活动。在发布商品时就需要进行分布式缓存、本地缓存预热\n不可预知的热key：比如某个商品突然称为爆款。接入热点探测系统（定期上报key的查询次数，热点系统检测是否为热key），如果是热key立即建立本地缓存与缓存\n\n除此外，对于热key问题，即使有缓存手段也要做好兜底工作，做好限流熔断兜底。\n\n热key如何发现？\n\n1、在LFU算法下，可以使用--hotkeys\nredis-cli -p 6379 --hotkeys\n\n该参数能够返回所有 key 的被访问次数\n2、MONITOR命令\n实时查看 Redis 的所有操作的方式，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。\n对 Redis 性能的影响比较大，因此禁止长时间开启 MONITOR（生产环境中建议谨慎使用该命令）。\n3、业务代码是否有日志？\n大key问题\n怎么算是一个大key？\n\n\n如果是String类型：value超过1MB\n复合类型（List、Hash、Sort、Sorted Sort）：value元素超过5000个\n\n\n大key带来的副作用：\n\n\n占用内存大\n处理大key的网络IO消耗大：比如一个key是1mb，qps是1000，那么每秒就有1GB的流量处理，一般的千兆宽带是扛不住这个压力的\ndel困难：删除大key时，阻塞的时间会比较长\n\n\n如何发现大key？\n\n1、加--bigkeys参数：\nredis-cli -p 6379 --bigkeys -i 3# 每3秒执行一次大key扫描\n\n这种方式会扫描所有的key，且只能找出每种数据结构 top 1 bigkey（占用内存最大的 String 数据类型，包含元素最多的复合数据类型）\n实际上这种方式会调用scan命令进行执行\n2、使用scan命令\nSCAN 命令在遍历大量数据时不会阻塞服务器，但是返回的数据可能不是实时的。\nSCAN 0 MATCH user:* COUNT 100# 从游标 0 开始扫描，匹配所有user:开头的键，并且最多返回100个\n\n3、借助开源工具，分析RDB文件（前提使用了RDB的方式）\n4、借助平台的分析服务（阿里云Redis有bigkey实时分析）\n\n如何处理大key？\n\n\n手动清理：\n\nRedis 4.0+可以使用 UNLINK 命令来异步删除一个或多个指定的 key\nRedis 4.0 以下可以考虑使用 SCAN 命令结合 DEL 命令来分批次删除。\n\n\n分割：将一个bigkey分为多个小key，比如一个hash通过二次hash，拆分为多个hash\n\n采用合适的数据结构：例如，文件二进制数据不使用 String 保存、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）\n\n开启lazy-free： Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理\n\n\nRedis分布式锁查看此篇：redis分布式锁\n相关链接\n博客园\nb站狂神说\nRedis设计与实现\ncsdn图解epoll\n极客时间蒋德钧老师的redis课\n\n","categories":["Redis"],"tags":["Redis"]},{"title":"Hyperledger Fabric","url":"/2022/11/22/%E5%8C%BA%E5%9D%97%E9%93%BE/%E8%B6%85%E7%BA%A7%E8%B4%A6%E6%9C%AC/","content":"\n引言：Hyperledger Fabric：一个私有的需要许可的区块链\n\n\n\nHyperledger FabricHyperledger是Linux基金会的一个开源项目，负责超级账本项目，而Hyperledger fabric（以下简称fabric）是其中之一。\n\nHyperledger Fabric官方文档\n区块链技术指南\n\nFabric特性\n支持模块化：项目的各个细节都可以进行不同的实现（包括共识协议、身份认证、秘钥管理协议等）\n需要许可：与比特币和以太坊不同，需要认证许可（意味着Fabric需要成员之间有基本的信任）\nCFT共识协议：不一定要实现BFT，CFT也是可以的\n智能合约支持的语言：Java、Go、NodeJS\n\nPKI基本概念公钥基础结构PKI：一组互联网技术，或是一种认证标准，用于在网络中进行安全通信；（比如HTTPS的TLS安全传输层服务就是PKI的模式）\nPKI的核心思想是：使用数字证书来验证身份和加密\n\n数字证书是一种包含公钥和身份信息的文件，由证书授权中心CA签发和管理。\n公钥是用来加密或是解密的密码学工具，与私钥对应（对称加密与非对称加密）\n\n\nPKI可以类比为身份证系统：\n\n数字证书就像身份证，包含了个人信息和照片（相当于公钥）。\nCA就像派出所，负责颁发和管理身份证，并做了防伪措施（相当于数字签名）。\n当两个人交流时，他们可以互相出示身份证，以确认对方是谁，并进行加密通话（相当于加密数据，当然这个现实中做不到）。\n四个关键要素PKI 有四个关键要素：\n\n数字证书：最常见的证书类型是符合 X.509标准的证书\n公钥和私钥\n证书授权中心\n证书撤销列表\n\n公钥与私钥的认证流程对于公钥和私钥：如图所示\n\nbob 发送时：\n\n将消息 “我爱你” 先进行数字摘要（比如 MD5），生成一个摘要 Digest\n然后使用私钥对 Digest 加密，生成签名 Signature1\n发送时发送：消息 + Signature（两个都要发送）\n\nAlice 接收时：\n\nAlice 接收到的消息是 “我不爱你”，对这个消息也进行摘要，生成 Signature2\nAlice 使用公钥对 Signature 进行解密，得到 Signature1\n对比 Signature1 与 Signature2，发现不同，Alice 就知道消息被篡改了\n\n\nCA机构的运作流程证书授权中心CA一般是被网站、系统认可的一个机构，它负责颁布数字证书。\n\n证书授权中心向不同的参与者颁发证书（证书是一个包含了公钥和身份的文件）\n这些证书由 CA 进行签名，并将参与者的公钥绑定在一起\n因此：如果一个参与者信任这个CA机构，那么他也可以信任与它绑定在一起的证书内包含的公钥\n根CA与中间CA：CA有两种，中间CA可以分担一部分根CA的任务，也可以防止根CA的暴露；\n信任链：根CA与中间CA有信任链，并且中间CA可以与其他含有信任链的中间CA建立信任链\n\n在区块链网络Fabric中，提供了Fabric CA（Fabric网络中的根CA），用于管理区块链网络中用户和节点的身份证书\n证书撤销列表证书撤销列表CRL：保存撤销的证书的列表\n第三方机构验证另一方的身份，就需要检查CA的CRL确保证书是否被撤销\n这个检查不是必须的，但是不检查就会承担无效身份的风险\n成员服务提供者MSPFabric是一个私有的链：意思是不能像比特币或是以太坊那样允许任何节点加入，fabric需要基本的信任，因此fabric其实是一个私有的区块链（联盟链）\n因为需要基本的信任，所以Fabric区块链的参与者需要一种向网络中的其他参与者证实自己身份的机制从而在网络中进行交易（好像与CA的职责很类似）\n\nMSP与CA的区别：\n\nCA像是颁布信用卡的机构，CA可以颁布各式各样的信用卡；\nMSP是本商店承认的允许使用的信用卡列表\n\nPeer节点PeerPeer节点是网络中最重要的组成部分，Peer储存了账本和链码（链码和账本将网络中共享的流程和信息对应地封装起来）\nPeer与账本与链码的关系：一个Peer节点可以有多个账本与链码\n并且Fabric自动给账本与链码做了冗余备份，防止单点失效\n账本数量和访问账本的链码的数量之间没有固定的关系\n作用：\n\n存储链码与账本\n与APP或是管理员交互\n\nAPP与Peer\n如图A连接到P1想要通过链码S1来查询或更新账本L1：\n查询账本需要三步对话：\n\nAPP通过Fabric SDK连接到Peer节点上\n\nAPP调用安装在Peer上的链码（发送提案 Proposer）\n\nPeer使用提案调用链码\n链码通过查询账本生成查询（更新）的响应 Response\n\n\nPeer返回给A提案响应\n\n\n如果只是查询操作到此就结束了，更新账本的操作需要额外的两步：\n\nAPP从所有的响应中创建一笔交易 Transaction，发送交易给Order节点排序 Order\nOrder将交易打包为区块，发送给所有Peer节点\nPeer对区块进行验证，将交易提交到账本（一个独立的 Peer 节点目前是不能进行账本更新的，因为其他的 Peer 节点必须首先要同意这个变动（即达成共识））\n\n\n账本更新后，会生成一个回调事件，返回给App信息\n\n通道与Peer\n账本的基本单位是通道（Channel），每个通道内的成员可以共享账本，不同通道内账本则彼此隔离\n\n\n账本实际上在Peer上存储，但是逻辑上账本属于一个通道\n通道内组件可以进行私密交易\n通道可以理解为由物理Peer节点组成的逻辑结构（因为Peer提供了对channel的访问和管理的控制）\n\n\n PS：在某些其他区块链平台中，有群组的概念，其实就是为了实现通道的功能\n\n组织与Peer区块链网络是由多个组织来管理的，而不是单个组织；\n组织越多，这个网络也就越庞大，Peer就是组织的资源\n\n排序节点并没有在图上标识，除了排序节点外，其他一切都是非中心化的\n身份与PeerPeer 节点会有一个身份信息被分给他们，这是通过一个特定的证书认证机构CA颁发的数字证书（包括公钥和身份信息）来实现的\n\n如图所示，有两个组织、两个CA机构、两个MSP、一个channel、四个节点及他们的身份信息。\n\nPeer 节点连接到一个通道的时候，它的数字证书会通过通道MSP来识别它的所属组织\n一个 Peer 节点只能被一个组织所有，因此也就只能被关联到一个单独的 MSP（P1 和 P2 具有由CA1颁发的身份信息；P3和P4有CA2颁发的身份信息）\nMSP负责提供身份信息与组织的映射关系，还决定了一个Peer节点在组织中的角色及对网络中资源的访问权限，一个Peer只能关联一个MSP\n\n\nPS：\nPeer 节点、应用程序、终端用户、管理员以及排序节点如果想同一个区块链网络进行交互的话，必须要有一个身份信息和一个相关联的 MSP。\n我们使用身份信息来为每个跟区块链网络进行交互的实体提供一个名字——一个主角（principal）\n\n排序节点与Peer应用程序和 Peer 节点彼此互相交互来确保每个 Peer 节点的账本永远保持一致是通过以排序节点作为中心媒介的一种特殊机制。\n在一个账本的更新被应用到 Peer 节点的本地账本之前， Peer 节点会请求网络中的其他 Peer 节点来批准这次更新（即Peer节点需要达成共识）。\n\n想要更新账本的应用程序会被引入到一个三阶段的流程：\n（其实这里的三阶段流程类似于经典的三阶段提交流程，对比学习可以check这个链接）\n第一阶段：APP发送提案给Peer\n\nAPP生成一笔交易的提案，它把提案发送给一系列的被要求的节点（即背书节点）来获得背书。例如：图中的A1生成T1然后传输给背书节点P1与P2\n\n（名词解释：提案就是输入参数，比如执行一个交易所需要的输入；背书的意思就是支持，得到背书就是得到节点的支持）\n\n背书节点会将提案初步进行执行，但是并不更新刷新到账本，只是简单地为它提供签名然后将它返回给应用程序，即返回提案响应。例如：图中P1与P2使用交易与提案执行链码S1与S2，同意提案（即生成背书），并且返回响应给A1\n\n应用程序接收到有效数量的被签过名的提案响应之后，交易流程中的第一个阶段就结束。例如：A1收到两个背书响应E1与E2\n\n\n\n问题1：APP会选择那些Peer节点呢？\n\n取决于背书策略（背书策略在链码中指定）：策略定义了一个交易在能够被接收前，需要哪些节点为这个提案做背书\n\n问题2：得不到背书节点的支持会发生什么呢？\n\n得不到背书的提案，说明此时有不一致的情况发生，APP可以放弃此提案，如果坚持使用没有得到背书的提案在第三阶段会被拒绝\n\n问题3：链码在这一阶段是怎样的？\n\n三个阶段中，其实交易已经在第一节阶段执行了链码，在之后的过程中与链码无关\n第二阶段：排序并将交易打包到区块这一阶段的主人公是Order节点：\n\n接收背书提案并将其排序\n打包进区块\n\n排序节点需要做的就是将多个背书提案排序，打包为区块分发给各个Peer节点\n\n如图所示，A1、A2、A3将背书过的交易，发送给排序节点，排序节点将这些交易打包为一个块B2，排序的顺序是T1、T2、T3、T4、T5\n注意以下几点：\n\n虽然图中只有一个排序节点，但是排序节点可以不止一个\n排序的顺序不一定与排序服务接收的顺序相同\n排序节点打包后的区块是最终的，不像以太坊、比特币会产生账本的分叉\n\n第三阶段：验证与提交在排序节点发送打包后的区块给Peer后（分发），每个 Peer 节点上区块中的每笔交易都会被验证（即检查背书），失败的交易会被统计，成功的交易会被提交\n\n如图所示：O1将打包后的区块B2发送给P1与P2，P1与P2分别check区块内每一项交易的背书，视情况添加到账本中\n注意：\n\n排序节点分发区块给各个Peer时，不一定需要连接所有的Peer，Peer之间可以使用Gossip协议传输区块\n无效的交易仍然保留在排序节点创建的区块中\n\n智能合约与链码智能合约与链码的关系\n链码（或者智能合约）是对外的API接口，便于APP对账本进行查询或更新\n\n在Hyperledger Fabric中，经常混用智能合约与链码，一般我们认为两个逻辑一样，但是如果非要找一个区别：链码是一个更大的范围，链码包含多个智能合约，并且包含了打包部署的过程\n举个例子：比如vehicle chaincode链码包含多个智能合约car contract、boat contract、truck contract\n背书策略\n在以太坊与比特币中没有此概念，这是Fabric独有的。Hyperledger Fabric更真实地模拟了现实世界\n\n每个链码有一个背书策略，策略指明了区块链网络中哪些组织必须对一个给定的智能合约所生成的交易进行签名，以此来宣布该交易有效\n有效交易\n所谓有效交易：\n\n检查背书策略：是否有要求的组织的背书\n交易在背书节点签名时，交易的读集与世界状态的值匹配，并且中间过程中没有被更新\n\n\n注意：所有交易，不管是有效的还是无效的，都会被添加到区块链历史中，但是仅有效的交易才会更新世界状态。\n下面是一个例子：ORG1转让一辆车CAR1给ORG2\n\n如图所示，上半部分从左到右一次是APP、链码、背书策略；下半部分是一个交易\n所有的交易都有：一个标识符identifier、一个提案proposal、一个被一群组织签名的响应response\n标识符表名这是第三个交易t3，并且输入是CAR1、ORG1、ORG2，输出是&#123;CAR1.owner=ORG1，CAR1.owner=ORG2&#125;，来表示CAR1之前属于ORG1，现在属于ORG2。可以看到输出被ORG1与ORG2签名表示认可\n系统链码区块链系统定义了一些系统级别的链码：生命周期系统链码、配置系统链码、查询系统链码、背书系统链码、验证系统链码\n链码的生命周期官方文档，在开发完成链码后，链码的声明周期由以下四个步骤组成：\n\n打包链码：一个或者每一个组织完成。\n安装链码到peer节点：每一个使用链码或是为链码背书的组织\n为你的组织批准链码定义：每一个使用链码的组织\n提交链码定义到链上：一个组织即可\n\n1、打包链码此过程可以使用第三方工具，但是完全可以使用peer指令完成。\n打包的链码需要包括两个部分：\n\n打包的jar，比如mychaincode.jar需要打包为mychaincode.tar.gz\nmetadata.json文件，内容包括了链码的语言、路径、标签\n\n2、安装链码用peer所在组织的管理员身份Peer Administrator，在每个要执行和背书交易的peer节点上安装链码包。\n\n如果链码有错误，安装过程中会返回错误。\n在构建成功后，会返回一个包ID（之后会使用到，没保存也可以查询到）\n\n3、批准定义\n链码定义的作用：通过每个组织对链码定义的投票来决定，是否让这个链码运行在通道上。\n\n当通道成员批准一个链码定义，这个批准便作为一个组织在接受链码参数方面的投票，来决定是否允许这个链码运行在通道上\n链码定义的内容：\n\n名称：应用调用链码时使用的名称\n版本：一个版本号或者和给定链码包关联的值\n序列号：链码被定义的次数。这个值是一个整数，并且被用来追踪链码的更新次数。第一次安装并且同意一个链码定义，这个序列号会是1。当你下一次更新链码，序列号会是2。\n背书策略\n包ID（第二步得到的ID号）\n\n这个批准操作需要提交给排序服务，在此之后会分发给所有的 peer 节点\n在批准交易被成功提交后，同意的定义存储在你的组织中所有 peer 节点都可访问到的集合中（有多个 peer 节点，也只需要该组织同意一次）\n4、提交链码到链上（通道）当一个通道上的多数成员同意链码定义，就可以将链码提交到通道\n提交时需要以组织管理员的身份来提交Organization Administrator\n在链码定义已经提交到通道上后，链码容器会将安装到的 peer 节点上启动，来允许通道成员开始使用链码。\n账本账本fabric账本子系统包括两个组件：\n\n世界状态：记录给定时间点的账本状态（世界状态就是账本数据库）\n交易日志（即区块链）：记录产生当前世界状态的所有交易（历史记录）\n\n关于账本，需要注意几点：\n\n世界状态+交易日志才能组成完整的账本；\n世界状态其实是一个键值数据库（可以使用任何想使用的KV数据库）；\n交易日志是一个区块链\n区块链总是以文件实现，世界状态以数据库实现\n区块链是属于通道的\n\n世界状态与区块链的图示：\n\n世界状态就是一个KV数据库，Value可以是一个复杂的KV串。世界状态的实现可以使用 LevelDB（默认数据库，适合简单的KV对）和 CouchDB（适合JSON文档）\n\n区块链的第一块没有存放交易，称为创世区块，在Fabric中，创世区块包含了网络配置\n区块的结构\n区块由三部分构成：\n\n区块头\n区块编号：从0开始，每新增一个区块+1\n当前区块hash值\n前一个区块的hash值\n\n\n区块数据：包含一个有序的交易列表\n区块元数据：包含了区块被写入的时间，还有区块写入者的证书、公钥以及签名\n\n交易的结构\n交易的组成有5部分：\n\n头 Header：记录重要的元数据，比如链码名及版本\n签名 Signature：APP创建的加密签名，用来检查交易是否被篡改\n提案 Proposal：包含了智能合约的输入参数\n响应 Response：它是以读写集 （RW-set）的形式记录下世界状态之前和之后的值\n背书 Endorsements：一组签名交易响应（背书策略规定的一些组织的签名）\n\n排序服务Hyperledger Fabric的排序特点以太坊和比特币是依靠概率共识算法（如PoW、部分PoS），而Hyperledger Fabric是依靠确定性共识算法（如Paxos、Raft、PBFT），这意味着Fabric的账本不会产生分叉\n除此外，Fabric的排序节点将排序与背书分离，提高了排序的效率\n排序节点排序节点的职责：\n\n排序与分发：接收背书提案将其排序，以及打包为区块\n维护允许创建通道的组织列表（联盟）\n基本的访问控制：限制谁可以读写数据，以及谁可以配置数据\n\n排序服务的实现在2.0开始全面使用Raft，在之前的版本中使用过Kafka、Solo（现在都已经被淘汰）\n关于Raft算法可以参考另一篇博客：Raft\nFabric网络模型官网示例了一个基础的网络，这里介绍一下这个网络模型\n\n网络的成员\n组织：R1、R2、R3、R4表示不同的组织，比如三家银行与一个政府单位\nCA机构：CA1、CA2、CA3、CA4每个组织一个，不同组件使用证书表示自己来自于哪一个组织（通过MSP匹配CA与组织）\n节点：P1、P2、P3，网络中的实际运行者\n通道：C1、C2，需要相互交流的组织就分入同一个通道，通道由配置CC1、CC2进行配置\n账本的副本：L1、L2每个通道一个账本，存储在对应节点上\n排序服务：O4，很多分布式解决一致性的方案就是收集所有节点各自的操作然后统一进行排序，这里也一样\n网络配置：NC4，图中只有一个最初的网络配置\n成员服务提供者MSP：Membership Service Provider，匹配CA与组织\n智能合约：S5、S6\n客户端应用程序：A1、A2、A3\n\n一、初始化现在有R1、R2、R3、R4想要搭建一个HyperLedger fabric网络N，其中R4确定为网络初始者，有权利设置网络的初始版本\n\n如图所示，NC4是初始的网络配置，R4负责管理；网络初始时只提供最基础的排序服务O4；\n二、添加网络管理员现在给网络添加管理员R1，帮助R4一起管理网络\n\n如图所示，R4添加管理员R1，此时R1和R4都有管理NC4更新网络的权利\n三、定义联盟\n联盟：具有着共同命运的一个群组，一个联盟内的组织需要进行交流或是交易\n\n一般将拥有共同目标的组织归为一个联盟\n\n管理员可以定义联盟，如图，网络管理员（R1或是R4）将R1与R2归为一个联盟，这个配置存储在NC4中，如图中的X1\n四、为联盟创建通道\n联盟内通过通道进行交流；通道是一个主要的通信机制，通过它联盟的成员可以彼此通信。\n\n\n如图所示，NC4定义了联盟X1，现在为X1建立通道，R1和R2通过配置文件CC1管理和控制C1\n注意排序服务O1也连接到了C1，之后连接到C1的节点都可以与O4通信\n通道C1保证了R1与R2之间相互共享信息，但是对R3与R4保密\n五、添加节点与账本给网络中的C1通道添加节点P1，并且在P1上保存账本的副本L1\n\n节点是保存区块链账本副本的网络组件。账本L1物理在P1节点上，但是逻辑上来说他是C1的，因为通道与账本是一一对应的，而节点可以有很多个\nCA1给P1颁发证书，标识其为组织R1的组件\n六、安装与运行智能合约\n\n智能合约定义了对账本的所有通用的访问模式（就是定义了一组方法），比如A1可以通过调用S5的方法来查询账本的内容\n\n安装运行需要如下几步：\n\n安装：管理员R1许可，将智能合约S5安装到P1节点上\n实例化：在C1通道上实例化S5（因为此时连接到通道C1的组件（除了P1）并不知道S5的存在）实例化后，通道内的所有组件就都知道S5的存在\n调用：此时客户端应用程序A1可以使用智能合约S5通过节点P1访问账本L1\n\n注意以下几点：\n\n不需要在每个节点上都安装智能合约：当一个组织在一个通道中有多个 Peer 节点时，它可以选择哪个节点可以安装智能合约\n虽然同样都在C1通道上，但是智能合约S5的逻辑（即代码）只能被P1看到，而O4与A1都只能看到S5的输出与输出（实例化的是智能合约接口，而不是智能合约的实现）这也可以表明智能合约逻辑上在通道上，而物理上在节点上\n实例化需要附加信息：背书策略，只有在R1或R2背书的情况下，交易才能被接受并存储到账本L1上。\n调用：客户端应用程序A1通过向智能合约背书策略指定的组织R1、R2所属的节点发送交易提案来实现。\n智能合约：\n输入：交易提案\n输出：经过背书的交易响应\n\n\n\n在调用完成后，交易响应与交易提案打包在一起，形成一个完整背书的交易，他们会被分发到整个网络\n七、完善联盟网络结构联盟X1中，R2还没添加到网络中，现在为R2添加节点P2，并且在P2中备份账本L1并且安装合约S5，但是不需要再实例化了，实例化只需要发生一次（这也表示了合约逻辑上在通道上）\n\n现在A1和A2都可以使用节点P1或P2在C1上调用 S5，此时我们就完成了一个基本的网络结构，现在离我们最开始的图就差另外一个通道C2了，过程与此一致\n\n节点类型上面的示例网络中有几种节点类型：\n\n记账节点：每个节点都是记账节点，维护账本\n\n背书节点：每一个带有智能合约的节点都可以作为一个背书节点（没有安装），负责对应用的请求进行背书\n\n排序节点：排序节点负责对网络中所有交易进行排序处理，且整理为区块结构\n\n证书节点：提供标准的PKI服务，负责对网络中的所有证书进行管理（签发+撤销）\n\n领导节点：如果一个组织在一个通道有多个节点，那么会有一个领导节点，负责将交易从排序节点分发到该组织中的其他记账节点\n\n锚节点：如果一个节点需要同另外一个组织的一个节点进行通信的话，那么它可以使用对方组织的通道配置中定义的锚节点\n\n\nHyperledeger Fabric实践贴几个安装运行的文档：\n\n环境配置和文件下载\nfabcar网络测试\n链码安装测试\n\n环境安装最好先换源：换为清华源\n更改/etc/apt/sources.list的内容，并更新sudo apt update\n前置需求：git、docker、docker-compose、（go、Java、Node）\n\n关于fabric的下载，可以cvhttps://bit.ly/2ysbOFE的脚本在linux下运行：\n\n用浏览器访问网址：https://bit.ly/2ysbOFE\n将脚本复制粘贴到虚拟机或是服务器上，比如起名叫temp.sh\n将脚本其中的一些内容修改，找到以下位置，修改BINARIES为false，卡的原因就是因为这里去下载了两个文件，十分麻烦，我们自己去下载这两个文件，然后用ftp工具传输到虚拟机或服务器即可DOCKER=trueSAMPLES=trueBINARIES=false # 改了这里\n修改完成后运行脚本\n\nsudo chmod +x temp.sh./temp.sh\n\n\n注意这里的版本，要和你的脚本文件中的版本对应，我使用的是2.4.1和1.5.2\n\n\n用浏览器访问下载1：https://github.com/hyperledger/fabric/releases/download/v2.4.1/hyperledger-fabric-linux-amd64-2.4.1.tar.gz\n用浏览器访问下载2：https://github.com/hyperledger/fabric-ca/releases/download/v1.5.2/hyperledger-fabric-ca-linux-amd64-1.5.2.tar.gz\n\n\n将下载完的软件传输到虚拟机或是服务器上，可以借助xshell等工具\n将两个包解压到fabric-samples文件夹下，比如\n\ntar -zxvf hyperledger-fabric-linux-amd64-2.4.1.tar.gz -C ./fabric-samplestar -zxvf hyperledger-fabric-ca-linux-amd64-1.5.2.tar.gz -C ./fabric-samples\n\n这样就可以了\n运行测试网络参考官方文档\n进入目录查看命令帮助：\n# 进入test-network文件目录cd fabric-samples/test-network# 查看帮助./network.sh -h \n\n第一步：直接运行，注意查看你是否有docker的权限，如果没有记得加sudo\n# 删除先前运行的所有容器或工程./network.sh down# 启动网络（不会创建channel）./network.sh up# 这个命令会完成两步操作：# 1、使用cryptogen工具或者Fabric CA来创建Org1、Org2、Orderer组织的身份证书# 2、使用configtxgen工具来创建联盟，生成系统通道的创世区块genesis.block\n\n（下面是执行流程，可跳过）\n\n此时我们就创建了一个Fabric网络：有两个peer节点 + 一个排序节点orderer\n如果你仔细看此时的输出内容：\n# 测试网络使用 cryptogen帮我们创建认证证书Generating certificates using cryptogen tool # 创建 组织1的认证：使用./organizations/cryptogen目录下的配置文件生成证书Creating Org1 Identities+ cryptogen generate --config=./organizations/cryptogen/crypto-config-org1.yaml --output=organizationsorg1.example.com+ res=0\n\n这个文件./organizations/cryptogen/crypto-config-org1.yaml的具体内容：\nPeerOrgs:  # Org1  - Name: Org1    Domain: org1.example.com    EnableNodeOUs: true    Template: # 从零开始起名：peer%d，也可以自己定义名称      Count: 1      SANS:        - localhost    Users:       Count: 1 # 节点总数\n\n组织2的相同，这里再贴一个排序节点的：\nOrdererOrgs:  # Orderer  - Name: Orderer    Domain: example.com    EnableNodeOUs: true    # &quot;Specs&quot; spec的每一个条目由两部分组成hostname、commonname    # commonname默认是&#123;&#123;.Hostname&#125;&#125;.&#123;&#123;.Domain&#125;&#125;，在这里就是orderer.example.com    Specs:      - Hostname: orderer        SANS:          - localhost\n\n此时如果我们看test-network/organizations/这个目录，会发现多了2个目录，与我们的配置相同，并且目录下就产生了对应的CA证书\n├── ordererOrganizations│   └── example.com│       ├── ca│       ├── msp│       ├── orderers│       ├── tlsca│       └── users└── peerOrganizations    ├── org1.example.com    │   ├── ca    │   ├── connection-org1.json    │   ├── connection-org1.yaml    │   ├── msp    │   ├── peers    │   ├── tlsca    │   └── users    └── org2.example.com        ├── ca        ├── connection-org2.json        ├── connection-org2.yaml        ├── msp        ├── peers        ├── tlsca        └── users\n\n然后就是进行第二步，创建联盟以及创建初始块\n# 生成CCP文件Generating CCP files for Org1 and Org2 /home/hynis/hynis/fabric-samples/test-network/../bin/configtxgen# 生成创世块Generating Orderer Genesis block+ configtxgen -profile TwoOrgsOrdererGenesis -channelID system-channel -outputBlock ./system-genesis-block/genesis.block\n\n生成四个文件就是：connection-org1.json、connection-org1.yaml、connection-org2.json、connection-org2.yaml\n以connection-org1.json为例：\n&#123;    &quot;name&quot;: &quot;test-network-org1&quot;,    &quot;version&quot;: &quot;1.0.0&quot;,    &quot;client&quot;: &#123;        &quot;organization&quot;: &quot;Org1&quot;,        &quot;connection&quot;: &#123;            &quot;timeout&quot;: &#123;                &quot;peer&quot;: &#123;                    &quot;endorser&quot;: &quot;300&quot;                &#125;            &#125;        &#125;    &#125;,    &quot;organizations&quot;: &#123;        &quot;Org1&quot;: &#123;            &quot;mspid&quot;: &quot;Org1MSP&quot;,            &quot;peers&quot;: [                &quot;peer0.org1.example.com&quot;            ],            &quot;certificateAuthorities&quot;: [                &quot;ca.org1.example.com&quot;            ]        &#125;    &#125;,    &quot;peers&quot;: &#123;        &quot;peer0.org1.example.com&quot;: &#123;            &quot;url&quot;: &quot;grpcs://localhost:7051&quot;,            &quot;tlsCACerts&quot;: &#123;                &quot;pem&quot;: &quot;---省去公钥内容\\n---\\n&quot;            &#125;,            &quot;grpcOptions&quot;: &#123;                &quot;ssl-target-name-override&quot;: &quot;peer0.org1.example.com&quot;,                &quot;hostnameOverride&quot;: &quot;peer0.org1.example.com&quot;            &#125;        &#125;    &#125;,    &quot;certificateAuthorities&quot;: &#123;        &quot;ca.org1.example.com&quot;: &#123;            &quot;url&quot;: &quot;https://localhost:7054&quot;,            &quot;caName&quot;: &quot;ca-org1&quot;,            &quot;tlsCACerts&quot;: &#123;                &quot;pem&quot;: [&quot;---省去公钥内容\\n---\\n&quot;]            &#125;,            &quot;httpOptions&quot;: &#123;                &quot;verify&quot;: false            &#125;        &#125;    &#125;&#125;\n\n此时我们使用docker ps命令就可以看到三个镜像了：\n启动了orderer.example.com、peer0.org1.example.com、peer0.org2.example.com三个镜像\n\n（上面是执行流程，可跳过）\n第二步：创建一个通道\n# 创建通道./network.sh createChannel [-c 指定名称 默认为mychannel]\n\n第三步：然后我们在这个网络上启动一个链码（智能合约）\n# -ccn 指定链码名称# -ccp 指定文件路径# -ccl 指定编码的语言：go, java, javascript, typescript# 部署链码前安装jqsudo apt install jq# 部署Java链码./network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-java -ccl java\n\n\nPS：部署Go链码可能会遇到的问题解决办法\n但是直接运行上面的命令会报错，我们需要去对应的链码路径下安装其依赖\ncd ../asset-transfer-basic/chaincode-go/go mod vendor\n\n运行链码出错，你可能需要改一下测试文件对应位置的go.mod内的go版本1.14为1.13\n\n第四步：进入sudo bash执行以下操作\n然后配置几个与网络交互的环境\n# 1 $&#123;PWD&#125;表示pwd 当前路径位置export PATH=$&#123;PWD&#125;/../bin:$PATH# 2export FABRIC_CFG_PATH=$PWD/../config/\n\n添加组织1：\nexport CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=localhost:7051# ----分割线---# 其中 CORE_PEER_TLS_ROOTCERT_FILE与CORE_PEER_MSPCONFIGPATH# 指向组织1 organizations文件夹中的加密材料\n\n初始化账本：（如果此步失败，请进入sudo bash重试）\npeer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;InitLedger&quot;,&quot;Args&quot;:[]&#125;&#x27;\n\n查询账本内容：\npeer chaincode query -C mychannel -n basic -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27;\n\n输出：\n[&#123;&quot;ID&quot;:&quot;asset1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Tomoko&quot;,&quot;appraisedValue&quot;:300&#125;,&#123;&quot;ID&quot;:&quot;asset2&quot;,&quot;color&quot;:&quot;red&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Brad&quot;,&quot;appraisedValue&quot;:400&#125;,&#123;&quot;ID&quot;:&quot;asset3&quot;,&quot;color&quot;:&quot;green&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Jin Soo&quot;,&quot;appraisedValue&quot;:500&#125;,&#123;&quot;ID&quot;:&quot;asset4&quot;,&quot;color&quot;:&quot;yellow&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Max&quot;,&quot;appraisedValue&quot;:600&#125;,&#123;&quot;ID&quot;:&quot;asset5&quot;,&quot;color&quot;:&quot;black&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Adriana&quot;,&quot;appraisedValue&quot;:700&#125;,&#123;&quot;ID&quot;:&quot;asset6&quot;,&quot;color&quot;:&quot;white&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Christopher&quot;,&quot;appraisedValue&quot;:800&#125;]\n\n调用 asset-transfer (basic) 链码改变账本上的资产所有者：\npeer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset6&quot;,&quot;Christopher&quot;]&#125;&#x27;\n\n因为asset-transfer (basic)链码的背书策略需要交易同时被Org1和Org2签名，使用 --peerAddresses 标签来指向 peer0.org1.example.com 和 peer0.org2.example.com，因为网络TLS也被开启，所以也需要指定TLS证书\n然后我们使用另外一个身份：\n# Environment variables for Org2export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=localhost:9051\n\n查询：\npeer chaincode query -C mychannel -n basic -c &#x27;&#123;&quot;Args&quot;:[&quot;ReadAsset&quot;,&quot;asset6&quot;]&#125;&#x27;\n\n输出，发现&quot;appraisedValue&quot;比原来少了100\n&#123;&quot;owner&quot;:&quot;Christopher&quot;,&quot;color&quot;:&quot;white&quot;,&quot;size&quot;:15,&quot;appraisedValue&quot;:700,&quot;assetID&quot;:&quot;asset6&quot;&#125;\n\n\n第五步：关闭网络\n./network.sh down\n\n链码如何编写注意时刻参考以下两个文档：\n\nJava Doc链接\n官方的FabCar的Demo\n\n核心注解\n类注解：Contract注解（声明合约相关信息）、Default注解（标明这个合约是默认使用的合约）、DataType注解（表示该类可以作为返回或传递给事务函数的复杂类型之一）\n方法注解：Transaction注解（该方法为可调用的事务函数）\n属性注解：Property注解（可以指定属性的类型及规范，比如字符串可以要求匹配正则，数字要求在一定范围）\n\n关于@Contract注解，下面是详细的描述：\n// 标注在合约上，可以使用name给一个别名public @interface Contract &#123;    Info info() default @Info; // 见下面的Info注解    String name() default &quot;&quot;; // 提供替代的名称，而不是用类名    String transactionSerializer() default &quot;org.hyperledger.fabric.contract.execution.JSONTransactionSerializer&quot;;&#125;// 标注合约的相关信息public @interface Info &#123;    String title() default &quot;&quot;;    String description() default &quot;&quot;; // 描述    String version() default &quot;&quot;; // 版本号    String termsOfService() default &quot;&quot;; // 使用期限    License license() default @License; // 许可协议    Contact contact() default @Contact; // 联系人：可以描述email、name、url&#125;\n\n下面是官方的一个例子：\n@Contract(    name = &quot;FabCar&quot;,    info = @Info(        title = &quot;FabCar contract&quot;,        description = &quot;The hyperlegendary car contract&quot;,        version = &quot;0.0.1-SNAPSHOT&quot;,        license = @License(            name = &quot;Apache 2.0 License&quot;,            url = &quot;http://www.apache.org/licenses/LICENSE-2.0.html&quot;),        contact = @Contact(            email = &quot;f.carr@example.com&quot;,            name = &quot;F Carr&quot;,            url = &quot;https://hyperledger.example.com&quot;)))\n\n核心接口核心接口ContractInterface：所有的合约都应该实现这个接口\n实现该接口的类中，标有Transaction注释的每个方法都被视为事务函数，事务函数可以被调用，每个事务函数的第一个参数是Context。其他参数由开发人员自行决定。\n这个接口有三个比较重要的方法：\n\ncreateContext()：为context创建ChaincodeStub\n\nbeforeTransaction()：事务调用前执行一次\n\nafterTransaction()：事务调用后执行一次\n\n\n事务被调用的顺序是：createContext()  -&gt; beforeTransaction() -&gt; the transaction function -&gt; afterTransaction()\n核心类\nContext：在事务函数中使用，提供了上下文、使用世界状态的api\ngetStub()：获取ChaincodeStub对象\ngetClientIdentity()：获取ClientIdentity对象\n\n\nChaincodeStub：管理事务上下文，提供对状态变量的访问，并支持调用其他链码实现，这个类的方法很多，此处只列几个\nputStringState(key, value)：添加世界状态，不存在就添加，存在就更新\ngetStringState(key)：根据key获取value\ndelState(key)：删除key及对应的value\ngetStateByRange(startKey, endKey)：范围get，参数是两个string\ngetQueryResult()：富查询\n\n\n\n链码如何安装在链上\n官网\n中文版本\n\n整个过程为：1、启动网络。2、打包智能合约。3、安装链码。4、为链码提供定义，用于Fabric进行管理。5、将链码定义提交到通道。6、调用链码进行使用\nCaliper安装与使用Caliper：Fabric联盟链的性能测试工具\n\ncaliper官方文档\ncaliper中文文档\ncaliper的docker镜像\ncaliper-benchmark：一个含有示例的github仓库\ncaliper官方仓库\n\nCaliper基本架构与概念解释参考文档\n\n可以看到，Caliper需要三个配置文件，然后通过不断的对被测系统SUT进行测试，最后生成测试报告：\n\nSUT：特定被测系统（Caliper 是一种针对特定被测系统 (SUT) 生成工作负载并持续监控其响应的服务）\nbenchmark configuration：基准配置文件：告诉 Caliper 它应该执行多少轮，应该以什么速率提交 TX，以及哪个模块将生成 TX 内容\nnetwork configuration：网络配置文件：特定于 SUT 的。该文件通常描述 SUT 的拓扑结构、其节点所在的位置（它们的端点地址）、网络中存在的身份/客户端以及 Caliper 应部署或与之交互的智能合约\nworkload module：工作负载模块，基准测试的大脑。由于 Caliper 是一个通用基准框架，因此它不包含任何具体的基准实现（对于不同的链码实现不同的测试，是Nodejs文件）\nbenchmark artifacts：运行基准测试可能需要额外的工件，这些工件在不同的基准测试和运行之间可能会有所不同\n\n安装\n参考此篇文档caliper测试fabric\n\n先启动测试网络，部署一个js的链码\ncd test-network/./network.sh up createChannel./network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-javascript -ccl javascript\n\n\n需要npm环境、Node环境\nsudo apt install npm# n是node管理工具sudo npm install n -g# 安装node版本16.19.1，这是个包管理工具 类似于nvmsudo n 16.19.1\n\n在fabric-samples/目录下创建文件夹caliper-workspace及对应文件，文件结构如下所示\n./caliper-workspace/├── benchmarks│   └── myAssetBenchmark.yaml├── networks│   └── networkConfig.yaml└── workload    └── readAsset.js\n\n进入caliper-workspace目录：\ncd ./caliper-workspace# 安装calipernpm install --only=prod @hyperledger/caliper-cli@0.4.2# 绑定SDKnpx caliper bind --caliper-bind-sut fabric:2.2\n\n网络配置文件由五部分内容构成：\n\nname：配置的名称\nversion：使用的配置文件的版本\ncaliper：向 Caliper 指示目标 SUT\nchannels： Fabric 通道和部署在这些通道上的智能合约\norganizations：Fabric 组织的列表\n\n填充networkConfig.yaml文件内容：\nname: Calier testversion: &quot;2.0.0&quot;caliper:  blockchain: fabricchannels:  - channelName: mychannel    contracts:    - id: basicorganizations:  - mspid: Org1MSP    identities:      certificates:      - name: &#x27;User1&#x27;        clientPrivateKey:          path: &#x27;../../fabric-samples/test-network/organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/keystore/priv_sk&#x27;        clientSignedCert:          path: &#x27;../../fabric-samples/test-network/organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/signcerts/User1@org1.example.com-cert.pem&#x27;    connectionProfile:      path: &#x27;../../fabric-samples/test-network/organizations/peerOrganizations/org1.example.com/connection-org1.yaml&#x27;      discover: true\n\n文件中定义的第一个组织称为默认组织。在工作负载模块中，如果您未指定调用组织，则会使用默认组织。由于无论如何只定义了 1 个组织\n而且只需要指定至少一个组织，无需提供有关作为测试网络一部分的 Org2 的详细信息。只需提供一个组织是一种非常常见的模式。\n测试工作负载工作负载模块在基准测试回合中与部署的智能合约进行交互，对于不同的链码，此处的逻辑也有所区别，对于示例所用的链码来说，就是此处的文件readAsset.js\n&#x27;use strict&#x27;;const &#123; WorkloadModuleBase &#125; = require(&#x27;@hyperledger/caliper-core&#x27;);class MyWorkload extends WorkloadModuleBase &#123;    constructor() &#123;        super();    &#125;    async initializeWorkloadModule(workerIndex, totalWorkers, roundIndex, roundArguments, sutAdapter, sutContext) &#123;        await super.initializeWorkloadModule(workerIndex, totalWorkers, roundIndex, roundArguments, sutAdapter, sutContext);        for (let i=0; i&lt;this.roundArguments.assets; i++) &#123;            const assetID = `$&#123;this.workerIndex&#125;_$&#123;i&#125;`;            console.log(`Worker $&#123;this.workerIndex&#125;: Creating asset $&#123;assetID&#125;`);            const request = &#123;                contractId: this.roundArguments.contractId,                contractFunction: &#x27;CreateAsset&#x27;,                invokerIdentity: &#x27;User1&#x27;,                contractArguments: [assetID,&#x27;blue&#x27;,&#x27;20&#x27;,&#x27;penguin&#x27;,&#x27;500&#x27;],                readOnly: false            &#125;;            await this.sutAdapter.sendRequests(request);        &#125;    &#125;    async submitTransaction() &#123;        const randomId = Math.floor(Math.random()*this.roundArguments.assets);        const myArgs = &#123;            contractId: this.roundArguments.contractId,            contractFunction: &#x27;ReadAsset&#x27;,            invokerIdentity: &#x27;User1&#x27;,            contractArguments: [`$&#123;this.workerIndex&#125;_$&#123;randomId&#125;`],            readOnly: true        &#125;;        await this.sutAdapter.sendRequests(myArgs);    &#125;    async cleanupWorkloadModule() &#123;        for (let i=0; i&lt;this.roundArguments.assets; i++) &#123;            const assetID = `$&#123;this.workerIndex&#125;_$&#123;i&#125;`;            console.log(`Worker $&#123;this.workerIndex&#125;: Deleting asset $&#123;assetID&#125;`);            const request = &#123;                contractId: this.roundArguments.contractId,                contractFunction: &#x27;DeleteAsset&#x27;,                invokerIdentity: &#x27;User1&#x27;,                contractArguments: [assetID],                readOnly: false            &#125;;            await this.sutAdapter.sendRequests(request);        &#125;    &#125;&#125;function createWorkloadModule() &#123;    return new MyWorkload();&#125;module.exports.createWorkloadModule = createWorkloadModule;\n\n基准配置文件基准配置文件定义基准测试轮次并引用定义的工作负载模块。它将指定生成负载时要使用的测试工作人员的数量、测试轮次的数量、每轮的持续时间、每轮期间应用于事务负载的速率控制以及与监视器相关的选项。\nmyAssetBenchmark.yaml文件内容如下：\ntest:    name: basic-contract-benchmark    description: test benchmark    workers:      number: 2    rounds:      - label: readAsset        description: Read asset benchmark        txDuration: 30        rateControl:          type: fixed-load          opts:            transactionLoad: 2        workload:          module: workload/readAsset.js          arguments:            assets: 10            contractId: basic\n\n其中：比较关键的配置参数有，参考官方配置\n\n\n\n属性\n描述\n\n\n\ntest.rounds[i].txNumber\n每一个round，caliper需要提交的事务数量\n\n\ntest.rounds[i].txDuration\n每个round的执行时间（以s为单位）\n\n\ntest.rounds[i].rateControl\n速率控制器一般使用两种：固定速率fixed-rate与固定负载fixed-load\n\n\n例如这样的组合：txNumber + fixed-rate\ntxNumber : 500rateControl:  type: fixed-rate  opts:    tps: 25# 表示这一个round会以每秒25个的速度发送500个事务给系统\n\n再如这样的组合：txDuration+ fixed-rate\ntxDuration: 60rateControl:  type: fixed-rate  opts:    tps: 5# 表示这一个round会以每秒5个的速度发送60s，也就是总共发送3000个事务\n\n\n\n运行基准测试在caliper-workspace目录下，运行：\nnpx caliper launch manager --caliper-workspace ./ --caliper-networkconfig networks/networkConfig.yaml --caliper-benchconfig benchmarks/myAssetBenchmark.yaml --caliper-flow-only-test --caliper-fabric-gateway-enabled\n\n生成的报告将详细说明每轮基准测试的以下项目：\n\n名称 - 来自基准配置文件的回合名称\nSucc/Fail - 成功/失败交易的数量\n发送速率：caliper 发出交易的速率\n延迟（最大/最小/平均）：与发出交易和接收响应之间所用时间（以秒为单位）相关的统计数据\n吞吐量：平均每秒处理的事务数\n\n例如下表\n\n\n\nName\nSucc\nFail\nSend Rate (TPS)\nMax Latency (s)\nMin Latency (s)\nAvg Latency (s)\nThroughput (TPS)\n\n\n\nreadAsset\n2266\n0\n76.5\n1.19\n0.01\n0.03\n76.5\n\n\n","categories":["区块链"],"tags":["区块链","超级账本"]},{"title":"存储器管理","url":"/2020/12/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86/","content":"\n引言：操作系统中的存储器管理；\n更新：增加《CSAPP》中的知识点内容\n\n\n\n\n存储器管理操作系统很重要的一个工作，完成对存储器的控制与管理\n存储技术RAM\nRAM（Random Access Memory）随机访问存储器\n\n分为两类：静态与动态\nSRAM\nSRAM（Static RAM）：静态RAM\n\n所谓静态RAM，我认为静态的意思就是指其实现比较稳定：\n结构特点：\n​        其每一位都存放在一个双稳态的存储器单元内（这个存储器单元是由6个晶体管电路来实现的，具体实现无需了解）\n这种单元有这样一个特性：\n\n无限期的保持在两个不同的电压状态之一（即：不存在中间状态，要么是0，要么是1，任何一点点干扰都会使其偏向一边）\n\n（《CSAPP》中说到SRAM使用了一个倒摆来阐述这个特性）\n\n注意：\n1、这里的稳定，会在断电之后失效，所以SRAM会在断电后丢失数据\n2、也可以这么理解，只要有电SRAM就会永远保证其值不会发生变化\nDRAM\nDynamic RAM：动态RAM\n\n结构特点：其每一位都依靠一个电容来进行存储，每个单元都由一个电容和一个访问晶体管组成，相对于SRAM，DRAM就不是稳定的了：\n\nDRAM对干扰非常敏感，比如光照就可以让DRAM的电容改变\n\n（基于这个特性，数码照相机中的传感器就是DRAM实现的）\n\nDRAM不稳定，那它怎么去存数据？\n\n​        DRAM不稳定，但是他可以保证在10-100ms的时间内不改变，而CPU的时钟周期是纳秒级别的，所以对于CPU来说，DRAM足够稳定能存储数据了\n（可以这么理解，比如使用白纸黑字来记录数据，虽然数据不能永远存在，但对于人来说，已经足够使用了）\nSRAM与DRAM的对比\n\n\n种类\n晶体管数/单元\n相对访问时间\n是否稳定\n是否敏感\n相对花费\n应用\n\n\n\nSRAM\n6\n1x\n稳定\n不敏感\n1000x\n高速缓存\n\n\nDRAM\n1\n10x\n不稳定\n敏感\n1x\n主存，相机传感器\n\n\n注意到：\n\nSRAM速度大约是DRAM的10倍，而花费却是其1000倍\n高速缓存就是SRAM构成的\n主存就是由DRAM构成的\n\n传统DRAM的结构实现上面相当于简单介绍了一下DRAM，这里具体介绍一下DRAM的结构\n\n结构：\n\nDRAM芯片\n一个DRAM芯片由d个超单元组成（每个超单元可以传输1字节的信息）\n一个超单元由w个DRAM单元组成（每个DRAM单元可以传输1bit信息）\n超单元为一个方阵，r行，c列（d = r*c）\naddr：代表地址线，图中有两根，所以可以指向4位的地址\ndata：代表数据选，图中有8根，所以一次可以传输1字节信息（一个超单元）\n内部行缓冲区（下面会举一个例子）\n\n\n内存控制器：两个功能\n可以一次传入或传出w位\n可以给DRAM芯片发送行地址RAS与列地址CAS\n\n\n\n\n如何从DRAM（主存）读取一个数据？\n\n还是这个图，现在我们要从中读取（2,1）位置的数据\n\nCPU传来地址，要读取（2,1）的数据，那么内存控制器地址线传输地址，会先传输行地址2，在传输列地址1（分两次传输）\na）传输行地址2：此时读取行号为2的整行数据，读入到内部行缓冲区\nb）传输列地址1：从内部行缓冲区读取列为1的数据，通过数据线返回\n（此处使用CSAPP中的图）\n\n\n为什么要设计DRAM芯片为二维结构？\n\n这里涉及到一个折衷的问题：\n\n设计为4*4的结构：地址线使用2根即可，但是要传输行与列，意味着取一个数需要传入两次地址\n\n设计为1*16的结构：地址线需要4根，但是读一个数据，一次就可以读取到\n\n\n内存模块现在我们已经知道了DRAM芯片的构成，再向上抽象，DRAM芯片是构成内存模块的组成部分：\n\n​        可以看到此处的内存模块由8个DRAM芯片构成，每次读取数据时，会将相同的行列传到每一个DRAM芯片中，然后每一个DRAM芯片都会返回对应超单元的数据，分别组成数据的不同高度的位\n这样，就实现了一次读取64位的数据\n内存控制器\n此处我们总结一下内存控制器的作用：\n\n1、翻译地址：可以将CPU传来的地址，翻译为DRAM芯片的行与列\n2、多播：将行地址与列地址传输到每一个DRAM\n3、组合数据返回：将每一个DRAM芯片读出来的数据，组合起来，返回给CPU\nROM\nROM（Read Only Memory）只读存储器\n由于历史原因，称为只读存储器，但其实有的类型是可读可写的\n\n分类：\n\nPROM（Program ROM）：可编程ROM，只能被写一次；（内容原理是每一个单元都是一个熔丝，只能被高电流熔断一次）\nEPROM（Erasable PROM）：可擦写可编程ROM，允许1k次的重复写操作；（其实现原理是EPROM有一个石英窗口，允许紫外线进入，当紫外线照射到存储单元时，对应位置就变为0）\nEEPROM（Electrically EPROM）：电子可擦除ROM（直接在印制的电路卡上编程，可达10w次重写操作）\nFlash Memory：闪存，其实现基于EEPROM（固态硬盘就是闪存的一种实现）\n\n从CPU到主存\nCPU是如何读取一个数据到寄存器的呢？\n\n例如命令\nmovq A, %rax-- 此处的A代表一个地址，这种寻址方式也叫直接寻址\n\n要知道这个问题，我们先得大致了解CPU的指令是如何传递到主存的，如图：\n\n结构：\n\nCPU芯片内部有对外的总线接口\n系统总线：连接IO桥与CPU\n内存总线：连接IO桥与主存\n\n作用：IO桥负责将系统总线的电子信号转换为内存总线的电子信号\nmovq A, %rax-- 此处的A代表一个地址，这种寻址方式也叫直接寻址（movq的q代表读取一个64位的数据）\n\n此命令在执行中，就分为三个过程\n\nCPU总线接口将A通过系统总线——IO桥（完成电子信号转换）——内存总线传递到主存\n内存控制器将地址翻译为DRAM地址，取数据，传回\n总线接口读出数据，放入CPU寄存器中\n\n磁盘（机械硬盘）磁盘的结构要了解清楚几个概念：盘片、盘面、磁道、柱面、扇区\n\n一个机械硬盘内部的主要结构有：主轴、磁头、盘片\n间隙用来作为扇区与扇区之间的分隔符\n\n盘片会绕着主轴进行旋转，磁头可以在最内圈到最外圈之间摆动（这是机械运动，所以磁盘的读取速度十分缓慢）\n\n\n机械硬盘内部是真空密封的，打开就不能使用了，为什么？\n\n“读写头在磁盘表面一层薄薄的气垫上飞翔”，这个厚度很薄，即使很小的一粒灰尘，对于磁头来说都相当于摩天大楼，会发生读写头碰撞(head crash)\n有以下转换公式：\n1盘片 = 2 盘面 = 2*k 磁道 = 2*K*n 扇区 = 2*K*n*512 字节\n\n\n一个盘片的两面都刷油磁性介质，都可以存储数据\n磁道是一个圈（图中画的密度很均匀，但其实实际上不是均匀的）\n柱面就是很多个盘片相同的磁道组成的一个面\n\n一个磁盘可以存储的数据大小公式：\n磁盘容量 = 每扇区字节数 * 每磁道扇区数 * 每盘面磁道数 * 2 * 盘片数\n\n其中每磁道扇区数也可以换为每盘面柱面数，这两个值是相同的\n磁盘格式化一个新的磁盘是不能使用的，我们需要首先进行格式化\n格式化主要做的内容有：\n\n用标识扇区的信息填写扇区之间的间隙\n标识出有故障的柱面并且不使用\n每个区要预留一组柱面作为备用\n\n如果你使用Linux挂载过磁盘，那么其中一步就是格式化磁盘，换成可以使用的文件格式。\n磁盘如何存储数据磁盘的数据存放在了扇区内（一般一个扇区512字节）\n对于一个文件来说（磁盘通过这样的方式尽可能的优化查询时间）\n先会存放在一个扇区内，如果不够，就存放在同一个磁道内，如果还不够，就存放在同一个柱面内，如果还不够，就放在相邻的磁道内\n磁盘如何查找数据磁盘查找数据主要分为三个部分：\n\n寻道时间（磁头摆动到对应磁道的时间）\n旋转时间（磁盘旋转到期望扇区所需的时间，最坏的情况就得转一圈）\n传送时间（读取一个扇区所需要的时间）\n\n首先磁盘需要定位到对应磁道（此时磁臂会进行摆动），定位后要找到期望的扇区（磁盘疯狂旋转，会转到文件的开始位置），然后磁头开始读取对应位置的数据。\n磁盘调度算法考虑的就是使得平均寻道时间最短\n例如：假定磁盘有 200 个磁道，当前有 9 个访问者（进程）先后提出 I/O 操作，需要访问的磁道分别为：55，58，39，18，90，160，150，38，184；又假定当前磁头位置为 100\n先来先服务 / 先进先出优点：公平\n缺点：未考虑优化寻道，有大量进程访问者竞争一个磁盘，则这种算法的性能接近于随机调度\n\n最短寻道时间优先（SSTF）\n选择使磁头臂从当前位置开始移动距离最短的 I/O 访问者\n\n缺点：每次选择距离最短者同时，忽略了可能由于不断的有新的 I/O 请求进程加入到队列中，且与当前磁头位置较近，会使得原请求队列中的距离远的访问者总也得不到调度，产生所谓 “饥饿” 现象\n \n扫描算法 SCAN\n考虑了两个方面的问题：\n\n方向\n与当前磁道号距离最短\n\n作先由内向外运动，再由外向内运动，或反之。这样就避免了饥饿现象。\n由于这种算法使得磁臂移动规律颇似电梯的运动，因而也称为电梯算法。\n\n\n缺点：\n会导致某些请求会被延迟读写\n循环扫描算法 CSCAN\n为了减少这种延迟，**规定磁头单向读 / 写运动 (如只由内向外)，完成读写后立即返到最小 / 大磁道号的位置 (构成循环)**，再进行扫描。即 CSCAN 算法\n\n\n磁盘控制器磁盘的结构确实很复杂，但是磁盘设计厂商为我们做了一层抽象，以便于我们使用逻辑磁盘块\n\n磁盘控制器：维护着逻辑块号与实际磁盘扇区的映射关系\n\n如果OS要执行一个IO操作，读取磁盘的一个数据，那么OS就会发过来一个逻辑块号，然后磁盘控制器将其翻译为一个（盘面， 磁道， 扇区）的三元组\n然后磁盘就会去对应位置读取数据，然后将其复制到OS内核的一个小的缓冲区中，然后OS再去缓冲区读取数据\n固态硬盘一种基于闪存存储技术的存储介质\n固态硬盘的结构如下：\n\n\n闪存翻译层（作用类似于磁盘控制器）\n一个或多个闪存芯片\n一个闪存芯片由B个块组成\n一个块由P个页组成（一页大小约为512字节，类似于扇区）\n\n\n\n\n\n固态硬盘的特点：\n\n数据的读写是以页为单位读写的，如果要写一页，需要擦除该页所属的块\n随机读要比随机写快\n\n\n为什么写操作慢？\n\n\n写操作执行之前，需要擦除对应块的所有页的数据，才能进行写入\n如果要更改一页的部分数据，需要将这一页所属块的所有数据复制到一个新块后，才能对页进行修改\n\n但即使这么复杂，也比磁盘要快很多，这也是固态硬盘贵和重要的原因\n存储器的层次结构如图：\n\n\n其中主存储器与寄存器也被称为可执行寄存器\n对于可执行寄存器的访问：通过指令load与store\n对于辅存中的信息的访问：通过I/O中断机制\n\n\n高速缓存和磁盘缓存是用来缓和主存与寄存器、辅存和主存之间速度差异过大的不匹配的问题的，都利用了局部性原理\n寄存器与主存属于OS管理的部分，而辅存的管理属于设备管理\n\n存储管理的目的\n主存的分配和管理\n当用户需要内存时，系统为之分配相应的存储空间；不需要时，及时回收，以供其它用户使用。\n\n提高主存储器的利用率\n不仅能使多道程序动态地共享主存，提高主存利用率，最好还能共享主存中某个区域的信息\n\n“扩充”主存容量\n为用户提供比主存物理空间大得多的地址空间，以至使用户感觉他的作业是在这样一个大的存储器中运行\n\n存储保护\n确保多道程序都在各自分配到存储区域内操作，互不干扰，防止一道程序破坏其它作业或系统文件的信息。\n\n\n程序的装入和链接#include&lt;stdio.h&gt;int main()&#123;    printf(&quot;hello world!&quot;);    return 0;&#125;\n\n从编写一个hello world的c程序，到运行它，中间存在这些过程：\n\n编译\n链接\n装入\n\n程序的编译编译之前，其实还有一步预编译的过程，在这个过程中，会识别#include&lt;stdio.h&gt;，告诉预处理器读取系统头文件stdio.h的内容，并将它直接插入到程序的文本中，结果就得到了另一个C程序，这个c程序以.i作为文件的扩展名\n然后就开始进行编译过程，会将这个.i的程序翻译成.s的程序，这个程序是一个汇编语言程序，汇编器（例如as汇编器）会将这个.s文件翻译成真正的机器语言文件，结果产生一个.o文件，这个文件是一个二进制文件\n程序的链接此时我们有一个.o文件，注意我们的程序调用了printf函数，这个函数我们并没有实现，而是C编译器提供的标准C库的一个函数，这个函数存在于printf.o的单独预编译好了的目标文件中，我们必须将它与我们的程序进行合并\n根据链接时间的不同，程序链接分成三种：\n\n静态链接\n装入时动态链接\n运行时动态链接\n\n静态链接\n一种事先链接方式，即在程序运行之前，先将各目标模块及它们所需的库函数，链接成一个完整的装入模块(执行文件)，以后不再拆开\n\n需要克服两个问题：\n\n对相对地址进行修改\n各个地址都是从0开始计算的，假设有A、B、C三个模块，他们的长度分别为L、M、N，A调用了B，B调用了C，此时我们需要把B中的相对地址加L，C中的相对地址加L+M\n\n\n变换外部调用符号\n把B的起始地址变为L，C的起始地址变为L+M（原本都是0）\n\n\n\n静态链接后的文件就是可执行文件\n存在问题：\n\n不便于对目标模块的修改和更新（如要更新其中一个模块，需要打开装入模块）\n无法实现对目标模块的共享\n\n装入时动态链接\n将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的链接方式。\n\n优点：\n\n便于对目标模块的修改和更新，各个模块分开存放\n可以实现对目标模块的共享\n\n存在问题：        由于程序运行所有可能用的目标模块在装入时均全部链接在一起，所以将会把一些不会运行的目标模块也链接进去。如程序中的错误处理模块。\n运行时动态链接\n对某些模块的链接推迟到程序执行时才进行链接。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到装入模块上\n\n程序的装入\n由装入程序将装入模块装入内存中\n\n装入方式有以下几种：\n\n绝对装入方式\n可重定位装入方式\n动态运行时的装入方式\n\n绝对装入方式这是一种早期的方式，早期的计算机很小，程序员可以直接操作绝对地址，程序编译后直接就是绝对地址（不需要进行逻辑地址与绝对地址的转换）\n缺点：\n\n只适用于单道程序环境\n需要程序员熟悉内存\n程序的地址都是绝对地址，修改麻烦，一个的改动可能会让全部地址都得改动\n\n可重定位的装入方式\n在多道程序环境下，目标模块中的其它地址都是相对于0编址。\n应根据内存的当前情况，将装入模块装入到内存的适当位置。\n通常是把在装入时对目标程序中指令和数据的修改过程称为重定位\n\n例如，有一条指令load ax ,[2500]，将会把2500处的内容读取到ax寄存器中，此时的位置相对于0编址的，在程序被装入主存后，地址是从10000开始的，重定位就是此时将程序中的所有地址进行转换，将逻辑地址转换为绝对地址\n物理地址 = 基地址 + 相对地址\n注意：\n\n地址转换在装入时一次完成，不再允许程序再次更改位置\n\n动态运行时装入方式实际情况中程序在运行过程中它在内存中的位置可能经常要改变，重定位就不能满足我们的要求\n\n动态运行时装入方式：装入后并不立即将地址进行映射，而是将地址转换推迟到程序真正要执行的时刻\n\n因此， 装入内存后的所有地址都仍是相对地址\n注意：\n\n需要重定位寄存器的支持\n\n连续分配存储管理方式\n连续分配存储方式：早期的一种分配方式，为每一个用户程序分配一段连续的内存空间（程序中代码或数据逻辑地址相邻，分配的物理地址也相邻）\n\n连续分配方式可以分为四类：\n\n单一连续分配\n固定分区分配\n动态分区分配\n动态可重定位分区分配\n\n单一连续分配\n用于单用户、单任务的OS中。\n\n核心：\n\n将内存分为系统区（占内存低地址端）和用户区（占内存高地址端）\n采用静态重定位分配方式\n由装入程序检查其绝对地址是否越界，即可达到保护系统的目的。\n\n特点：\n\n简单\n只需要小量软硬件支持\n\n缺点：\n\n内存空间浪费大，各类资源利用率也不高\n程序运行受主存容量限制\n不支持多道\n\n固定分区分配\n分区分配方式：将内存分成若干个分区（大小相等/不相等），除OS占一区外，其余的每一个分区容纳一个用户程序\n分为两种：\n\n固定分区存储管理\n动态分区存储管理\n\n\n\n固定分区存储管理方式：\n将内存空间划分为若干个固定大小的分区，除OS占一区外，其余的一个分区装入一道程序。\n\n注意：分区的大小可以相等，也可以不等，但事先必须确定，在运行时不能改变。\n特点：\n\n分区大小及边界在运行时不能改变\n需要建立一张分区说明表或使用表（区号、大小、起止、状态）\n\n\n过程：\n当某个用户程序要被装入时\n\n内存分配程序检索分区说明表\n若找到满足要求的分区即分配分区，修改说明表状态，否则拒绝\n当程序运行完毕，释放对应分区，同时修改说明表状态\n\n特点：\n\n管理简单\n作业的大小并不一定与某个分区大小相等，从而使一部分存储空间被浪费，利用率低\n\n例如：\n\n\n动态分区分配方式\n在作业进入内存时，根据作业的大小动态地建立分区，并使分区的大小正好适应作业的需要。\n因此系统中分区的大小是可变的，分区的数目也是可变的。  \n\n特点：\n\n管理简单\n利用率有所提高\n\n核心：\n\n空闲分区表\n空闲分区链\n分区分配算法（专门一节来讨论）\n首次适应算法\n循环首次适应算法\n最佳适应算法\n最坏适应算法\n\n\n分配与回收操作\n\n空闲分区表登记系统中的空闲分区\n\n\n\n分区号\n大小KB\n起始地址KB\n状态\n\n\n\n1\n50\n85\n空闲\n\n\n2\n32\n155\n空闲\n\n\n3\n70\n275\n空闲\n\n\n空闲分区链​        用链头指针将系统中的空闲分区链接起来，构成空闲分区链。\n​        每个空闲分区的起始部分存放相应的控制信息(如大小,指向下一空闲分区的指针等).\n分区分配算法见后一节\n分配回收操作分配操作：按不同的算法有不同的分配操作\n​        核心步骤：m.szie - u.size &lt;= size\n​        m.size空闲分区大小，u.size请求的分区大小，size事先规定的不再切割的大小\n​        如果这个判断为true，则说明剩下的区域太小，干脆全部分配给该请求\n回收操作：\n\n系统根据回收分区的大小及首地址，在空闲分区表中检查是否有邻接的空闲分区，如有，则合成为一个大的空闲分区，然后修改有关的分区状态信息。\n\n有四种情况：\n\n哪种回收情况，回收后，空闲分区数目要减少一个？\n第三种情况\n可重定位分区分配方式\n零头（碎片）：内存中无法被利用的存储空间\n分为两类：\n\n内零头（内部碎片）：分配给作业的存储空间中未被利用的部分。如固定分区中存在的碎片。\n外零头（外部碎片）：系统中无法利用的小的空闲分区。如动态分区中存在的碎片\n\n\n为了消除零头，目前主要有两种办法：\n\n拼接（也叫紧凑或紧缩技术）\n离散分配方式\n\n拼接时机：\n\n分区回收时\n当找不到足够大的空闲分区且总空闲分区容量可以满足作业要求时\n\n功能：将内存中所有作业移到内存一端（作业在内存中的位置发生了变化，这就必须对其地址加以修改或变换即称为重定位），使本来分散的多个小空闲分区连成一个大的空闲区\n动态分区分配方式 + 拼接\n特点：\n\n可以充分利用存储区中的“零头/碎片”，提高主存的利用率\n但若 “零头/碎片”大多，则拼接频率过高会使系统开销加大。\n\n离散分配方式​    使用分页式存储管理方式\n分区分配算法（基于顺序搜索）首次自适应算法\n空闲分区（链）按地址递增的次序排列。\n在进行内存分配时,从空闲分区表/链首开始顺序查找,直到找到第一个满足其大小要求的空闲分区为止。\n然后再按照作业大小，从该分区中划出一块内存空间分配给请求者，余下的空闲分区仍留在空闲分区表（链）中。\n\n例题：\n​        系统中的空闲分区表如下，现有三个作业分配申请内存空间100K、30K及7K。给出按首次适应算法的内存分配情况及分配后空闲分区表\n\n\n\n区号\n大小\n起址\n\n\n\n1\n32k\n20k\n\n\n2\n8k\n52k\n\n\n3\n120k\n60k\n\n\n4\n331k\n180k\n\n\n解：\n​        由首次自适应算法可知，100k被分配到了分区3，30k被分配到了分区1，1k被分配到分区2，空闲分区表如下：\n​        大小要减去分配的大小，起止要加上分配走的大小\n\n\n\n区号\n大小\n起址\n\n\n\n1\n2k\n50k\n\n\n2\n1k\n59k\n\n\n3\n20k\n160k\n\n\n4\n331k\n380k\n\n\n特点：\n\n优先利用内存低地址部分的空闲分区,从而保留了高地址部分的大空闲区。\n\n但由于低地址部分不断被划分,致使低地址端留下许多难以利用的很小的空闲分区(碎片或零头),而每次查找又都是从低地址部分开始,这无疑增加了查找可用空闲分区的开销。\n\n\n循环首次适应算法\n又称为下次适应算法\n与首次适应算法的区别是：\n​        不再每次从空闲分区表/链首开始查找,而是从上次找到的空闲分区的下一个空闲分区开始查找\n\n例题：（还是这个题）\n​        系统中的空闲分区表如下，现有三个作业分配申请内存空间100K、30K及7K。给出按循环适应算法的内存分配情况及分配后空闲分区表\n\n\n\n区号\n大小\n起址\n\n\n\n1\n32k\n20k\n\n\n2\n8k\n52k\n\n\n3\n120k\n60k\n\n\n4\n331k\n180k\n\n\n解：\n​        区别在于从上次分配后的区号开始查找：\n\n\n\n区号\n大小\n起址\n\n\n\n1\n25k\n27k\n\n\n2\n8k\n52k\n\n\n3\n20k\n160k\n\n\n4\n301k\n210k\n\n\n特点：\n\n使存储空间的利用更加均衡，不致使小的空闲区集中在存储区的一端\n但这会导致缺乏大的空闲分区。\n\n最佳适应算法\n与首次适应算法区别在于：\n​        空闲分区表/链按容量大小递增的次序排列。（注意：每次还是从链首开始查找）\n\n例题：（还是这个题）\n​        系统中的空闲分区表如下，现有三个作业分配申请内存空间100K、30K及7K。给出按最佳适应算法的内存分配情况及分配后空闲分区表\n\n\n\n区号\n大小\n起址\n\n\n\n1\n32k\n20k\n\n\n2\n8k\n52k\n\n\n3\n120k\n60k\n\n\n4\n331k\n180k\n\n\n解：\n​        区别在于要按容量大小排序：排序后\n\n\n\n区号\n大小\n起址\n\n\n\n1\n8k\n52k\n\n\n2\n32k\n20k\n\n\n3\n120k\n60k\n\n\n4\n331k\n180k\n\n\n​        分配：\n\n\n\n区号\n大小\n起址\n\n\n\n1\n1k\n59k\n\n\n2\n2k\n50k\n\n\n3\n20k\n160k\n\n\n4\n331k\n180k\n\n\n特点：\n\n若存在与作业大小一致的空闲分区,则它必然被选中\n若不存在与作业大小一致的空闲分区，则只划分比作业稍大的空闲分区，从而保留了大的空闲分区\n但空闲区一般不可能正好和它申请的内存空间大小一样,因而将其分割成两部分时,往往使剩下的空闲区非常小,从而在存储器中留下许多难以利用的小空闲区（碎片或零头）。\n\n最坏适应算法\n与最佳适应算法区别在于：\n​        空闲分区表/链按容量大小递减的次序排列。（注意：每次还是从链首开始查找）\n\n例题：（还是这个题）\n​        系统中的空闲分区表如下，现有三个作业分配申请内存空间100K、30K及7K。给出按最佳适应算法的内存分配情况及分配后空闲分区表\n\n\n\n区号\n大小\n起址\n\n\n\n1\n32k\n20k\n\n\n2\n8k\n52k\n\n\n3\n120k\n60k\n\n\n4\n331k\n180k\n\n\n解：\n​        区别在于要按容量大小递减排序：排序后\n\n\n\n区号\n大小\n起址\n\n\n\n1\n331k\n180k\n\n\n2\n120k\n60k\n\n\n3\n32k\n20k\n\n\n4\n8k\n52k\n\n\n​        分配后：\n\n\n\n区号\n大小\n起址\n\n\n\n1\n194k\n317k\n\n\n2\n120k\n60k\n\n\n3\n32k\n20k\n\n\n4\n8k\n52k\n\n\n特点：\n\n总是挑选满足作业要求的最大的分区分配给作业。\n这样使分给作业后剩下的空闲分区也较大，可装下其它作业。\n但由于最大的空闲分区总是因首先分配而划分，当有大作业到来时，其存储空间的申请往往会得不到满足。\n\n分区的存储保护\n存储保护：\n​        为了防止一个作业有意或无意地破坏操作系统或其它作业\n\n保护方法：\n\n界限寄存器方法\n上下界寄存器方法\n基址、限长寄存器方法\n\n\n存储保护键方法\n\n界限寄存器方法\n存储保护键方法​        给每个存储块分配一个单独的保护键，它相当于一把锁。进入系统的每个作业也赋予一个保护键，它相当于一把钥匙。当作业运行时，检查钥匙和锁是否匹配，如果不匹配，则系统发出保护性中断信号，停止作业运行\n对换（交换 Swapping）\n​        将暂时不用的某个进程及数据（首先是处于阻塞状态优先级最低的）部分（或全部）从内存移到到外存（备份区或对换区，采用连续分配的动态存储管理方式）中去，让出内存空间，同时将某个需要的进程调入到内存中，让其运行。\n\n交换的类型：\n\n整体对换（其实就是处理器调度中的中程调度，也叫进程对换）\n部分对换（以“页”或“段”为单位进行内外存调度）\n\n为了实现进程对换，OS必须实现：\n\n对换空间的管理\n进程的换入\n进程的换出\n\n对换空间的管理OS把外存分为：\n\n文件区\n文件区主要用来长期存放文件，采用离散分配方式\n\n\n对换区\n对换区用于存放从内存换出的进程，短暂存储，为了提高换入换出速度，使用连续分配方式\n\n\n\n进程的换入与换出换出：\n\n时机：一进程创建子进程，无足够内存\n过程：\n选择处于阻塞状态且优先级最低的进程\n启动磁盘，将该进程的程序和数据传送到磁盘的对换区\n回收该进程所占用的内存空间，修改PCB\n\n\n\n换入：\n\n过程：\n系统定时地查看所有进程的状态，从中找出“就绪”状态但已换出的进程。**(静止就绪)**\n选择换出时间最久进程\n将其换入\n\n\n\n分页存储管理方式在第五节，我们知道，连续分配存储方式虽然简单，但是会产生很多碎片，使用拼接技术代价极高，所以我们可以使用离散分配的方式\n\n分页式存储管理（主流）\n分段式存储管理\n段页式存储管理\n\n\n在分页存储管理方式中，如不具备页面对换功能，不支持虚拟存储器功能，\n则在调度作业运行时，必须将它的所有页面一次调入内存，且在运行过程中页必须一直驻留内存。\n若内存没有足够的块，则作业等待，\n这种存储管理方式称为纯分页或基本分页存储管理方式 \n\n基本思想\n将用户进程的逻辑地址空间划分为若干个大小相等的区域，称为页，从0开始编号\n内存空间也分成若干个与页大小相等的区域，称为块（页框），从0开始编号\n\n在为进程分配内存时，以块为单位,将进程中若干页装入到多个不相邻的块中，最后一页常装不满一块而出现页内碎片。\n如：作业9KB，页面大小2KB，划分5个页，最后一页只有1KB。\n注意：需要CPU的硬件支持——地址变换机构\n核心内容地址结构逻辑地址：页号 + 位移量（页内地址）\n\n页号的大小决定地址空间有多少页，例如页号有20bit，那么就允许有2^20即1M页\n位移量决定每页的大小，例如页内地址有12bit，那么每页就有2^12即4KB\n\n物理地址：块号 + 块内位移\n\n块号说明内存有多少块\n块内位移与逻辑地址的页内地址相等\n\n例如：页面大小为1K；用户作业的逻辑地址为：1027(十进制)；\n​        那么它可以这么表示（1,3） 1027 - 1024 =3\n有如下公式：\n逻辑地址A页面大小L页号P页内地址dP = INT [A / L]d = [ A ] MOD L\n\n例题：设有一页式存储管理系统，向用户提供的逻辑地址空间最大为16页，每页2048B，内存总共有8个存储块，试问逻辑地址至少应为多少位？内存空间有多大？\n解：\n​        逻辑地址空间最大为16页，即2^4，那么页号就占4bit\n​        每页2048B，即2KB，那么页内位移与块内位移就是11bit\n​        内存有八个存储块，块号就有2^3，那么块号就有3bit\n​    所以解得：逻辑地址有15bit，内存空间有8*2KB，即16Kb\n页面大小由地址结构（逻辑）决定(页内位移的位数)\n如果页面较小：\n\n页面数多，页表长\n页面换进换出效率低下\n\n如果页面较大：\n\n增加页面碎片，不利于内存利用率\n\n所以页面大小通常为2的幂次\n页表\n\n记录了页面在内存中对应的块号\n页表一般放在内存中\n页表的基址及长度由页表寄存器（[页表始地+页表长度]）给出\n未执行时存放在PCB中\n\n\n访问一个字节的数据/指令需访问内存2次(页表一次,内存一次),所以出现内存访问速度降低的问题\n\n地址变换机构能将用户地址空间中的逻辑地址变换为内存空间中的物理地址\n分为：\n\n基本的地址变换机构\n具有快表（TLB）的地址变换机构\n\n基本的地址变换机构\n例1： 若在一分页存储管理系统中，某作业的页表如表所示，已知页面大小为1024B，试将逻辑地址1011，2148，5012转化为相应的物理地址？画出其地址转换图。\n\n\n\n页号\n块号\n\n\n\n0\n2\n\n\n1\n3\n\n\n2\n1\n\n\n3\n6\n\n\n解：    由页号共四页可知，页号占2bit，页内地址为10bit\n​           块号有第6页，说明页号至少为3bit，块内地址10bit\n​            1011 = 0011 1111 0011，可以得出页号为0，页内地址为11 1111 0011\n​            查表，可知页号0对应块号2，所以物理地址为 0 1011 1111 0011（0BF3H）   \n​        2148同理，5012越界，产生越界中断\n具有快表（TLB）的地址变换机构为提高地址变换速度，加了TLB\n\n一种特殊告诉缓存存储器\n内容为页表的一部分\nCPU产生的逻辑地址页首先在快表中查询，若找到就找出对应物理块；否则再按原有结构寻找\n\n\n信息共享分页存储管理，虽然解决了零头问题，但是不利于页面共享\n若共享数据与不共享数据划在同一块中，则：有些不共享的数据也被共享，不易保密。\n实现数据共享的最好方法——段式存储管理\n信息保护页式存储管理系统提供了两种方式：\n\n地址越界保护：页号&lt;页表长度（页表寄存器）\n在页表中设置保护位：定义操作权限：只读，读写，执行等\n\n分段存储管理方式为了满足用户的一系列需求：\n\n方便编程\n按逻辑关系分为若干个段，每个段从0编址，并有名字和长度，访问的逻辑地址由段名和段内偏移量决定\n\n\n信息共享\n共享是以信息为逻辑单位，页是存储信息的物理单位，段却是信息的逻辑单位\n\n\n信息保护\n动态链接：动态链接以段为单位。\n动态增长\n\n基本思想空间划分：\n​        将用户作业的逻辑地址空间划分成若干个大小不等的段（由用户根据逻辑信息的相对完整来划分）。\n​        各段有段名（常用段号代替），首地址为0。\n内存分配：\n​        在为作业分配内存时，以段为单位，分配一段连续的物理地址空间；段间不必连续。\n注意：\n\n整个作业的逻辑地址空间是二维的，其逻辑地址由段号和段内地址组成；物理地址空间是一维的\n需要CPU的硬件支持（地址变换机构）\n\n段表\n记录了（段号，段长，基址）\n段表记录了段与内存位置对应关系\n保存在内存中\n有段表寄存器（段表始址 + 段表长度）\n访问一个数据也需要访问2次内存\n\n例：采用段式存储管理的系统中，若地址用24位表示，其中8位表示段号，则允许段的最大长度是___\n24-8=16 段的最大长度2^16\n注意：\n\n在分段存储管理中，要检查两次越界\n检查段号是否越界\n检查段内地址是否越界\n\n\n\n例如：段表为\n\n\n\n段号\n内存起始地址\n段长\n\n\n\n0\n210\n500\n\n\n1\n2350\n20\n\n\n2\n100\n90\n\n\n3\n1350\n590\n\n\n有下表：\n\n\n\n0\n430\n\n\n\n2\n120\n\n\n求表中逻辑地址对应的物理地址\n解：由0查段表，得到内存起始地址为210，段长为500，430&lt;500，所以物理地址为430+210=640\n​        由2查段表，得到内存起始地址为100，段长为90，由于90&lt;120，所以段内地址越界\n优缺点优点：\n\n便于程序模块化处理；段的保护容易\n便于处理动态的数据结构；可增、减分段长度\n便于动态链接。每一分段是一组有意义的信息或具有独立功能的程序段\n便于共享分段。\n\n缺点：\n\n和分页管理一样，处理机要为地址变换花费时间，要为段表提供附加的存储空间，这使操作系统复杂化\n为满足分段的动态增长和减少外零头，要采用拼接手段\n产生碎片(外部碎片)。\n\n分段和分页的主要区别\n\n\n\n页式存储管理\n段式存储管理\n\n\n\n目的\n实现非连续分配,  解决碎片问题(页内碎片)\n更好满足用户需要\n\n\n信息单位\n页（物理单位）\n段（逻辑单位）\n\n\n大小\n固定（由系统定）\n不定（由用户程序定）\n\n\n内存分配单位\n页\n段\n\n\n作业地址空间\n一维\n二维\n\n\n优点\n有效解决了碎片问题  有效提高内存的利用率\n更好地实现数据共享与保护  段长可动态增长  便于动态链接\n\n\n着重注意：\n\n页信息的物理单位，段是信息的逻辑单位\n作业地址空间，分页是一维，分段是二维\n\n后来结合段式与页式，有了段页式存储管理方式：\n\n将内存等分为块，程序按逻辑模块分为若干段\n只会产生内零头\n\n虚拟存储器程序想要运行就得全部装入内存中去，\n\n但是有的程序很大，所需的内存空间大于内存总容量；\n\n有大量作业运行，但内存不够所有作业\n\n\n此时提出了虚拟存储器\n虚拟存储器的最大容量由计算机的地址结构决定\n常规存储器管理方式的特征\n一次性：作业在运行前需一次性地全部装入内存。将导致上述两问题。\n驻留性：作业装入内存后，便一直驻留内存，直至作业运行结束。\n\n局部性原理\n一较短时间内，程序的执行仅限于某个部分，相应地，它所访问的存储空间也局限于某个区域\n分为：\n\n时间局部性：刚被访问的数据可能不久后被再次访问\n空间局部性：访问后的存储单元的附加很可能被访问\n\n\n所以，此后没有必要将程序全部装入内存中去，而是如果要访问的页不在内存才去将该页调入内存\n\n虚拟存储器：是指仅把作业的一部分装入内存便可运行作业的存储管理系统，它具有请求页(段)调入功能和页（段）置换功能，能从逻辑上对内存容量进行扩充，其逻辑容量由外存容量和内存容量之和决定，其运行速度接近于内存，成本接近于外存\n\n请求分页（段）存储管理方式在分页（段）方式上，增加了\n\n请求调页（段）功能：访问的页面不存在时要求将页面调入内存\n页面（分段）置换功能：将当前不需要运行的页面换入外存，需要用的换入内存\n\n特征\n多次性（最基本）：虚拟存储器最重要的特征。指一个作业被分成多次调入内存运行。\n对换性：允许在作业运行过程中进行换进、换出。换进、换出可提高内存利用率。\n虚拟性（最本质）：从逻辑上扩充内存容量，使用户所看到的内存容量远大于实际内存容量\n\n虚拟性以多次性和对换性为基础，而多次性和对换性又是离散分配为基础\n实现\n\n\n\n分页请求系统\n分段请求系统\n\n\n\n基本单位\n页\n段\n\n\n长度\n固定\n可变\n\n\n分配方式\n固定分配\n动态\n\n\n复杂性\n简单\n较复杂\n\n\n页表机制\n\n\n页号\n块号\n状态位\n访问字段\n修改位\n外存地址\n\n\n\n\n\n\n\n\n\n\n\n新增加：\n\n状态位：表示该页是否调入内存\n访问字段：记录本页最近一段时间内的访问次数\n修改位：表示调入内存后是否被修改\n外存地址：指出外存上的地址\n\n缺页中断机制当访问的页不在内存时（通过判断状态位），就产生缺页中断\n缺页中断与一般中断的区别：\n\n在指令执行期间产生和处理中断信号。缺页中断要立即处理\n一条指令在执行期间，可能产生多次缺页中断。\n\n地址变换机构\n例题： 某虚拟存储器的用户空间共有32个页面，每页1KB，主存16KB。假定某时刻系统为用户的第0、1、2、3页分别分配的物理块号为5、10、4、7，试将虚拟地址0A5C变换为物理地址。\n解：32个页面 &gt;&gt; 页号为2^5 &gt;&gt; 页号占5bit\n​        每页1kb&gt;&gt;页内地址与块内地址为&gt;&gt;10bit\n0A5C转换为二进制为000 1010 0101 1100，页号为2，查出块号为4，即0100\n结果为0010010 0101 1100 = 125C\n请求分页页面置换算法\n用来选择换出页面的算法\n页面置换算法的优劣直接影响到系统的效率，若选择不合适，可能会出现抖动现象\n抖动：\n​        刚被淘汰出内存的页面，过后不久又要访问它，需要再次将其调入，而该页调入内存后不入又再次被淘汰出内存，然后又要访问它，如此反复\n\n最佳置换算法（OPT）\n选择永远不再需要的页面或最长时间以后才需要访问的页面予以淘汰\n是一种理论算法，不可实现，这种方法用来衡量其他算法的质量\n\n例如：假定系统为某进程分配了3个物理块，进程运行时的页面走向为 1,2,3,4,1,2,5,1,2,3,4,5，开始时3个物理块均为空，计算采用最佳置换页面淘汰算法时的缺页率？\n\n\n\n页面走向\n1\n2\n3\n4\n1\n2\n5\n1\n2\n3\n4\n5\n\n\n\n物理块1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n3\n3\n3\n\n\n物理块2\n\n2\n2\n2\n2\n2\n2\n2\n2\n2\n4\n4\n\n\n物理块3\n\n\n3\n4\n4\n4\n5\n5\n5\n5\n5\n5\n\n\n缺页\n缺\n缺\n缺\n缺\nH\nH\n缺\nH\nH\n缺\n缺\nH\n\n\n解：如表格所示，缺页率为7/12（H代表命中）\n先进先出置换算法（FIFO）\n最先进来的页面最先换出去\n\n还是这个题：\n例如：假定系统为某进程分配了3个物理块，进程运行时的页面走向为 1,2,3,4,1,2,5,1,2,3,4,5，开始时3个物理块均为空，计算采用最佳置换页面淘汰算法时的缺页率？\n\n\n\n页面走向\n1\n2\n3\n4\n1\n2\n5\n1\n2\n3\n4\n5\n\n\n\n物理块1\n1\n1\n1*\n4\n4\n4*\n5\n\n\n5\n5*\n\n\n\n物理块2\n\n2\n2\n2*\n1\n1\n1*\n\n\n3\n3\n\n\n\n物理块3\n\n\n3\n3\n3*\n2\n2\n\n\n2*\n4\n\n\n\n缺页\n缺\n缺\n缺\n缺\n缺\n缺\n缺\n\n\n缺\n缺\n\n\n\n解：如表格所示，缺页率为9/12\n假如本题我们再给一个物理内存块，结果是：\n\n\n\n页面走向\n1\n2\n3\n4\n1\n2\n5\n1\n2\n3\n4\n5\n\n\n\n物理块1\n1\n1\n1\n1*\n\n\n5\n5\n5\n5*\n4\n4\n\n\n物理块2\n\n2\n2\n2\n\n\n2*\n1\n1\n1\n1*\n5\n\n\n物理块3\n\n\n3\n3\n\n\n3\n3*\n2\n2\n2\n2*\n\n\n物理块4\n\n\n\n4\n\n\n4\n4\n4*\n3\n3\n3\n\n\n缺页\n缺\n缺\n缺\n缺\n\n\n缺\n缺\n缺\n缺\n缺\n缺\n\n\n10/12，多给了一块内存块，缺页率还增加了！这就是Belady异常\n\nBelady现象是指：采用FIFO算法时，如果对—个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多但缺页率反而提高的异常现象。\n\n最近最久未使用算法（LRU）\nleast recently used：选择最近没有使用的页面进行淘汰（依据局部性原理）\n需要硬件的支持：\n\n栈：栈顶始终是最新被访问页面的编号，而栈底则是最近最久未使用页面的页面号\n寄存器：寄存器每一位代表一个页，置为1代表刚被访问，每隔一段时间（100ms）将寄存器右移一位\n\n\n还是此题：\n例如：假定系统为某进程分配了3个物理块，进程运行时的页面走向为 1,2,3,4,1,2,5,1,2,3,4,5，开始时3个物理块均为空，计算采用最佳置换页面淘汰算法时的缺页率？\n\n\n\n页面走向\n1\n2\n3\n4\n1\n2\n5\n1\n2\n3\n4\n5\n\n\n\n物理块1\n1\n1\n1*\n4\n4\n4*\n5\n5\n5*\n3\n3\n3\n\n\n物理块2\n\n2\n2\n2*\n1\n1\n1*\n1\n1\n1*\n4\n4\n\n\n物理块3\n\n\n3\n3\n3*\n2\n2\n2*\n2\n2\n2*\n5\n\n\n缺页\n缺\n缺\n缺\n缺\n缺\n缺\n缺\nH\nH\n缺\n缺\n缺\n\n\n解：如表格所示，缺页率为10/12\n淘汰算法的性能评价缺页率：f = 缺页次数 / 总次数 \n命中率：H = 命中次数 / 总次数\n抖动问题：导致系统效率急剧下降的主辅存之间的频繁的页面置换现象称为抖动\n影响缺页中断率的因素\n页面大小：页面大一点有助于缺页率降低，但是会使浪费增大\n分配给作业的主存：主存越大，减少却也次数（任何程序在局部性放入主存时都有一个临界值的要求，这个主存要求的临界值被称为工作集）\n\n总结\n“内零头”：是指分配给作业的存储空间中未被利用的部分。“外零头”：是指系统中无法利用的小存储块。\n\n\n固定分区分配：产生“内零头”\n可变分区分配：产生“外零头”\n页式虚拟存储器：产生“内零头”\n段式虚拟存储器：产生“外零头”\n段页式：产生“内零头”\n\n","categories":["操作系统"],"tags":["操作系统","存储器管理","请求分页方式"]},{"title":"树与类树","url":"/2024/08/17/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91%E4%B8%8E%E7%B1%BB%E6%A0%91/","content":"\n引言：树与类似树的数据结构，做一个总篇（BST、AVL、红黑树、线段树、TriE、并查集、堆）\n\n\n\n\n树\n本文的内容来自于自己的其他博客（大约在2020年写的），最近正好在复习数据结构相关内容，此处做一个树与类树的相关整理。\n\n二叉树树的基本结构，不过多叙述：\n\n具有天然的递归结构：每个结点的左、右子树都是二叉树\n\n\n\n满二叉树：除了叶子结点外，每个结点都有两个孩子\n\n完全二叉树：除最后一层，每个节点都有两个孩子，而且最后一层的孩子尽量靠左\n\n\n\nBST\n首先是一棵二叉树\n独有的特点：每一个节点的值\n大于左子树所有结点的值\n小于右子树所有结点的值\n\n\n每一棵子树也是二分搜索树\n\n\n注意：存储的元素必须具有可比较性，存储一个int类的数据，当然可以比较大小，但是存储一个学生类、车类等实体类，我们必须规定它的比较方式，比如学生可以按年龄比较等等\n\n二分搜索树代码Java实现一个BST树\n//泛型必须满足可比较性，所以继承了Comparable接口public class BinarySearchTree&lt;E extends Comparable&lt;E&gt;&gt; &#123;    private class Node &#123;        public E e;        public Node left, right;        public Node(E e) &#123;            this.e = e;            left = null;            right = null;        &#125;    &#125;    private Node root;    private int size;    public BinarySearchTree() &#123;        root = null;        size = 0;    &#125;    public int size() &#123;        return size;    &#125;    public boolean isEmpty() &#123;        return size == 0;    &#125;    public void add(E e) &#123;        root = add(root, e);    &#125;    /**     * 递归插入     */    private Node add(Node node, E e) &#123;        if (node == null) &#123;            size++;            return new Node(e);        &#125;        if (e.compareTo(node.e) &gt; 0) &#123;            node.right = add(node.right, e);        &#125; else if (e.compareTo(node.e) &lt; 0) &#123;            node.left = add(node.left, e);        &#125;        return node;    &#125;    public boolean contains(E e) &#123;        return contains(root, e);    &#125;    /**     * 递归     */    public boolean contains(Node node, E e) &#123;        if (node == null) &#123;            return false;        &#125;        if (node.e.compareTo(e) == 0) &#123;            return true;        &#125; else if (node.e.compareTo(e) &gt; 0) &#123;            return contains(node.left, e);        &#125; else &#123;            return contains(node.right, e);        &#125;    &#125;    /**     * 前序遍历二叉搜索树：根 -&gt; 左 -&gt; 右     */    public void preOrder() &#123;        preOrder(root);    &#125;    private void preOrder(Node node) &#123;        if (node == null) &#123;            return;        &#125;        System.out.println(node.e);        preOrder(node.left);        preOrder(node.right);    &#125;    /**     * 中序遍历二叉搜索树：左 -&gt; 根 -&gt; 右     */    public void inOrder() &#123;        inOrder(root);    &#125;    private void inOrder(Node node) &#123;        if (node == null) &#123;            return;        &#125;        inOrder(node.left);        System.out.println(node.e);        inOrder(node.right);    &#125;    /**     * 二叉搜索树的后序遍历：左 -&gt; 右 -&gt; 根     */    public void postOrder() &#123;        postOrder(root);    &#125;    private void postOrder(Node node) &#123;        if (node == null) &#123;            return;        &#125;        postOrder(node.left);        postOrder(node.right);        System.out.println(node.e);    &#125;    /**     * 返回以node为根的二分搜索树的最小值所在的节点     * @return     */    private Node minimum(Node node)&#123;        if(node.left == null)&#123;            return node;        &#125;        return minimum(node.left);    &#125;    /**     * 返回以node为根的二分搜索树的最大值所在的节点     * @return     */    private Node maximum(Node node)&#123;        if(node.right == null)&#123;            return node;        &#125;        return minimum(node.right);    &#125;    /**     * 寻找最小值     * @return     */    public E minimum()&#123;        if(size==0)&#123;            throw new IllegalArgumentException(&quot;BST is empty!&quot;);        &#125;        return minimum(root).e;    &#125;    /**     * 寻找最大值     * @return     */    public E maximum()&#123;        if(size==0)&#123;            throw new IllegalArgumentException(&quot;BST is empty!&quot;);        &#125;        return maximum(root).e;    &#125;    /**     * 删除最小值     * @return     */    public E removeMin()&#123;        E ret = minimum();        root = removeMin(root);        return ret;    &#125;    /**     * 删除以node为根的最小结点     * @param node     * @return 删除节点后新的二分搜索树的根     */    private Node removeMin(Node node) &#123;        if(node.left ==null)&#123;            Node rightNode = node.right;            node.right = null;            size--;            return rightNode;        &#125;        node.left = removeMin(node.left);        return node;    &#125;    /**     * 删除最大值     * @return     */    public E removeMax()&#123;        E ret = maximum();        root = removeMax(root);        return ret;    &#125;    private Node removeMax(Node node) &#123;        if(node.right ==null)&#123;            Node leftNode = node.left;            node.left = null;            size--;            return leftNode;        &#125;        node.right = removeMax(node.right);        return node;    &#125;    /**     * 删除任意结点：1962年Hibbard提出的-Hibbard Deletion     * @param e     * @return     */    public void remove(E e)&#123;        root = remove(root, e);    &#125;    /**     * 删除以node为根的二分搜索树中值为 e 的结点     * @param node     * @param e     * @return     */    private Node remove(Node node, E e)&#123;        if(node == null)&#123;            return null;        &#125;        if(e.compareTo(node.e) &lt; 0)&#123;            node.left = remove(node.left, e);            return node;        &#125;else if(e.compareTo(node.e) &gt; 0)&#123;            node.right = remove(node.right, e);            return node;        &#125;else&#123; // e 等于 node.e            if(node.left == null)&#123;                Node rightNode = node.right;                node.right = null;                size --;                return rightNode;            &#125;            if(node.left == null)&#123;                Node leftNode = node.left;                node.left = null;                size --;                return leftNode;            &#125;            // 左右结点的左右子树均不为空            // 找 “最近” 的结点，这里找了被删除结点的后驱结点，其实也可以选择前驱            Node successor = minimum(node.right);            successor.right = removeMin(node.right);            successor.left = node.left;            // 与不再有关系，将node左右结点置为空            node.left = node.right = null;            return successor;        &#125;    &#125;&#125;\n\nDFS使用栈迭代的方式进行前序遍历（对于中序遍历可能会难一点，见LeetCode 中序遍历 题目）\n/**     * 前序遍历二叉搜索树：非递归（深度优先遍历）     * 使用栈来辅助存储     * 要点：先将右孩子压入栈，然后将左孩子压入栈，因为出栈时是先进后出，所以前序遍历要先压入右孩子     */public void preOrderNR() &#123;    Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;();    stack.push(root);    while (!stack.isEmpty())&#123;        Node cur = stack.pop();        System.out.println(cur.e);        if(cur.right!=null) &#123;            // 先压入右孩子            stack.push(cur.right);        &#125;        if(cur.left!=null)&#123;            stack.push(cur.left);        &#125;    &#125;&#125;\n\nBFS使用队列/** * 二叉搜索树的层序遍历（广度优先遍历） * 使用队列来辅助记录孩子节点 */public void levelOrder()&#123;    Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;();    queue.add(root);    while (!queue.isEmpty())&#123;        Node cur = queue.remove();        System.out.println(cur.e);        if(cur.left!=null)&#123;            queue.add(cur.left);        &#125;        if(cur.right!=null)&#123;            queue.add(cur.right);        &#125;    &#125;&#125;\n\n前继与后继节点\n1962年Hibbard提出的-Hibbard Deletion\n\n删除任意结点操作中，删除一个任意结点的值，关键在于要糅合被删除结点的孩子结点，关键是要找到被删除结点的“最近”的节点，如图，绿色的结点就是被删除结点的最近的结点\n\n所以我们要做的事情就是用这个绿色的结点替换掉蓝色的结点，就可以了\n(你可能发现了，其实也可以找53这个结点)\n\n实际使用中：\n\n\n中序遍历使用最广，因为前序遍历得到的是一个有序的串\n后序遍历的思想可以使用在内存的释放过程中\n前序遍历其实也叫作深度优先遍历\n层序遍历也叫作广度优先遍历\n\n注意：当存入的数据是一个有序的数据时，我们的二叉搜索树会退化成一个链表，为了解决这个问题，我们就要实现平衡二叉树（以后我们会说到平衡二叉树）\nAVL\n平衡二叉树：任意节点的左子树和右子树的高度差不能超过1\n\n平衡因子AVL通过平衡因子判断当前节点是否平衡，即它的左右子树差超过1的时候，认为不平衡\n\n树上黑色的数字代表该节点的高度：\n\n例如2那个叶子节点，它的高度是1\n例如8那个节点，它的左子树高度是3，右子树高度是1，那么他的高度就是较大的那个树的高度再加1，就是4\n\n树上的蓝色数字代表这个结点的平衡因子：\n\n例如2那个叶子结点，它的左右孩子都是null，所以它的平衡因子是0 - 0 = 0\n例如8那个叶子结点，它的左子树高度为3，右子树高度为1，所以它的平衡因子是3 - 1 = 2，超过了1，所以该树从这个结点开始不再平衡\n\n平衡被破坏当我们从一个根节点开始不断插入值的时候，这棵树会不断的生长，如果在插入一个值的时候，平衡被破坏了，那么不管如何，将这颗树改为平衡状态一定是在这个叶子节点的父节点路径上\n\n左旋与右旋一种最早的也是最经典的平衡二叉树，由G.M.Adelson-Velsky和E.M.Landis两位俄罗斯的科学家找出了 左旋和右旋 两种操作来实现树的平衡。\n对于平衡二叉树，有两种不平衡的状况（如图）：\n\n以上的两种状况其实可以分为两类：\n\nLL 与 RR\nLR 与 RL\n\n我们先来看右旋（同理可以得到左旋的代码）如图：\n\n在右旋完成后，我们需要去更新height（平衡因子）两个值，但是留心观察我们会发现，其实只需要更新x和y，而且要先更新y再更新x（因为对于T3来说根本没有发生变化，先更新y的原因是因为更新x需要y的值，所以要先更新y）\n右旋代码如下：\n    // 对节点y进行向右旋转操作，返回旋转后新的根节点x    //        y                              x    //       / \\                           /   \\    //      x   T4     向右旋转 (y)        z     y    //     / \\       - - - - - - - -&gt;    / \\   / \\    //    z   T3                       T1  T2 T3 T4    //   / \\    // T1   T2private Node rightRotate(Node y) &#123;    Node x = y.left;    Node T3 = x.right;    // 向右旋转过程    x.right = y;    y.left = T3;    // 更新height    y.height = Math.max(getHeight(y.left), getHeight(y.right)) + 1;    x.height = Math.max(getHeight(x.left), getHeight(x.right)) + 1;    return x;&#125;\n\n对于LR与RL这种情况，只需先转换为LL与RR情况，在做改变即可：\n\n完整代码public class AVLTree&lt;K extends Comparable&lt;K&gt;,V&gt; &#123;    private class Node &#123;        public K key;        public V value;        public Node left, right;        public int height; // 当前所处高度值        public Node(K key, V value) &#123;            this.key = key;            this.value = value;            left = null;            right = null;            height = 1; //默认高度为1        &#125;    &#125;    private Node root;    private int size;    public AVLTree() &#123;        root = null;        size = 0;    &#125;    // * 获得结点的高度    private int getHeight(Node node)&#123;        if(node==null) &#123;            return 0;        &#125;        return node.height;    &#125;    // * 计算结点的平衡因子    private int getBalanceFactor(Node node)&#123;        if(node == null) &#123;            return 0;        &#125;        return getHeight(node.left) - getHeight(node.right);    &#125;    public void add(K key, V value) &#123;        root = add(root, key, value);    &#125;    // 判断该二叉树是否是一个平衡二叉树    public boolean isBalanced()&#123;        return isBalanced(root);    &#125;    public boolean isBalanced(Node node)&#123;        if(node == null) &#123;            return true;        &#125;        int balanceFactor = getBalanceFactor(node);        if(Math.abs(balanceFactor) &gt; 1)            return false;        return isBalanced(node.left) &amp;&amp; isBalanced(node.right);    &#125;    // * 每次增加结点改变高度值    private Node add(Node node, K key, V value) &#123;        if (node == null) &#123;            size++;            return new Node(key, value);        &#125;                if(key.compareTo(node.key) &lt; 0) &#123;            node.left = add(node.left, key, value);        &#125; else if(key.compareTo(node.key) &gt; 0) &#123;            node.right = add(node.right, key, value);        &#125; else // key.compareTo(node.key) == 0        &#123;            node.value = value;        &#125;        // 对当前的node值更新它的height：它的高度是左右子树更高那个加1        node.height = 1 + Math.max(getHeight(node.left),getHeight(node.right));        // 计算结点的平衡因子        int balanceFactor = getBalanceFactor(node);        // 如果平衡因子(有可能为负数)超过了1 ，那么我们就需要进行自平衡了        // 如果不平衡，那么判断这个结点的两个孩子：如果左孩子平衡值大于等于0，那么需要右旋；如果右孩子平衡值大于等于0，那么需要左旋        // LL        if (balanceFactor &gt; 1 &amp;&amp; getBalanceFactor(node.left) &gt;= 0) &#123;            return rightRotate(node);        &#125;        // RR        if (balanceFactor &lt; -1 &amp;&amp; getBalanceFactor(node.right) &lt;= 0) &#123;            return leftRotate(node);        &#125;        // LR        if (balanceFactor &gt; 1 &amp;&amp; getBalanceFactor(node.left) &lt; 0) &#123;            node.left = leftRotate(node.left);            return rightRotate(node);        &#125;        // RL        if (balanceFactor &lt; -1 &amp;&amp; getBalanceFactor(node.right) &gt; 0) &#123;            node.right = rightRotate(node.right);            return leftRotate(node);        &#125;        return node;    &#125;    // 对节点y进行向右旋转操作，返回旋转后新的根节点x    //        y                              x    //       / \\                           /   \\    //      x   T4     向右旋转 (y)        z     y    //     / \\       - - - - - - - -&gt;    / \\   / \\    //    z   T3                       T1  T2 T3 T4    //   / \\    // T1   T2    private Node rightRotate(Node y) &#123;        Node x = y.left;        Node T3 = x.right;        // 向右旋转过程        x.right = y;        y.left = T3;        // 更新height        y.height = Math.max(getHeight(y.left), getHeight(y.right)) + 1;        x.height = Math.max(getHeight(x.left), getHeight(x.right)) + 1;        return x;    &#125;    // 对节点y进行向左旋转操作，返回旋转后新的根节点x    //    y                             x    //  /  \\                          /   \\    // T1   x      向左旋转 (y)       y     z    //     / \\   - - - - - - - -&gt;   / \\   / \\    //   T2  z                     T1 T2 T3 T4    //      / \\    //     T3 T4    private Node leftRotate(Node y) &#123;        Node x = y.right;        Node T2 = x.left;        // 向左旋转过程        x.left = y;        y.right = T2;        // 更新height        y.height = Math.max(getHeight(y.left), getHeight(y.right)) + 1;        x.height = Math.max(getHeight(x.left), getHeight(x.right)) + 1;        return x;    &#125;    private Node removeMin(Node node) &#123;        if (node.left == null) &#123;            Node rightNode = node.right;            node.right = null;            size--;            return rightNode;        &#125;        node.left = removeMin(node.left);        return node;    &#125;    /**     * 寻找最小值     */    public V minimum() &#123;        if (size == 0) &#123;            throw new IllegalArgumentException(&quot;BST is empty!&quot;);        &#125;        return minimum(root).value;    &#125;    /**     * 返回以node为根的二分搜索树的最小值所在的节点     *     * @return     */    private Node minimum(Node node) &#123;        if (node.left == null) &#123;            return node;        &#125;        return minimum(node.left);    &#125;    public V remove(K key) &#123;        Node node = getNode(root, key);        if (node != null) &#123;            root = remove(root, key);        &#125;        return null;    &#125;    private Node remove(Node node, K key)&#123;        if( node == null ) &#123;            return null;        &#125;        Node retNode;        if( key.compareTo(node.key) &lt; 0 )&#123;            node.left = remove(node.left , key);            // return node;            retNode = node;        &#125;        else if(key.compareTo(node.key) &gt; 0 )&#123;            node.right = remove(node.right, key);            // return node;            retNode = node;        &#125;        else&#123;   // key.compareTo(node.key) == 0            // 待删除节点左子树为空的情况            if(node.left == null)&#123;                Node rightNode = node.right;                node.right = null;                size --;                // return rightNode;                retNode = rightNode;            &#125;            // 待删除节点右子树为空的情况            else if(node.right == null)&#123;                Node leftNode = node.left;                node.left = null;                size --;                // return leftNode;                retNode = leftNode;            &#125;            // 待删除节点左右子树均不为空的情况            else&#123;                // 找到比待删除节点大的最小节点, 即待删除节点右子树的最小节点                // 用这个节点顶替待删除节点的位置                Node successor = minimum(node.right);                //successor.right = removeMin(node.right);                successor.right = remove(node.right, successor.key);                successor.left = node.left;                node.left = node.right = null;                // return successor;                retNode = successor;            &#125;        &#125;        if(retNode == null) &#123;            return null;        &#125;        // 更新height        retNode.height = 1 + Math.max(getHeight(retNode.left), getHeight(retNode.right));        // 计算平衡因子        int balanceFactor = getBalanceFactor(retNode);        // 平衡维护        // LL        if (balanceFactor &gt; 1 &amp;&amp; getBalanceFactor(retNode.left) &gt;= 0)            return rightRotate(retNode);        // RR        if (balanceFactor &lt; -1 &amp;&amp; getBalanceFactor(retNode.right) &lt;= 0)            return leftRotate(retNode);        // LR        if (balanceFactor &gt; 1 &amp;&amp; getBalanceFactor(retNode.left) &lt; 0) &#123;            retNode.left = leftRotate(retNode.left);            return rightRotate(retNode);        &#125;        // RL        if (balanceFactor &lt; -1 &amp;&amp; getBalanceFactor(retNode.right) &gt; 0) &#123;            retNode.right = rightRotate(retNode.right);            return leftRotate(retNode);        &#125;        return retNode;    &#125;    // 返回以node为根节点的二分搜索树中，key所在的节点    private Node getNode(Node node, K key)&#123;        if(node == null) &#123;            return null;        &#125;        if(key.equals(node.key)) &#123;            return node;        &#125; else if(key.compareTo(node.key) &lt; 0) &#123;            return getNode(node.left, key);        &#125; else // if(key.compareTo(node.key) &gt; 0)        &#123;            return getNode(node.right, key);        &#125;    &#125;        public boolean contains(K key) &#123;        return getNode(root, key) != null;    &#125;    public V get(K key) &#123;        Node node = getNode(root, key);        return node == null ? null : node.value;    &#125;    public void set(K key, V newValue)&#123;        Node node = getNode(root, key);        if(node == null) &#123;            throw new IllegalArgumentException(key + &quot; doesn&#x27;t exist!&quot;);        &#125;        node.value = newValue;    &#125;    public int getSize() &#123;        return size;    &#125;    public boolean isEmpty() &#123;        return size == 0;    &#125;&#125;\n\n2-3树在了解红黑树之前，要先学习一下2-3树\n\n2-3树：满足二分搜索树的性质，但不是二叉树。\n2-3树就是每个节点有2个或者3个孩子的树\n\n\n 例如这就是一棵2-3树：\n\n重要的性质：2-3树是一棵绝对平衡（从根节点到任意节点的路径一定是相同的）的树\n绝对平衡如图：2-3树是一棵可以保持绝对平衡的树\n\n红黑树2-3树与红黑树的等价在理解2-3树是什么之后，理解红黑树就不会太难了。2-3树与红黑树之间的关系如图：\n\n由此我们再来看红黑树的性质：\n\n红黑树就是这样的树：\n\n每个节点是红色或者黑色\n根节点是黑色\n叶子节点是黑色\n如果一个节点是红色的，那么他的孩子节点都是黑色的\n如果一个红节点的孩子有一个是红色的，就出现四节点了，就不是我们所说的2-3树了\n\n\n从任意一个节点到叶子节点，经过的黑色节点是一样的（黑平衡）\n如同2-3树，是一棵绝对平衡的树\n\n\n\n\n添加元素红黑树只会添加红节点，以这个为前提，我们来看\n\n\n左旋、右旋、颜色翻转现在有一个二节点要加入到一个三节点上：\n\n加在了黑节点的右子树上：直接颜色翻转\n加在了红节点的左子树上：先右旋，后颜色翻转\n加在了红节点的右子树上：先左旋，再右旋，再颜色翻转\n\n\n完整代码public class RBTree&lt;K extends Comparable&lt;K&gt;, V&gt; &#123;    // * 表示红色与黑色    private static final boolean RED = true;    private static final boolean BLACK = false;    private class Node&#123;        public K key;        public V value;        public Node left, right;        public boolean color;        public Node(K key, V value)&#123;            this.key = key;            this.value = value;            left = null;            right = null;            color = RED;    //* 只插入黑色节点        &#125;    &#125;    private Node root;    private int size;    public RBTree()&#123;        root = null;        size = 0;    &#125;    public int getSize()&#123;        return size;    &#125;    public boolean isEmpty()&#123;        return size == 0;    &#125;    // * 判断节点node的颜色    private boolean isRed(Node node)&#123;        // * 为null代表叶子结点，叶子节点都是黑色        if(node == null) &#123;            return BLACK;        &#125;        return node.color;    &#125;    //   node                     x    //  /   \\     左旋转         /  \\    // T1   x   ---------&gt;   node   T3    //     / \\              /   \\    //    T2 T3            T1   T2    private Node leftRotate(Node node)&#123;        Node x = node.right;        // 左旋转        node.right = x.left;        x.left = node;        // 改变颜色        x.color = node.color;   // 新的根节点继承原本根节点的颜色        node.color = RED;       // 左孩子变为红色        return x;    &#125;    //   node                     x    //  /   \\     右旋转         /  \\    //  x   T2   ---------&gt;     y   node    // / \\                           / \\    //y   T1                       T1   T2    private Node rightRotate(Node node)&#123;        Node x = node.left;        // 右旋转        node.left = x.right;        x.right = node;        // 维持节点颜色        x.color = node.color;        node.color = RED;        return x;    &#125;    // * 颜色翻转    private void filpColors(Node node)&#123;        node.color = RED;        node.left.color = BLACK;        node.right.color = BLACK;    &#125;    // 向红黑树中添加新的元素(key, value)    public void add(K key, V value)&#123;        root = add(root, key, value);        root.color = BLACK; // 完成后的根节点必须为黑色节点    &#125;    // 向以node为根的红黑树中插入元素(key, value)，递归算法    // 返回插入新节点后红黑树的根    private Node add(Node node, K key, V value)&#123;        if(node == null)&#123;            size ++;            return new Node(key, value); // 默认插入红色节点        &#125;        if(key.compareTo(node.key) &lt; 0) &#123;            node.left = add(node.left, key, value);        &#125; else if(key.compareTo(node.key) &gt; 0) &#123;            node.right = add(node.right, key, value);        &#125; else // key.compareTo(node.key) == 0        &#123;            node.value = value;        &#125;        // 左黑右红 -&gt; 左旋        if(isRed(node.right) &amp;&amp; !isRed(node.left))&#123;            node =leftRotate(node);        &#125;        // LL都为红        if(isRed(node.left) &amp;&amp; isRed(node.left.left))&#123;            node = rightRotate(node);        &#125;        // 左右为红        if(isRed(node.left) &amp;&amp; isRed(node.right))&#123;            filpColors(node);        &#125;        return node;    &#125;    // 返回以node为根节点的二分搜索树中，key所在的节点    private Node getNode(Node node, K key)&#123;        if(node == null) &#123;            return null;        &#125;        if(key.equals(node.key)) &#123;            return node;        &#125; else if(key.compareTo(node.key) &lt; 0) &#123;            return getNode(node.left, key);        &#125; else // if(key.compareTo(node.key) &gt; 0)        &#123;            return getNode(node.right, key);        &#125;    &#125;    public boolean contains(K key)&#123;        return getNode(root, key) != null;    &#125;    public V get(K key)&#123;        Node node = getNode(root, key);        return node == null ? null : node.value;    &#125;    public void set(K key, V newValue)&#123;        Node node = getNode(root, key);        if(node == null) &#123;            throw new IllegalArgumentException(key + &quot; doesn&#x27;t exist!&quot;);        &#125;        node.value = newValue;    &#125;    // 返回以node为根的二分搜索树的最小值所在的节点    private Node minimum(Node node)&#123;        if(node.left == null) &#123;            return node;        &#125;        return minimum(node.left);    &#125;    // 删除掉以node为根的二分搜索树中的最小节点    // 返回删除节点后新的二分搜索树的根    private Node removeMin(Node node)&#123;        if(node.left == null)&#123;            Node rightNode = node.right;            node.right = null;            size --;            return rightNode;        &#125;        node.left = removeMin(node.left);        return node;    &#125;&#125;\n\n对比AVL红黑树不是完美的平衡树，只是实现了黑平衡，牺牲了平衡性，换来了插入与查询速度的均衡态\n\n对于查询较多的情况，AVL树较好（红黑树牺牲了平衡性，达到了2logn）的高度\n红黑树的统计性能更好（综合增删查改所有操作）\n\nTrie\n一个便于搜索的多叉树。我们学习了树结构实现映射，它的时间复杂度是O(log n)，如果有两百万个条目，大约会花费20，但是Tire查询每个条目的时间复杂度和字典中一共有多少条目无关，取决于查询单词的长度O(w)\n\n一棵Trie就像是这样\n\n字典树结构那么这样的一棵树，它的节点是如何定义的？\nclass Node&#123;    char c;    Node next[];    public Node(char c) &#123;        this.c = c;        this.next = new Node[26];    &#125;&#125;\n\n假如我们的业务是实现单词的存储，那么应该就是这样，每一个结点可以存储26个字母。\n但是假如我们的业务是存储网址信息等等，我们会扩展到更多更多，所以我们可以使用一个Map集合来充当这里的数据\nclass Node&#123;    Map&lt;Character, Node&gt; next;&#125;\n\n但是，如果要存储单词的话，我们会遇到一个问题，就是假设存储cat和category，两个词前面都是cat，那么我们如何存储呢？\n我们可以再给Node加一个字段，就是isWord\nclass Node&#123;    boolean isWord;    Map&lt;Character, Node&gt; next;&#125;\n\n完整代码public class Trie&#123;    private class Node&#123;        boolean isWord;        Map&lt;Character, Node&gt; next;        public Node(boolean isWord) &#123;            this.isWord = isWord;            this.next = new TreeMap&lt;&gt;();        &#125;        public Node()&#123;            this(false);        &#125;    &#125;    private Node root;    private int size;    public Trie()&#123;        root = new Node();        size =0;    &#125;    public int getSize()&#123;        return size;    &#125;    public void add(String word)&#123;        Node cur = root;        char[] chars = word.toCharArray();        for (int i = 0; i &lt; chars.length; i++) &#123;            if(cur.next.get(chars[i]) == null)&#123;                cur.next.put(chars[i], new Node());            &#125;            cur = cur.next.get(chars[i]);        &#125;        // 如果之前这不是一个单词        if(!cur.isWord)&#123;            cur.isWord = true;            size ++;        &#125;    &#125;    // 查询是否有一个单词    public boolean contains(String word)&#123;        Node cur = root;        char[] chars = word.toCharArray();        for (int i = 0; i &lt; chars.length; i++) &#123;            if(cur.next.get(chars[i]) == null)&#123;                return false;            &#125;            cur = cur.next.get(chars[i]);        &#125;        return cur.isWord;    &#125;    /** 查询是否在Tire中以prefix为前缀的单词     */    public boolean isPrefix(String prefix)&#123;        Node cur = root;        char[] chars = prefix.toCharArray();        for (int i = 0; i &lt; chars.length; i++) &#123;            if(cur.next.get(chars[i]) == null)&#123;                return false;            &#125;            cur = cur.next.get(chars[i]);        &#125;        return true;    &#125;&#125;\n\n线段树区间染色问题线段树也叫区间树(Segment Tree)，有些问题我们关注的是一个区间\n例如区间染色问题\n\n区间染色问题：有一个数组区间[0~N]区间，每次操作，我们将其一段染为一种颜色（颜色可以覆盖）\n\n经过m次操作后，我们能看到多少种颜色？\nm次操作后，我们能在[i , j]区间内看到多少种颜色？\n\n\n审题我们可以知道主要有两种操作：\n\n染色操作\n查询操作\n\n自然而然我们会选择遍历数组，但是这样的话，染色操作和查询操作都需要O(N)的复杂度\n再比如计算机经常会有的区间查询操作，我们可能也要统计一个区间的最大值，最小值，区间和等等信息。再比如，你想统计一下2020年你们项目中消费最高的用户，消费最少的用户，学习时间最长的用户。如果我们使用线段树，我们进行这种的操作都可以实现在O(log N)之内\n\n那么什么是线段树？\n\n和普通的树唯一的区别，就是每个节点存放的数据是一个区间\n\n线段树特点：\n\n是一棵平衡二叉树（任意节点的最大深度和最小深度的差最大为1）\n可以使用数组来表示（虽然叶子结点不会分布在同一层，但是我们可以把不存在的叶子结点当做空来处理）\n一个n个节点的线段树需要开辟4n个空间\n\n为什么一个n个节点的线段树需要4n个空间？对于一颗平衡二叉树来说，第一层有2^0个节点，一直到第h层，有2^h个节点。整棵树总共有着2^(h+1）-1个节点，对比最后一层和全部节点数我们会有这样的感觉，几乎最后一层的节点数就和整棵树的大小是一样的，而线段树基本就是使用最后一层来存储元素。\n有了上述的观念，我们再来看这个问题。因为我们要以满二叉树的标准来存储元素，假设有n个节点，而n=2^h，我们只需要使用2n个存储空间即可。，但是如果再多一个节点，我们就需要再开辟一行空间，也就是再来一行，需要使用4n个空间\n完整代码（无增添操作，线段树的优势在于实现更新和查询操作）\n这里我们使用一个接口，来表示两个元素之间的相互操作。例如相加操作、相减操作等等一系列甚至是复杂的业务操作\npublic interface Merger&lt;E&gt; &#123;    E merge(E a, E b);&#125;\n\n具体代码：\npublic class SegmentTree&lt;E&gt; &#123;    private E[] data;    private E[] tree;    // 根据具体业务决定    private Merger&lt;E&gt; merger;    public SegmentTree(E[] arr, Merger&lt;E&gt; merger) &#123;        this.merger = merger;        data = (E[]) new Object[arr.length];        for (int i = 0; i &lt; arr.length; i++) &#123;            data[i] = arr[i];        &#125;        tree = (E[]) new Object[4 * arr.length];        buildSegmentTree(0, 0, arr.length - 1);    &#125;    /** 创建线段树      */    private void buildSegmentTree(int treeIndex, int l, int r) &#123;        // 如果只有一个元素        if (l == r) &#123;            tree[treeIndex] = data[l];            return;        &#125;        // 注意这里的范围，可以写为 (r+l)/2，但是r+l可能会出现整型溢出的问题        // 所以我们这样写 l+(r-l)/2        int mid = l + (r - l) / 2;        buildSegmentTree(leftChild(treeIndex), l, mid);        buildSegmentTree(rightChild(treeIndex), mid + 1, r);        //tree[treeIndex] = tree[rightChild(treeIndex)] + tree[leftChild(treeIndex)];        //假如我们的业务需要求分段的和，我们就可以写为+的形式        //所以这里我们使用一个新的接口来进行两个泛型的运算        tree[treeIndex] = merger.merge(tree[leftChild(treeIndex)], tree[rightChild(treeIndex)]);    &#125;    // 返回区间[queryL, queryR]的值    public E query(int queryL, int queryR) &#123;        if (queryL &lt; 0 ||            queryL &gt;= data.length ||            queryR &lt; 0 ||            queryR &gt;= data.length ||            queryL &gt; queryR) &#123;            throw new IllegalArgumentException(&quot;索引不正确&quot;);        &#125;        return query(0, 0, data.length - 1, queryL, queryR);    &#125;    // 在以treeID为根的线段树中[l...r]的范围内，搜索区间[queryL...queryR]的值    private E query(int treeIndex, int l, int r, int queryL, int queryR) &#123;        if (l == queryL &amp;&amp; r == queryR) &#123;            return tree[treeIndex];        &#125;        int mid = l + (r - l) / 2;        int leftTreeIndex = leftChild(treeIndex);        int rightTreeIndex = rightChild(treeIndex);        //要查询的部分在右子树        if (queryL &gt;= mid + 1) &#123;            return query(rightTreeIndex, mid + 1, r, queryL, queryR);        &#125; else if (queryR &lt;= mid) &#123;            return query(leftTreeIndex, l, mid, queryL, queryR);        &#125; else &#123;            E leftResult = query(leftTreeIndex, l, mid, queryL, mid);            E rightResult = query(rightTreeIndex, mid + 1, r, mid + 1, queryR);            // 最终业务决定            return merger.merge(leftResult, rightResult);        &#125;    &#125;    public void set(int index, E e) &#123;        if (index &lt; 0 || index &gt;= data.length) &#123;            throw new IllegalArgumentException(&quot;索引不正确&quot;);        &#125;        data[index] = e;        set(0, 0, data.length - 1, index, e);    &#125;    private void set(int treeIndex, int l, int r, int index, E e) &#123;        if (l == r) &#123;            tree[treeIndex] = e;            return;        &#125;        int mid = l + (r - l) / 2;        int leftTreeIndex = leftChild(treeIndex);        int rightTreeIndex = rightChild(treeIndex);        if (index &gt;= mid + 1) &#123;            set(rightTreeIndex, mid + 1, r, index, e);        &#125; else &#123;            set(leftTreeIndex,l,mid,index,e);        &#125;        // 更新每一级的范围        tree[treeIndex] = merger.merge(tree[leftTreeIndex],tree[rightTreeIndex]);    &#125;    public E get(int index) &#123;        if (index &lt; 0 || index &gt;= data.length) &#123;            throw new IllegalArgumentException(&quot;索引不正确&quot;);        &#125;        return data[index];    &#125;    // 当做满二叉树来存储，那么肯定符合完全二叉树的性质    private int leftChild(int index) &#123;        return 2 * index + 1;    &#125;    private int rightChild(int index) &#123;        return 2 * index + 2;    &#125;&#125;\n\n堆优先队列\n普通队列：先进先出FIFO\n\n优先队列：出队顺序和入队顺序无关，和优先级相关\n\n\n优先队列应用很广，比如操作系统的任务调度，就需要动态选择优先级最高的任务执行；还有一个游戏的AI，当敌人来了之后会默认的攻击威胁程度最大的敌人等等，都使用了优先队列\n优先队列需要实现的接口依然还是：\npublic interface Queue&lt;E&gt; &#123;    int getSize();    boolean isEmpty();    void enqueue(E e);    E dequeue();    E getFront();&#125;\n\n但是我们可以使用不用的数据结构实现相同的功能，比如说普通的线性结构（数组，链表），比如说顺序的线性结构（保持着排序）等等，但是最好的方式是使用堆来实现，比较如下\n\n二叉堆二叉堆是一棵完全二叉树（缺失的叶子节点都在右下方）\n\n\n堆的特性：\n\n一棵完全二叉树\n一颗平衡二叉树\n堆的某个节点的值总是不大于其父节点的值（最大堆）\n同上也有最小堆\n\n可以使用树的结构来实现堆，但是由于堆是一棵完全二叉树，所以可以使用数组来实现完全二叉树（可以完美的对应数组的下标）\n\n\n如图，有三条性质，这三条性质就是数组下标和二叉堆结点的对应关系，而且为了防止0号空间无使用，我们略微改变了一下，就有\n\nparent(i) = ( i - 1 ) / 2\nleftChild (i) = 2*i +1\nrightChild (i) = 2*i + 2\n\n使用数组实现二叉堆，代码如下：（数组使用我们之前实现的数组）\n\n增添方法思想：将要添加的元素放在完全二叉树的最后一个节点，然后逐级与根节点比较，放置在一个合适的位置上\n\n删除方法思想：交换堆顶和最后一个节点，将新的头结点放置在一个合适的位置\n\n\n完整代码public class MaxHeap&lt;E extends Comparable&lt;E&gt;&gt; &#123;    private Array&lt;E&gt; data;    public MaxHeap(int capacity) &#123;        data = new Array&lt;&gt;(capacity);    &#125;    public MaxHeap() &#123;        data = new Array&lt;&gt;();    &#125;    public int size() &#123;        return data.getSize();    &#125;    public boolean isEmpty() &#123;        return data.isEmpty();    &#125;    /**     * 三个辅助方法：     * 1. 返回完全二叉树的数组表示中，一个索引所表示的元素的父亲节点的索引     * 2. 返回完全二叉树的数组表示中，一个索引所表示的元素的左孩子节点的索引     * 3. 返回完全二叉树的数组表示中，一个索引所表示的元素的右孩子节点的索引     */    private int parent(int index) &#123;        if (index == 0) &#123;            throw new IllegalArgumentException(&quot;索引0：没有父亲节点&quot;);        &#125;        return (index - 1) / 2;    &#125;    private int leftChild(int index) &#123;        return 2 * index + 1;    &#125;    private int rightChild(int index) &#123;        return 2 * index + 2;    &#125;    /**     * 向堆中添加元素     */    public void add(E e) &#123;        data.addLast(e);        siftUp(data.getSize() - 1);    &#125;    /**     * 调整最大堆的结构     */    private void siftUp(int k) &#123;        while (k &gt; 0 &amp;&amp; data.get(parent(k)).compareTo(data.get(k)) &lt; 0) &#123;            // 交换两个元素            swap(k, parent(k));            k = parent(k);        &#125;    &#125;    private void swap(int i, int j) &#123;        E temp = data.get(i);        data.set(i, data.get(j));        data.set(j, temp);    &#125;    public E findMax() &#123;        if (isEmpty()) &#123;            throw new IllegalArgumentException(&quot;堆是空的&quot;);        &#125;        return data.get(0);    &#125;\t// 此方法也就是优先队列的出队方法    public E extractMax() &#123;        E e = findMax();        // 先将最大和最小交换位置        swap(0, data.getSize() - 1);        // 删除最后一个元素        data.removeLast();        siftDown(0);        return e;    &#125;    private void siftDown(int k) &#123;        // 如果左孩子都越界了，那么肯定要停止了        while (leftChild(k) &lt; data.getSize()) &#123;            int j = leftChild(k);            // 判断有没有右孩子，且 右孩子比左孩子大            if (j + 1 &lt; data.getSize()                    &amp;&amp; data.get(j + 1).compareTo(data.get(j)) &gt; 0) &#123;                j++;                // data.get(j) 是左右孩子中的最大值            &#125;            // 如果 k位置的值比他的两个孩子内更大的孩子大，说明已经完成调度            if (data.get(k).compareTo(data.get(j)) &gt;= 0) &#123;                break;            &#125;            swap(k, j);            k = j;        &#125;    &#125;&#125;\n\n优先队列：\npublic class PriorityQueue&lt;E extends Comparable&lt;E&gt;&gt; implements Queue&lt;E&gt;&#123;    private MaxHeap&lt;E&gt; maxHeap;    @Override    public int getSize() &#123;        return maxHeap.size();    &#125;    @Override    public boolean isEmpty() &#123;        return maxHeap.isEmpty();    &#125;    @Override    public void enqueue(E e) &#123;        maxHeap.add(e);    &#125;    @Override    public E dequeue() &#123;        return maxHeap.extractMax();    &#125;    @Override    public E getFront() &#123;        return maxHeap.findMax();    &#125;&#125;\n\n类树类树是我提的伪概念，即与普通的数很相似，但是又不是树的那些数据结构\n并查集一种由孩子节点指向父亲节点的特殊的数据结构，可以用来很方便的解决连接问题（判断是否相互连接，如网络（社交网络）中节点间的连接状态，例如一个人是否可以通过朋友的朋友认识另一个人）\n并查集主要支持两个操作：\n\nunion(p,q)将p和q联系起来\nisConnected(p,q)判断p与q是否有联系\n\n并查集接口如下：\npublic interface UnionFind &#123;    void union(int p, int q);    boolean isConnected(int p, int q);    int getSize();&#125;\n\n这里准备了6种实现方式，有着不同的机制或者是对方法的优化\nquick findid数组存储对应的集合，这种实现方式使得我们isConnected方法更快（O(1)级别），但是union方法会比较慢\npublic class UnionFind1 implements UnionFind &#123;    // 表示数据的下标，可以理解为一个指针    private int[] id;        public UnionFind1(int size) &#123;        this.id = new int[size];        // 给每一个数据一个不同的下标        for (int i = 0; i &lt; id.length; i++) &#123;            id[i] = i;        &#125;    &#125;    @Override    public void union(int p, int q) &#123;        int pId = find(p);        int qId = find(q);        if(pId == qId) &#123;            return;        &#125; else &#123;            for (int i = 0; i &lt; id.length; i++) &#123;                if(id[i] == pId) &#123;                    id[i] = qId;                &#125;            &#125;        &#125;    &#125;    /**查看元素p和q是否在一个集合     */    @Override    public boolean isConnected(int p, int q) &#123;        return find(p) == find(q);    &#125;    /**查找元素p所对应的集合编号     */    private int find(int p)&#123;        if(p&lt;0&amp;&amp;p&gt;=id.length) &#123;            throw new IllegalArgumentException(&quot;不正确的下标&quot;);        &#125;        return id[p];    &#125;    @Override    public int getSize() &#123;        return id.length;    &#125;&#125;\n\nquick union主流的并查集的实现方式，数组中的每个元素指向，**将两个操作的时间复杂度都为O(h)**，h为树的高度\npublic class UnionFind2 implements UnionFind &#123;    private int[] parent;    public UnionFind2(int size)&#123;        parent = new int[size];        for (int i = 0; i &lt; parent.length; i++) &#123;            parent[i] = i;        &#125;    &#125;    @Override    public void union(int p, int q) &#123;        int pRoot = find(p);        int qRoot = find(q);        if(pRoot == qRoot)&#123;            return;        &#125;        parent[pRoot] = qRoot;    &#125;    @Override    public boolean isConnected(int p, int q)&#123;        return find(p) == find(q);    &#125;    /**找到对应的根节点*/    private int find(int p)&#123;        if(p &lt; 0 &amp;&amp; p &gt;= parent.length) &#123;            throw new IllegalArgumentException(&quot;不正确的下标&quot;);        &#125;        while (p != parent[p])&#123;            p = parent[p];        &#125;        return p;    &#125;    @Override    public int getSize() &#123;        return parent.length;    &#125;&#125;\n\n优化1：size增加了一个字段sz，存储以i为根的集合中元素的个数，在Union操作的时候，我们可以将元素个数少的指向元素个数多的\npublic class UnionFind3 implements UnionFind&#123;    private int[] parent;    private int[] sz;   // 以i为根的集合中元素的个数    public UnionFind3(int size)&#123;        parent = new int[size];        sz = new int[size];        for (int i = 0; i &lt; parent.length; i++) &#123;            parent[i] = i;            sz[i] = 1;        &#125;    &#125;    @Override    public void union(int p, int q) &#123;        int pRoot = find(p);        int qRoot = find(q);        if(pRoot == qRoot)&#123;            return;        &#125;        // -----------------这里-----------------------        // 将元素少的合并到元素多的元素上        if(sz[pRoot] &gt; sz[qRoot])&#123;            parent[pRoot] = qRoot;            sz[qRoot]+= sz[pRoot];        &#125;else &#123;            parent[qRoot] = pRoot;            sz[pRoot] += sz[qRoot];        &#125;    &#125;    @Override    public boolean isConnected(int p, int q)&#123;        return find(p) == find(q);    &#125;    /**找到对应的根节点     */    private int find(int p)&#123;        if(p&lt;0&amp;&amp;p&gt;=parent.length) &#123;            throw new IllegalArgumentException(&quot;不正确的下标&quot;);        &#125;        while (p!=parent[p])&#123;            p = parent[p];        &#125;        return p;    &#125;    @Override    public int getSize() &#123;        return parent.length;    &#125;&#125;\n\n优化2：rank其实我们可以直接存储树的高度，而不是元素的个数，如图\n\npublic class UnionFind4 implements UnionFind &#123;    private int[] parent;    private int[] rank;   // 以i为根的集合所表示的树的高度    public UnionFind4(int size) &#123;        parent = new int[size];        rank = new int[size];        for (int i = 0; i &lt; parent.length; i++) &#123;            parent[i] = i;            rank[i] = 1;        &#125;    &#125;    @Override    public void union(int p, int q) &#123;        int pRoot = find(p);        int qRoot = find(q);        if (pRoot == qRoot) &#123;            return;        &#125;        // 将树高更低的集合合并到高的集合上        if (rank[pRoot] &lt; rank[qRoot]) &#123;            parent[pRoot] = qRoot;        &#125; else if (rank[pRoot] &gt; rank[qRoot])&#123;            parent[qRoot] = pRoot;        &#125;else &#123;// 相等情况            parent[qRoot] = pRoot;            rank[qRoot]++;        &#125;    &#125;    @Override    public boolean isConnected(int p, int q) &#123;        return find(p) == find(q);    &#125;    /** 找到对应的根节点     */    private int find(int p) &#123;        if (p &lt; 0 &amp;&amp; p &gt;= parent.length) &#123;            throw new IllegalArgumentException(&quot;不正确的下标&quot;);        &#125;        while (p != parent[p]) &#123;            p = parent[p];        &#125;        return p;    &#125;    @Override    public int getSize() &#123;        return parent.length;    &#125;&#125;\n\n优化3：路径压缩一个并查集，我们主要实现的操作就是两个，但是在极端情况下，我们发现还是会出现树很高的现象，但其实：\n\n只需要优化一下find方法，我们就可以在每次find时，更改树的结构\n/**找到对应的根节点*/private int find(int p) &#123;    if (p &lt; 0 &amp;&amp; p &gt;= parent.length) &#123;        throw new IllegalArgumentException(&quot;不正确的下标&quot;);    &#125;    while (p != parent[p]) &#123;        // 就是这一行代码        parent[p] = parent[parent[p]];        p = parent[p];    &#125;    return p;&#125;\n\n这一行代码：parent[p] = parent[parent[p]];看上去很复杂，其实就是在遍历到这里时，把该节点的父节点 换成父节点的父节点\n\n每一次find，我们都可以优化一遍，最后所有的子节点都会指向一个根，这样我们的树高大大的降低，这种路径压缩的操作，最后会\n优化3：递归优化经过路径优化后，你可能在想，为什么不直接在第一次find的时候，就将子节点连接到根节点呢？\n所以我们可以这样优化\n/** 找到对应的根节点*/private int find(int p) &#123;    if (p &lt; 0 &amp;&amp; p &gt;= parent.length) &#123;        throw new IllegalArgumentException(&quot;不正确的下标&quot;);    &#125;    if (p != parent[p]) &#123;        parent[p] = find(parent[p]);    &#125;    return parent[p];&#125;\n\n时间复杂度分析经过优化后，并查集的时间复杂度为O(log*n)\n\n跳表概率算法跳表的最底层类似一个链表，然后可以看做隔一个节点建立一个索引的结构。\n跳表的数据结构可以看做：\npublic class Node &#123;    private int data = -1;    // 存放跳转的索引    private Node[] forwards = new Node[MAX_LEVEL];    private int maxLevel = 0;&#125;\n\n跳表是依赖于概率算法的：比如现在要新加入一个节点，需要决定该节点的层级\n理论上来讲，一级索引应该占50%，二级索引占25%，三级索引占12.5%等等以此类推\n决定当前节点层级是通过随机来决定的，晋升的概率为1/2。\nprivate static final float PROB = 0.5 f;private int randomLevel() &#123;    int level = 1;    // 如果随机数大于0.5，就允许晋升    while (Math.random() &gt; PROB &amp;&amp; level &lt; MAX_LEVEL) &#123;        ++level;    &#125;    return level;&#125;\n\n对比红黑树\n为什么跳表范围查询比红黑树快？\n\n红黑树是老老实实一级一级查的，但是跳表是顺序和跳跃的结合，这使得跳表可以快速跳跃到目标区间的起点，而一旦找到起点后，可以直接顺序遍历底层链表。\n在Redis的实现中，有序集合使用了跳表，因为对于有序Set来说，一般需要支持的操作有：\n\n增\n删\n查一个数据\n查区间数据\n\n红黑树与跳表比较来说，对于前三个操作基本一致，但是查区间数据会慢一些，且实现要比跳表难一些。\n","categories":["数据结构"],"tags":["数据结构"]},{"title":"深入Java虚拟机内存结构篇","url":"/2021/07/24/JVM/%E6%B7%B1%E5%85%A5Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E7%AF%87/","content":"\n  引言:\n  JVM内存结构有关内容，不包括GC部分。\n\n\n\n\n深入Java虚拟机内存结构篇\n前言：Java真正的核心从这里开始\n\nJVM概述JVM特点\n语言无关性Java——跨平台的语言；JVM——跨语言的平台\n\nJava虚拟机不关心你是否使用了Java语言编写，她只关心Class文件，只要这个class文件符合规范，那么他就可以运行，至于是Java还是Scala还是其他，no care \n所以说，JVM可以不可以运行其他语言编写的程序呢？\n答案：可以的，只要该语言的编译器生成合乎规范的class文件即可\nJava代码执行流程基本流程：\n\n编写Java源码：获得.java文件\n\nJava编译器对 1 生成的文件进行编译：经过语法分析，由字节码生成器，生成.class文件\n\nJava虚拟机，读取.class文件\n\n类加载器\n字节码校验器\n两种执行方式：\n翻译字节码（解释执行）\nJIT编译器（编译执行）\n\n\n\n\n\nJVM指令集架构\n指令集架构\n\n有两种指令集架构：\n\n栈式架构：\n设计和实现简单，全部使用零地址指令分配\n不需要硬件支持，更好跨平台\n指令集小\n执行性能没寄存器架构高\n\n\n寄存器架构：类似于X86汇编语言\n依赖硬件，不同公司产的CPU可能指令集就不同，例如X86和MIPS，就是两种指令集\n\n\n\n所以Java为了实现跨平台，就使用了第一种栈式架构\n\nJVM生命周期\nJVM的启动：由引导类加载器BootStrap class loader创建一个初始类来实现JVM的启动\n\nJVM的执行：JVM启动的唯一原因是要执行Java程序，但对于操作系统来说，没有Java程序，运行的全部都是JVM进程\n\nJVM的退出，有以下几种情况：\n\n\n\n正常执行结束\n执行过程中遇到了异常、错误而终止\n操作系统叫停\n某线程调用Runtime类或System类的exit方法，或Runtime类的halt方法，并且Java安全管理器也允许本次的操作\n除此外，还有JNI(Java Native Interface)规范描述的一些情况\n\nHotSpot\nHotSpot到底是什么？\n\n\n一种VM实现方式：\n\n2000年，JDK1.3发布，Java HotSpot virtual machine正式发布\nHotSpot VM 是Sun JDK与Open JDK默认的JVM\n采用解释器与即时编译器JIT并存的结构\n目前，HotSpot VM 是广泛的JVM实现，主要学习的也就是这个！\n\n一种技术——热点代码探测技术\n\nJava原先是把源代码编译为字节码在虚拟机执行，这样执行速度较慢。\n而HotSpot将常用的部分代码编译为本地（原生，native）代码，这样显着提高了性能。\nJVM结构\n\nClass Loader：类加载器子系统\nRuntime Data Areas：运行时数据区\nExecution Engine：执行引擎\n\nClass Loader 类加载器子系统Class Loader 作用\n负责从文件系统或网络中加载Class文件，生成运行时数据结构\n只负责加载，不确保可以运行（Execution Engine决定）\n加载的类信息存放在 Method Area 方法区，堆中会有一个Class对象作为入口\n\n\n我们编写一个.java文件的类，例如Car，到在JVM中创建实例，有这几个过程：\n\n.java &gt;&gt;&gt;&gt;.class\n.class&gt;&gt;&gt;&gt; 进入JVM &gt;&gt;&gt;&gt; 生成 DNA元数据模板\nJVM根据DNA元数据模板生成多个Car对象\n\nClass Loader在这个过程中相当于一个快递员\n\n类的加载过程总共有三大步：\n\n加载 Loading\n链接 Linking：又分为验证、准备、解析\n初始化 Initialization\n\nLoading 加载\n通过一个类的全限定名获取此类的二进制字节流\n\n将这个字节流所代表的 静态存储结构转化为方法区的 运行时数据结构\n\n在堆中生成一个代表这个类的java.lang.Class对象，作为方法区对这个类的各种数据的访问入口\n\n\n对于加载来源的补充， .class文件可以来自：本地直接加载、网络获取、Jar包直接读取的、运行时自动生成（动态代理技术）、其他文件生成（例如JSP文件）、从加密文件中获取（防止反编译）\nLinking 链接链接有三个步骤：\n\n验证 verify\n\n目的：为了保证.class文件内容符合当前虚拟机的规范\n（例如我是HotSpot VM 你不能给我 Taobao Vm的字节码文件，这样我读不懂）\n包括四种验证：文件格式验证、元数据验证、字节码验证、符号引用验证\n\n\n准备 Prepare\n\n为类变量分配内存，并设置默认初始值（此时并不会给真正的值，初始化时才会给真正的值）\n注意：\n\n对于final static修饰的类常量，在编译时就分配了内存，在此阶段只是显式初始化\n不会为实例变量初始化，因为实例变量会随对象一起分配到堆区中\n\n\nPS：\n\n类变量：即类的变量，即用static修饰的变量，类变量的信息会放在方法区中\n实例变量：对象的变量，没有使用static修饰，会存放在Java堆中\n\n\n\n\n解析 Resolve\n\n目的：将常量池中的符号引用转换为直接引用\n\nps：\n\n符号引用（Symbolic Reference）是指在编译时期或者运行时期使用的一种符号名称，它并不直接指向内存中的位置。它是一个符号，用于表示某个类或者类的成员（字段、方法）\n直接引用：直接引用（Direct Reference）是指直接指向内存中的位置的引用。\n\n\n这里举一个例子，解释一下什么叫符号引用转换为直接引用：\n假设我们有如下一段程序：\npublic class User &#123;    private Database database; // 这里就是符号引用    public void connect() &#123;        database.connect();    &#125;&#125;\n\n\n在编译阶段和初始类加载阶段，User类中的database字段只是一个符号引用\n在链接阶段的解析阶段，JVM会将符号引用转换为直接引用，在链接阶段的解析阶段，JVM会将符号引用转换为直接引用，以便在程序执行时能够直接访问。\n\n在解析阶段，JVM会根据运行时常量池中的符号引用信息，查找并确定database字段的直接引用，然后将其与User类的字段进行关联。\n通过这个转换，当我们在User类的connect()方法中调用database.connect()时，JVM能够直接定位到database字段对应的内存位置，并执行相关操作。这样就避免了在每次访问database字段时进行符号解析的开销，提高了程序的执行效率。\n注意：\n\n实际上，解析过程通常在JVM初始化完后才会执行\n\nInitialization 初始化初始化阶段就是执行类构造器方法&lt;clinit&gt;()的过程（&lt;clinit&gt;()被称为类构造器方法，与类的构造器完全不同）\n\n ps:     &lt;clinit&gt;()方法不需要定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来\n\n只要程序中有静态代码块或是普通的类变量（指没有用final修饰），就会出现&lt;clinit&gt;()方法\n\n注意：\n\n类构造器&lt;clinit&gt;()方法不同于类的构造器（即&lt;clinit&gt;与&lt;init&gt;不同！！后者每一个类都有，前者则不一定）\n\n类构造器方法按顺序执行初始化（参见下文代码示例）\npublic class Hello &#123;    static &#123;        temp = 2;    &#125;    static int temp = 1;    public static void main(String[] args) &#123;        System.out.println(temp); //输出 1    &#125;&#125;\n\npublic class Hello &#123;    static int temp = 1;    static &#123;        temp = 2;    &#125;    public static void main(String[] args) &#123;        System.out.println(temp); //输出 2    &#125;&#125;\nfinal修饰的类变量不会在&lt;clinit&gt;方法中初始化\n\n如果该类有父类，会确保父类的&lt;clinit&gt;方法先执行\n\n一个类的&lt;clinit&gt;方法只会在首次使用这个类的时候运行，只运行一次！\n\n虚拟机必须保证，一个类的&lt;clinit&gt;方法会在并发下被同步加锁（即这个方法只会运行一次）\n\n\n类加载器的分类最常见的类加载器只有3个：（JDK9之前）\n\n引导类加载器（BootStrap ClassLoader）\n\n使用C/C++实现，在JVM内部\n用来加载Java核心库（JAVA_HOME/jre/lib/rt.jar、resources.jar、sun.boot.class.path路径下的内容，用于提供JVM自身运行所需要的类，比如String类、Integer类等等核心类库）\n其没有父类加载器，获取为nullname.class.getClassLoader == null\n加载另两个加载器\n出于安全考虑，只会加载包名为java, javax, sun开头的类\n\n\n扩展类加载器（Extension ClassLoader）\n\nJava语言编写，是sun.misc.Launcher$ExtensionClassLoader的内部类\n间接继承自ClassLoader\n从java.ext.dirs系统属性指定的目录中加载类库，或从JDK的安装目录jre/lib/ext子目录下加载类库。如果我们写的JAR也放在这里，也会由扩展类加载器自动加载。\n\n\n应用程序类加载器（App ClassLoader，也叫系统类加载器 System ClassLoader）\n\nJava语言编写，Launcher的内部类\n\n父类为扩展类加载器\n\n负责加载环境变量classpath或系统属性java.class.path指定路径下的类库\n\n加载自定义的类，可以使用ClassLoader.getSystemClassLoader()获取\n\n\nClassLoader classLoader = ClassLoaderTest.class.getClassLoader();System.out.println(classLoader);// sun.misc.Launcher$AppClassLoader@18b4aac2 自定义类使用AppClassLoader加载ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();System.out.println(systemClassLoader);// sun.misc.Launcher$AppClassLoader@18b4aac2 与上面的相同！！\n\nJDK9之后，引入了模块系统，对比之前的类加载器，有几个变化：\n\n启动类加载器：改为Java语言编写，但是获取依然为null（为了兼容）\n扩展类加载器：移除，换为平台类加载器（平台类加载器只是为了前向兼容，其本身已无实际意义）\n\n\n左边为JDK9之前，右边为JDK9之后。\n在委派给父类加载器之前，会先判断能否归属到某一个系统模块，如果能就优先委派给负责对应模块的类加载器。\n自定义类加载器\n什么时候我们才会要去自定义类加载器？\n\n\n隔离加载类（防止用中间件导致命名空间冲突）\n修改类加载的方式\n扩展加载源\n防止源码泄露（可以对指定的字节码文件进行解密）\n\n实现自定义类加载器的步骤\n继承ClassLoader类\n实现findClass()方法（JDK1.2前是重写loadClass方法）\n如果没有太复杂的需求，可以继承URLClassLoader类，避免自己去编写findClass()方法及其获取字节流的方式\n\nClassLoader是一个抽象类，除了BootStrapClassLoader，其余全部继承了ClassLoader类，它的抽象方法如下：\n\ngetParent()：返回该类加载器的超类加载器\nloadClass(String name)：加载名称为name的类，返回java.lang.Class类\nfindClass(String name)：查找名称为name的类，返回java.lang.Class类\ndefineClass(String name, byte[] b, int off, int len)：把字节数组 b 中的内容转换为一个Java类，返回结果为java.lang.Class类的实例\nresolveClass(Class&lt;?&gt; c)：连接指定的一个Java类\n\n获取ClassLoader的途径//【法一】：通过当前类的Class对象来获取ToGetClassLoader.class.getClassLoader();//【法二】：获取当前线程上下文的ClassLoaderThread.currentThread().getContextClassLoader();//【法三】：ClassLoader获取AppClassLoaderClassLoader.getSystemClassLoader();//【法四】：通过获取AppClassLoader，进而获取ExtensionClassLoaderClassLoader.getSystemClassLoader().getParent();\n\n双亲委派机制\n双亲委派机制：加载class文件时，把加载请求逐级向上递交，上级加载器不加载此class时，才会交由低级的加载器加载。\n\n如图：\n\n当我们加载自定义的一个类时，也会走这么一个流程：\n会一级一级向上传递，然后引导类加载器和拓展类加载器都说自己不加载，才会轮到系统类加载器加载。\n\n1、面试常见问题：如何将自己写的java.lang.String导入JVM\n\n答：如果是java.lang包下的内容，是无法加载的，因为双亲委派机制的存在，java.lang包下的内容全部会被引导类加载器加载。即使使用了自定义的类加载器去加载，规避双亲委派机制，但由于是java.开头的包，也会被沙箱安全机制拦截，报出安全异常。\n\n某博客看到如下的表格就直接拿来用了\n\n\n\n\n包路径不为java.lang\n包路径为java.lang\n\n\n\n通过应用类加载器加载成功\n当从程序内部加载自定义类时，加载失败，默认加载Java中的String；当从外部加载时（即写自定义类加载器），加载失败，Java加载类时存在检测机制，不允许加载任何包路径以java.开头的自定义类\n\n\n\n双亲委派机制的作用\n\n\n避免类的重复加载\n一个类只会由一个加载器加载，不会出现多个加载器加载一个类的情况\n\n保护程序安全，防止核心API被随意更改\n\n\n其他相关问题\n问题1：JVM中表示 两个class对象是否为同一个类 的两个必要条件是什么？\n\n\n类的全限定类名必须一致\n加载这个类的ClassLoader必须相同\n\n\n注意：JVM必须知道一个类是由哪个加载器加载的！\n对于非启动类加载器加载的类，JVM会将类加载器的引用做为类型信息的一部分放在方法区\nJVM解析一个类型到另一个类型的引用时，JVM需要保证这两个类加载器是相同的\n\n\n问题2：类的主动使用与被动使用（类的主动使用和被动使用区别就在于，有没有类加载过程中的初始化过程）\n\n主动使用，有七种情况：\n\n创建类的实例：通过关键字new实例化一个类\n访问某个类或接口的静态变量，或者对静态变量赋值\n调用类的静态方法\n反射：使用Java反射机制访问类的方法或字段。\n初始化一个类的子类\nJVM启动时被标明为启动类的类\nJDK 7开始提供的动态语言\n\n被动使用是指没有直接引用类，而是通过其他途径间接引用类，不会导致类的初始化，只会触发类的加载：\n\n访问类的常量：访问类的常量（被final修饰的基本类型或字符串类型）。\n使用类的数组：使用数组类型，该数组的元素类型是类，不会触发该类的初始化。\n通过子类引用父类的静态变量：通过子类引用父类的静态变量，不会触发子类的初始化。\n通过类名获取Class对象：通过Class.forName(&quot;ClassName&quot;)获取类的Class对象，不会触发该类的初始化。\n\n\n问题3：三个类加载器之间的关系是什么？\n\n\n注意：\n\n不是继承关系！！\n可以理解为等级制度！！\n\n真正的关系是这样的：\n\n\n注意：他们俩都是sun.misc.Launcher的内部类，Launcher本身只是一个启动器\n\nRuntime Data Areas 运行时数据区有五大部分：\n\n方法区 Method Area（在JDK1.8后 叫元数据区）\n堆 Heap\n程序计数器 Program Count Register (PC)\n本地方法栈 Native Method Stack (NMS)\n虚拟机栈 JVM Stack (VMS)\n\n其中，加粗的部分为每个进程一份（即整个JVM只有一个方法区和堆区），其他部分每个线程各有一份，共用方法区和堆区\n而且JVM中的线程与操作系统的线程是一一映射关系的\nPC\nPC 程序计数寄存器：不同于CPU内的PC，而是一种模仿的抽象，也叫程序钩子\n\nPC寄存器用来存储指向下一条指令的地址，也即将要执行的指令代码。由执行引擎（Execution Engine）读取下一条指令。\n如图：\n\n\n特点\n\n\n小而精：占很小的一块内存，处于运行速度最快的区域\n线程私有，PC与线程共存亡\n不会发生OOM（Out of Memory）\n记录当前方法的JVM指令地址（若执行Native Method，则PC是 undefined）\n\n\n当前方法：任何时间线程只能有一个方法在执行，这个方法就在当前虚拟机栈栈顶\n\n比下面的例子：\npublic class PC &#123;    public static void main(String[] args) &#123;        // -1 0 1 2 3 4 5 由 iconst_m1 0 1 2 3 4 5 指令执行        // 其他使用 bipush 值 指令执行        int a = 10;     // bipush 10        int b = 3;      // iconst_3        int k = a - b;  // isub    &#125;&#125;\n\n反编译后如下：左边的红色数字，代表指令地址（偏移地址），右边代表具体的指令\n\nPC在这个过程中会存放偏移地址，执行引擎会从PC中读取位置，再去执行指令\n相关问题：\n\n\n使用PC存储字节码指令地址有什么用？或者说为什么使用PC记录当前线程的执行地址？\n\n\n因为CPU会不停的切换线程，当切换回此线程时，得知道从哪儿继续任务，所以就使用PC这个结构来存储指令地址\n然后字节码解释器就通过改变PC值来明确下一条应该执行什么样的字节码指令\n\n\nPC寄存器为什么要设置为线程私有？\n\n\n如果不设置PC为私有，那么就得把PC内的值存到一个地方，这样切换线程时，需要不停的存PC读PC，增大了切换线程的开销。要是给每个线程一个PC，那么切换就消除了这个开销。\n虚拟机栈\n虚拟机栈：保存程序运行期间的局部变量（8种基本数据对象、引用对象的地址）、部分结果、参与方法的返回和调用\n\n\n线程私有，与线程共存亡\n存储的基本单位：栈帧（Stack Frame）\n速度仅次于PC\n不存在垃圾回收问题，但是存在Stack Overflow和Out Of Memory异常\nJVM对其有两个操作：入栈、出栈\n\n\n栈的Stack Overflow 与 OOM\n\nJVM允许栈可以是固定不变的，也可以是动态增长的：\n\n固定不变：线程创建时就指定了具体的大小，如果此线程运行过程中，超出了最大容量，那么会报出Stack Overflow Error异常\n动态增长：栈可以自己动态增长，但是在尝试扩展时，无法申请到足够的内存，或者在创建线程时，内存达不到申请的要求，就会抛出OOM异常\n\n总结就是：超出了栈范围 -&gt; Stack Overflow，无法申请到内存 -&gt; OOM\n可以使用Java的-Xss参数设置栈内存大小：java -Xss1m //设置1M的内存；k代表kb ；G代表 Gb\n栈帧 Stack Frame\n栈帧的特点\n\n\n每一个方法对应一个栈帧\n栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息\n处于栈顶的栈帧，叫做当前栈帧；对应的方法，称为当前方法；对应执行这个方法的类，就叫做当前类\n执行引擎运行的所有字节码指令只对当前栈帧进行操作\n若该方法调用其他方法，则会创建新的栈帧，压入栈中，待其运行完成后，出栈。\n\n注意：\n\n不同线程的所含的栈帧不允许相互引用\n如果方法嵌套使用，内方法的返回值会传回外方法的栈帧\n方法有两种方式将栈帧弹出：\nreturn语句\nthrow抛出异常\n\n\n\n\n栈帧的结构，由五个部分组成：\n\n局部变量表 Local Variables （使用插槽slot存放局部变量）\n操作数栈 Oprand Stack （存放计算的中间结果）\n动态链接 Dynamic Linking （负责符号引用和直接引用转换）\n方法返回地址 Return Address （调用该方法结束后，应该返回的地址）\n一些附加信息（调试信息、异常处理表）\n\n下面重点介绍局部变量表：\n\n 局部变量表\n\n\n是一个数字数组（int byte char short等均为数字；bool转换0表示假，非0表示真；引用类型可以使用地址，也为数字）\n局部变量表所需的容量大小在编译期就确定下来，保存在方法的code属性的maximum local variables数据项中，在方法运行期间不会改变。\n方法嵌套的次数由栈的大小决定。（如果一个方法的参数和局部变量越多，使得局部变量表变大，那么嵌套次数就会变少）\n对于GC来说，局部变量表所直接引用或间接引用的对象，都不会被回收\n\n局部变量表还有一个概念就是插槽 Slot，Slot是局部变量表最基本的存储单元，他有这样几个特点：\n\n哪些会占用插槽？this、入参、方法内的局部变量（插槽是可以重用的）\nbyte short char bool存储前会被转换为int；\n32位以内占用一个slot（包括引用类型和 returnAddress）；64位占用两个slot 如long double\nJVM会给每一个槽都分配一个索引，通过这个索引则可以取到值；方法被调用时，它的方法参数和局部变量都会按照顺序被复制到局部变量表的一个slot上\n对于构造方法和实例方法，会自动引入一个this变量，放在index为0的插槽（也就是第一个插槽）\n\n举个例子：\npublic static void main(String[] args) &#123;    char a = &#x27;c&#x27;;    long i = 10000000L;&#125;private void test() &#123;    int b = 10;    System.out.println(b);&#125;\n\n\n\n\n槽也可以重用，如果过了局部变量的作用域，那么下面的变量会占用此槽\n例如：一个实例方法\nprivate void test2() &#123;    int a = 10;    int b = 100;    &#123;        int c = a+b;    &#125;    for (int i = 0 ; i&lt; 10;i++)&#123;        System.out.println(2);    &#125;    int d = a + b;&#125;\n\n假如槽不会重用，那么会有几个槽呢？\n是不是会有6个（this、a、b 、c 、i 、d）？\n但实际上只有4个：（我怎么数了数是5个？注意看序号，有两个序号为3！）\n\nJVM执行这个方法时，执行过程如下：\n\n实例方法this用一个槽 (slot: 0)\n变量 a b各用一个槽 (slot: 1, 2)\n有c再用一个槽 (slot: 3)\n诶，c消失了，那就让i用c的槽吧 (slot: 3)\n诶，i也无了，变量d去用吧 (slot: 3)\n\n\n 问题：为什么类变量可以不给初值使用，但是局部变量不行\n\n现在我们知道原因了，因为：\n类在加载过程中，有加载、链接、初始化三个过程，而第二步链接又有验证、准备、解析三个过程，在准备阶段，所有的类变量会被给默认值，到了初始化阶段才会将程序员给变量的值赋值给类变量。\n但是对于局部变量来说，一个方法的局部变量表就没这么多过程了，如果没给初始值，系统也不知道这个值是多少，也就没法使用\n\n对于GC来说，局部变量表所直接引用或间接引用的对象，都不会被回收\n\n所以Java性能调优，局部变量表可以大作文章！\n关于JVM栈的几个问题\n\n举例栈溢出的情况\n\n\n答：Stack Overflow栈溢出，栈中存放栈帧，每一个栈帧代表一个方法，日常编程中，递归调用方法时，当栈帧累计增加起来，就会导致栈的大小不足，导致栈溢出\n\n\n-Xss调整栈大小，就能不出现Stack Overflow吗？\n\n\n答：当然不能，无论调多大的栈内存，都有可能用完。不过栈越大，能跑的方法也就越多，有时候调整栈变大，会解决Stack Overflow的问题。\n\n\n垃圾回收是否涉及到JVM栈\n\n\n答：垃圾回收不涉及VMS，只有方法区和堆才设计GC操作。\n\n\n方法中定义的局部变量是否线程安全\n\n\n答：线程安全：\n\n只有一个线程可以操作此数据，必是线程安全的；\n若有多个线程可以操作此数据，那这个数据就是共享数据，若没有进行同步，则存在安全问题；\n\nStringBuilder是一个线程不安全的类（StringBuffer是线程安全的）\n// 线程安全private void a() &#123;    StringBuilder sb = new StringBuilder();    sb.append(1);    sb.append(&quot;2&quot;);&#125;// 线程不安全private void b(StringBuilder sb) &#123;    sb.append(1);    sb.append(&quot;2&quot;);&#125;// 线程不安全private StringBuilder a() &#123;    StringBuilder sb = new StringBuilder();    sb.append(1);    sb.append(&quot;2&quot;);    return sb;&#125;\n\na方法中是线程安全的，因为a中的StringBuilder始终都是在VMS内的，每个线程的VMS是独占的，所以也就不存在线程安全问题；\nb方法中线程不安全，因为b中的StringBuilder是一个引用，这个对象存在的位置在堆中，堆不是线程独占的，所以有可能多个线程争抢，就存在线程安全问题；\nc方法线程不安全，因为它将StringBuilder返回出去（逃逸），没有完完全全在VMS内产生，又在VMS内消亡，所以会有线程安全问题\n总结：方法内什么样的局部变量不会出现线程安全问题呢？就是既在方法内产生，又在方法内消亡的局部变量。\n本地方法栈VMS用来管理Java方法调用，NMS来管理本地方法调用\n作用：登记方法中使用到的本地方法\n\n注意：当调用本地方法时，就不再受虚拟机控制了！\n\n堆存放一切对象实例\n\n特点\n\n\n进程共有，一个JVM只有一个堆内存\nJVM最大的一块内存空间\n内存大小可以调节 ，物理上不必连续，逻辑上连续（使用参数-Xms10m -Xmx20m设置堆最小10m，最大20m）\n线程可以在此划分私有的缓冲区（Thread Local Allocation Buffer ，TLAB）\n\n堆内存结构：在1.7与1.8有区别\n\nJDK 1.7 堆空间\n\n逻辑上堆分为：年轻代、老年代、永久代\n\n年轻代：又可以分为两部分\nEden 伊甸园区\nSurvivor区\nSurvivor 0区\nSurvivor 1区\n\n\n\n\n老年代\n永久代：不属于堆空间的一部分，只是逻辑上分到了这一部分\n\n\nJDK 1.8 堆空间\n\n逻辑上堆分为：年轻代、老年代、元空间\n年轻代与老年代没有变化\n\n元空间：物理上在直接内存内，不在堆中\n\n新生代与老年代\n默认比例：新生代 : 老年代  = 1 : 2\n\n可以通过参数进行设置 -XX:NewRatio=n其中n表示一个数字，假如为5，那么新生代与老年代比例就为1:5（开发中不会修改这个参数）\n新生代的大小可以用参数-Xmn显示指定，而且优先度大于上面的选项\n\n新生代中，Eden与另外两个Survivor区的比例是8:1:1  \n\n这个数值也可以调整：-XX:SurvivorRatio=8\n但去验证一下，会发现其实并不是完全的8:1:1，因为默认开启自适应，JVM会自动进行调整（但就算显示关闭自适应，也不会是8:1:1，只有显示声明参数设-XX:SurvivorRatio=8，才会是8:1:1）\n\n几乎所有的Java对象都在Eden区被new（例外：直接new了一个大于Eden区的对象）\n绝大部分Java对象都在新生代被销毁了\n\n对象的分配过程一个对象被分配，有以下流程：\n\nnew对象\n先放到Eden区（优先Eden区的TLAB）\nEden区已满 →  3\nEden区未满：直接放入\n\n\n触发YGC/Minor GC，清除游离的对象（会对Survivor与Eden都进行清理）\n清除后，将剩余的对象转至to区，并将from区内依然存在的对象也放入to区，对象每经历一次YGC，就会将一个属性值+1\n若此属性值，大于设置的阈值（默认是15），就会promotion（晋升）进入老年代\n\n\n\n流程如图：\n\n注意：\n\nYGC会清理Eden与Survivor的游离对象；但是触发YGC的只能是Eden区满\nSurvivor区满，会直接将其对象promotion至老年代\nfrom区与to区是根据survivor 0与survivor 1区谁满谁不满而言的，空的就是to区，另一个就是from区\n如果new的对象整个Eden都放不下，会去往老年区分配内存；如果老年区放不下，会进行FGC，执行完依然放不下，就会出现OOM\n阈值默认为15，可以通过-XX:MaxTenuringThreshold=&lt;N&gt;进行设置\nGC会频繁发生在新生代，很少发生在老年代，几乎不在永久区/元空间收集\n\nnew对象的线程安全问题new对象分配内存时，会优先分配在堆的TLAB（本地线程分配缓冲）内，TLAB属于线程私有，大约占Eden空间的1%，在TLAB可以不加锁快速分配\n但如果分配失败，那么会采用CAS重试的方式来保证分配安全。\n\nMinor GC、Major GC、Full GC区分HotSpot VM的实现，把GC分为两大种类型：\n\n部分收集（Partial GC）\n新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集\n老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集\n只有CMS GC会有只收集老年代的行为\n\n\n混合收集（Mixed GC）：收集整个新生代及部分老年代\n只有G1 GC会有Mixed GC\n\n\n\n\n整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集\n\n\nGC触发时机：\n\n\nYGC\n触发时机：Eden区空间不足！\n会引发STW(Stop the world)，暂停其他用户线程，只有GC结束后，才会使其继续执行\n\n\nMajor GC\n触发时机：老年代空间不足，先触发YGC，如果还不足触发MajorGC\nSTW的时间更长\n\n\nFull GC\n触发时机：\n调用System.gc()，系统建议执行Full GC，但不一定\n老年代空间不足\n方法区空间不足\nYGC后，进入老年代的平均大小大于老年代可用内存\nEden、from区向to区复制时，大小大于to区，也大于了老年代内存\n\n\nFull GC应尽量避免\n\n\n\n\n问题：为什么要把堆进行分代？不分代不能正常工作吗？\n\n答：不分代也可以正常工作，只不过性能没有分代强。在Java程序中，70%~80%对象都是临时对象，如果不进行分代，每次进行GC都需要遍历很多很多对象，这样性能肯定不会强。如果分为新生代、老年代，就可以大大加快效率\n对象提升规则针对不同年龄段的对象分配原则如下：\n\n优先分配到Eden\n大对象直接分配到老年代\n长期存活的对象分配到老年代\n动态对象年龄判断\n如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，无需等到MaxTenuringThreshold要求的年龄\n\n\n空间分配担保\n将Survivor区无法存放的对象放入老年代\n-XX:HandlePromotionFailure\n\n\n\nTLAB\nTLAB（Thread Local Allocation Buffer）\n\n\n堆是线程共享的区域，TLAB是堆上属于线程私有的区域\nTLAB在Eden区，仅占Eden空间的1%，我们可以通过选项-XX:TLABWasteTargetPercent来设置TLAB空间所占的大小\nJVM首选TLAB进行分配，如果内存不够大，会使用锁方式确保原子性，在非TLAB的Eden区域进行分配\n\n\n为什么使用TLAB\n\n为避免多个线程操作同一地址，需要使用锁机制，影响分配速度。加入TLAB可以直接避免线程安全问题，提高内存分配效率（这种分配方式也叫快速分配策略）\n参数设置总结-XX:+PrintFlagsInitial\t查看所有的参数的默认初始值-XX:+PrintFlagsFinal\t查看所有的参数的最终值-Xms\t初始堆空间内存（默认为物理内存的1/64）-Xmx\t最大堆空间内存（默认为物理内存的1/4）-Xmn\t设置新生代大小-XX:NewRatio\t设置新生代与老年代的比例-XX:SurvivorRatio\t设置新生代Eden和s0/s1的空间比例-XX:MaxTenuringThreshold\t设置新生代垃圾的最大年龄-XX:+PrintGCDetails\t输出详细的GC处理日志-XX:HandlePromotionFailure\t是否设置空间分配担保（JDK7+失效）\n\nYGC之前，JVM会检查老年代最大可用连续空间是否大于新生代所有对象的总空间\n\n如果大于：YGC会安全执行\n如果小于：会查看HandlePromotionFailure设置的值\n设置值为true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到新生代的对象的平均大小\n若大于：执行一次YGC，但是是有风险的\n小于，Full GC\n\n\n设置为false，执行Full GC\n\n\n\nJDK7+之后，HandlePromotionFailure失效，改为\n老年代最大可用连续空间是否大于新生代所有对象的总空间\n\n大于：YGC\n小于：Full GC\n\n逃逸分析\n堆是对象分配的唯一选择吗？\n\n不是的，栈上分配，标量替换技术都会导致对象不在堆中分配；TaoBaoVM创新的GCIH实现off-heap，可以将生命周期较长的对象放在堆外，提高GC回收效率（但是，这些技术都没有被采用，所以在Java中，堆就是对象分配的唯一选择！！）\n\n逃逸分析（Escape Analysis）：\n一种可以有效减少Java程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法\n\n逃逸分析的基本行为就是分析对象动态作用域：\n\n当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸\n当一个对象在方法中被定义后，被外部方法所引用，则认为发生逃逸\n例如：给成员变量赋值、方法返回值、实例引用传递变量都会发生逃逸\n\n\n\n没有发生逃逸的对象，就可以分配到栈上，随着方法执行结束，栈空间就被移除，就不需要GC了\n\n编译器会对代码做如下优化：\n\n\n栈上分配：如果对象没有逃逸，就可以优化为栈上分配\n\n同步省略：如果一个对象被发现只有一个线程访问，则这个对象可以不考虑同步\n\n在动态编译同步块的时候，JIT编译器可以借助逃逸分析来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程\n如果没有，那么JIT编译器在编译这个同步块的时候就会取消对这部分代码的同步\n取消同步的过程就叫同步省略，也叫锁消除。\n\n例如如下代码：\npublic void f()&#123;    Object hollis = new Object();    //其实这个锁加了并没用，但不妨碍做一个例子    synchronized(hollis) &#123;        System.out.println(hollis);    &#125;&#125;\n\n多个线程执行这个代码时，实际上JIT会对这段代码进行优化，最终如下执行\npublic void f()&#123;    Object hollis = new Object();    //同步省略，锁消除    System.out.println(hollis);&#125;\n标量替换：\n\n标量（Scalar）：指一个无法再分解成更小数据的数据（Java中原始数据类型就是标量）\n聚合量（Aggregate）：可以分解的数据\n经过逃逸分析，如果一个对象不会被外界访问到，就会把这个对象拆解成若干个成员变量（即将聚合量变为标量）\n\n例如如下代码：\npublic static void main(String[] args)&#123;\talloc();&#125;private static void alloc ()&#123;\tPoint point =new Point (1,2) ;\tSystem.out.println (&quot;point.x=&quot;+point.x+&quot;;point.y=&quot;+point.y);&#125; class Point&#123;\tprivate int x;    private int y;&#125;\n\n会被优化为：\nprivate static void alloc ()&#123;\tint x = 1;\tint y = 2;\tsystem.out.println(&quot;point.x=&quot; + x + &quot;; point.y=&quot;+y);&#125;\n\n逃逸分析技术并不成熟：\n​        其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。\n​        所以呢HotSpot VM没有采用栈上分配这种方式，所以在Java中所有对象都是在堆上分配的。\n\n（具体Java对象会不会栈上分配，这有一些争议。很多博客都写着，因为new 100w个user，开启逃逸分析后，堆中只会存放30w，少了很多，就认为对象可以在栈上存放，但是这些只能说明标量替换的效果，并不能证明真正实现了栈上分配；我查阅多个较为靠谱的资料，可以总结以下内容，如果有错误，请指正！）\n结论如下：\n\nJava对象一定都在堆内存放；Hotspot VM实际没有实现栈上分配，而是使用标量替换来进行优化。\n\n（此处结论参考的文献：美团技术团队此篇博客、尚硅谷宋红康JVM教程、极客时间杨晓峰Java核心技术面试精讲）\n\n你也可以认为，除了堆，栈上也存放了对象；因为即使是标量替换，也是将原本的对象拆开了存了进去。\n\n堆内存的设置堆内存在JVM建立时就确定了，可以通过参数来设置堆空间（新生代+老年代）大小：\n-Xms 表示堆区的起始内存 等价于-XX:InitialHeapSize-Xmx 表示堆区的最大内存 等价于-XX:MaxHeapSize\n\n如果堆区内存超过设置的最大内存，就会出现OOM错误\n通常设置两个值为相同的值，是为了GC清理完堆区后，不需要重新分隔计算堆区的大小，从而提高性能\n默认的初始化值，按电脑的内存不同而不同，大致关系如下：\n\n起始内存的值 =  电脑内存大小 / 64\n最大内存的值 = 电脑内存大小 / 4\n\n查看自己JVM堆内存的Demo\npublic class HeapMem &#123;    public static void main(String[] args) &#123;        // 查看堆空间大小        long initialMemory = Runtime.getRuntime().totalMemory();        long maxMemory = Runtime.getRuntime().maxMemory();        System.out.println(&quot;-Xms: &quot;+ initialMemory / 1024 / 1024 + &quot;M&quot;);        System.out.println(&quot;-XmX: &quot;+maxMemory / 1024 / 1024 + &quot;M&quot;);        System.out.println(&quot;系统内存大小（用-Xms来计算）&quot; + initialMemory * 64.0 / 1024 + &quot;G&quot;);        System.out.println(&quot;系统内存大小（用-Xmx来计算）&quot; + maxMemory * 4.0 / 1024 + &quot;G&quot;);    &#125;&#125;\n\n运行结果：（我的电脑是 16 GB）\n-Xms: 245M-XmX: 3614M系统内存大小（用-Xms来计算）1.6089088E7G系统内存大小（用-Xmx来计算）1.4804992E7G\n\n注意这里得到的值，并不是实际的堆空间大小，它只包括老年代与部分新生代（伊甸园区 + 任一个Survivor区），因此会小一些\n可以证实一下：给这个demo睡一会儿\npublic class HeapMem &#123;    public static void main(String[] args) &#123;        ...        try &#123;            Thread.sleep(1000000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n设置参数启动\n-Xms600m-Xmx600m\n\n打开cmd\n输入jps\n\n运行结果如下：\n-Xms: 575M-XmX: 575M系统内存大小（用-Xms来计算）3.76832E7G系统内存大小（用-Xmx来计算）2355200.0G\n\n打开cmd，输入如下内容，红色圈住为新生代、蓝色为老年代，其中后缀为U的为已使用，后缀为C表示总量\n\n我们加一下( S0C + S1C + EC + OC )/ 1024 = 600M\nSOC / 1024 = 25M ，输出结果少了25M，验证了猜想\n（也可以直接用**-XX:+PrintGCDetails参数**来打印内容）\n方法区（元空间）\nJdk7及之前，都叫做方法区；Jdk8之后改为元空间\n\n存放类的相关信息，其入口在堆中的Class对象实例中\n\n特点\n\n\n逻辑上属于堆，但其实是独立于Java堆的内存空间（No-Heap）\n属于共享区域\n物理上内存空间可以不连续\n大小可以固定也可以动态扩展；决定了系统可以保存多少个类\n如果类太多，元空间存不下，那么会出现OOM\n\n方法区的演进过程JDK7及之前，称方法区为永久代（方法区和永久代并不等价，仅在hotspot vm实现而言，两者等价）\nJDK8+，使用元空间取代了永久代，但有区别\n\n元空间不在虚拟机设置的内存中，而是直接使用本地内存\n内部结构也进行了调整\n\n\n方法区设置\nJDK7-\n\n\n使用-XX:PermSize来设置永久代初始分配空间，默认值 20.75M\n使用-XX:MaxPermSize来设置永久代最大可分配空间，32位机器默认64M，64位机器默认82M\n\n\nJDK8+\n\n\n使用-XX:MetaspaceSize与-XX:MaxMetaspaceSize取代上述原有两个参数\n默认值依赖于平台\nwindows下，默认初始值为21M，最大值默认为-1，意味着没有限制\n\n\n\n注意：\n\n大小可以固定，也可以动态增长\n如果运行中，超过了默认值21M，那么会触发Full GC，并重新设置MetaspaceSize\n为防止频繁的发生Full gc，建议设置大一点\n\n方法区内部结构\n方法区存放：\n\n\n类型信息\n运行时常量池\n静态变量\nJIT代码缓存\n域信息\n方法信息\n\n\n\n类型信息\n\n对于类、接口、枚举、注解，JVM必须存储以下信息：\n全限定类名\n直接父类的全限定类名（除了interface和java.lang.Object，因为他们没有父类）\n类的修饰符（例如pulic abstact final等）\n直接接口的一个有序列表\n\n\n\n\n域信息\n\n存放属性的相关信息以及声明顺序\n域名称\n域类型\n域修饰符\n\n\n\n\n方法信息\n\n存放方法的信息以及声明顺序\n方法名称\n方法返回类型（或void）\n方法的参数的数量和类型\n方法修饰符\n方法字节码、操作数栈、局部遍历表及大小（abstract和native方法除外）\n异常表（abstract和native方法除外）：每个异常处理开始的位置、结束位置、代码处理在PC中的偏移地址、被捕获的异常类的常量池索引\n\n\n类加载器的信息（哪一个加载器加载的此方法）\n\n\n类变量\n\n非final类变量：\n随着类的加载而加载\n\n\nfinal类变量\n编译时期就被分配\n\n\n\n\n运行时常量池（Run-time Constant Pool）\n\n重点来谈\n\n\n\n运行时常量池要知道运行时常量池，先来搞懂常量池\n\n常量池\n\n一个类编译成字节码文件后，仍然需要数据支持，这种数据很大，不能直接存到字节码内，就存放到了常量池中\n常量池存放的数据有：数量值、字符串值、类引用、字段引用、方法引用\n类似这样：\n\n反编译后常量池内容：\nConstant pool:   #1 = Methodref          #5.#24         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Fieldref           #4.#25         // User.id:Ljava/lang/String;   #3 = Fieldref           #4.#26         // User.name:Ljava/lang/String;   #4 = Class              #27            // User   #5 = Class              #28            // java/lang/Object   #6 = Utf8               id   ...等等...\n\n​        常量池可以看做一张表，存放编译期产生的字面量与符号引用，虚拟机指令根据这个表查找要执行的类名、方法名、参数类型、字面量等类型。\n\n运行时常量池\n\n\n方法区的一部分\n编译后字节码文件中的常量池会在类加载后放到此处\n每一个已加载的类型（类或接口）都维护一个常量池\n运行时常量池中不仅包括编译器的字面量，还有运行期解析后的方法或字段引用，此时不再是符号引用，而是真实的地址\n具有动态性：比常量池内容要多一些\n\n方法区演进细节\n\n\n版本\n方法区细节\n\n\n\nJDK1.6-\n有永久代，静态变量存放在永久代\n\n\nJDK1.7\n有永久代，但已经逐步去除永久代；字符串常量池、静态变量保存在堆中\n\n\nJDK1.8+\n无永久代，类型信息、字段、方法、常量保存在本地内存的元空间中，但字符串常量池、静态变量仍然保存在堆中\n\n\n\n\n为什么要用元空间替换方法区？\n\n\n为永久代设定空间大小很难确定\n某些场景下，使用动态加载类过多，容易导致永久代存满，触发多次Full GC，甚至很容易导致OOM\n\n\n对永久代进行调优十分困难\n历史原因：当时Hotspot VM要与JRockit VM进行合并，然而JRokit根本没有永久代（只有HotSpot有永久代）\n\n\n为什么要将StringTable（字符串常量池）放在堆中\n\n\n开发中StringTable使用频率很高，但是原本存放在永久代，只有Full GC才能清理回收这一块内存，而放在堆中，可以提高回收效率\n\n方法区垃圾回收方法区的垃圾回收主要回收两部分内容：\n\n常量池中废弃的常量\n\n不再使用的类型\n\n\n\n\n常量池中的两大类常量：字面量与符号引用\n\n\n\n字面量：例如文本字符串、final声明的常量值等\n符号引用\n类与接口的全限定名\n字段的名称与描述符\n方法的名称与描述符\n\n\n\n回收策略：只要常量没有被任何地方引用，就会被回收\n\n\n不再使用的类型（类的回收条件十分苛刻）\n\n\n判断一个类型不再使用，需要同时满足以下三个条件：\n\n该类没有实例，该对象的子类也没有任何实例\n加载该类的类加载器已经被回收（很难达成）\n该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方使用反射访问该类的方法\n\n注意：满足上述条件后也只是被允许被回收，JVM还提供了一个参数进行控制\n-Xnoclassgc控制是否回收类\n-verbose:class、-XX:+TraceClass-Loading、-XX:+TraceClassUnLoading查看类加载、类卸载信息\n\n方法区回收的意义：\n\n在大量使用反射、动态代理、CGLIB等字节码框架，动态生成JSP以及OSGi这类频繁自定义类加载器的场景中，通常都需要Java虚拟机具备类型卸载能力，以保证不会对方法区造成太大压力\n栈、堆、方法区的交互关系线程私有：虚拟机栈、本地方法栈、程序计数器\n线程共享：堆、元空间\n如图：可见方法区存放着类型的信息\n\n本地方法接口\n本地方法接口，就是为了给Java程序调用非Java代码所提供的一个部分。\n\n本地方法：Java用native关键字修饰，意思是此方法实现不是用Java实现的，可能是使用C/C++实现的等等\n\n例如Obejct的getClass方法\npublic final native Class&lt;?&gt; getClass();// 没有方法体？ 有方法体，只不过是其他语言\n\n\n为什么要用本地方法？\n\nJVM要和硬件、操作系统、外界交互，Java语言本身运行速度的并不快，此时用C/C++语言来实现，可以大大提高效率。\n执行引擎主要任务：\n\n负责将字节码指令解释/编译为对应平台上的本地机器指令\n解释执行\n编译执行\n\n注意：\n\n此时的编译称为后端编译，与前端编译（将java程序编译成字节码文件）不同\n执行引擎执行的指令由PC决定\n\n\n为什么Java是半编译半解释性语言？\n\nJava一开始只是解释型语言，只可以通过解释器进行解释执行，但是后来JIT的引入，使得Java可以编译执行。\n解释可以使Java跨平台、编译可以使Java运行更高效\n解释器\n解释器：根据预定义的规范，对字节码采用逐行解释的方式执行，目的是将字节码文件中的内容翻译为对应平台的本地机器指令执行\n\n在Hotspot Vm中，解释器有Intercepter模块与Code模块构成\n\nIntercepter模块：实现了解释器的核心功能\nCode模块：用于管理HotSpot VM在运行时生成的本地机器指令\n\nJIT编译器\n编译器：将源代码直接编译成和本地机器平台相关的机器语言\nJIT：Just In Time 即时编译技术，可以识别出热点代码，直接将其编译，提高执行效率\n\nJava中的“编译”：\n\n.java -&gt; .class：前端编译器（Javac）\n.class -&gt; 机器码：后端运行期编译器（JIT编译器）（Hotspot VM的C1、C2编译器）\n.java -&gt; 机器码：静态提前编译器（AOT编译器，程序运行之前就进行编译，可能是java未来的发展方向）\n\n\n如何识别出热点代码？\n\n一个被多次调用，或者是循环次数较多的循环体都可以叫热点代码，对于这个度量标准，有一个阈值以便于分析出真正的热点代码。（热点探测功能）\nHotspot VM会为每一个方法都建立2个不同类型的计数器，分别称为方法调用计数器（Invocation Counter）和回边计数器（Back Edge Counter）：\n\n方法调用计数器：用于统计方法的调用次数\n回边计数器：用于统计循环体执行的循环次数\n\n在Server模式下默认值为10000次，超过这个值就会进行JIT编译\n\n热度衰减：\n如果不进行热度衰减，随着时间的推移，所有的代码都有可能执行超过了阈值\n所以方法调用计数器统计的是一段时间之内的调用次数，如果超过这个时间，值会减少一半（类似于半衰期）\n\n我们可以设置Java的执行方式：\n\n完全解释：-Xint\n完全编译：-Xcomp\n解释器+即时编译混合模式：-Xmixed（默认）\n\nJVM内嵌有两个JIT编译器，分别是Client Compiler和Server Compiler，通常称为C1与C2编译器，我们可以选择使用\n\n-client：运行在Client模式下且使用C1编译器\nC1编译器会对字节码进行简单可靠的优化，耗时短\n\n\n-server（64位系统默认设置，64位系统即使设置client也会被忽略）：运行在Server模式下，使用C2编译器\nC2编译器会进行耗时较长的优化，以及激进优化，但优化后的代码执行速度更快\n\n\n\n-server模式下，默认开启分层编译策略\n\n分层编译：\n​        程序解释执行（不开启性能监控）可以触发c1编译，将字节码编译成机器码，可以进行简单优化，也可以加上性能监控，C2编译会根据性能监控信息进行激进优化。\n\n\nC1与C2的优化策略也有不同：（了解）\nC1编译器上主要有方法内联，去虚拟化、冗余消除。\n\n方法内联：将引用的函数代码编译到引用点处，这样可以减少栈帧的生成，减少参数传递以及跳转过程\n去虚拟化：对唯一的实现类进行内联\n冗余消除：在运行期间把一些不会执行的代码折叠掉\n\nC2的优化主要是在全局层面，逃逸分析是优化的基础。基于逃逸分析在c2上有如下几种优化:\n\n标量替换：用标量值代替聚合对象的属性值\n栈上分配：对于未逃逸的对象分配对象在栈而不是堆\n同步消除：清除同步操作，通常指synchronized\n\n\n未来（了解）：\n\nJDK10，加入了全新的即时编译器——Graal编译器\nJDK 9 引入了AOT编译器（静态提前编译器）\n\n直接内存特点\n属于OS直接提供的内存\n\n来源于NIO，通过存在堆中的DirectByteBuffer操作Native内存\n\nNIO：New IO / Non-Blocking IO\n相对于旧的IO：如 byte[] / char[]或是Stream\nNIO：Buffer、Channel，基于此还有框架Netty更快更高效\n\n\n读写性能更高\n\n直接内存可能会出现OOM\n\n分配回收成本较高\n\n不受JVM内存回收管理\n\n可以使用MaxDirectMemorySize进行设置；不指定，默认与堆的最大值-Xmx参数值一致\n\n\n这有一个小的Demo，可以体验一下使用ByteBuffer开辟直接内存\npublic class NativeMemory &#123;    private static final int Buffer = 1024 * 1024 * 1024; // 1GB内存    public static void main(String[] args) &#123;        ByteBuffer byteBuffer = ByteBuffer.allocate(Buffer); // 使用直接内存        System.out.println(&quot;直接内存访问完毕&quot;);        Scanner scanner = new Scanner(System.in);        scanner.next(); // 暂停一下程序，等待输入        System.out.println(&quot;直接内存开始释放&quot;);        byteBuffer = null;        System.gc();        scanner.next(); // 暂停一下程序，等待输入    &#125;&#125;\n\n\n\n对象的实例化在堆中，我们已经讲到过对象分配过程，但是那只是一部分。\n创建对象的方式\nnew创建，包括最基本的new，和使用静态方法或者是静态工厂生成的对象。\nClass的newInstance()方法：反射的方式，只能调用空参的构造器，权限必须是public（JDK8之后，这个方法过时了）\nConstructor的newInstance(Xxx)：可以调用空参、带参的构造器，权限没有要求\n使用clone()：不调用任何构造器，但是当前类需要实现Cloneable接口，实现clone()方法\n使用反序列化\n第三方库Objenesis\n\n对象创建的步骤\n判断对象的类是否已经加载、链接、初始化\nJVM遇到new指令，会去metaspace的常量池中定位到一个符号引用，检查这个符号引用对应的类是否已经被加载\n如果没有加载，在双亲委派模式下，使用当前类加载器以ClassLoader + 包名 + 类名为key，查找对应的.class文件，如果没有找到，抛出ClassNotFoundException异常；如果找到，进行类加载，生成对应的Class类对象\n\n为对象分配内存\n首先计算对象的大小，然后在堆中划分内存，此时会遇到一个问题：\n\n内存规整：JVM使用指针碰撞算法（Bump The Pointer）\n内存不规整：JVM使用空闲列表（Free List）分配\n\n\n指针碰撞算法（Bump The Pointer）：\n即在内存中，分开已使用的内存和未使用的内存，然后维护一个指针作为分界点；给对象分配内存时，只需要将指针移动相应大小即可（如果GC选择的是Serial、ParNew这种基于压缩算法的，虚拟机将采用这种分配方式，一般使用带有compact过程的收集器时使用指针碰撞）\n\n\n空闲列表（Free List）：\n一个记录哪些内存块可用的列表。分配内存时，从列表找一块足够大的空间划分给对象即可\n\n\n处理并发安全问题\n\n采用CAS失败重试、区域加锁保证更新原子性\n每个线程先分配一块TLAB\n\n\n初始化分配到的空间\n\n所有属性设置默认值，保持对象实例字段在不赋值时就可以直接使用\n\n\n设置对象的对象头\n\n对象头：（下面会进行主要讲解）\n包含两部分：运行时数据及类型指针\n\n\n执行init方法进行初始化\n此时才会执行类的构造器方法\n\n\n对象的内存布局对象在内存中存储，主要分为以下几个部分：\n\n对象头：包含两部分（对象头占12字节，其中markword占8字节，类型指针占4字节）\n\nMarkWord：存放三大部分即锁信息、GC信息、Hashcode\n哈希值\nGC分代年龄\n锁状态标志\n线程持有的锁\n偏向线程ID\n偏向时间戳\n\n\n类型指针：指向类元数据InstanceKlass，确定该对象所属的类型\n\n\n\n（数组的话还要记录数组的长度）\n\n实例数据（Instance Data）\n\n对象真正存储的有效信息（代码中定义的各种字段，包括从父类继承的）\n有几个规则：\n相同宽度的字段总是被分配到一起\n父类中定义的变量会出现在子类之前\n如果CompactFields参数为true，那么子类的窄变量有可能插入到父类变量的空隙\n\n\n\n\n对齐填充（使用占位符保证内存对齐，没什么其他作用，就是为了对齐，可能会存在）\n为什么要对齐？因为CPU读取内存，必须是一整块一整块的读，所以要将内存对齐\n\n\n\n如下代码，会占用内存几个字节？\nObject o = new Object();\n分为三部分：\n\n对象头：\nmarkword：占8字节\n类型指针klass point：占4字节\n\n\n实例数据\n无实例数据，不占大小\n\n\n字节填充\n64位机器的话，必须可以整除8，所以还需添加4字节\n\n\n\n一共占用16字节\n对象访问定位对象访问有两种访问方式：区别就是指向对象类型数据的指针存放在什么位置\n\n句柄访问：放在堆中的句柄池\n直接指针（HotSpot VM默认采用）：放在对象实例数据内\n\n句柄访问优点：如果对象位置发生移动，也不需要修改到对象类型数据指针的值\n缺点：需要在堆中开辟专属空间\n\n直接指针优点：不需要开辟额外空间\n\nStringTableString是使用最广泛的类之一，字符串常量池这个结构存在于堆中，但是比较重要，所以单独进行讲述\nString类public final class String    implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123;    private final char value[]; // JDK 1.8    private final byte value[]; // JDK 1.9    ...&#125;\n\n\nfinal修饰的类不可继承\n实现Serializable，支持序列化；实现了Comparable，可以比较大小\nJDK8及以前使用char[]存储数据，JDK9+改用使用byte[]\n不管是char[]还是byte[]均使用final修饰，均不可改变\n\n\n为什么改成使用byte[]\n\n因为研究发现，在堆中存储的String对象大部分是拉丁字符，如果使用char[]做存储，每一个字符需要使用两个字节，这样会导致一半的空间被浪费，所以使用了**byte[]数组 +编码标记（encoding-flag）**；对于其他文字（UTF-16）依然使用两个字节去存储\n\n不可变的字符序列\n\n\n当对一个字符串重新赋值时，需要重新指定内存区域赋值，不能使用原有的value进行赋值\n\n当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值\n\n调用replace方法修改指定字符或字符串时，需要重新指定内存区域赋值，不能使用原有的value进行赋值\n\n直接使用字面量进行赋值，此时的字符串位于字符串常量池中\n\n\ndemo如下，简单，不做赘述\nString s1 = new String(&quot;nihao&quot;); // 使用new进行创建String s2 = &quot;nihao&quot;; // 使用字面量进行创建String s3 = &quot;nihao&quot;;// == 比较地址System.out.println(s1 == s2); //false 说明new重新给了地址System.out.println(s2 == s3); //true 相同字面量来自字符串常量池，所以相同\n\n\n字符串常量池中不会存储相同的内容\n\nString内存分配Java为8种基本类型和String类型都提供了常量池\n常量池相当于是一个Java系统级别的缓存\n\n字符串常量池String Pool：\n是一个固定大小的HashTable（数组+链表），默认值大小长度为1009（JDK6为此值，而且可以自己任意设置；JDK7默认值60013，值可任意；JDK8开始，1009是可以设置的最小值）\n\n如果存放的String太多，会导致hash碰撞严重，降低查询效率\n常量池不会存放相同的元素\n\n\n基本类型的常量池由系统协调，String的常量池比较特殊，使用方法有两种：\n\n直接使用字面量复制的对象会存放在常量池中\n调用intern()方法，也会将String对象放在常量池中\n这是一个native方法\n\n\n\ndemo：存到常量池的两种方式\nString s1 = &quot;hello&quot;;String s2 = new String(&quot;hello&quot;);System.out.println(s1 == s2); // falseString s3 = s2.intern();System.out.println(s1 == s2); // false intern方法不会将原有的字符串值改变，而是返回一个新的字符串System.out.println(s1 == s3); // true\n\n\n另外，字符串常量池的位置不同版本也有所区别：\n\n\n1.6之前，存放在方法区的运行时常量池\n1.7之后移动到了堆内\n\n（插一句，网上很多人说1.8放在了元空间内，简直误人子弟，建议大家找可信的大牛的博客看）\n\n为什么移动到了堆中？\n\n原本存放在方法区中，缺点有两个：\n\n永久区内存小\n永久区满后，需要Full GC，频率低而且回收时间长\n\nString的拼接操作结论：\n\n常量与常量的拼接结果放在常量池，原理是编译期优化\n只要其中有一个是变量，结果就在堆（非常量池的堆）中，变量拼接的原理是**StringBuilder**\n如果拼接的结果使用intern()方法，则主动将常量池中还没有的字符串对象放入池中，并返回此对象地址\n\ndemo：\nString s1 = &quot;ab&quot;;String s2 = s1 + &quot;c&quot;;String s3 = &quot;abc&quot;;String s5 = &quot;ab&quot; + &quot;c&quot;;System.out.println(s2 == s3);// false 拼接双方只要有一个变量，结果就在非常量池的堆中System.out.println(s5 == s3); // true 编译器做了优化，检测到此处可以直接优化为&quot;abc&quot;\n\n字符串的拼接，如果其中有一个是变量，那么会调用StringBuilder来进行拼接，下面是上面demo的字节码，注意观察 3 行开始处new了StringBuilder，在11行调用了append()方法，19行调用了toString方法\n 0 ldc #9 &lt;ab&gt; //直接从字符串常量池调用 2 astore_0    // 存放到局部遍历表0的位置（这里的方法是一个static方法，没有this） 3 new #10 &lt;java/lang/StringBuilder&gt; // 此处new了一个StringBuilder 6 dup 7 invokespecial #11 &lt;java/lang/StringBuilder.&lt;init&gt; : ()V&gt;10 aload_011 invokevirtual #12 &lt;java/lang/StringBuilder.append : (Ljava/lang/String;)Ljava/lang/StringBuilder;&gt;14 ldc #13 &lt;c&gt;16 invokevirtual #12 &lt;java/lang/StringBuilder.append : (Ljava/lang/String;)Ljava/lang/StringBuilder;&gt;19 invokevirtual #14 &lt;java/lang/StringBuilder.toString : ()Ljava/lang/String;&gt;22 astore_1...\n\n上面的操作如果使用StringBuilder来执行，如下：\nString s1 = &quot;ab&quot;;String s2 = s1 + &quot;c&quot;;// 执行如下String s = new StringBuilder();s.append(&quot;ab&quot;);s.append(&quot;c&quot;);s2 = s.toString();\n\nnew Stringnew一个String对象，如下\nString s = new String(&quot;ab&quot;);\n\n会创建几个对象？\n字节码如下：\n可以看到，创建了2个对象：\n\nString对象\n\n字符串常量池中的&quot;ab&quot;对象\n\n\n 0 new #3 &lt;java/lang/String&gt; 3 dup 4 ldc #4 &lt;ab&gt; 6 invokespecial #5 &lt;java/lang/String.&lt;init&gt; : (Ljava/lang/String;)V&gt; 9 astore_010 return\n\n\n进阶：\nString s = new String(&quot;a&quot;)+ new String(&quot;b&quot;);\n\n创建了几个对象？\n有五个\n\nStringBuilder对象\nnew String(&quot;a&quot;)\n常量池中的a\nnew String(&quot;b&quot;)\n常量池中的b\n\n其实还有，最后赋值给变量s，调用了StringBuilder的toString方法，这个方法的字节码如下：\n 0 new #80 &lt;java/lang/String&gt; 3 dup 4 aload_0 5 getfield #234 &lt;java/lang/StringBuilder.value : [C&gt; 8 iconst_0 9 aload_010 getfield #233 &lt;java/lang/StringBuilder.count : I&gt;13 invokespecial #291 &lt;java/lang/String.&lt;init&gt; : ([CII)V&gt;16 areturn\n\n\nnew String(&quot;ab&quot;)\n\n总共创建了6个对象！注意最后一个ab并不在常量池中！\nString的intern()方法public native String intern();\n\n执行时，此方法会判断池中是否还有本字符串对象：\n\n如果存在，返回池中地址\n不存在，放入池内，返回地址\n\n仔细观察下面这个demo，进一步体会itern()：\nString s1 = new String(&quot;1&quot;);s1.intern();String s2 = &quot;1&quot;;System.out.println(s1 == s2);// false// ----------------我是分割线----------------------String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;);s3.intern();String s4 = &quot;11&quot;;System.out.println(s3 == s4);//JDK1.6 false ; JDK1.7/1.8 true\n\n剖析：\n上半部分，很好理解：\n​        s1指向String对象原地址，s2指向的是来自池中的地址，s1调用intern方法会返回一个池中的对象地址，但是s1并没有接收这个变量，所以结果是false\n​        但是此处有一个要注意的地方，就是执行new String(&quot;1&quot;);时，已经将&quot;1&quot;放入池中，即执行intern()方法之前，&quot;1&quot;就在池中\n下半部分，有点绕：\n上一节我们介绍了这个具体的过程，他最后一步调用了StringBuilder的toString方法，但是此时，池中并没有11（池中只存在&quot;1&quot;）\n所以调用intern方法后，会将11放入池中，此时池中存在的是s3的地址，所以使用s4获取时，获得的也是相同的地址，结果为true\n\nintern()方法总结：\n\n\njdk1.6中：\n如果串池中有，则不会放入。返回已有的串池中的对象的地址\n如果没有，会把此对象复制一份，放入串池，并返回串池中的对象地址\n\n\nJdk1.7起：\n如果串池中有，则并不会放入。返回已有的串池中的对象的地址\n如果没有，则会把对象的引用地址复制一份，放入串池，并返回串池中的引用地址\n\n\n\nG1编译器的String的去重操作（了解）数据得出，堆中存活数据集合内的String对象占25%，堆存活数据集合里重复的String对象有13.5%（注意：这里指的堆是除了池中的堆）\n所以为了提高性能，就要对重复的String对象进行去重：\n\nGC工作时，会访问存活的对象，此时就会检查此对象是否是候选的待去重的String对象\n如果是：将这个对象引用插入到一个候选队列中。另外一个去重的线程就会处理这个队列。\n\n\n使用一个HashTable来记录所有被String对象引用的不重复的char数组。去重时，会查这个hashmap，来看堆上是否存在相同的char数组\n\nJava内存模型（JMM）注意，JMM与JVM的结构或者是运行时数据区的组成要分清楚，完全不是一码事\n\nJava内存模型(即Java Memory Model，简称JMM)本身是一种抽象的概念，并不真实存在\n它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式\n\nJMM要掌握的内容：\n\nCPU的寄存器、缓存、主存的层次关系\nJVM堆、栈与硬件的对应关系\n主内存与工作内存\n共享变量的操作\nJMM如何实现原子性、有序性、可见性\nhappens before原则\n从JMM理解volatile\n\nJMM与硬件结构硬件结构，CPU寄存器是最最最最块的内存了，即使快如主存，在寄存器面前也是不够看，所以引入了缓存\n缓存是为了解决主存与寄存器速度不匹配而引入的，但是带来了新的问题，一个变量如果在三个地方都存在，那么他的更新就有延迟，于是JMM有协议规定这方面协同\n\n可见，运行时数据区与硬件结构并没有直接的对应关系。\n主内存与工作内存\n主内存存储：存储所有的变量（包括对象的、方法的、类的变量）\n工作内存存储：每个线程对应有一个工作内存，存储对应线程使用到的变量\nJMM规定了：\n\n线程对变量的所有操作（读+写）都必须在工作内存中进行，而不能直接读写主内存。（即使是volatile变量，也必须操作工作内存）\n不同的线程之间无法直接访问对方本地内存中的变量。\n\n共享变量在JMM中，共享变量存放在主内存中，工作内存共享变量的副本\n线程只可以对自己工作内存中的共享变量进行操作，但却不能对主存内的共享变量进行直接的操作\n浏览blog过程中发现一张特别容易理解的图：\n（通过这个图可以好好想想volatile的原理）\n\n如图所示，主内存一开始A=1，线程1想将A赋值为2，必须先更改自己本地内存为2，再将数据刷回主内存中，线程2步骤同理。\nJMM的八种内存操作\n在较早的版本有8种操作，后来缩减为了4种操作，但是缩减只是通过合并实现的，所以可以继续研究8种操作。\n\n\nJVM保证这八种操作都是原子的（double与long之后讨论）\n首先解释一下：\n\nlock：（主内存）将主内存的某一个变量标识为某线程独占（lock可以执行N次，unlock需要执行N次才能释放该lock状态）\nunlock：（主内存）释放lock状态\n\n其次read与load是一对，不允许单独出现，而且必须read后load（不要求连续执行）\n\nread：（主内存）将主内存变量传输到线程的工作内存\nload：（工作内存）接收read到的变量，作为副本存入工作内存\n\nstore与write也是一对，不允许单独出现，而且必须store后write（不要求连续执行）\n\nstore：（工作内存）将工作内存的变量传输给主内存\nwrite：（主内存）将store传来的变量保存在主内存\n\n额外解释一下：\n\nuse：（工作内存）将一个变量传输给执行引擎（执行引擎负责编译执行）\nassign：（工作内存）将从执行引擎接收到的值赋值给工作内存中的变量\n\nhappens before原则\n程序顺序规则（线程内必须串行执行）\n锁规则（解锁必须发生在上锁后）\nvolatile规则（强迫每次的读写都必须刷新到主内存，不能为了省事直接去工作内存读）\n线程启动规则（线程的start()方法先于它的其他操作）\n传递性（A先于B，B先于C，A必先于C）\n线程终止规则（线程的所有操作先于线程的终结）\n线程中断规则\n对象终结规则（构造方法先于finalize()方法）\n\n这八个规则确定的内容，即使没有锁等同步操作，也可以按序执行\n从JMM理解volatilevolatile有两个特性：\n\n实现了可见性\n实现了有序性\n\n那么他是如何实现的呢\n实现可见性volatile 强迫对被修饰变量的读写刷新在主存\n即如果你要写或是读一个volatile变量，必须从主存拿（如果不修饰，线程会偷懒，直接就读取工作内存中存放的变量的副本）\n注意：volatile 只对原子操作有限制，典型的例子 i++就不是一个原子操作，它包括两步，+1与赋值\n如何实现？缓存一致性协议 + happens before规范\n缓存一致性协议有很多，Intel家的MESI（缓存一致性协议）逻辑如下：\n当CPU写数据时，如果发现操作的变量是共享变量，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。\n实现有序性禁止指令重排序（多核下，为了进一步提高CPU计算速度，引入了流水线，流水线下，就会对指令进行重排序）\n如何实现？内存屏障\n\n内存屏障(Memory Barrier)：\n又称内存栅栏，是一个CPU指令，它的作用有两个：\n\n一是保证特定操作的执行顺序\n二是保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）\n\nvolatile就是通过内存屏障实现的\n\n如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。\nMemory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本\n\n\n图片均来自与敖丙博客，见相关链接\n文章相关链接\n尚硅谷JVM教程：强推，最强JVM视频教程\n《深入理解Java虚拟机》阅读笔记：省下看书的时间\n《深入理解Java虚拟机》：书还是要看的\nJMM参考1：博客\nJMM参考2：博客\n\n","categories":["JVM"],"tags":["JVM"]},{"title":"MySQL进阶","url":"/2021/08/12/MySQL/mysql%E8%BF%9B%E9%98%B6/","content":"\n引言：\nmysql进阶内容：包括mysql的引擎、mysql的索引、mysql主从复制等\n\n\n\n\n三大范式\n第一范式：数据库表的每一列都是不可分割的原子数据项\n\n\n第二范式：在1NF的基础上，非主属性必须完全依赖于码（在1NF基础上消除非主属性对主码的部分函数依赖）\n\n\n第三范式：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除非主属性对主码的传递依赖）\n\n另外补充：\nBC范式：在3NF的基础上，消除主属性对键的部分依赖和传递函数依赖（此外还有第四范式、第五范式。）\n名词解释：\n\n函数依赖\nA→B，通过A属性的值，可以确定唯一B属性的值，则称B依赖于A（A是B的充分条件）\n例如：学号→姓名，（学号，课程名）→分数\n\n完全函数依赖：A→B，A是B的唯一充分条件\n部分函数依赖：A→B，并且A的一个真子集A’也可以退出B，A’→B，就称为部分函数依赖。\n传递函数依赖：A→B,B→A，通过A可以确定唯一的C\n\n\n码\n\n候选码：能唯一标识一组元组，而其子集不能\n主属性：候选码的属性\n非主属性：不是主属性就是非主属性\n\n\n\nMysql基本架构大的层面分为两层，Server层 与 存储引擎层：\nServer层有五个部分组成、存储引擎有很多实现\n\n连接器——管理连接、权限验证有两个作用：\n\n管理连接\n获取权限：如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，此连接的权限判断逻辑，都将依赖于此时读到的权限\n\n（注意：成功连接后，即使管理员对此用户的权限进行修改，也不会影响已经存在的连接权限）\n\n长连接：用户连接成功后，一直使用一个连接来持续请求\n短连接：每次执行很少的sql就断开连接，下次重新创建连接\n\n注意：\n\n连接时间由参数wait_timeout控制，默认8小时\n\n建议使用长连接，避免浪费资源\n\n\n\n为什么全部使用长连接后，有些时候MySQL占用内存涨得特别快？\n\n​        因为Mysql在使用时，临时使用的内存是在管理连接的对象内的，所以会导致占用内存涨得快，导致内存占用太大，被OS强行杀掉~\n解决措施：\n\n定期断开长连接。使用一段时间或在一个大的查询后断开，下次重连。\n执行mysql_reset_connection（Mysql5.7 +版本），可以初始化连接资源\n\n查询缓存——命中返回每次查询的结果，都会放在查询缓存中，这里相当于一个K-V映射。\nK是你的查询语句，V就是查询结果\nMysql发现你查询的语句一样，那就会直接返回\n注意：\n\n不建议使用查询缓存！因为容易过期，只要有一个更新语句，查询缓存就会失效\n系统配置表（长期不会更改的表）才适合用查询缓存\n可以设置参数query_cache_type为DEMAND，这样默认的sql都不会使用查询引擎\nMysql 8.0彻底去掉了查询缓存功能\n\n分析器识别分析你的Sql语句（比如说看看你用了什么关键字，是什么类型的语句等等），如果有问题抛出异常\n优化器——语句优化可以加快查询速度，确定执行方案\n进阶：\n\n在有多个索引的时候决定使用哪个索引\n在使用join时决定连接方式\n\n优化器如何估计成本优化器需要估计每个可能的索引的选择性和成本，通过index dive技术来估计成本：\n\n首先判断索引的区分度（基数），即该索引是否可以帮助过滤掉大量的无关数据，这个值通过统计信息进行判断。（可以使用ANALYZE TABLE employees;来更新优化器的统计信息）\n估计代价：\n比较使用索引的成本和全表扫描的成本\n如果使用普通索引，考虑回表的代价\n\n\n\n执行器先判断你有没有操作这个表的权限，然后才回去执行\n以一个Sql为例：\nselect * from T where ID = 10; # 假设表T没有索引\n\n执行流程为：（假设表T没有索引）\n\n调用执行引擎读取第一行，判断ID是否为10\n读取下一行，重复，直到最后一行\n返回结果集\n\n如果有索引流程也差不多：\n\n调用执行引擎：取满足条件的第一行\n重复执行满足条件的下一行\n返回结果集\n\nMyISAM 与 Innodb其他存储引擎可以使用show engines;查看\n\n\n\n对比项\nMyISAM\nInnodb\n\n\n\n外键\n不支持\n支持\n\n\n事务\n不支持\n支持\n\n\n行表锁\n表锁，即使操作一条数据也会锁住整个表\n行锁，操作时可以只锁住某一行；适合高并发\n\n\n缓存\n只缓存索引，不缓存真实数据\n不仅缓存索引，还会缓存真实数据；对内存要求高\n\n\n表空间\n小\n大\n\n\n关注点\n性能\n事务\n\n\nInnodb独立表空间Innodb中的每一个表，都会有一个.idb文件，这个文件就是一个独立表空间：\n\n\n段（Segment）：一个表空间会有很多段，常见的段有：\n数据段：存放B+树的叶子节点\n索引段：存放B+树的非叶子节点\n回滚段：存放回滚数据的区的集合（MVCC使用）\n\n\n区（Extent）：数据量大会有分区，每一个分区大约1MB，一页16KB，大约一个区有64页，在物理存储时，尽量使B+树相邻的页放在相邻的物理位置上，提高顺序IO的性能。\n页（Page）：页是Innodb读取数据的最小单位，一页16kb（是OS的页的四倍）\n行（Row）：Innodb有四种行格式，Redundant（已淘汰）、Compact、Dynamic（5.7默认）、Compressed\n\nInnodb如何存储Null值数据行存储NULL值这里重点介绍Compact，后面两个都是基于Compact的优化：\n\n如果表中不是所有字段都设计为NOT NULL，那么就会存在这个额外信息NULL值列表\n该值是一个bitmap，每一位代表对应列是否允许为null，并且该值占一个字节，如果允许为null的列存在9个，那么就会占用两个字节，以此类推。\n\n行数据的额外字段中还有头信息中存储着mvcc的关键字段：\n\nDB_TRX_ID：创建或修改记录的事务ID\nDB_ROW_ID：隐藏主键\nDB_ROW_PTR：回滚指针\n\n\n索引存储NULL值主键索引是不允许为null的，普通索引是允许为null的，实际的结构中是这样的：\n\n所有的NULL值会被认为是最小的值，被放在B+树的最左侧。\n因此如果使用这样的sql语句去查询：\nselect * from s1 where key1 is null -- key1是一个普通索引\n\nmysql的执行逻辑是，在辅助索引树上找到null，挨个回表查询聚簇索引树。\n因此：在我们使用is null或is not null时是否走索引是有待商榷的，在成本比较小的时候，会使用索引，成本大于查全表时，就不会走索引。\nExplain用来查看执行计划，这里给出官网资料\n以一个简单的表为例，说明一下Explain的使用：\n表temp：id为主键\n\n\n\nid\nk\n\n\n\n1\n2\n\n\nexplain SELECT k FROM `temp` where id = 1;\n\n输出结果：\n\n\n\nid\nselect_type\ntable\npartitions\ntype\npossible_keys\nkey\nkey_len\nref\nrows\nfiltered\nExtra\n\n\n\n1\nSIMPLE\ntemp\n(null)\nconst\nPRIMARY\nPRIMARY\n4\nconst\n1\n100.00\n(null)\n\n\n对各个字段进行说明：\n其中的核心字段有：id、table、select_type、type、key、rows、Extra\n\nid+ table：通过这两个字段，可以判断查表的顺序\n\nselect_type：查询语句的类型\n\nSIMPLE：简单查询，即不涉及UNION或子查询\nPRIMARY：主查询，复杂的SQL查询中最外层的查询\nSUBQUERY：子查询中的第一个SELECT语句\nUNION：UNION中的第二个及之后的SELECT\nDERIVED：派生表的查询，例如 FROM 子句中的子查询\n\n\npartitions：该列显示的为分区表命中的分区情况。非分区表该字段为空（null）。\n\ntype：表之间通过什么方式建立连接的，或者通过什么方式访问到数据的，下一节详细介绍\n\npossible_keys：可能会被使用的索引，实际不一定会使用，但是一般都以key为准\n\nkey：实际使用的索引，如果为null,则没有使用索引，否则会显示你使用了哪些索引\n\nkey_len：索引占用的字节数（下一节具体给出了各种类型占用的字节数）\n\nref：表示where语句或者表连接中与索引比较的参数\n\nrows：优化器大概帮你估算出你执行这行函数所需要查询的行数。\n\nFilter：按条件查询的行数与总行数的比值，是一个百分数\n\nExtra：显示额外信息\n\n\ntype属性从左到右，性能越来越差\nNULL &gt; system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL\n\n\nNULL：能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引的查询\nexplain select 20*10; # 计算一个数字explain select Max(id) from temp; # 查最大值，优化器自动去最边叶子结点取值，无需查表或索引\nSYSTEM ：此表只有一行记录（等于系统表），这是const类型的特例，平时不大会出现，可以忽略。\n\nconst 表示使用主键或者唯一性索引进行等值查询，最多返回一条记录（性能好，推荐使用，因为只有一行，所以列值可以被优化器视为常量）\nSELECT * FROM tbl_name WHERE primary_key=1;SELECT * FROM tbl_name  WHERE primary_key_part1=1 AND primary_key_part2=2;\neq_ref 用于联表查询的情况，表连接使用到了主键或唯一键联合查询。\nSELECT * FROM ref_table,other_table  WHERE ref_table.key_column=other_table.column;SELECT * FROM ref_table,other_table  WHERE ref_table.key_column_part1=other_table.column  AND ref_table.key_column_part2=1;\nref 表示使用非唯一性索引进行等值查询\nSELECT * FROM ref_table WHERE key_column=expr;SELECT * FROM ref_table,other_table  WHERE ref_table.key_column=other_table.column;SELECT * FROM ref_table,other_table  WHERE ref_table.key_column_part1=other_table.column  AND ref_table.key_column_part2=1;\nfulltext：使用FULLTEXT索引执行\n\n一种全文搜索的匹配方式，使用倒排索引\n一张表只能存在一个fulltext索引，但是可以有多个列\n创建 FULLTEXT 索引的列必须是 CHAR、VARCHAR 或 TEXT 数据类型\n\n\nref_or_null 与ref相同，区别是可以包含null值的行\n\nindex_merge 表示查询使用了两个以上的索引，最后取交集或者并集，常见and，or的条件使用了不同的索引\n\n但是实际上由于要读取多个索引，性能可能大部分时间都不如range\n\n\nunique_subquery：会替换某些eq_ref子查询IN，一个索引查找功能，完全替代了子查询，以获得更好的效率\nvalue IN (SELECT primary_key FROM single_table WHERE some_expr)\nindex_subquery：同上，但是使用非唯一索引\nvalue IN (SELECT key_column FROM single_table WHERE some_expr)\nrange 索引范围查询\nSELECT * FROM tbl_name  WHERE key_column = 10;SELECT * FROM tbl_name  WHERE key_column BETWEEN 10 and 20;SELECT * FROM tbl_name  WHERE key_column IN (10,20,30);SELECT * FROM tbl_name  WHERE key_part1 = 10 AND key_part2 IN (10,20,30);\nindex使用索引进行全表扫描，通常比All快\n\n因为，索引文件通常比数据文件小，虽然all和index都是读全表，但index是从索引中读取的，而all是从硬盘读的\n\n\nALL 全表扫描，如果一个查询的type是All,并且表的数据量很大，那么请解决它！！！\n\n\nkey_len属性每种类型所占的字节数如下：\n\n\n\n类型\n占用空间\n\n\n\nchar(n)\nn个字节\n\n\nvarchar(n)\n2个字节存储变长字符串，如果是utf-8，则长度 3n + 2\n\n\ntinyint\n1个字节\n\n\nsmallint\n2个字节\n\n\nint\n4个字节\n\n\nbigint\n8个字节\n\n\ndate\n3个字节\n\n\ntimestamp\n4个字节\n\n\ndatetime\n8个字节\n\n\n字段允许为NULL\n额外增加1个字节\n\n\nextra属性表示额外的扩展信息，常见的有：\n\nUsing where：使用where条件查询，但是没有使用索引\nUsing index：用到了覆盖索引（即在索引上就查到了所需数据，无需二次回表查询），性能很好\nUsing filesort：使用了外部排序，即排序的字段没有用到索引\nUsing temporary：用到了临时表，如果 ORDER BY 或 GROUP BY 中的列没有索引，MySQL 可能会使用临时表来完成排序或分组操作\nUsing join buffer：在进行表关联的时候，没有用到索引，使用了连接缓存区存储的临时结果\nUsing index condition：使用到了索引下推\nRange：使用了范围扫描\nFulltext search：使用了全文搜索\n\nMysql日志Mysql三种日志：bin log、redo log、undo log\n\nWAL（Write Ahead Logging）：先写日志，再写磁盘\n\n这里先做一个简单的介绍：\n\nbin log：存放所有的更新操作\n\nredo log：配合bin log使用，也是存放所有更新操作\n\nundo log：负责事务的原子性，保证可以回滚\n\n\n其中bin log属于Mysql Server层级别、redo log与undo log属于Innodb存储引擎级别\n\nbin log与redo logbin log与redo log会一起使用，bin log相当于总账本，而redo log想当于记录今天流水的账本，之后Mysql会将redo Log的内容写到bin log内（二阶段提交，下文会介绍）\n注意：\n\nbin log与redo log大小固定\n\nredo log可以设置为一组四个文件，每个文件大小为1GB\n\n\n\ncheckpoint：擦除的位置，checkpoint之前的数据将数据更新到数据文件\nwrite pos：记录当前位置\n两个指针都是循环写，即写到最后，又从头开始，循环使用这一部分空间\n\nredo log 实现了crash safe\n\n\ncrash safe：保证Mysql出现故障后，之前的数据也不会丢失的能力\n\nbin log与redo log的基本作用binlog(binary log)：记录对数据库的修改操作（增删改、表结构修改），会校验事务的完整性（事务begin commit），也有备份点用于还原数据。主库可以使用binlog去备份出从库\nredolog：WAL写前日志，在写入binlog数据前，先写入redolog，作为crash safe的安全保障手段，redolog可以恢复在断点时那些没能刷回磁盘的数据。\n\n为什么要有redolog？\n\n数据写入的过程是：先写入内存，缓存够一部分后，再刷脏页刷入磁盘中\n内存的数据是易失的，如果发生断电，那么缓存的数据就会丢失掉，因此引入的解决办法是写前日志WAL\n写入binlog前，先写redolog，这样可以减少数据丢失\nredo log与 bin log的区别三大区别：\n\n级别不同：redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。\n存储内容不同：redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\n写的方式不同：redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\nredo log 与 bin log 是如何联系的它们有一个共同的数据字段，叫XID。\n崩溃恢复的时候，会按顺序扫描redo log：\n\n 如果碰到既有prepare、又有commit的redo log，就直接提交\n如果碰到只有prepare、而没有commit的redo log，就拿着XID去binlog找对应的事务\n\n二阶段提交由来：由于bin log 与 redo log属于不同的级别（bin log属于mysql\n级别，而redo log与undo log属于Innodb级别），\n​        为了保证数据同步，就得保证这两个文件一致，所以有了二阶段提交的概念\n\n两状态提交：有两个状态prepare 与commit\n数据要进行更新时，会先写日志，再去更改数据，这个过程会先去写redo log，将状态设置为prepare状态；\n（咔嚓~~~~如果此时断电，因为binlog数据还没有写入，所以会丢弃redo log中的prepare这部分数据，并且进行回滚）\n然后再写bin log；\n（咔嚓~~~~如果此时断电，因为bin log已经写入，判断redo log中也存在，只不过状态是prepare，依然可以继续进行）\n提交事务，将状态改为commit\n\n二阶段提交过程：（这个图也能帮我们了解清楚，一条更新语句的执行过程）\n\n调换顺序存在的问题：\n\n情况1：假设先写redo log再写bin log：\n假如写完redo log后mysql崩溃重启，由于写了redo log，所以会恢复这个数据，但是bin log没有写入，所以如果之后使用bin log恢复数据，就会与原库不同\n\n情况2：假设先写bin log再写redo log：\n假如写完bin log后mysql崩溃重启，由于还没写redo log，崩溃后恢复，两个文件不一致，判断此事务无效；虽然原库虽然会无此数据，但使用bin log恢复后，新的数据与原库不同；\n\n\nbinlog日志格式binlog 日志有三种格式，可以通过binlog_format参数指定。\n\nstatement\nrow\nmixed\n\n他们之间的区别是：\n比如现在这样的一条语句update T set update_time=now() where id=1\n\nstatement：直接存储，update T set update_time=now() where id=1，但是对于now()操作不友好，获取当前的时间，这种操作再次执行时与原本的操作不会一致。\nrow：会记录原始的数据值，不能直接查看，需要借助解析binlog的工具，比如update_time=now()变成了具体的时间update_time=1627112756247，但是这种方式存储的数据量就比较大\n\nmixed是一种折中方案：MySQL 会判断这条SQL语句是否可能引起数据不一致，如果是，就用row格式，否则就用statement格式\n双一规则这一部分的知识参考\n二阶段提交中，redo log和bin log可以保证数据的不丢失。\n但是bin log和 redo log是如何做到写入数据的？如果写入的情况出现丢失怎么办？\n简单来说简单的来说双一规则就是两个参数，规定了刷盘的时机。\n一个更新操作从开始到提交需要经过：\n\nbegin\n查数据，然后更新数据，更新数据的写入操作可能会写入到change buffer内（这个此处不予深入讨论）\n先写入到redolog buffer，之后会写入到page cache\n写入binlog buffer，之后会写入到page cache\ncommit\n再次写入到redolog buffer，之后写入到page cache\n\n我们要注意的是：\n写入binlog和redolog并不是直接就能写进去的，他们在内存中都有buffer，每次想要持久化时，需要先write进入page cache（这是文件系统的缓存），然后再fsync真正的从内存刷回到磁盘中\n\nwrite操作：一般每次事务都会write\nfsync操作：不一定，可以设置\n\n\n那么执行多少次事务，才去进行一次write与fsync操作呢？\n\n双一，一次write一次fsync，发生一次事务，就刷一次盘，这是最安全的方式。\nbinlog 写入磁盘规则binlog是如何写入磁盘的？\nbinlog有缓存机制cache，如图所示：\n\n每个线程都有自己的binlog cache\n每个线程都需要将结果写入到唯一的binlog文件中\n每个事务提交后会有两个过程：\nwrite：将cache的数据wirte进bin log文件\nfsync：将binlog文件写入磁盘\n\n\n\n\nMysql提供了参数sync_binlog对事务的write和fsync操作进行控制：\n每次提交事务，参数配置不同，fsync的次数也不同\n\nsync_binlog=0：只write，不fsync\nsync_binlog=1：每一次write进行一次fsync\nsync_binlog=N：每N次write进行一次fsync\n\n一般会将这个参数设置为“1”，双一规则的其中一个1就是这个。\nredolog  写入磁盘规则redolog在写入磁盘前，会先写入内存\n\n\n写入redolog buffer中，也就是内存中\n写入到磁盘中，存于page cahce中，但是没有持久化（和 binlog一样 只是write,没有fsync）\n持久化到磁盘中\n\n同样，mysql提供参数innodb_flush_log_at_trx_commit，设置为几，就在几次事务提交后持久化到磁盘\n这就是另外一个“1”。\n因此，两阶段提交的过程涉及到两次刷盘的过程：redolog刷盘，binlog 刷盘\nredo log组提交机制如果每次都刷两次盘，那么也太吃性能了。\n组提交机制就是为了提高性能的：\n\n日志逻辑都有一个序列号 LSN\n用于对应redo log的一个个写入点，LSN是单调递增的，对应redo log的一个个写入点，每一个写入长度为length的redo log，LSN的值就会加上length\n\n\n\n如图所示，有三个事务，每个事务有一个LSN序列号，现在要将trx1写入磁盘，那么就判断LSN值为160，那么LSN小于等于160的redo log，都会被redo log都会被持久化到磁盘中\n这就是所谓的组提交，组越晚提交，提交的数量也就越多，节省IO时间\n因此，加上write和fsync的话，二阶段提交的真实过程就是：\n\n\nwrite redo log，进入prepare状态\nwrite bin log\nfsync redo log\nfsync bin log\nwrite redo log，进入commit状态\n\n一般来说,也是将数据库设置为双一设置。\n\n在什么时候设置为非双一呢？\n\n\n业务高峰期，如果有预支的高峰期，会改为非双一\n备库延迟，让备库赶上主库\n备库恢复主库副本\n批量导入数据的时候\n\n崩溃的判断规则\nredo log崩溃恢复时的判断规则：\n\n\n如果redo log里面的事务是完整的（即有了commit标识），则直接提交；\n如果redo log里面的事务只有完整的prepare，则判断对应的事务binlog是否存在并完整： \n如果是，则提交事务\n 否则，回滚事务\n\n\n\n\nbin log如何保证完整性：\n\n一个事务的binlog是有完整格式的：\n\nstatement格式的binlog，最后会有COMMIT；\nrow格式的binlog，最后会有一个XID event\nMySQL 5.6.2版本以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性\n\nMysql索引B树、B+树由来​        每一种数据结构都是为了解决一种问题而提出的，B+树也不例外\n​        我们知道数据库存放数据，目的是为了查询，而查询当然越快越好\n​        索引就是为了提高查询速度而提出的（下文会介绍索引）\n​        索引查询的原理大致就是K-V映射，这我们立刻就能想到哈希，但是哈希存在一些问题：哈希表需要全部放入内存、哈希表不能范围查询、哈希碰撞严重影响效率\n​        于是提出使用树来进行存储，树有很多种，最常见的就是二叉树，为了加快速度，使用了二叉搜索树BST\n​        但是遇到一些递增或递减的数据，会使BST的效率大大降低，于是提出了自平衡树AVL，但是AVL树便于查询，插入的效率会很低，于是又有了红黑树\n​        红黑树确实实现了搜索与插入的平衡，但是红黑树依然不能克服二叉树存在的问题——随着插入的数据越多，树的高度越高\n​        于是提出了B树一个自平衡的多叉排序树\n总之，经历了哈希表、二叉树、BST、AVL、红黑树这些阶段，终于提出了B树\nB树​        首先了解**平衡二叉树，平衡二叉树每一个结点都维护了一个高度，一个节点是否是平衡的，取决于它的左孩子与右孩子高度的差值是否大于1**\n​        其次就是要知道二叉排序树，二叉排序树节点的左节点小于自身，右节点大于自身。\n​        但是二叉树有弊端，最坏情况下需要遍历树的高度，二叉树很容易达到一个很深的高度，高度越高，效率越低。\n​        所以B树由此影响，提出了平衡多路查找树（一个多叉树结构的平衡排序树）\n（注意：B树与B-树是同一个概念）\n\nB树是这么一棵树：（五个规则）\n\n根节点至少有两个节点（或者说根节点至少有一个元素）\n中间节点包含 k-1 个元素和k个孩子，其中 m/2 &lt;= k &lt;= m（m是最多有几个叉）\n叶子结点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m\n所有叶子节点都在同一层\n每个节点中的元素从大到小排列\n\nB树中存放的元素是key-value值\n\nB+树B+树在B树的基础上，有着如下改变：\n\nB+树有两种类型的节点：内部结点（也称索引结点）和叶子结点。\n内部节点就是非叶子节点，内部节点不存储数据，只存储索引，数据都存储在叶子节点。\n\n\n内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。\n每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。（即叶子结点为一个链表）\n父节点存有右孩子的第一个元素的索引\n\nB+树的添加删除操作，可以看此篇blog，图文描述特别清楚，可以深刻理解B树与B+树的结构\n为什么B+树很适合磁盘的存储逻辑？\n磁盘的读取单位是页（4KB），B+树的设计中为了配合磁盘，每一个节点的大小就是N倍页的大小（Innodb的一页16KB，是4倍的OS的页）\nB+树的树高很小，为了减少IO次数\n磁盘顺序IO访问的效率会更高，B+树很适合范围查询\n\nB树与B+树适用的场景\nB+树的内部节点只存储索引，因此树高会低很多，适合范围查询。\n\nB树内部节点存储数据与索引，可以做专门的优化，对于访问频次高的数据可以调整到更靠近根节点的位置\n\n\nMysql三层B+树可以存储多少数据？mysql使用innodb存储引擎，每一个节点都是一页，每一页存放16kb的数据，叶子节点存储数据，非叶子节点只存储索引\n现在我们规定以下前提：\n\n一页大小：16kb\n非叶子节点的主键大小：假设为bigint类型，8byte\n非叶子节点的页指针大小：6byte\n叶子节点每一条记录的的大小：假设为1kb\n\n第一层中的索引数量：\n\n最少：2条（起码有两条才能有三层b+树）\n\n最多：16 * 1024 / (6 + 8) = 1,170，每个索引需要存放索引（8byte）和的页指针（6byte）\n\n\n第二层中的索引数量：\n\n最少：1,170 + 1 = 1171（第二层起码有一页是满的，第二页起码得有1条）\n最多：1,170 * 1,170 = 1,368,900（一页最多有1170条，最多有1170页）\n\n第三层叶子结点的记录数：\n\n最少：1171 * 16 + 1 = 18,737（在三层结构下，1w条数据的查询和2kw条数据的查询开销是一样的）\n最多：1,368,900 * (16kb / 1kb) = 21,902,400（每条数据1kb，那么每页能存16条数据，最后大约可以存储2kw条数据）\n\n这是假设一行数据在1kb的情况下，如果是256byte，那么基本会扩大4倍，即约8kw。\n结论：在前提一页为16kb、索引8byte、非叶子节点野指针6byte的情况下\n每行数据大小为1kb，那么三层b+树数据总量在2kw左右\n\n在此前提下，四层B+树呢？\n\n第三层索引数量：\n\n最多：1,368,900 * 1170 = 1,601,613,000\n\n叶子结点记录数：\n\n最多：1,601,613,000 * 16 = 25,625,808,000（约为200亿数据）\n\n结论：千万级别一般是3层，十亿+级别一般是四层\nMyISAM与Innodb不同的索引结构索引的分类\n单列索引\n主键索引：唯一且非空\n唯一索引\n普通索引\n\n\n联合索引：使用多个键构成的索引\n全文索引：只能在CHAR、VARCHAR、TEXT类型字段上使用全文索引\n\n\n对于这两个mysql引擎，他们实现的方式有所区别\n本文参考\nMyISAM中的索引B+树我们知道，有内部结点与外部结点，内部结点就是索引，外部结点才会存放数据真正的值\n在MyISAM中，如下图，索引一层一层，最后的叶子结点存放的数据是真实数据的地址，注意，存放的是数据的地址！！\n\n在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复\nInnodb中的索引最大的区别就是B+树叶子结点存放的是数据，区别与MyISAM中存放的数据的地址\n\n表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。\n这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引\n\n\n这种索引叶节点包含了完整的数据记录。这种索引叫做聚集索引，相对而言，MyISAM中的索引就称为非聚集索引\n聚集索引的特点：必须要按主键聚集，而且聚集索引只能有一个（Innodb有一个聚集索引与多个非聚集索引）\n因此Innodb必须有主键，而MyISAM可以没有主键\n\n如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键（唯一键）\n如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段rowid长度为6个字节，类型为长整形\n总结：主键 -&gt; 唯一键 -&gt; 6个字节的rowid\n\n除此外，在Innodb的辅助索引，与MyISAM也有区别，MyISAM的辅助索引结构与主索引完全一致，只是可以重复这一点区别\n在Innodb中，InnoDB的辅助索引data域存储相应记录主键的值而不是地址\n即辅助索引构建的B+树的叶子结点，存放的不是地址，而是主键的值\n\n\n聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。（这也是为什么要用聚集索引的原因）\n\n聚集索引和辅助索引\nInnodb：\n主键索引是聚集索引，所谓聚集索引，是指会按照主索引去创建一颗B+树，此B+树的叶子节点存储的是数据行（所以会出现回表的现象）\n辅助索引的叶子节点存储的是主键的值\n\n\nMyISAM是非聚集索引：\n主键索引是非聚集索引\n辅助索引和主键索引一样，叶子节点存储的都是数据行的地址\n\n\n\n\n聚集索引的好处与坏处特点：将数据存储在叶子节点上，这样找到了最终的索引，也就找到了数据（会比非聚集索引少一次IO）\n好处：比非聚集索引少一次IO，会更快一些\n坏处：首先是会有回表现象的发生，其次是对于修改删除的操作需要更新索引树，开销增大\n\n为什么Innodb的辅助索引的叶子节点存储主键值，而不是存储地址？这样不就没有回表问题了吗？\n\nMyISAM的实现中，辅助索引存储的就是实际的地址，如果Innodb也设计为这样，虽然不会有回表问题，但会有更大的维护成本：\n数据是会不断变化的，它的地址也可能发生变化，比如：页分裂或者页合并\n\n什么是页分裂？\n\n在插入新的数据时，当前页可能已满，那么就需要新的一页去存储对应的数据。\n一般来说，会将满的一页的数据，分成两页存储，各存储一半。\n页分裂有可能会导致递归分裂\n从结构而来的结论使用占内存小的字段作为主键：因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大\n不用非单调的字段作为主键：因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择\n索引不是越多越好\n不要对经常变动的数据加索引\n总结\n\n\n区别项\nMyISAM\nInnodb\n\n\n\n数据结构\nB+树\nB+树\n\n\n外部节点存放\n数据的地址\n数据本身\n\n\n辅助索引与主索引的区别\n结构相同；主索引不允许重复\n结构不同；辅助索引外部节点存放的是主索引的值\n\n\n回表假设有一个表，有id name age gender四个字段，其中id为主键，name为普通索引\n现在有这么一个SQL\nselect * from table where name = zhangsan\n\nMysql会如何去进行搜索？\n​        首先name是一个普通索引，也会建立一个B+树，但是这个B+树是辅助索引，它的叶节点只会存放主键的值，所以mysql从name会查到主键id，进而才会查到整个记录（检索了2棵B+树）\n这种现象就叫做回表\n\n回表：根据普通索引查询到聚簇索引的key值后，再根据key值再获取到记录\n\n\n索引覆盖再有一个sql语句\nselect id,name from table where name = zhangsan\n\n如何搜索？\n根据辅助索引存储的为聚集索引的值这一点，我们可以知道，通过普通索引name去查询聚集索引id和name，只需要查询一棵树，这种现象较索引覆盖（查一棵B+树）\n\n索引覆盖：\n当只查询普通索引和聚集索引的内容时，只需要查普通索引即可的现象\n\n\n最左匹配现在对id name age gender四个字段，设置其中id为主键，&lt;name,age&gt;为索引列\n有下列sql语句，mysql执行时，对哪种sql会使用索引？\nselect * from table where name = ? and age = ? # 会select * from table where age = ? and name = ? # 会select * from table where age = ? # 不会select * from table where name = ? # 会\n\n解释：\n其中1与2是因为mysql有优化器，会将sql语句自动调整顺序，即2在执行时是按1执行的\n为什么3没使用索引，而4使用了呢？\n这是因为我们设置联合索引是&lt;name,age&gt;，其中name为左，所以会，这种现象叫最左匹配\n\n满足最左匹配，在读取时会使用索引，更加高效！\n\n联合索引什么样的查询会用到索引（深入最左匹配）还是此篇blog，强烈建议仔细阅读此篇blog，本文主要对此文进行了总结，原文有更多示例与论证，对不同情况下的查询都进行了分析，此处做一个总结：\n\n设有titles表的主索引为&lt;emp_no, title, from_date&gt;（联合索引：有多个列一起组合为一个索引）\n\n全列匹配：对于主索引的每一列都进行精确匹配（这里精确匹配指“=”或“IN”匹配）例如搜索条件为WHERE emp_no=&#39;10001&#39; AND title=&#39;Senior Engineer&#39; AND from_date=&#39;1986-06-26&#39;，每一个都给了一个精确的值\n\n这时会用到索引\n（而且mysql查询优化器会自动对查询的顺序进行优化）\n\n\n最左前缀匹配：当查询条件精确匹配索引的左边连续一个或几个列时，如&lt;emp_no&gt;或&lt;emp_no, title&gt;时\n\n会用到索引\n但是只会用一部分，此处就只用了&lt;emp_no&gt;的索引（最左）\n\n\n查询条件用到了索引中列的精确匹配，但是中间某个条件未提供：例如查询的索引是&lt;emp_no, from_date&gt;，此时和情况2相同，也只会使用左边的索引；区别是：由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date\n\n可以使用添加辅助索引的方法，使mysql使用上from_date这个索引，增快效率\n如果缺少的中间索引（此例中的title）的值种类不多的时，可以使用IN来进行填坑\n\n\n查询条件没有指定索引的第一列：没有指定最左索引，例如WHERE from_date=&#39;1986-06-26&#39;：\n\n没有联系到最左前缀，不会使用索引\n\n\n匹配某列的前缀字符串：例如WHERE emp_no=&#39;10001&#39; AND title LIKE &#39;Senior%&#39;，如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀\n\n范围查询：对某一列进行范围查询，例如WHERE emp_no &lt; &#39;10010&#39; and title=&#39;Senior Engineer&#39;\n\n范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。\n同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。\n\n\n查询条件中含有函数或表达式：使用函数或表达式，例如WHERE emp_no=&#39;10001&#39; AND left(title, 6)=&#39;Senior&#39;\n\n不会使用索引\n\n\n\n\n因此在写查询语句时尽量避免表达式出现在查询中，而是先手工私下代数运算，转换为无表达式的查询语句\n\nlike”%xxx”一定不会走索引吗？也不一定，如果能触发索引覆盖，还是会走索引的，比如：\ncreate table `user`(    id int primary key auto_increment,    name varchar(20),    xxx int,    index idx_name(name),);select id, name from `user` where name like &#x27;%冥&#x27;; -- 走索引select * from `user` where name like &#x27;%冥&#x27;; -- 不走\n\n这种情况下会走索引，而且查询计划是index也就是使用索引的全表查询（会查询整个name的辅助索引的B+树）\n虽然效率也不是很高，但要比走主键索引快（因为不需要回表）\n索引下推5.7版本后退出的新功能，首先要知道mysql大致分为三层：\n\nclient：交互\nserver：服务\n存储引擎：存储\n\n对于SQL\nselect * from table where name = ? and age = ?\n\n没有索引下推之前：首先根据name从存储引擎获取符合规则的数据，然后在server层用age进行过滤筛选\n有索引下推后：直接用两个索引从存储引擎获取数据（省去了server层与存储引擎交互的过程）\n索引优化给合适的列建立索引索引可以加快查询的速度，但是并不是每次查询都要建立索引\n索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间\n两种情况，不建议建立索引：\n\n表的记录较少，在一两千条之内，以2000作为分界线，2000条以上再建立索引\n索引的选择性较低\n\n\n选择性：\n选择性（Selectivity），取值范围为(0, 1]，是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：\nIndex Selectivity = Cardinality / #T\n选择性越高的索引价值越大\n\n前缀索引用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销\n兼顾了性能与开销\n永远使用与业务无关的自增字段作为主键Innodb聚集索引，会把数据记录记录在一个叶子结点上\n如果使用自增字段，那么他会按序排放，没有额外的操作，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）\n如果不使用自增字段，B+树本身维护自己的有序性，就有一定的开销，频繁的移动、分页操作造成了大量的碎片\n唯一索引&amp;普通索引\n唯一索引与普通索引，如果不考虑业务的要求（比如说，不要求键唯一），那么这两个索引谁更快呢 ？\n\n比如这个例子：\nselect id from T where k=5; # id是主键\n\n\n\n查询操作\n\n找k为5的记录\n\n如果k为普通索引：查询到第一个满足k=5的记录后，继续向下找，直到第一个不满足k=5条件的记录\n如果k为唯一索引：查询到第一个满足k=5的记录后，就停止查找。\n\n好像唯一索引要快一点？但其实速度都差不多\n​        Mysql的读是按页读的，每页16kb，所以在把对应的页调入内存后，普通索引多的那些判断对于CPU来说，九牛一毛，所以性能差不多\n\n更新操作\n\n先说结论，普通索引要快一点（由于change buffer）\nchange buffer操作磁盘，是最影响速度的一步，所以所有的缓存都是为了统一的进行与磁盘的操作\n所以change buffer作用如下：在不影响数据一致性的前提下，将Innodb的更新操作缓存在change buffer中，之后再将数据写入磁盘\n\n什么条件下会使用change buffer？\n\n对于唯一索引来说，更新操作都得首先判断是否重复，所以唯一索引必须先从内存中读出数据，已经读到内存中了，也就没必要使用change buffer了\n这里回到上一节的那个问题，更新操作\n第一种情况：要更新的目标在内存中\n\n唯一索引：找到记录，判断是否重复，更新\n普通索引：找到记录，更新\n\n这种情况下，也没什么区别\n第二种情况：要更新的目标在磁盘中\n\n唯一索引：从磁盘中将数据读入到内存中，然后判断是否重复，更新\n普通索引：找到记录后，更新到change buffer\n\n显然，普通索引完胜\nchange buffer 与 redo log buffer的区别这两个区域都是为了提高效率的，而且功能好像也有点类似，这里做一个区分：\nbuffer pool代表内存，change buffer 就在其中 \nsystem table 表示系统表空间，data表示数据表空间\n执行如下操作：\ninsert into t(id,k) values(id1,k1),(id2,k2);\n\n\n\npage 1 在内存中 ，直接插入\npage 2 不在内存，就更新内存的change buffer\n将上述记录写到redo log内\n\n如果是读操作：\nselect * from t where k in (k1, k2)\n\n\n\npage 1 在内存，直接读出来\npage 2 不在内存， 从内存读出，然后应用change buffer的操作，返回结果\n\n结论\n如果没有业务的需要，建议使用普通索引：普通索引的写速度是要大于唯一索引的，\nchange buffer 节省随机读磁盘的IO损耗\nredo log 节省随机写磁盘的IO损耗\n\n索引的其他问题\n1、 mysql的数据存在哪里\n\n​        存放在磁盘中（毫无疑问）\n\n2、 Mysql在磁盘是如何读取数据的\n\n​        按页读取，页由OS确定，一般为4K或8K，只能按页读取，也就是只能读4的整数倍\n​        mysql的Innodb引擎在读取时每次读取16kb\n\n3、 索引存放在哪里\n\n​        存放在磁盘中，启动mysql后，索引会被加载到内存中（为了防止断电后重新生成索引）\n\n4、 使用哈希存的利弊：\n\n​        利：O(1)级别查询速度\n​        弊（三点）：1. 哈希冲突会导致查询速度下降；2. 哈希表需要全部放在内存中使用，耗内存量大；3. 不支持范围查询，如果要范围查询需要对整个哈希表进行遍历\n在mysql数据库中：memory引擎使用Hash、Innodb引擎自适应（由引擎来选择使用Hash还是树）\n\n5、 为什么使用B+树而不是红黑树\n\n红黑树虽然实现了查询与插入的近似相同，但是树高依然不能限制（这是由于红黑树依然是一棵二叉树）\n随着数据的大量插入，树的高度会使整个查询的效率变慢\n而B+树会大大降低树高\n\n6、 为什么使用B+而不是B树\n\n\nB树实现效果如图，B树每一个磁盘块将数据与索引存放在一起\n我们假设data占用1kb大小、索引占用的大小忽略，Innodb中默认一次读块16kb，那么一个块内就可存放16个记录\n如果是三层的B树，那么就有16^3=2^12=4096条记录，这显然还是太少了\n限制B树的原因是：将索引与数据存放到了一起\n而B+树，分开内部与外部节点，内部结点纯放索引，而外部节点纯放数据，就解决了这个问题\n\n\n7、 B+树的阶是由自己指定的吗？\n\n不是，是由mysql自己调节的\n\n8、key与index的区别\n\nkey包括两部分：约束与索引\nindex就是单纯的索引，帮助辅助查询使用\n索引失效的原因\n不满足最左前缀原则\n使用了函数表达式where YEAR(created_time)= %xxx\n存在隐式类型转换：比如where age=&#39;25&#39;，可以查，但会导致索引失效\n使用了where name = %xxx\n使用了OR操作符：where name=&#39;xx&#39; or age=30，使用了or，如果其中有一个没有索引，就会使索引失效\n数据量太小：数据量较小索引可能会增大查询时间\n数据分布不均匀：索引的区分度很小\nmysql的统计信息没有算准：可以手动ANALYZE table来重新统计信息\n\n优化器对索引的选择​        在最开始讲Mysql基本架构的时候说过，优化器会对我们的SQL语句进行优化，会选择使用哪一个索引来进行搜索\n优化器的选择依据优化器选择索引的依据：有很多，最主要的有三个\n\n扫描行数\n考虑基数\n考虑实际扫描行数\n考虑回表\n\n\n是否使用临时表\n是否排序\n\n\n如何判断扫描行数？\n\n优化器优化的时候，还不能知道这个语句会扫描多少个记录，那么他是如何知道扫描的行数有多少？\n\n通过统计信息来判断，对于索引就是索引的区分度，也就是基数Cardinality\n\n可以用show index from 表来查看索引的基数\n\nMysql 如何得到基数的值？\n\n​        进行采样统计，选择N个数据页，计算这些页面上不同的值，求一个平均值，再乘以这个索引的页面数，就有了这个索引的基数。\n​        基数也不是不变的，当改动大于一个值，就会重新计算统计信息。我们可以使用analyze table t来要求Mysql重新计算统计信息\n\n统计信息存放的位置：\n\n可以设置参数innodb_stats_persistent的值：\n\n为on：持久化存储\n为off：只存储在内存中\n\n索引选择异常和处理选错异常了怎么办？\n【法一】使用force index强制指定一个索引（这属于程序员的操作）\n【法二】修改语句，但不修改逻辑（这种情况少）\n【法三】在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n【法四】对于统计信息不准的情况，可以用analyze table 表名命令来要求重新计算\n字符串的前缀索引​        当遇到一些类似于邮箱、身份证号这种长的字符串时，查询的次数也很多，所以我们需要设置他们为索引，但是他们的长度往往会很长，所以前缀索引既可以节省内存，又可以作为索引提高查询效率\n语法：\nalter table SUser add index index1(email);# 设置email整个字符串为索引alter table SUser add index index2(email(6));# 设置email前6个字节为索引\n\n前缀索引的检索区别\n使用前缀索引后，可能会导致查询语句读数据的次数变多\n\n因为使用前缀索引，所以可能导致一次查树并不能得到结果，还需要回表继续进行搜索\n\n前缀索引设置长度的依据，可以通过区分度来判断\n\n比如使用这个语句\nselectcount(distinct left(email,4)）as L4,count(distinct left(email,5)）as L5,count(distinct left(email,6)）as L6,...\n\n这样比较L4、L5、L6的值，我们就能知道前缀设多少长度才好\n\n使用前缀索引，就舍弃了索引覆盖的优化\n\n如果区分度不大该怎么办？比如说身份证，如果要设置前缀索引，那么需要设置到很多字节之后区分度才会有提高，这种情况我们可以这么做\n\n使用倒序索引\n\n将身份证倒过来作为索引存储，查询时这么查\nselect field_list from t where id_card = reverse(&#x27;input_id_card_string&#x27;);# 使用reverse翻转\n\n\n使用hash字段\n\n也可以再添加一个字段，作为保存身份证的校验码，注意比较的时候，要将这个校验码和身份证一同做比较\n比方说可以用CRC32函数\nselect field_list from t where id_card_crc=crc32(&#x27;input_id_card_string&#x27;) and id_card=&#x27;input_id_card_string&#x27;;\n\n\n\n\n倒序索引与使用hash字段作为索引的缺点：\n\n不能进行范围查找\n\n区别：\n\n倒序索引不需要额外占空间\nhash字段做索引更加稳定一些\n\nSql语句为什么执行变慢了Mysql抖动\nMysql抖动：Mysql执行过程中，时不时有一句的查询速度特别慢\n\n首先知道两个概念：\n\n脏页：数据页读入内存后，进行了修改，但是内存页还没有写回数据页，此时这个内存页就叫脏页\n干净页：写回了磁盘的内存页就叫干净页\n\nMysql抖动的那个瞬间，很可能是在刷脏页\n任何情况下都可能在刷脏页：\n\nredo log写满了：导致必须得刷脏页\n要载入新的数据页，淘汰旧的数据页：如果淘汰的旧的数据页是脏页，那么必须得先将数据写回\n系统空闲时：Mysql认为系统很闲，就会不停刷脏页\nMysql正常关闭时，需要将全部脏页写回磁盘\n\n四种情况中，只有情况1与情况2是我们应该着重考虑的，为了减小抖动，我们必须得设置合理的刷脏页机制\n刷脏页的机制情况1告诉我们得考虑redo log的写入速度\n情况2告诉我们得考虑脏页的比例\n在Mysql中，也是这么考虑的，它会按某种算法，计算两个数值的大小，取最大的那一个，作为当前刷脏页的速度\n\nCount(*)的执行过程Count的执行方式在不同的MySQL引擎中，count(*)有不同的实现方式：\n\nMyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；\n而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n\n\n为什么Innodb不学MyISAM，也将总行数记录下来？\n\n因为Innodb支持了事务，所以一个时间内，对于总行数是不确定的\n而MyISAM不支持事务，也就不需要考虑这些，直接记录一个总行数就行\n\n为什么不能使用统计信息里面的Table_rows，它不也是行数吗？\n\n统计信息，都是优化器通过采用分析得到的，也就是说，并不是真正的行数\n\nCount(*) Count(1) Count(主键) Count(字段)的区别\n\n\ncount(字段)：首先明确count聚合函数，是返回当前不为null的数据的个数，所以查询字段，会返回当前字段不为null的个数\nCount(主键)：InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server 层。server层拿到id后，判断是不可能为空的，就按行累加（由于有读操作，还有判断操作，可见效率比较低）\ncount(1)：InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个 数字“1”进去，判断是不可能为空的，按行累加（不取值，可见效率比查主键高一点）\ncount(*)：Mysql专门对此语句进行了优化，不会去取值，它的效率是最高的\n\n速度排行：Count(*) ≈ Count(1) &gt; Count(主键) &gt; Count(字段)\n\nMysql如何对count(*)进行的优化？\n\n虽然count也是一行一行加起来的得到的数据，但是它有着优化：\n​        主键索引树的叶子节点是数据，而普通索引树的叶子节点是 主键值。\n​        所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得 到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历\n自己进行计数当我们的表越来越大，count函数要执行的时间就会越来越长~\n怎么解决？我们只能自己想办法计数\n\n使用缓存系统保存计数，例如使用Redis\n\n这种方法的好处，是比较快，但是坏处就是，崩溃后数据容易丢\n\n在数据库保存计数\n\n可以开启一个事务，来专门进行计数，可以解决崩溃后数据丢失的问题\nMysql主从复制主从复制的由来Sql的某些操作（比如备份），是表锁，表锁的期间，其他进程是不能访问数据库的，很影响服务\n如果建立多个库，让其中一个库（主库）负责写，其他库负责读就可以提高效率\n此外，为了进一步的扩大单个机器的IO性能，多库并用可以提高效率；而且还可以做热备份\n什么是主从复制\n主从复制：数据可以从一个数据服务器主节点复制到一个或多个从节点\n\n在mysql中，采用了异步复制方式，这样从节点不需要一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行\n主从复制原理Mysql5.6之前的主从复制\n​        主库的DML操作会记录到binlog日志当中，并随后等待从节点的IO线程读取，并写入到Relay log中继日志当中，然后由sql线程读取加载到从节点执行，恢复数据\n其中IO线程与Sql线程是只能轮流执行\n细分一下，总过程由4步组成：\n\n主库将DML操作与数据，写入到名为binlog的日志文件中\n从节点将开启IO线程，读取binlog到内存中\nIO线程将读取的内容写入到Relay log中继日志中，并关闭IO线程\n从库开启Sql线程，读取并执行Relay log的sql，将数据恢复到与主库一致\n\n分析整个流程，会发现第四步是影响主从复制的主要原因（前三步都是顺序读取，而最后一步执行多个sql操作是随机读取，可能需要操作多个不同的数据块）\n所以在Mysql5.6之前的版本的主从复制延迟问题非常严重\n于是Mysql设计者就开始思考，第四步的瓶颈在于操作多个数据块，随机读取造成时间延迟，于是着手向多线程转变\nMysql5.6的并行复制改变：\n\n5.6之前：Slave机上有两个线程IO与Sql线程，前者负责从master读取binlog文件 ，后者负责执行\n5.6：加入coordinator（协调者）线程，负责判断event是不是可以并发执行，并分配给worker（负责以前sql thread的任务）；coordinator线程负责两个任务\n判断可以并行执行：选择worker线程执行事务的二进制日志\n判断不可以并行执行或为DDL语句：等待所有worker线程执行完成后再执行（coordinator也可以执行二进制日志）\n\n\n\n如图：\n\n但是此时的并行粒度是库级别的，即不同库的才会进行并行执行，但是常见的情况是一库多表，于是粒度需要细致到表、行\nMysql5.7的并行复制在5.6.3就尝试使用并行复制，到5.7正式实现了并行复制，完全解决了复制延迟问题，这里我们直接介绍mysql5.7的并行复制原理\n\nenhanced multi-threaded slave MTS 官方称为MTS\n\n引入组提交：涉及到binlog与redo log\n通过对事务进行分组，可以优化减少生成二进制日志所需的操作数。\n当事务同时提交时，它们将在单个操作中写入到二进制日志中。\n如果事务能同时提交成功，那么它们就不会共享任何锁，这意味着它们没有冲突，因此可以在Slave上并行执行。所以通过在主机上的二进制日志中添加组提交信息，这些Slave可以并行地安全地运行事务。\n分组后，每一个组的相关信息，都存放在GTID中\n\ncrash safe：有了redo log 之后，可以保证数据在断电后，也可以进行恢复，这种保证数据不会丢失的能力叫crash safe\n\nMysql事务&amp;MVCC当前读&amp;快照读\n当前读：读取的是数据的最新记录\n快照读：读取的是历史版本的记录（读取快照的记录）\n\n触发当前读的语句：\nselect ... lock in share mode # 给此语句加一个共享锁select ... for update # 给此语句加一个排他锁update ...delete ...insert ...\n\n触发快照读的语句：\nselect ...\n\nInnodb行记录的不可见字段每一行都会包含几个不可见字段\n有三个重要的不可见字段：\n\nDB_TRX_ID：创建或修改该记录的事务ID\nDB_ROW_ID：隐藏主键，如果没有显示给主键且没有唯一键，就会创建这个主键，占有6字节，是长整型\nDB_ROW_PTR：回滚指针，事务失败的回滚位置（与 undo log配合使用）\n\n\n\nundo log：当多个事务操作同一行数据时，undo log就会保存这样的一个链表，链首为最新的历史记录，链尾为最早的历史记录，方便事务失败恢复\n\nread view\nreadview：事务在进行快照读的时候产生的读视图\n\nreadview包含以下几部分：\n\ntrx_list：活跃的事务id\nup_limit_id：列表中事务最小的id\nlow_limit_id：系统尚未分配的下一个id\n\n这些值可以与DB_TRX_ID进行判断（属于可见性算法的内容，这里不做详述）\n我们来看这样的一个例子：\n\n以我们的观点来看，mysql的事务隔离级别是RR可重复读的，就应该看不到更改的值，为什么上图情况1还看到了更新后的数据？\n原因在于readview的生成时机不同：\n\n对于不同的事务隔离级别，其readview的生成时机不同：\n\nRC 读提交级别：每一次快照读都会生成新的readview\nRR 可重复读级别：只有第一次快照读会生成readview；之后的读操作都会使用第一次生成的readview\n\n\n正确的判断逻辑总结如下：\n\n事务自己的更新操作，自己是可以读到的\n如果版本未提交，不可见\n如果版本已提交：\n创建快照前生成，可见\n创建快照后生成，不可见\n\n\n\n\n来一个例子练手：事务A与事务B最后读到的数据会是什么？\n初始：表结构(id, k)，数据为(1, 1)，autocommit=1自动提交打开\n\n首先解释一下：start transaction with consistent snapshot可以马上开启一个事务（会直接创建一个读视图）\n（begin / start transaction并不是立即开启，只有执行到第一个Innodb语句才会开启事务）\n结果：事务A读到的数据是(1, 1)，事务B读到的数据是(1 ,3)\n理解过程：\n以事务A的角度分析：\n\n（图的解释：每个事务下面的第一个数组表示当前的活跃事务ID，右边的链表代表undo log，所以在ABC之前有个事务id为99，ABC各自的id为100、101、102）\n​        获取k值时，发现当前版本为(1, 3)，可是这个事务还未提交，所以会向前看，即看历史版本1，为(1 ,2)，历史版本1虽然已经提交了，但是这个事务是在我创建完快照后才提交的，所以读不到，继续向前读。\n以事务B的角度分析：\n​        获取K值时，发现当前版本为(1 ,3)，这个事务是我自己的，所以会读到。\n\n还是这个例子，做一个小改动\n\n结果：在事务B执行到update时，会发生锁等待，事务B需要等待事务C提交后才会执行（又将行级锁联系了起来）\nACID的实现原理有了以上内容，我们就基本上能搞懂Mysql是如何实现ACID的：\n\n原子性A：同时成功，要么同时失败；通过 undo log 来实现\n隔离性I：多个事务之间，相互独立；通过MVCC来实现\n持久性D：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失；通过redo log来实现\n一致性C：在事务开始之前和事务结束以后，数据库的完整性没有被破坏；通过实现AID特性来实现\n\n正确的事务启动方式\n使用begin;或start transaction，配套的有commit与rollback\n使用set autocommit=0\n\n一句话：关闭自动提交，每次显示的开启事务\n也可以用commit work and chain来提交上一个事务并开启下一个事务\n不要使用长事务！\n为什么不要使用长事务？\n\n​        长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间\n所以我们每次使用事务，都要记得 关闭自动提交，显示开启事务\n也可以设置SET MAX_EXECUTION_TIME事务的最大执行时间\nMysql锁全局锁使用FTWRL可以加全局锁：整个库都处于只读状态\nFlush table with read lock\n\n使用场景：做全库备份\n\n当然，全库备份有更好的方式——在RR级别下，使用事务进行备份\n​        官方自带的工具mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的\n所以，对于全是Innodb引擎的数据库，最好使用–single-transaction参数来进行备份\n\n有RR，为什么还要FTWRL？\n\n不是所有的引擎都支持事务，比如MyISAM，这种情况就只能FTWRL\n\n要让全局只读，为什么不使用set global readonly=true的方式呢？\n\n\n某些系统使用readonly的值会被用来做其他逻辑\n如果出现异常，FTWRL可以释放锁，但是这种方式不行\n\n表级别锁MySQL里面表级别的锁有两种：\n\n一种是表锁\n一种是元数据锁（meta data lock，MDL)\n\n\n表锁：\nMysql的表锁属于Server层实现的，和存储引擎无关，用法：\n\nLOCK TABLES ：上锁\nUNLOCK TABLES ：释放锁\n\n语法：设置表锁必须先关闭自动提交\nSET AUTOCOMMIT=0; LOCK TABLES t1 WRITE, t2 READ, ...; # 给t1上写锁、t2上读锁[do something with tables t1 and t2 here]; COMMIT; UNLOCK TABLES;\n\n\n元数据锁MDL：\n无需显示使用，Mysql会自动加\n作用：保证其他线程在读或写的时候，表的结构不会被更改\n\n线程对表CRUD：Mysql加MDL读锁\n线程更改表结构，如alter：Mysql加MDL写锁\n\n注意：MDL机制要注意\n比如这个例子\n\n过程：\n\nSessionA读数据，mysql自动加MDL读锁\nSessionB读数据，无影响\nSessionC更改表结构，由于此表有MDL读锁，所以会进入阻塞\nSessionD读数据，由于SessionC被阻塞，SessionD也会被阻塞\n\n\n如何安全的给小表加字段？\n\n标准的办法：alter table语句里面设定等待时间（用NOWAIT或WAIT n）\n​        如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程\nALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ...\n\n行级别锁InnoDB 实现了以下两种类型的行锁：\n\n共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。\n排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。\n\n为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁：\n\n为什么要用意向锁？\n\n​        为了解决表锁与之前可能存在的行锁冲突，避免为了判断表是否存在行锁而去扫描全表的系统消耗。\n​        注意：意向锁是表锁\n例如这么一个场景：\n\n事务 A 锁住了表中的一行，让这一行只能读，不能写。\n之后，事务 B 申请整个表的写锁。\n如果事务 B 申请成功，那么理论上它就能修改表中的任意一行，这与 A 持有的行锁是冲突的。\n\n\n\n意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。\n意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。\n\n锁的兼容情况如下表：\n\n\n\n列：当前的锁\\行：请求的锁\nX\nIX\nS\nIS\n\n\n\nX\n冲突\n冲突\n冲突\n冲突\n\n\nIX\n冲突\n兼容\n冲突\n兼容\n\n\nS\n冲突\n冲突\n兼容\n兼容\n\n\nIS\n冲突\n兼容\n兼容\n兼容\n\n\n（巧记：意向锁之间兼容，其他遇X则冲）\n加锁方法\n事务可以通过以下语句显式给记录集加共享锁或排他锁：\n共享锁（S）：SELECT ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。\n排他锁（X)：SELECT  ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁\n\n\n普通的select语句不加锁\nupdate insert deleteInnodb会自动加排他锁\n意向锁是由Innodb自动加的\n\n使用场景select ... for update加排他锁：\n​        为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。\nselect ... in share mode加共享锁：\n​        为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。\n两阶段协议\n两阶段锁协议：\n​        行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放\n\n例子：\n\n事务B会被阻塞，直到事务A运行完成，验证了两阶段锁\n两阶段锁协议告诉我们：如果一个事务要锁多个行，那么要把最可能造成锁冲突的尽量往后放！\n\n正确的安排事务的执行顺序！\n\n例子：学生A去电影院B买电影票\n这个事务涉及到三个步骤：\n\nA的钱扣除\nB的钱增加\n增加一条交易记录\n\n如何进行排序呢？\n如果有学生C也在电影院B买票，那么步骤2就会有锁冲突\n因此2应该放在最后，比如执行3、1、2的顺序，这样做就会提高并发度！\n死锁与死锁检测死锁：两个事务各自拿了对方的锁，而又在等待对方释放的状态\n比如这个例子：\n\n上一节提到两阶段协议，所以事务A在更新完id=1的那行数据后，不会释放行级锁，造成死锁状态\n\n怎么打破死锁的局面？\n\n有两种策略：\n\n直接进入等待，直到超时。（这个超时时间可以设置参数innodb_lock_wait_timeout，默认为50s）\n主动发起死锁检测，死锁后，主动回滚死锁链条中某一个事务，让其他事务得以执行（innodb_deadlock_detect设置为on，默认就是开启的）\n\n显然，第一种方法的时间太长，对于一个在线服务来说根本不能接受，而且超时值设置太小，又会导致非死锁操作也被kill掉\n第二种方式也是Mysql默认的方式，可以快速的发现死锁问题并处理，但是也存在负担\n（试想每一个事务运行中，Mysql都要检查其他事务是不是拿了这个事务的锁，这样的检测负担很大！）\n\n怎么解决更新热点行的性能问题？\n\n比如说还是这个电影院，影院在做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。\n【法一】：如果能保证不出现死锁问题，直接关了死锁检测（显然不太可取）\n【法二】：控制并发度\n\n限制客户端：可以限制同时只能有10个用户在进行操作，这样死锁检测的成本很低（不太可行，即使很少的客户端，每个客户端操作很少，也会有很大的并发量）\n将并发限制放在中间件中：可行\n\n【法三】：设计上优化，可以给电影院的账单行设为10行甚至更多，对齐求和就是总金额，这样也可以减少负担\n\n如果要删除1w行数据，应该选择哪种sql？\n\n直接执行delete from T limit 10000;\n在一个连接中循环执行20次 delete from T limit 500;\n第三种，在20个连接中同时执行delete from T limit 500;\n\n\n当然要选择第二种sql，第一种Sql，执行时间太长了\n第三种Sql显然会造成死锁\n第二种，分次迭代删，才是最好的\n索引与锁在Innodb实现中，行锁是通过给索引上的索引项加锁来实现的（而在Oracle中是通过在数据块中对相应数据行加锁来实现的）\n所以使用索引来检索，才会加行锁，除此外都加表锁\n由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）\n间隙锁当我们用范围条件而不是相等条件检索数据时，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；\n\n间隙（GAP)：对于键值在条件范围内但并不存在的记录\n间隙锁（Next-Key锁）：InnoDB也会对这个“间隙”加锁，这种锁机制就是间隙锁\n\n​        很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。\n​        因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。\n\n\n为什么要使用间隙锁？\n\n\n防止幻读，以满足相关隔离级别的要求；\n满足恢复和复制的需要（恢复时不能出现幻读现象）\n\nOrder by详解排序在Mysql中，有两种处理方式：\n\n全字段排序\nrowid排序\n\n以此sql为例，介绍两种排序\n全字段排序先来看此sql\nselect city,name,age from t where city=&#x27;杭州&#x27; order by name limit 1000;# 其中city为普通索引\n\n使用Explain命令去看一下执行计划，在Extra字段就会显示Using filesort，表示需要进行排序\n\n Mysql会给每个线程分配一块内存用于排序，称为sort buffer\n\n上面的sql执行流程如图：\n\n注意：按name排序这个过程，有可能在内存中，也有可能是外部排序\n决定是在内存还是在外部，取决于sort_buffer_size\n\n待排序的数据小于sort_buffer_size：内存中排序\n大于sort_buffer_size：使用外部排序（会使用临时文件）\n\n\n外部排序：使用归并排序法，会创建很多临时文件，各自排序，然后最后汇总为一个文件\n\nrowid排序​        如果Mysql认为，要排序的内容单行长度就很大，那么他会使用rowid排序\n排序的过程如图：\n\n他和全字段排序的区别就在于我在图中圈住的部分：\n\n首先rowid排序在排序时，不会给sort_buffer读入所有字段了，而是读入待排序的键和主键\n在排位序后，会用id再去读出数据\n\n由于2情况的发生，会导致读的行数会比全字段排序多一些\nMySQL数据类型使用注意1、整数的UNSIGNED属性\n对于不需要存储负数的元素，可以使用此属性翻倍存储值\n2、CHAR和VARCHAR的区别\n\nCHAR：不可变，固定大小，即使没有存满，也会补充空格填满\nVARCHAR：可变，存储额外的长度字段\n\n3、VARCHAR(10)和VARCHAR(100)的区别是什么？\n系数表示的都是存储的最大值。对于相同的内容，在磁盘存储时大小是一致的，但是如果提取到内存中，VARCHAR100可能会预分配更大的内存空间\n4、DECIAML的存储方式\n定点数存储方式：DECIMAL(M,D)，M表示总位数，D表示小数位数\n存储时，每9位占4字节\n\n\n\n剩余数字\n字节数\n\n\n\n0\n0\n\n\n1-2\n1\n\n\n3–4\n2\n\n\n5–6\n3\n\n\n7–9\n4\n\n\n举个例子：\nDECIMAL(18,9)列的小数点两边各有九位，因此整数部分和小数部分各需要4个字节。 \nDECIMAL(20,6)列有14个整数位和6个小数位。整数位中的九位需要四个字节，其余五位需要三个字节，六位小数需要三个字节\n5、TEXT和BLOB\n\nTEXT用来存储更长的文本数据\nBLOB用来存储二进制大对象，比如图片、音视频\n\n日常开发基本不用，因为：有限制，不能有默认值、无法内存中创建临时表、不能直接创建索引（只能指定前缀长度，创建前缀索引）\n6、NULL和&quot;&quot;的区别\n\nNULL需要额外存储（BITMAP），&quot;&quot;不占额外空间\nSUM、AVG、MIN、MAX 等聚合函数会忽略 NULL 值\nCOUNT操作中，COUNT(*)会统计null值与&quot;&quot;，COUNT(列)不会统计null值，但会统计空字符串\nNULL值比较要用IS NULL\n\nmysql的DATETIME和TIMESTAMP\n存储内容：\nDATETIME：存储YYYY-MM-DD HH:MM:SS\nTIMESTAMP：存储自1970年开始的秒数，在2038年会用完\n\n\n存储空间：\nDATETIME 8字节\nTIMESTAMP 4字节\n\n\n时区相关：\nDATETIME：UTC时间，与时区无关\nTIMESTAMP：与时区有关，显示的值依赖于当前时区\n\n\n默认值：\nDATETIME：默认为null\nTIMESTAMP：默认为当前秒数\n\n\n\n\nmysql的TIMESTAMP2038年用完怎么办？\n\n\n换用DATETIME\n使用bigint存储秒数\n\n其他相关问题自增主键一定是连续的吗？设置主键为auto_increacement，那么主键一定就是连续的吗？\n不一定，可能存在这么几种情况：\n\n设置过自增初始值和自增步长\n唯一键冲突：比如插入数据(null,1,123)，判断id为null，就去取自增id，然后执行插入的时候，发现唯一键123冲突，插入失败，那么下一次插入时，自增ID就会跳过一个。\n事务回滚：事务回滚后，不会回滚自增ID的值（为什么？因为回滚ID可能会导致两个事务在插入过程中出现主键冲突的问题）\n批量插入：为了效率，不会挨个申请，而是一次性申请一批量\n\n深分页优化优化的原因在Mysql中，经常会使用到limit关键字，比如\nselect * from Userslimit 1000000, 10;\n\nmysql的实际处理并不是直接去取1000000之后的十条数据，而是取1000010条数据，然后忽略前1000000条，返回后十条数据。\n因此对深度分页进行一些合理的优化可以提高sql速度\n范围查询在ID连续时，可以使用范围查询代替limit\n-- 第一种select * from Users where id &gt; 1000000 and id &lt;= 1000010;-- 第二种select * from Users where id &gt; 1000000 limit 10;\n\n要求：ID连续\n\n为什么这种方式比limit快？\n\n这种方式会：先找到id为1000000的索引位置，然后取十条数据后返回\nlimit方式：取1000010条数据（而且有1000000次回表），忽略前1000000次的数据，返回10条\n延迟关联把条件转移到主键索引树，减少回表的次数：\nINNER JOIN方式：\n-- 第一种SELECT t1.* FROM t_order t1INNER JOIN (SELECT id FROM t_order limit 1000000, 10) t2ON t1.id = t2.id;-- 第二种SELECT t1.* FROM t_order t1,(SELECT id FROM t_order limit 1000000, 10) t2WHERE t1.id = t2.id;\n\n子查询方式：\n# 通过子查询来获取 id 的起始值，把 limit 1000000 的条件转移到子查询SELECT * FROM t_order WHERE id &gt;= (SELECT id FROM t_order limit 1000000, 1) LIMIT 10;\n\n这种方式不如使用INNER JOIN\n\n这种方式为什么快？\n\n其实也是延迟关联的方式，子查询获取到ID集合后，才去拿数据，减少回表次数\n覆盖索引如果数据只需要获得ID与普通索引的值，能利用索引覆盖的特性，可以完全避免回表。\n数据库字段设计规范1、能用数字存储，就尽量用数字而不使用字符串\n\n存储IP地址，就可以使用整数，mysql还有方法处理IP地址：\n\n\nINET_ATON()：把 ip 转为无符号整型 (4-8 位)\nINET_NTOA() :把整型的 ip 转为地址\n\n插入数据前，先用 INET_ATON() 把 ip 地址转为整型，显示数据时，使用 INET_NTOA() 把整型的 ip 地址转为地址显示即可\n\n存储时间类型\n\n时间类型可以使用DATETIME（8字节）、TIMESTAMP（4字节）、BIGINT（8字节）\n\n在INNODB存储引擎，如果有按时间排序或是按时间范围查找，性能bigint &gt; timestamp &gt; datetime\n如果为了时区无关，使用DATETIME\n如果只是为了存储，可以考虑TIMESTAMP，但是只能存储到2038年\n\n2、对于非负类型，使用无符号数据表示\n无符号比有符号多一倍空间\n3、小数值，表示年龄、状态，用TINYINT类型（占用1字节）\n4、如果有BLOB或是TEXT列，尽量分离到单独的扩展表中\n\nBLOB或TEXT如果遇到排序，是不会使用内存临时表排序的，只能使用磁盘临时表，性能很差\nBLOB和TEXT查询一定不要使用select *\n\n5、尽可能所有列定义为Not Null\nmysql存储null值，需要额外1字节存储（bitmap）\n6、财务相关使用decimal类型，精准浮点数\n在计算时不会丢失精度。占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节\n数据库索引设计规范1、单表的索引最多不要超过5个，会增大执行计划的分析时间，反而降低查询性能\n2、禁止使用全文索引，OLTP不应该搞OLAP的事情\n3、主键的选择\n\n最好不要使用业务相关字段\n要选择有序的字段，不适用UUID、HASH、字符串作为主键，可以使用雪花算法\n尽量要小\n\n4、联合索引的顺序选择，最左键应该要区分度大、字段长度小、使用最频繁\n5、不使用外键\n\n外键会影响父表与子表的写操作性能\n外键建议在业务端实现\n\n数据库SQL开发规范1、不在数据库做运算、复杂运算业务端完成\n**2、禁止使用select ***\n\n会消耗更多资源：CPU、网络带宽\n无法使用索引覆盖等优化机制\nselect具体字段，会减少表结构发生变化后的影响\n\n3、禁止使用不含字段的INSERT语句，防止表结构变化后出现问题\ninsert into t values (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;); # 禁止insert into t(c1,c2,c3) values (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;); #推荐\n\n4、尽量使用预编译语句\n\n预编译语句只需要解析一次，且可以重复使用，每次传输只需传参数，可以提高效率，还可以避免SQL注入\n\n5、大数据量使用连接查询代替子查询\n\n子查询多次遍历数据（先查子查询语句，结果存入内存临时表或是磁盘临时表），然后再去使用外部查询查子查询的结果\n\n连接查询可以同时利用多个表之间的索引（如果可以）得到结果，只查一次\n\n\n6、除非要去重，否则使用UNION ALL而不是UNION\n相关链接\n博客1：平衡二叉树\n博客2：B树与B+树图文阐述\n博客3：mysql不同引擎的索引实现\n视频课\n博客4：Mysql并行复制\n视频课*2：关于事务\n知乎：mysql锁\n极客时间：Mysql实战45讲\nExplain官网介绍\n\n","categories":["MySQL"],"tags":["MySQL","B树","索引","锁"]},{"title":"Java 线程与并发","url":"/2021/08/10/JUC/Java%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/","content":"\n  引言:\n  JUC核心部分\n\n\n\nJava 线程与并发本章分为两个部分：\n上半部分：Java多线程——基础\n下半部分：Java并发编程——进阶\nJava多线程创建线程的方式在Java中，有四种创建线程的方法：\n\n继承Thread类\n继承Thread类\n重写run()方法\n用start()方法开启线程（是一个Native方法）\n\n\n实现Runnable接口\n实现Runnable接口\n重写run()方法\n使用Thread的构造方法，传入实现了Runnable接口的类对象创建对象\n调用Thread对象的start()方法\n\n\n实现Callable接口（一个有返回值的线程）\n实现Callable&lt;T&gt;接口，注意有泛型\n重写call()方法\n通过ExecutorService对象的submit( Callable&lt;T&gt; )方法，将实现了Callable接口的thread上传，返回值是一个Future对象\n通过Future对象的get()方法就可以获取到值\n\n\n线程池（具体内容会在下一章Java并发编程进行介绍）\n通过Executor来获取线程池\n通过ExecutorService的execute(Runnable接口)执行任务，没有返回值\n通过ExecutorService的shutdown()方法关闭线程池\n\n\n\n第一种方式demo（过于简单可以跳过）:\npublic class MyThread01 extends Thread&#123;    @Override    public void run() &#123;        super.run();        System.out.println(&quot;继承Thread实现线程&quot;);    &#125;    public static void main(String[] args) &#123;        MyThread01 myThread = new MyThread01();        myThread.start();    &#125;&#125;\n\n第二种方式的demo（过于简单可以跳过）：\npublic class MyThread02 implements Runnable&#123;    @Override    public void run() &#123;        System.out.println(&quot;用接口新建线程&quot;);    &#125;    public static void main(String[] args) &#123;        MyThread02 myThread02 = new MyThread02();        Thread thread = new Thread(myThread02);        thread.start();    &#125;&#125;\n\n实现Callable接口demo：\npublic class MyThread03 implements Callable&lt;String&gt; &#123;    @Override    public String call() throws Exception &#123;        // 具有返回值的线程，重写call方法        String[] strs = &#123;&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;&#125;;        return strs[new Random().nextInt(5)];    &#125;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        MyThread03 thread = new MyThread03();        // 创建执行服务        ExecutorService service = Executors.newFixedThreadPool(1);        // 提交执行        Future&lt;String&gt; res = service.submit(thread);        // 使用get获取返回值        String s = res.get();        System.out.println(s);        // 关闭服务        service.shutdownNow();    &#125;&#125;\n\n线程池demo：\n// 1 获取线程池ExecutorService threadPool = Executors.newFixedThreadPool(10);while(true) &#123;    // 2. 执行任务，这里使用了lambda表达式    threadPool.execute(() -&gt; &#123;        System.out.println(Thread.currentThread().getName() + &quot; is running ..&quot;);        try &#123;            Thread.sleep(3000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;);&#125;\n\n不同创建方式的区别\n继承Thread类：优点是简单方便；缺点是Java单继承，如果已经有一个父类，将不再能使用这种方法。\n实现Runnable接口：较好的创建线程的方法\n实现Callable接口：需要配合ExecutorService使用，如果需要返回值可以使用这种方法，返回值可以通过Future获得\n使用线程池：较为复杂，但是功能多样。\n\n线程中使用的设计模式：静态代理模式静态代理模式中有 真实对象、代理对象\n\n真实对象与代理对象要实现同一个接口\n代理对象要代理真实的角色\n\n优点：\n静态代理模式可以帮助我们处理一些其他的事情，真实对象可以专注于做本职任务\n\n举例：\n在多线程中，实现Runnable接口的类就使用了静态代理模式：\n例如这个demo：真实对象——MyThread02、代理对象Thread，他们实现了同一个接口Runnable，然后通过代理类Thread代理真实对象myThread02，执行run方法（通过start执行）\npublic class MyThread02 implements Runnable&#123;    @Override    public void run() &#123;        System.out.println(&quot;用接口新建线程&quot;);    &#125;    public static void main(String[] args) &#123;        MyThread02 myThread02 = new MyThread02();        Thread thread = new Thread(myThread02);        thread.start();    &#125;&#125;\n\n线程的五大状态老生常谈的问题，说再多不如图：\n（其实这里的五大状态，应该算OS层面的线程的五大状态，具体JVM里线程的状态，后面会说）\n\n除此外，还要说明几点：\n\n创建状态：此时Jvm会为其分配内存空间，初始化成员变量的值\n就绪状态：JVM为其创建方法栈和PC\n运行状态：获得了CPU\n阻塞状态分三种情况\n等待阻塞：线程调用了wait()方法，进入等待队列\n同步阻塞：要获取的同步锁被别的线程占用，JVM会将这个队列放入锁池（Lock Pool）中\n其他阻塞：由于sleep()、join()，或者是IO请求时产生中断\n\n\n导致线程死亡的情况（下一节详细介绍）\n正常结束：run或call方法运行结束\n异常结束：抛出未捕获的Error或是Exception\n调用stop：stop()不建议使用，因为很容易导致死锁；官方也声明这是一个即将过时的方法。\n\n\n\n终止线程的方式终止线程有很多方式，这里主要介绍四种：\n正常退出程序run()或call()方法运行结束，线程正常退出\n使用flag退出线程大多数情况下，线程是伺服线程，所以我们一般使用一个变量来控制线程的退出：\n\n伺服线程：即需要长时间运行的线程，多为循环体\n\npublic class ThreadSafe extends Thread &#123;    public volatile boolean exit = false;    public void run() &#123;        while (!exit)&#123;            //do something        &#125;    &#125;&#125;\n\n注意到，此变量使用了volatile关键字，可以使同一时刻只能有一个线程修改exit的值（此关键字看下文详细阐述）\n使用Interrupt\n注意：中断并不会直接终止线程，而是给线程发送一个中断信号，线程可以根据中断信号来决定是否终止自己的执行。\n\n因此终止线程需要我们自己动手，中断只是发出一个信号，在线程中，使用isInterrupted()判断\npublic void run() &#123;    while (!Thread.currentThread().isInterrupted()) &#123;        // 执行线程逻辑    &#125;&#125;\n\n根据线程是否处于阻塞状态，使用interrupt中断线程有两种情况：\n\n线程处于阻塞状态：\n\n一些操作（如 sleep()、wait()、join() 等）会导致线程阻塞\n\n当阻塞的线程调用 interrupt()方法时，会抛出 InterruptException异常。此时我们想跳出线程就必须通过代码捕获该异常，然后 break 跳出循环状态\n\n注意：只有当捕获异常并break后，才能正常结束run方法\n\n```javawhile (!Thread.currentThread().isInterrupted()){\ntry &#123;\n    System.out.println(&quot;sleep&quot;);\n    Thread.sleep(2000);\n    System.out.println(&quot;wakeup&quot;);\n&#125; catch (InterruptedException e) &#123;\n    break;\n&#125;\n\n}\n2. 线程不处于阻塞状态：   - 使用`isInterrupted()`判断线程的中断标志来退出循环。当使用`interrupt()`方法时，中断标志就会置`true`      ```java   public class ThreadSafe extends Thread &#123;       public void run() &#123;            while (!isInterrupted())&#123;                //非阻塞过程中通过判断中断标志来退出               try&#123;                   Thread.sleep(5*1000);                   //阻塞过程捕获中断异常来退出               &#125;catch(InterruptedException e)&#123;                   e.printStackTrace();                   break;//捕获到异常之后，执行 break 跳出循环               &#125;           &#125;       &#125;    &#125;\n\n\n\n使用stop一个已经过时的方法，线程不安全 0\nthread.stop()调用之后，创建子线程的线程就会抛出ThreadDeatherror 的错误，并且会释放子线程持有的隐式锁。\n一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用 thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。\nsleep()与wait()\nsleep()方法在Thread类中，是一个本地静态方法\n\npublic static native void sleep(long millis) throws InterruptedException;\n\n\nwait()方法是在Object类中的，是一个不可重写的本地方法\n\npublic final native void wait(long timeout) throws InterruptedException;\n\n\n\n\n对比项\nsleep\nwait\n\n\n\n是否让出CPU\n是\n是\n\n\n是否让出对象锁\n不释放\n释放\n\n\n如何进入就绪状态\n设定时间到或是调用interrupt()方法唤醒休眠线程\n调用notify方法\n\n\n使用范围\n任何地方\n必须在同步代码块中\n\n\n\nwait是醒着的等待，所以会释放锁\nsleep抱着锁睡着了，所以不会释放锁 \n\nstart方法在Java源码中，start()方法会调用本地方法start0()，由C来实现线程的创建\n\n所以Java本质上来说，是创建不了线程的，需要调用C++来实现\n\n源码如下：\npublic synchronized void start() &#123;    if (threadStatus != 0)        throw new IllegalThreadStateException();    group.add(this);    boolean started = false;    try &#123;        start0();        started = true;    &#125; finally &#123;        try &#123;            if (!started) &#123;                group.threadStartFailed(this);            &#125;        &#125; catch (Throwable ignore) &#123;            /* do nothing. If start0 threw a Throwable thenit will be passed up the call stack */        &#125;    &#125;&#125;private native void start0();\n\n\nstart方法与run方法的区别：\n\nThread t1 = new Thread(r1);t1.start(); t1.run();\n\n\n使用 Thread.start() 来启动新的线程，实现并行执行。\n使用 Thread.run() 仅仅是在当前线程上同步地执行 run() 方法的代码，不会启动新的线程\n\nJava并发编程JUC\n并发编程离不开JUC，什么是JUC？\n\n指JDK下的包：java.util.concurrent，简写为JUC\n这个包内包含所有的与并发相关的操作，因此取名为JUC\n\n并发：cpu快速切换程序执行，形成同时运行的假象（多个任务在同一时间段内交替执行）\n并行：相对于串行而言，指多个程序同时执行（多个任务在同一时刻同时执行）\n\n守护线程\n守护线程（也叫后台线程）：\n为用户线程提供公共服务，没有用户线程时会自动离开\n\n特点：\n\n优先级比较低\n普通线程可以通过setDaemon(true)来设置一个线程为守护线程\n守护线程中创建的新线程依然是守护线程\n守护线程是JVM级别的；以 Tomcat 为例，如果你在 Web 应用中启动一个线程，这个线程的生命周期并不会和 Web 应用程序保持同步。也就是说，即使你停止了 Web 应用，这个线程依旧是活跃的\n只要有一个用户线程，那么守护线程就不会退出；如果全是守护线程，那么守护线程也就会退出\n\nJava默认有两个线程：\n\nmain线程： Java 程序的入口，它从 main 方法开始执行。在 main 方法中创建的任何线程都会成为主线程的子线程\nGC线程：GC线程就是守护线程，当GC线程是JVM中仅剩的线程时，GC线程会自动离开\n\n线程池线程池的作用\n增快响应速度\n控制并发量（最主要的原因）\n对线程进行统一管理\n减小线程切换时的上下文开销\n\n\n实现原理：每一个Thread都有一个start方法，当调用start启动线程时，JVM就会调用该类的run方法\n线程池就是通过不断向start方法中传递Runnable对象\n\n线程池常见类的简介\n\nExecutor：顶级接口\n\nExecutorService：次级接口，一般使用此类使用线程池，通过调用execute与submit方法执行任务\n\nexecute方法：没有返回值，执行Runnable方法\nsubmit方法：返回Future接口对象，\n\n\nExecutors：JDK官方实现的四类线程池，其本质就是ThreadPoolExecutor创建，只不过参数不同\n\nScheduledExecutorService：ExecutorService的子接口，实现了任务定时执行，JDK实现的线程池中，newScheduledThreadPool会返回一个此接口的对象\n\nThreadPoolExecutor：创建线程最详细的方法，有七个参数\n\n\n线程池的组成&amp;参数\n线程池管理器：用于创建并管理线程池 \n工作线程：线程池中的线程\n任务接口：每个任务必须实现的接口，用于工作线程调度其运行 \n任务队列：用于存放待处理的任务，提供一种缓冲机制\n\n在Executor框架内，ThreadPoolExecutor负责创建线程池，构造方法如下：\npublic ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue) &#123;    this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,         Executors.defaultThreadFactory(), defaultHandler);&#125;\n\n\ncorePoolSize：线程池线程数量\nmaximumPoolSize：最大线程数量\nkeepAliveTime：最大连接时长（当前线程数量处于上面两个数量之间，就会判断最大连接时长）\nunit：时间单位\nworkQueue：阻塞队列，被提交但是没有被执行的任务\nthreadFactory：线程工厂，这里使用默认的线程工厂\nhandler：拒绝策略\n\n线程池的状态ThreadPoolExecutor有五种状态：这五个状态由ctl来控制，ctl是一个AtomicInteger类型的变量，状态就由ctl来获取\nprivate static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;// 线程池创建后处于Running状态private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;// 调用shutdown方法进入，不能接受新的任务，但是会将阻塞队列中的任务执行完毕private static final int STOP       =  1 &lt;&lt; COUNT_BITS;// 调用shutDownNow进入STOP状态，线程池不能接受新的任务，阻塞队列中的任务也会被丢弃private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;// 所有任务终止，ctl记录的任务数量为0，就会变为TIDYING（接着会执行Terminated()函数）private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;// 执行完terminated方法后，就会由TIDYING转变为TERMINATED状态\n\n拒绝策略\n线程池中线程已经使用完，且任务队列也已经满了，此时就需要对新来的任务进行拒绝\n\nJDK内置有四种拒绝策略，这四种拒绝策略是ThreadPoolExecutor类的内部类\n\nAbortPolicy ：直接抛出异常，阻止系统正常运行。 \nCallerRunsPolicy： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。（显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降）\nDiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务\nDiscardPolicy： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。\n\n不同线程池\nJava中有四种线程池，他们的顶层接口是Executor，但是严格意义上来说Executor并不是一个线程池，而是一个执行线程池的工具，真正的线程池接口是ExecutorService\nExecutorService有四个静态方法：\n\nnewSingleThreadExecutor\nnewFixedThreadPool\nnewScheduledThreadPool\nnewCachedThreadPool\n\n下面我们来说这些不同线程池的特点\nnewSingleThreadExecutorpublic static ExecutorService newSingleThreadExecutor() &#123;    return new FinalizableDelegatedExecutorService        (new ThreadPoolExecutor(1, 1,                                0L, TimeUnit.MILLISECONDS,                                new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;\n\n特点：\n\n核心线程只有一个\n所有任务按照先来先执行的顺序执行\n\nnewScheduledThreadPoolpublic static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123;    return new ScheduledThreadPoolExecutor(corePoolSize);&#125;//ScheduledThreadPoolExecutor():public ScheduledThreadPoolExecutor(int corePoolSize) &#123;    super(corePoolSize, Integer.MAX_VALUE,          DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,          new DelayedWorkQueue());&#125;\n\n特点：\n\n可以定时执行\n\n返回ScheduledExecutorService接口，是ExecutorService的子接口\n\n有两个重要的方法：\n\nschedule()方法可以实现延迟执行，有三个参数：\n\nRunnable接口\n延迟时间\n时间单位\n\n\nscheduleAtFixedRate()可以实现定时周期执行，有四个参数：\n\nRunnable接口\n初始延迟时间\n执行周期\n时间单位\n\n\n\n\n\ndemo：\npublic static void main(String[] args) &#123;    ScheduledExecutorService ses = Executors.newScheduledThreadPool(3);    ses.schedule(()-&gt; System.out.println(&quot;延迟3s后执行&quot;),3, TimeUnit.SECONDS);    ses.scheduleAtFixedRate(()-&gt; System.out.println(&quot;最开始延迟5s后，每三秒执行一次&quot;),5,3, TimeUnit.SECONDS);    ses.shutdownNow();&#125;\n\nnewCachedThreadPoolpublic static ExecutorService newCachedThreadPool() &#123;    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                  60L, TimeUnit.SECONDS,                                  new SynchronousQueue&lt;Runnable&gt;());&#125;\n\n特点：\n\n没有创建核心线程（核心线程数为0），最大线程数为Integer.MAX_VALUE\n\n将任务添加到同步等待队列SynchronousQueue（如果入列成功，那么会等待空闲的线程去运行，如果没有空闲线程，会创建线程运行）\n\n适用于短期异步程序\n\n若一个线程60s未被使用，会被移除\n\n\nnewFixedThreadPoolpublic static ExecutorService newFixedThreadPool(int nThreads) &#123;        return new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());&#125;\n\n特点：\n\n创建有n个线程的线程池\n只会创建核心线程！（因为核心线程数与非核心线程数相等）\n如果任务队列没有任务，线程会阻塞在take方法，不会被回收\n如果线程因失败或异常而终止，那么会创建一个新线程代替他持续后续的任务（可选）\n池若不关闭，线程也不会移除\n\n线程池工作原理\n由图可以看出，创建线程池的是Executors类，回到第一节的demo\n线程池的工作原理如下：\n\n线程池刚创建时，内部没有一个线程\n当调用execute()方法添加任务，会与corePoolSize进行对比\n如果正在运行的线程数量小于corePoolSize，马上创建线程运行这个任务\n如果正在运行的线程数量大于等于corePoolSize，那么这个任务放入任务队列\n如果任务队列满了，而且正在运行的线程数量小于maxmumPoolSize，那么还是要创建非核心线程立刻运行这个任务\n如果任务队列满了，而且正在运行的线程数量大于等于maxmumPoolSize，那么会抛出RejectExecutionException异常（默认的抛弃策略AbortPolicy）\n\n\n线程完成任务会从任务队列找下一个任务来执行\n当一个线程闲置，并且运行时间超过keepAliveTime时，线程池会判断，如果当前运行的线程数量大于corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到corePoolSize的大小\n\n原理如图：\n\n阻塞队列BolckingQueue的API：\n\n\n\n方法\\处理方式\n抛出异常\n返回特殊值\n一直阻塞\n超时退出\n\n\n\n插入方法\nadd(e)\noffer(e)\nput(e)\noffer(e,time,unit)\n\n\n移除方法\nremove()\npoll()\ntake()\npoll(time,unit)\n\n\n检查方法\nelement()\npeek()\n-\n-\n\n\n常用的实现了此接口的类有：\n\nArrayBlockingQueue\n底层由数组组成，有界的阻塞队列\n可以指定初始化大小，一旦初始化不能修改\n构造方法中可以设置是否为公平锁\n\n\nLinkedBlockingQueue\n无界的阻塞队列\n底层是链表\n队列按照先进先出的原则对元素进行排序\n\n\nDelayQueue\n该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素\n也没有大小限制\n\n\nPriorityBlockingQueue\n基于优先级的无界阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定）\n内部控制线程同步的锁采用的是非公平锁\n\n\nSynchronousQueue\n比较特殊，没有容器存储，适用于一些线程间直接传递任务的场景\n是newCachedThreadPool使用的阻塞队列\n每个插入操作必须等待一个相应的删除操作：一个put必须等一个take，一个take必须等一个put\n\n\n\nJava中线程的方法与状态转换在JDK源码中，Thread.State类代码如下，有六个状态：\npublic enum State &#123;\t// 新建    NEW,    // 运行    RUNNABLE,    // 阻塞    BLOCKED,    //等待    WAITING,    //超时等待    TIMED_WAITING,   \t// 终止状态    TERMINATED;&#125;\n\n线程的基本方法有wait()、notify()、notifyAll()、sleep()、join()、yield\n\n\nwait()：直接调用后会进入waiting状态；会释放锁；加时间参数的话，会进入TIMED_WAITING状态\n\n注意：wait()方法不能写在if的执行语句中，如果有此需求，可以使用while进行判断（虚假唤醒）\n\n\nnotify()：唤醒在一个锁上等待的单个线程；如果有很多线程，会随机选择一个唤醒\n\nsleep()：进入TIMED_WAITING状态，不会释放当前占有的锁；\n\nyield()：会让线程从执行进入就绪状态，让出当前CPU时间片\n\ninterrupt()：本意是给这个线程一个通知信号，会影响这个线程内部的一个中断标示位；不会改变线程的状态\n\n调用方法不会中断一个正在运行的线程；仅仅只是改变了一个中断标识位\n\n若线程原本调用sleep()而处于TIMED_WAITING状态，调用此方法会抛出InterruptException，从而使线程提前结束TIMED_WAITING状态\n\n抛出InterruptException后，会恢复中断标志位\n\n中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程\n比如，你想终止 一个 thread时，可以调用thread.interrupt()方法，在线程的 run 方法内部可以根据thread.isInterrupted()的值来优雅的终止线程\n\n\n\njoin()：等待其他线程终止，在当前线程中调用join()，会使当前线程阻塞，等到另一个线程结束，才会变为就绪状态。\n\n为什么要有join()方法？很多情况下主线程启动了子线程，需要用到子线程的返回结果，即主线需要等到子线程结束后再结束，就有了join方法\n\n\n\n下面是一个join方法的使用示例：\nThread thread1 = new Thread(() -&gt; &#123;    System.out.println(&quot;Thread 1 started.&quot;);    try &#123;        Thread.sleep(2000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;    System.out.println(&quot;Thread 1 finished.&quot;);&#125;);Thread thread2 = new Thread(() -&gt; &#123;    System.out.println(&quot;Thread 2 started.&quot;);    try &#123;        Thread.sleep(3000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;    System.out.println(&quot;Thread 2 finished.&quot;);&#125;);thread1.start();thread2.start();try &#123;    thread1.join(); // Main等待 thread1 执行完毕    thread2.join(); // Main等待 thread2 执行完毕&#125; catch (InterruptedException e) &#123;    e.printStackTrace();&#125;System.out.println(&quot;Main is the last completed.&quot;);// 输出结果// Thread 1 started.// Thread 2 started.// Thread 1 finished.// Thread 2 finished.// Main is the last completed.\n\nwait的使用wait并不是Thread的方法，而是Object的方法，但是wait能改变当前线程的状态。\nwait一般搭配Synchronized使用。\nwait与notify打印ABC下面是一个wait与notify的使用示例，例子循环打印ABC：\npublic class WaitNotify &#123;    public static void main(String[] args) &#123;        Printer printer = new Printer();        Thread threadA = new Thread(() -&gt; &#123;            printer.printLetter(&quot;A&quot;, 0, 1);        &#125;);        Thread threadB = new Thread(() -&gt; &#123;            printer.printLetter(&quot;B&quot;, 1, 2);        &#125;);        Thread threadC = new Thread(() -&gt; &#123;            printer.printLetter(&quot;C&quot;, 2, 0);        &#125;);        threadA.start();        threadB.start();        threadC.start();    &#125;&#125;class Printer &#123;    private int currentThreadIndex = 0;    private final Object lock = new Object();    public void printLetter(String letter, int threadIndex, int nextThreadIndex) &#123;        synchronized (lock) &#123;            for (;;) &#123;                while (currentThreadIndex != threadIndex) &#123;                    // 如果当前打印的ID不是需要的，那么进入等待，并且释放当前的锁                    try &#123;                        lock.wait();                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                System.out.print(letter);                currentThreadIndex = nextThreadIndex;                lock.notifyAll();            &#125;        &#125;    &#125;&#125;\n\n\n虚假唤醒\n虚假唤醒：例如，生产者生产了1个商品，但是却唤醒了3个消费者来消费，最终只能有一个消费者消费成功，其他两个线程就被“忽悠”了\n\n测试demo：\nclass PV&#123;    private int x = 0;    public synchronized void p() throws InterruptedException &#123;        if( x == 0)&#123;// 将这里改为while            this.wait();        &#125;        x --;        System.out.println(Thread.currentThread().getName()+&quot;：&quot;+x);        this.notifyAll();    &#125;    public synchronized void v() throws InterruptedException &#123;        if( x != 0)&#123;// 将这里改为while            this.wait();        &#125;        x ++;        System.out.println(Thread.currentThread().getName()+&quot;：&quot;+x);        this.notifyAll();    &#125;&#125;\n\nmain方法\npublic static void main(String[] args) &#123;    PV pv = new PV();    new Thread(()-&gt; &#123;        for (int i = 0; i &lt; 10; i++) &#123;            try &#123;                pv.v();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;,&quot;A&quot;).start();    // 同上，继续创建线程 B、C、D分别运行 p()、v()、p()操作&#125;\n\n运行结果如下：\nA：1B：0A：1C：0A：1B：0A：1C：0B：-1B：-2B：-3C：-4C：-5...\n\n发现出现了负数这种情况，显然不是我们想要的\n为什么会出现这种问题？\n注意这里\nif( x != 0)&#123;    this.wait();&#125;x ++;this.notifyAll();\n\n我们使用if进行判断，只会执行一次，如果该线程被唤醒，那么将不会去判断x != 0这个条件\n所以要使用while，将方法中if判断改为while即可\n总结：\n如果要判断条件并进行wait()方法，不能使用if()，会出现虚假唤醒的现象\n锁及相关概念（重点）乐观锁与悲观锁乐观锁与悲观锁是一种对于锁的思想：\n\n乐观锁：认为写入少\n悲观锁：认为写入多\n\n由两种观点，就有不同的实现：\n乐观锁认为写入少，所以不会上锁，但是更新时会进行一个判断（CAS操作），这样即使没有上锁，也不会出现线程安全问题。\n悲观锁认为写入多，在每次读/写数据时都会进行上锁，其他线程想要进行读写数据，必须先拿到锁（Synchronized就是悲观锁的一种实现）。\n什么是CASCAS（Compare And Swap/Set）：比较并变换，是一个原子操作，相同则更新\n\nCAS(V,E,N)\nV 表示要更新的变量（内存值，由于多线程的存在，可能与E不同）\nE 表示预期值（旧的）\nN 表示新值（想设置的新值）\n\nCAS比较流程：\n\n如果V==E值时，会将 V=N（内存值 == 预期值，说明没有线程对当前变量进行写操作）\n如果V!=E，则当前线程什么都不做（内存值 != 预期值，说明已经有其他线程做了更新，那么现在就不能更改这个值）\n最后，CAS操作返回当前 V 的真实值\n\n注意：\n\nCAS 操作是抱着乐观的态度进行的（乐观锁），它总是认为自己可以成功完成操作\nCAS可以用来实现自旋锁：即会有一个线程进行自旋，反复判断是否符合条件\n当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败\n失败的线程不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作\n基于这样的原理，CAS 操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。\n\n在Java中，原子类AtomicInteger有CompareAndSet的操作：\nAtomicInteger atomicValue1 = new AtomicInteger(9);AtomicInteger atomicValue2 = new AtomicInteger(10);int expectedValue = 10;int newValue = 20;boolean updatedState1 = atomicValue1.compareAndSet(expectedValue, newValue);boolean updatedState2 = atomicValue2.compareAndSet(expectedValue, newValue);// 因为期望值10与现有值9不同，因此不会设置，返回原值System.out.println(&quot;Value updated: &quot; + updatedState1); // falseSystem.out.println(&quot;Final Value: &quot; + atomicValue1.get()); // 9// 因为期望值10与现有值10相同，因此改变为20，并且返回原值System.out.println(&quot;Value updated: &quot; + updatedState2); // trueSystem.out.println(&quot;Final Value: &quot; + atomicValue2.get()); // 20\n\n\nCAS存在的问题：\n\n\nABA问题\n循环性能开销大\n只能保证单个变量的原子操作\n\nAtomicIntegerAtomicInteger是一个保证原子操作的Integer类\n它的关键结构如下：\n// 存储内存偏移量（相对于对象的起始位置，获得成员变量的偏移量）private static final long valueOffset;// 创建一个AtomicInteger，就先获得他的内存的偏移static &#123;    try &#123;        valueOffset = unsafe.objectFieldOffset            (AtomicInteger.class.getDeclaredField(&quot;value&quot;));    &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;// 真实的值由此存储，为了保证有序和可见，使用volatile修饰private volatile int value;\n\n我们知道，普通的int，他的i++操作并不是一个原子操作，但是AtomicInteger的getAndIncrement是一个原子操作\npublic final int getAndIncrement() &#123;    return unsafe.getAndAddInt(this, valueOffset, 1);&#125;\n\ngetAndIncrement调用了unsafe类，unsafe类提供了一些底层的、危险的操作，通常用于实现Java标准库和虚拟机的内部功能\n下面是其getAndAddInt：\n// 下面贴出unsafe的getAndAddInt方法传入三个参数:本实例，value的内存地址偏移(偏移量是相对于对象的起始地址的位置)，要加的数量public final int getAndAddInt(Object var1, long var2, int var4) &#123;    int var5;    // 进入自旋    do &#123;        // 使用 getIntVolatile 方法从指定对象的指定偏移量处获取整数值        var5 = this.getIntVolatile(var1, var2);        // 循环执行 CAS 操作，直到成功为止    &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));    return var5;&#125;\n\n因此AtomicInteger的实现原理就是：volatile + cas\nABA问题CAS过程中，有ABA问题\n\n\n如何解决ABA问题？\n\n加一个版本号即可，每次更改这个值就对齐加1，然后cas比较这个版本号就知道是否出现了ABA问题\n自旋锁\n自旋锁：CPU对线程进行轮询，反复询问是否释放锁，直到释放为止\n自旋周期：CPU轮询的时间\n\n优点：减少了线程阻塞；对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度上升\n缺点：如果锁竞争激烈或是占用锁时间长，那么会持续的占用CPU是极大的性能损耗\n在Java中，1.5时自旋周期时定死的，在1.6后加入了适应性自旋锁，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定\n// 自旋锁的开启JDK1.6 中-XX:+UseSpinning 开启-XX:PreBlockSpin=10 设置自旋次数JDK1.7 后，去掉此参数，由 jvm 控制\n\n使用CAS操作可以实现一个自旋锁。\n可重入锁（递归锁）与不可重入锁\n可重入锁（也叫递归锁）：\n理解方式一：当一个线程获取对象锁之后，这个线程可以再次获取本对象上的锁，而其他的线程是不可以的\n理解方式二：一个线程执行一个嵌套的方法时，当外部方法获取到锁，他内部调用的方法无需再去获取锁\n理解方式三：锁分配的单位是线程，而不是方法。一个方法无论嵌套自身的方法多少次，锁依然在这个线程内，因此无需再获取锁\n\n在JAVA环境下ReentrantLock和synchronized都是可重入锁\n可重入锁的目的是为了解决死锁的问题\n公平锁与非公平锁公平锁（Fair）：加锁前检查是否有排队等待的线程，优先排队等待的队列，先来先得\n非公平锁（Nonfair）：加锁不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待（可以插队）\n注意：\n\n非公平锁性能高于公平锁5-10倍，因为公平锁要维护等待队列\n在Java中，synchronized是非公平锁，ReentrantLock默认的lock()方法采用的是非公平锁\n非公平锁可能会导致“饥饿”的现象发生。\n\n共享锁和独占锁独占锁（也被称为写锁）：每次只有一个线程能持有锁；一种悲观策略，无论是读操作还是写操作，都会进行加锁。\n共享锁（也被称为读锁）：允许多个线程同时获取锁，并发访问，共享资源。一种乐观锁\n注意：\n\nJUC中的ReadWriteLock读写锁，允许一个资源可以被多个读操作访问，或者被一个写操作访问，但两者不能同时进行\n在共享锁占有期间，不允许写操作，如果有写操作，需要释放共享锁，转为独占锁（这种转变也称为锁升级）\n\nAQS同步抽象队列\nAQS (AbstractQueuedSynchronizer)：抽象的队列式同步器，定义了一套多线程访问共享资源的同步器框架，很多锁都是通过AQS来实现的，例如ReentrantLock、Semaphore、CountDownLatch\n\n这个抽象类主要维护了一个状态state还有一个FIFO的线程等待队列：\n\nstate状态：\nprivate volatile int state;// state 代表共享资源；可以看到其使用volatile修饰\n\n有三个方法可以操作这个状态的值：\nprotected final int getState() &#123;    return state;&#125;protected final void setState(int newState) &#123;    state = newState;&#125;protected final boolean compareAndSetState(int expect, int update) &#123;    // See below for intrinsics setup to support this    return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;\n\n这里贴一个使用AQS实现的独占锁demo：一般AQS都会使用静态内部类来实现\npublic class AqsLock &#123;    // 建议使用内部类来实现    static class Sync extends AbstractQueuedSynchronizer&#123;        private static final int UNLOCK = 0;        private static final int LOCK = 1;        @Override        protected boolean tryAcquire(int acquires) &#123;            if (compareAndSetState(UNLOCK, LOCK)) &#123;                // 设置当前线程为独占线程                setExclusiveOwnerThread(Thread.currentThread());                return true;            &#125;            return false;        &#125;        @Override        protected boolean tryRelease(int releases) &#123;            if (getState() == UNLOCK) &#123;                throw new IllegalMonitorStateException(&quot;Lock is not held by the current thread.&quot;);            &#125;            // 清除当前独占线程            setExclusiveOwnerThread(null);            setState(UNLOCK);            return true;        &#125;        @Override        protected boolean isHeldExclusively() &#123;            return getState() == LOCK &amp;&amp; getExclusiveOwnerThread() == Thread.currentThread();        &#125;        public void lock() &#123;            acquire(1);        &#125;        public void unlock() &#123;            release(1);        &#125;    &#125;        public static void main(String[] args) &#123;        ...    &#125;&#125;\n\npublic static void main(String[] args) &#123;    Sync sync = new Sync();    Runnable task = () -&gt; &#123;        System.out.println(Thread.currentThread().getName() + &quot; is trying to acquire the lock.&quot;);        sync.lock();        try &#123;            System.out.println(Thread.currentThread().getName() + &quot; has acquired the lock.&quot;);            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            System.out.println(Thread.currentThread().getName() + &quot; is releasing the lock.&quot;);            sync.unlock();        &#125;    &#125;;    Thread thread1 = new Thread(task);    Thread thread2 = new Thread(task);    thread1.start();    thread2.start();&#125;\n\n执行结果为：\nThread-0 is trying to acquire the lock.Thread-1 is trying to acquire the lock.Thread-0 has acquired the lock.Thread-0 is releasing the lock.Thread-1 has acquired the lock.Thread-1 is releasing the lock.\n\n锁升级总共有四种：无状态锁、偏向锁、轻量级锁、重量级锁\n在内存中，锁的信息存放在对象头中的markword中（markword包含的内容有三大部分：Hashcode、锁信息、GC信息）\n\n锁升级：\n​        随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级到重量级锁；\n​        但是锁的升级只能是单向的，不存在降级\n\n偏向锁大部分情况下锁并不存在多线程竞争，而总是由同一线程多次获得\n由此提出了偏向锁\n\n偏向锁：在某个线程获得锁后，消除这个线程重入（CAS）的开销，看起来非常偏向这个线程，所以叫偏向锁\n\n轻量级锁的获取及释放依赖多次CAS，但是偏向锁只需要在置换线程ID时依赖一次CAS指令\n特点：\n\n偏向锁主要用来优化同一线程多次申请同一个锁的竞争\n\n一次CAS，只比较Thread ID\n\n消除了重入开销\n\n\n轻量级锁\n“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的\n\n作用：\n\n多次CAS，自旋判断\n\n重量级锁synchronized是通过对象内部的一个叫做监视器锁来实现的，但是监视器锁本质又是依赖于操作系统底层的Mutex lock来实现的\n操作系统想要实现一个重量级锁，必须从用户态切换到核心态，所以这也是synchronized效率低的原因\n\n重量级锁：依赖于操作系统的Mutex Lock实现的锁\n\nJDK1.6 以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和 “偏向锁”\n锁升级过程\n当一个线程A要去获取一个锁的时候，简单过程如下：\n\n如果处于无锁状态，那么将锁设置为偏向锁，并设置A的线程号记录在对象头\n如果A重复进入此锁，只需要判断线程A线程ID与记录是否相同，就给锁（一次CAS即可）\n\n\n如果线程B想要获取锁，进行一次CAS判断\nCAS判断成功：线程B获取到锁\nCAS判断失败：升级为轻量级锁\n\n\n轻量级锁进行多次CAS判断，如果仍然不能满足当前的竞争状况，那么升级为重量级锁\n重量级锁是OS实现的排他锁，需要从用户态进入到核心态，十分浪费性能。\n\nSynchronized\nJava中使用专门的关键字Synchronized，是悲观锁、可重入锁、非公平锁\n\n直接修饰：\n\n修饰方法：锁住对象的实例(this)，即方法的调用者\n修饰静态方法：锁住Class实例（因为Class数据存放在永久代（元空间），此位置是全局共享的，所以相当于一个全局锁）\n\nsynchronized(obj)&#123;&#125;同步块中\n\nobj称为同步监视器；可以是任何对象，但是推荐使用共享资源作为同步监视器（修饰方法时，同步监视器就是this或是class）\n\n底层实现对象头的markword会关联到一个monitor对象（这个对象是用C++语言写的）\n\n当我们进入一个方法的时候，执行monitor enter，就会获取当前对象的一个所有权，这个时候monitor进入数为1，当前的这个线程就是这个monitor的owner。\n如果你已经是这个monitor的owner了，你再次进入，就会把进入数+1（每次重入加一）\n同理，当他执行完monitor exit，对应的进入数就-1，直到为0，才可以被其他线程持有。\n\n所有的互斥，其实在这里，就是看你能否获得monitor的所有权，一旦你成为owner就是获得者。\n\n\nSynchronized修饰的方法在抛出异常时,会释放锁吗?\n\n会\nLocksynchronized是悲观锁，无论线程是读还是写都会独占整个资源，因此出现了Lock接口\nJUC下有locks包，这个包内，最常见就有ReentrantLock与ReentrantReadWriteLock\n\nReentrantReadWriteLock虽然没有实现Lock接口，但是他的两个静态内部类ReadLock与WriteLock均实现了Lock接口\nLock接口部分方法如下：\nvoid lock(); //若锁处于空闲状态，当前线程将获取到锁boolean tryLock();//如果锁可用, 则获取锁, 并立即返回 true, 否则返回 false/* tryLock()和lock()的区别在于：\ttryLock()只是&quot;试图&quot;获取锁, 如果锁不可用, 不会导致当前线程等待, 当前线程仍然继续往下执行代码. \tlock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行.*/void unlock();//执行此方法时, 当前线程将释放持有的锁. 锁只能由持有者释放, 如果线程并不持有锁, 却执行该方法, 可能导致异常的发生Condition newCondition();//条件对象，获取等待通知组件。该组件和当前的锁绑定，当前线程只有获取了锁，才能调用该组件的 await()方法，而调用后，当前线程将缩放锁。void lockInterruptibly();//使用此方法获取锁时，如果线程正在等待获取锁，那么这个线程可以响应中断，即可以中断线程的等待状态/*也就是说，\t当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，\t假若此时线程A获取到了锁，而线程B只有在等待，\t那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。*/\n\n注意：\n\n当一个线程获取了锁之后（运行状态），是不会被interrupt()方法中断的；除非调用的是lockInterruptibly()方法获取锁\n\n中断只能作用于处于WAITING状态的线程\n\n\n因此使用锁的基本方式均为：\nLock lock = ...; // 声明一个锁lock.lock();//加锁try &#123;    // 同步操作&#125; catch (Exception e)&#123;    e.printStackTrace();&#125;finally &#123;    lock.unlock();     // 必须在finally中释放锁；因为lock即使发生异常也不会自动释放锁&#125;\n\nReentrantLockReentrantLock继承了Lock接口并实现了接口中定义的方法，是一种可重入锁\n\n方法介绍：\n![locks方法](http://img.yesmylord.cn//Package locks.png)\n首先是实现了Lock接口的方法（上面已经介绍），其他是ReentrantLock自己的方法：\ngetHoldCount(); //查询当前线程保持此锁的次数，也就是执行此线程执行 lock 方法的次数。getQueueLength(); //返回正等待获取此锁的线程估计数，比如启动 10 个线程，1 个线程获得锁，此时返回的是 9getWaitQueueLength(Condition condition); //返回等待与此锁相关的给定条件的线程估计数。/* 比如 10 个线程，用同一个 condition 对象，并且此时这 10 个线程都执行了condition 对象的 await() 方法，那么此时执行此方法返回 10 */hasWaiters(Condition condition);// 查询是否有线程等待与此锁有关的给定条件(condition)，对于指定 contidion 对象，有多少线程执行了 condition.await 方法hasQueuedThread(Thread thread); // 查询给定线程是否等待获取此锁hasQueuedThreads(); //是否有线程等待此锁isFair(); //该锁是否公平锁isHeldByCurrentThread();// 当前线程是否保持锁锁定，线程的执行 lock 方法的前后分别是 false 和 trueisLock();//此锁是否有任意线程占用\n\n这里可以对比一下synchronized与ReentrantLock：\n\n\n\n对比项\nsynchronized\nReentrantLock\n\n\n\n如何加锁解锁\nJVM自动控制\n程序员手动进行\n\n\n是否公平\n非公平锁\n默认为非公平锁\n\n\n是否可重入\n可重入\n可重入\n\n\n发生异常\nJVM自动释放锁\nfinally中手动释放锁\n\n\n可中断锁\n不可中断锁\n可中断锁\n\n\n总结：ReentrantLock对比synchronized主要增加了三项功能：\n\n等待可中断：当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情，它对处理执行时间非常长的同步块很有帮助（而在等待由synchronized产生的互斥锁时，会一直阻塞，是不能被中断的）\n可实现公平锁：可以使用new ReentrantLock(true)来使用公平锁\n锁可以绑定多个Condition：\nReentrantLock对象可以同时绑定多个Condition对象（条件变量或条件队列）；\n而在synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含条件，但如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁\nReentrantLock则无需这么做，只需要多次调用newCondition()方法即可。而且我们还可以通过绑定Condition对象来判断当前线程通知的是哪些线程（即与Condition对象绑定在一起的其它线程）\n\n\n\ndemo：\npublic class Test &#123;    private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();    private Lock lock = new ReentrantLock();    //注意这个地方，锁对象要放在成员变量这个地方    public static void main(String[] args)  &#123;        final Test test = new Test();                 new Thread()&#123;            public void run() &#123;                test.insert(Thread.currentThread());            &#125;;        &#125;.start();                 new Thread()&#123;            public void run() &#123;                test.insert(Thread.currentThread());            &#125;;        &#125;.start();    &#125;           public void insert(Thread thread) &#123;        // 锁的创建不能放在方法内，要不然每一个线程获得的都是不同的锁        lock.lock();        try &#123;            System.out.println(thread.getName()+&quot;得到了锁&quot;);            for(int i=0;i&lt;5;i++) &#123;                arrayList.add(i);            &#125;        &#125; catch (Exception e) &#123;            // TODO: handle exception        &#125;finally &#123;            System.out.println(thread.getName()+&quot;释放了锁&quot;);            lock.unlock();        &#125;    &#125;&#125;\n\nReentrantLock的源码实现ReentrantLock内部其实是用AQS来保证的同步：\n// ReentrantLock成员变量，Sync实现了AQSprivate final Sync sync;// ReentrantLock构造方法，默认使用非公平锁public ReentrantLock() &#123;    sync = new NonfairSync();&#125;\n\nabstract static class Sync extends AbstractQueuedSynchronizer &#123;    abstract void lock();    // 默认就是非公平锁，因此此方法就是tryLock方法    final boolean nonfairTryAcquire(int acquires) &#123;        // acquires代表资源数，这里可以看做是1        final Thread current = Thread.currentThread();        // 获取当前的state状态        int c = getState();        if (c == 0) &#123;            if (compareAndSetState(0, acquires)) &#123;                // 1、CAS判断如果没有被占用，那么我就占用                setExclusiveOwnerThread(current);                return true;            &#125;        &#125;        else if (current == getExclusiveOwnerThread()) &#123;            // 2、如果就是我占用了这个锁，就将重入次数+1            int nextc = c + acquires;            if (nextc &lt; 0) // overflow 重入次数太多，加到了int的最大值，再加就是负数了，SOF了                throw new Error(&quot;Maximum lock count exceeded&quot;);            setState(nextc);            return true;        &#125;        return false;    &#125;    ....// 还有其他方法，不过不太重要&#125;\n\n默认使用非公平锁：\nstatic final class NonfairSync extends Sync &#123;    final void lock() &#123;        if (compareAndSetState(0, 1))            // 没人获取锁，则设置自己占有            setExclusiveOwnerThread(Thread.currentThread());        else            // 如果已经被占用，那就去执行tryAcquire()            acquire(1);    &#125;    protected final boolean tryAcquire(int acquires) &#123;        // 在这里调用nonfairTryAcquire方法        return nonfairTryAcquire(acquires);    &#125;&#125;\n\n\n\n\n\n\n\n\n\nReadWriteLock读写锁将读操作与写操作进行分离：\npublic interface ReadWriteLock &#123;    Lock readLock();// 返回读锁    Lock writeLock();// 返回写锁&#125;\n\nReentrantReadWriteLock是ReadWriteLock的一个实现类，将读写操作分离：\n满足四个原则：\n\n允许多个线程一起读\n只允许一个线程写\n读时不能写（悲观读）\n写时不能读\n\n锁的降级与升级：支持锁降级（写锁变为读锁），但是不支持锁升级（读锁变为写锁）！\nReentrantReadWriteLock的Demo如下：\npublic class ReadWriteLockDemo &#123;    private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock();    public void readData() &#123;        readWriteLock.readLock().lock(); // 获取读锁        try &#123;            // 执行读操作        &#125; finally &#123;            readWriteLock.readLock().unlock(); // 释放读锁        &#125;    &#125;    public void writeData() &#123;        readWriteLock.writeLock().lock(); // 获取写锁        try &#123;            // 执行写操作        &#125; finally &#123;            readWriteLock.writeLock().unlock(); // 释放写锁        &#125;    &#125;&#125;\n\nSemaphore\nSemaphore：信号量，是对具体物理资源的抽象\n处理多个共享资源的问题\n关于信号量的详细解释，可以看我的另一篇blog\n\n注意：现有资源数目信号量S。P、V操作分别代表消费者（申请资源）、生产者（释放资源）\n\nS == 1：信号量就变为互斥信号量\nS &gt; 0：说明S资源还有S个\nS &lt; 0：说明等待队列还有-S个进程阻塞着\n\nJava中demo：\n// 信号量值为 3Semaphore s = new Semaphore(3);try &#123;    s.acquire();    // 省略业务逻辑&#125; catch (InterruptedException e) &#123;    e.printStackTrace();&#125; finally &#123;    s.release();&#125;\n\n可见信号量与ReentrantLock使用该方法基本一致\n锁优化有了锁虽然解决了线程安全问题，但是带来了性能的下降，此时就要进行锁优化了。\n一般我们会有如下的锁优化方法：\n\n减少锁持有时间：只在有线程安全问题的程序上加锁\n减小锁粒度：将大对象拆成小对象，降低锁竞争\n锁分离：根据功能分离锁，例如ReadWriteLock，将读与写进行分离\n锁粗化：通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短。但是，凡事都有一个度，如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 \n锁消除：编辑器级别的事情，可以对没有共享需求的代码进行优化，直接消除锁，这些多半是程序员编码不规范引起的。\n\nVolatile关键字\nvolatile本意是“易失的”，在计算机内代表，被这个关键字修饰的变量不会被缓存起来；\n对于非volatile变量来说，访问它的值会先从内存copy到CPU cache中，如果刚copy完，内存中的值就发生了改变，那么CPU读到的是cache中的值，而不是最新值\n对于volatile修饰的变量，每次都要去内存中读取\n\n被这个关键字修饰的变量代表着两种特性：可见性与有序性\n\n变量可见性：变量对所有线程可见（这里的可见性指：一个线程修改了变量的值，那么新的值对于其他线程是可以立即获取的）\n禁止重排序：多核CPU会对指令进行重排序，以加快指令的执行速度，使用此关键字可以不让CPU这么做\n\n优点：\n比synchronized更轻量级的一个同步锁，不会使线程阻塞\nvolatile 适合这种场景：一个变量被多个线程共享，线程直接给这个变量赋值\n注意：\n\n被volatile修饰的变量可以保证单次读/写操作的原子性\n不能保证i++这种操作的原子性，因为本质上其是两次操作 读+写\n必须同时满足两个条件，才能保证线程安全：\n对变量的写操作不依赖于当前值（i++），或者说是单纯的变量赋值（类似flag = true，不是这种a += 10）\n该变量没有包含在具有其他变量的不变式中（不同的 volatile 变量之间，不能互相依赖）只有在状态真正独立于程序内其他内容时才能使用 volatile\n\n\n\n可见性与有序性实现的底层原理\n底层是如何确保volatile的可见性的？\n\n通过缓存一致性协议：不同厂商有不同协议，这里以牙膏厂的MESI为例：\n​        当CPU写数据时，如果发现操作的变量是共享变量，会发出信号通知其他CPU将该变量的缓存行置为无效状态\n\n底层是如何确保volatile的有序性的？\n\n通过内存屏障，这是一个CPU指令，不能对其进行重排序，volatile就是基于内存屏障实现的\nJUC通信工具类\n\n\n类\n作用\n\n\n\nSemaphore\n限制线程的数量\n\n\nExchanger\n两个线程交换数据\n\n\nCountDownLatch\n线程等待直到计数器减为0时开始工作\n\n\nCyclicBarrier\n作用跟CountDownLatch类似，但是可以重复使用\n\n\nPhaser\n增强的CyclicBarrier\n\n\nSemaphore用于资源有限的场景中，可以限制线程的数量\n比如我想限制只有3个线程在工作：\npublic class SemaphoreDemo &#123;    static class MyThread implements Runnable &#123;        private int value;        private Semaphore semaphore;        public MyThread(int value, Semaphore semaphore) &#123;            this.value = value;            this.semaphore = semaphore;        &#125;        @Override        public void run() &#123;            try &#123;                semaphore.acquire(); // 获取permit                System.out.println(                        String.format(                                &quot;当前线程是%d, 还剩%d个资源，还有%d个线程在等待&quot;,                                value,                                semaphore.availablePermits(), semaphore.getQueueLength()                        )                );                // 睡眠随机时间，打乱释放顺序                Random random = new Random();                Thread.sleep(random.nextInt(1000));                System.out.println(String.format(&quot;线程%d释放了资源&quot;, value));            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; finally &#123;                semaphore.release(); // 释放permit            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        Semaphore semaphore = new Semaphore(3);        // 最多只可以有三个线程在工作        for (int i = 0; i &lt; 10; i++) &#123;            new Thread(new MyThread(i, semaphore)).start();        &#125;    &#125;&#125;\n\nExchanger用于两个线程交换数据，数据支持泛型（所以我们可以传IO流之类的）\n调用到exchange()方法，线程会进入阻塞状态，只有另一个exchange()\n方法被调用，才会继续执行\n核心方法：\n\nexchange(E e)：将数据交给另一个线程（会进入阻塞）\n\nfinal static Exchanger&lt;String&gt; ex1 = new Exchanger&lt;&gt;();public static void main(String[] args) &#123;    for (int i = 0; i &lt; 4; i++) &#123;        new Thread(() -&gt; &#123;            try &#123;                String msg1 = ex1.exchange(Thread.currentThread().getName() + &quot;向你问好&quot;);                System.out.println(Thread.currentThread().getName()+&quot;收到信息：&quot; + msg1);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;).start();    &#125;&#125;\n\nCountDownLatch\n闭锁、或者叫门闩：在闭锁到达结束状态之前，这扇门一直是关闭的。可以用来等其他线程执行。\n\n假设某个任务执行之前，需要等待其他线程完成一些任务，那么就可以用CountDownLatch类\n主要的方法有：\n\nnew CountDownLatch(int count)：构造方法，参数是一个int值，代表需要等待几个任务\nawait()：进入等待状态\nawait(long time, TimeUnit unit)：进入等待状态，如果count为0或者时间到也会释放\ngetCount()：获取当前count值\ncountDown()：让count值减1，如果count为0，就会自动解锁await\n\npublic class CountDownLatchDemo &#123;    // 定义前置任务线程    static class PreTaskThread implements Runnable &#123;        private String task;        private CountDownLatch countDownLatch;        public PreTaskThread(String task, CountDownLatch countDownLatch) &#123;            this.task = task;            this.countDownLatch = countDownLatch;        &#125;        @Override        public void run() &#123;            try &#123;                Random random = new Random();                Thread.sleep(random.nextInt(1000));                System.out.println(task + &quot; - 任务完成&quot;);                countDownLatch.countDown();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        // 假设有三个模块需要加载        CountDownLatch countDownLatch = new CountDownLatch(3);        // 主任务        new Thread(() -&gt; &#123;            try &#123;                System.out.println(&quot;等待数据加载...&quot;);                System.out.println(String.format(&quot;还有%d个前置任务&quot;, countDownLatch.getCount()));                countDownLatch.await();                System.out.println(&quot;数据加载完成，正式开始游戏！&quot;);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;).start();        // 前置任务        new Thread(new PreTaskThread(&quot;加载地图数据&quot;, countDownLatch)).start();        new Thread(new PreTaskThread(&quot;加载人物模型&quot;, countDownLatch)).start();        new Thread(new PreTaskThread(&quot;加载背景音乐&quot;, countDownLatch)).start();    &#125;&#125;\n\nCyclicBarrier\n栅栏，\n\nCyclicBarrirer从名字上来理解是“循环的屏障”的意思。\n前面提到了CountDownLatch一旦计数值count被降为0后，就不能再重新设置了，它只能起一次“屏障”的作用。\n而CyclicBarrier拥有CountDownLatch的所有功能，还可以使用reset()方法重置屏障\npublic class CyclicBarrierDemo &#123;    static class PreTaskThread implements Runnable &#123;        private String task;        private CyclicBarrier cyclicBarrier;        public PreTaskThread(String task, CyclicBarrier cyclicBarrier) &#123;            this.task = task;            this.cyclicBarrier = cyclicBarrier;        &#125;        @Override        public void run() &#123;            // 假设总共三个关卡            for (int i = 1; i &lt; 4; i++) &#123;                try &#123;                    Random random = new Random();                    Thread.sleep(random.nextInt(1000));                    System.out.println(String.format(&quot;关卡%d的任务%s完成&quot;, i, task));                    cyclicBarrier.await();                &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                    e.printStackTrace();                &#125;                cyclicBarrier.reset();                 // 重置屏障            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        CyclicBarrier cyclicBarrier = new CyclicBarrier(3, () -&gt; &#123;            System.out.println(&quot;本关卡所有前置任务完成，开始游戏...&quot;);        &#125;);        new Thread(new PreTaskThread(&quot;加载地图数据&quot;, cyclicBarrier)).start();        new Thread(new PreTaskThread(&quot;加载人物模型&quot;, cyclicBarrier)).start();        new Thread(new PreTaskThread(&quot;加载背景音乐&quot;, cyclicBarrier)).start();    &#125;&#125;\n\nCopyOnWriteArrayList并发编程时，使用ArrayList会遇到Concurrent Modification Exception并发修改异常，表明ArrayList不能在并发开发中使用\npublic static void main(String[] args) &#123;    final List&lt;Integer&gt; list = new ArrayList&lt;&gt;();    //      1. 使用vector List&lt;Integer&gt; list = new Vector&lt;&gt;();    //      2. 使用 List&lt;Integer&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;());    //      3. CopyOnWriteArrayList&lt;Integer&gt; list = new CopyOnWriteArrayList&lt;&gt;();    Runnable runnable = new Runnable() &#123;        @Override        public void run() &#123;            for (int i = 0; i &lt; 10; i++) &#123;                list.add(i);                System.out.println(list);            &#125;        &#125;    &#125;;    new Thread(runnable).start();    new Thread(runnable).start();    // ConcurrentModificationException 抛出&#125;\n\n为了避免这个异常，我们有三种解决办法：\n\n使用Vector，这个类是线程安全的，但是效率极低\n使用集合类的synchronizedList方法\n使用CopyOnWriteArrayList，这是最佳的方法\n\nCopyOnWrite：写入时复制（COW 计算机程序设计领域的一种优化策略）\nThreadLocal\nThreadLocal 线程本地变量：在同一线程，不同组件之间传递数据\n\n当我们遇到这种情况：线程设置的变量只有自己读取（即保证线程隔离）\n我们可以使用ThreadLocal也可以使用Synchronized，区别在于ThreadLocal并没有加锁，它的执行速度与效率会远远高于Synchronized。\nSynchronized与ThreadLocal的区别：\n\nSynchronized\n使用时间换空间\n目的在于保证多个线程在操作共享资源时的顺序。\n\n\nThreadLocal\n使用空间换时间\n目的在于保证多线程中数据隔离\n\n\n\n作用：主要是实现了数据隔离，不同线程之间不会互相干扰\nThreadLocal的使用ThreadLocal的使用非常简单，例如这个demo\nThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();threadLocal.set(&quot;存值&quot;);String s = threadLocal.get();threadLocal.remove();\n\n主要使用的方法就四个：构造方法、set、get、remove\nThreadLocal本身并不存储值，而是将值存储在Thread类的ThreadLocalMap中，ThreadLocalMap的key是ThreadLocal对象本身（注意：并不是Thread对象，而是ThreadLocal对象！！），value就是我们设置的值。\n在看下面的例子：下面这个例子使用同一个ThreadLocal，互相之间不干扰不能获取到别人的值。\nThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;&gt;();threadLocal.set(15);System.out.println(threadLocal); // java.lang.ThreadLocal@14ae5a5Thread t1 = new Thread(() -&gt; &#123;    System.out.println(threadLocal); // java.lang.ThreadLocal@14ae5a5 确实是同一个对象    System.out.println(threadLocal.get()); // null 但是获取不到值    threadLocal.set(20);    System.out.println(threadLocal.get()); // 20&#125;);t1.start();t1.join(); // main线程等待t1线程执行完成后执行System.out.println(threadLocal.get()); // 15\n\nThreadLocal的定义\nThreadLocal与Thread的关系\n\n\nThread类内部定义了两个ThreadLocalMap的引用\n\n// Thread类ThreadLocal.ThreadLocalMap threadLocals;ThreadLocal.ThreadLocalMap inheritableThreadLocals;\n\n\nThreadLocalMap的定义是在ThreadLocal类内部定义的\n\n// ThreadLocal类内部定义了静态内部类ThreadLocalMapstatic class ThreadLocalMap &#123;    static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123;        // Entry是弱引用的，且key就是ThreadLocal本身        Object value;        Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;            super(k);            value = v;        &#125;    &#125;    ...&#125;\n\n\n使用ThreadLocal的set方法，实际上是使用了对应线程的ThreadLocalMap的set方法\n\nprivate void set(Thread t, T value) &#123;    ThreadLocalMap map = getMap(t);    if (map != null) &#123;        map.set(this, value);    &#125; else &#123;        createMap(t, value);    &#125;&#125;\n\n\nThreadLocal会在第一次被使用时（get、set）去创建对应线程的ThreadLocalMap\n\nThreadLocal的原理每一个Thread维护一个ThreadLocal，每一个Thread含有一个ThreadLocalMap\n这个Map的key是ThreadLocal实例本身，value是我们想要设置的值\n\n要想搞清楚ThreadLocal，首先看Thread类中含有两个属性均为ThreadLocalMap类型（这里先知道Thread类有这个属性即可）\nThreadLocal.ThreadLocalMap threadLocals = null;// 初始值均为NullThreadLocal.ThreadLocalMap inheritableThreadLocals = null;// inheritableThreadLocals是为了实现父子线程间共享threadLocal数据而提供的\n\n再来看ThreadLocal的构造方法，很简单，与默认构造一样：\npublic ThreadLocal() &#123;&#125;\n\n在看get()方法：（下面的方法在ThreadLocal类中）\npublic T get() &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);     // 此处getMap返回了当前线程的ThreadLocal的值，如果为null，说明没有初始化，那么就初始化一下    if (map != null) &#123;        // 如果不为null，说明有ThreadLocalMap，就去取值，由getEntry实现了真正的取值        ThreadLocalMap.Entry e = map.getEntry(this);        if (e != null) &#123;            @SuppressWarnings(&quot;unchecked&quot;)            T result = (T)e.value;            return result;        &#125;    &#125;    // 如果这个值为null，说明还没初始化，就初始化一下    return setInitialValue();    // 这个方法点到最后，就是通过 new 创建了 LocalThreadMap&#125;// get 方法中初始化 ThreadLocal 对象源码如下：private T setInitialValue() &#123;    T value = initialValue();    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null)        map.set(this, value);    else        // 创建LocalThreadMap        createMap(t, value);    return value;&#125;//最终创建ThreadLocal对象的代码如下：void createMap(Thread t, T firstValue) &#123;    // 这里new了一个ThreadLocal，这里证明了ThreadLocalMap的key是ThreadLocal对象本身this    t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;\n\n真正的get其实是由这里的getEntry()方法完成的：值得一提的是在ThreadLocalMap中是使用开放地址法处理哈希碰撞的\n\n处理哈希碰撞的方法：\n\n开放地址法：如果遇到哈希冲突，就重新寻找真正的存放数据的下标位置（重新计算哈希也有不同的方法）\n线性探测（ThreadLocalMap就是这种方式）：从此下标开始，挨个往下找\n二次探测：探测步数是原始相隔位置的平方\n再哈希法：用不同哈希函数再求一遍哈希值\n\n\n链地址法：如果遇到哈希冲突，就拉一条链表出来。HashMap中就是使用这种方法进行处理的\n建立公共溢出区：专门存放所有哈希碰撞后的数据\n\n\nprivate Entry getEntry(ThreadLocal&lt;?&gt; key) &#123;    // Entry对象 是ThreadLocalMap的一个对象，他类似于HashMap中的Entry，都是实际存储数据的位置    int i = key.threadLocalHashCode &amp; (table.length - 1);   \t// 获取哈希表中该值的下标    Entry e = table[i];    if (e != null &amp;&amp; e.get() == key)        return e;    else        // 因为使用开放地址法，所以这里需要重新找下标        return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123;    Entry[] tab = table;// table是一个Entry数组    int len = tab.length;    while (e != null) &#123;        ThreadLocal&lt;?&gt; k = e.get();        if (k == key)            return e;        if (k == null)            expungeStaleEntry(i);        else            i = nextIndex(i, len);        e = tab[i];    &#125;    return null;&#125;// 可以看到，寻找的方式是线性探索private static int nextIndex(int i, int len) &#123;    return ((i + 1 &lt; len) ? i + 1 : 0);&#125;\n\n（set()方法实现的原理与get()方法差不多，就不再赘述；）\nEntry代码如下，注意继承了弱引用类：\n\n弱引用 —— 发现即回收\n特点：\n\n只被弱引用关联的对象只能生存到下一次 GC 发生为止（无论内存是否足够）\n由于垃圾回收线程的优先级很低，所以不一定很快被回收掉；这种情况可以存活较长时间\n\n\nstatic class ThreadLocalMap &#123;    static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123;        /** 注意这里Entry继承了弱引用类*/        Object value;        Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;            // 注意key是ThreadLocal本身！！            super(k);            value = v;        &#125;    &#125;    ...省略代码...&#125;\n\nThreadLocal的内存泄漏问题ThreadLocalMap定义在ThreadLocal内，但是实际上是Thread的成员。\nThread内含有ThreadLocalMap的强引用，一般来说ThreadLocalMap的生命周期是与Thread一致的。\n但由于thread一般是复用的，因此Thread一般不会消亡，也就导致ThreadLocalMap不会消亡，即使对应Entry的key，也就是ThreadLocal被GC回收掉，其value也会存在，也就导致了内存泄漏。\nThreadLocal被设计为弱引用，是为了减少内存泄漏带来的影响，但是不能消除内存泄漏。\n避免内存泄漏的方式：\n\n底层设计有优化，在每次get、set操作时，会自动清除key（也就是ThreadLocal）为null的Entry。但如果一直没有调用get、set方法，那么还是会有内存泄漏的问题。\n养成良好习惯，每次使用完后手动调用remove方法\n\nInheritableThreadLocal为了使得父子线程之间可以传递数据，引入了InheritableThreadLocal\nThreadLocal&lt;String&gt; tl1 = new InheritableThreadLocal&lt;&gt;();tl1.set(&quot;main&quot;);new Thread(()-&gt;&#123;    System.out.println(&quot;thread:&quot; + tl1.get());&#125;).start();System.out.println(&quot;main:&quot; + tl1.get());\n\n输出结果：\nmain:mainthread:main\n\n但注意，InheritableThreadLocal和线程池共同使用的时候，会出现问题，比如：\nInheritableThreadLocal&lt;String&gt; tl = new InheritableThreadLocal&lt;&gt;();tl.set(&quot;main1&quot;);ExecutorService es = Executors.newFixedThreadPool(1);System.out.println(&quot;main:&quot;+tl.get()); // main:main1es.execute(()-&gt;&#123;    System.out.println(&quot;thread:&quot;+tl.get());    // thread:main1&#125;);Thread.sleep(1000);tl.set(&quot;main2&quot;);es.execute(()-&gt;&#123;    System.out.println(&quot;thread:&quot;+tl.get());    // thread:main1&#125;);\n\n输出结果为：\nmain:main1thread:main1thread:main1 // 看这里main:main2\n\n注意到tl.set(&quot;main2&quot;);值没有发生作用，这是为什么呢？\n\nmain线程设置为main1\n\n一开始线程池之中没有线程，在第一次使用线程池执行任务时，会创建线程\n\n子线程会将父线程的InheritableThreadLocalcopy到子线程的InheritableThreadLocal\n此后，子线程的InheritableThreadLocal与父线程其实就没有关系了\n\n\nmain线程更改值为main2\n\n在下一次执行任务时，线程池的线程还是之前的线程（线程复用），由于其copy的map没有发生变化，因此其存的值还是main1\n\n\n因此，InheritableThreadLocal不能再线程池场景下使用\nTransmittableThreadLocal如果我们现在有一个场景，需要在多个线程之间（线程池）进行通信，可以使用TTL\n注意：线程池需要使用TtlExecutors.getTtlExecutorService包裹：\nExecutorService es = TtlExecutors.getTtlExecutorService(Executors.newFixedThreadPool(1));\n\n此时再去运行，即正常：\nTransmittableThreadLocal ttl = new TransmittableThreadLocal();ttl.set(&quot;main1&quot;);ExecutorService es = TtlExecutors.getTtlExecutorService(Executors.newFixedThreadPool(1));System.out.println(&quot;main:&quot;+ttl.get());es.execute(()-&gt;&#123;    System.out.println(&quot;thread:&quot;+ttl.get());&#125;);Thread.sleep(1000);ttl.set(&quot;main2&quot;);es.execute(()-&gt;&#123;    System.out.println(&quot;thread:&quot;+ttl.get());&#125;);Thread.sleep(1000);System.out.println(&quot;main:&quot;+ttl.get());\n\n输出结果为：\nmain:main1thread:main1thread:main2 // 看这里main:main2\n\n原理：TTL如何做到的？\n核心有两点：\n\n如何实现线程之间共享数据？\n使用一个静态的static ThreadLocal&lt;Map&gt;，静态成员属于类，以实现线程池之间共享\n\n\n有线程更改数据，那么在什么时候进行数据传递？\n任务的执行都是一个Runnable接口实现的方法，TTL额外实现了一个集成Runnable接口的类，在线程池调用run方法之前进行ThreadLocal的copy，在执行完成后进行复原\n这也是为什么要使用TtlExecutors.getTtlExecutorService包裹一下线程池的原因\n\n\n\n对应源码：TtlRunnable源码\npublic void run() &#123;    Object captured = this.capturedRef.get();    if (captured != null &amp;&amp; (!this.releaseTtlValueReferenceAfterRun || this.capturedRef.compareAndSet(captured, (Object)null))) &#123;        // 执行前对该线程原本的ThreadLocal进行备份        Object backup = Transmitter.replay(captured);        try &#123;            // 执行            this.runnable.run();        &#125; finally &#123;             // 执行后复原            Transmitter.restore(backup);        &#125;    &#125; else &#123;        throw new IllegalStateException(&quot;TTL value reference is released after run!&quot;);    &#125;&#125;\n\n\nTL、ITL、TTL之间的关系\n\n从左到右依次继承：InheritableThreadLocal继承了ThreadLocal，TransmittableThreadLocal继承了InheritableThreadLocal\n\n总结\nThread维护了一个MapThreadLocalMap，这个Map的key是ThreadLocal，value是我们想要设置的值\nThreadLocalMap是每个Thread都拥有的一个属性\nThreadLocalMap是ThreadLocal 线程的内部类\nThreadLocalMap中Entry的key是ThreadLocal类，而且是弱引用（有内存泄露的风险）\nThreadLocalMap中避免哈希碰撞的方法是开放地址法 + 线性探索\nThreadLocalMap与synchronized都可以进行数据隔离，区别是ThreadLocal使用空间换时间，synchronized则相反\n\n详解此部分关于AQS、CountDownLatch、ReentrantLock等的源码级理解\nAQSAQS抽象同步队列是一个抽象类，Java的ReentrantLock、CountDownLatch都是AQS实现的。\nAQS提出一个这样的模型：一个共享变量state，以及一个双向链表CLH队列，每一个请求资源的线程，都会被封装成一个CLH队列的结点\n关键实现state 状态：\nprivate volatile int state;// state 代表共享资源；可以看到其使用volatile修饰\n\n有三个方法可以操作这个状态的值：\nprotected final int getState() &#123;    return state;&#125;protected final void setState(int newState) &#123;    state = newState;&#125;protected final boolean compareAndSetState(int expect, int update) &#123;    // See below for intrinsics setup to support this    return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;\n\n数据结构AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。其中Sync queue，即同步队列，是双向链表，包括head结点和tail结点，head结点主要用作后续的调度。\n而Condition queue不是必须的，其是一个单向链表，只有当使用Condition时，才会存在此单向链表。并且可能会有多个Condition queue。\n\nAQS有两个内部类Node和ConditionObject\nfinal boolean transferForSignal(Node node) &#123;    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))        return false;    Node p = enq(node);// 将节点加入到同步队列    int ws = p.waitStatus;    if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))        LockSupport.unpark(node.thread);    return true;&#125;\n\n\n\n锁共享方式\n互斥锁：只有一个线程可以执行，比如ReentrantLock就是这样的实现\n共享锁：多个线程可以同时执行，比如CountDownLatch\n\n自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了（模版方法模式）\nisHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。    tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。\n\nNode的状态AQS的每一个Node，都是一个Thread的包装，AQS为什么是一个双向链表，是因为AQS需要通过前继节点来判断当前节点的行动：\nNode有这几种状态\nstatic final int CANCELLED =  1; // 指示当前线程被取消执行static final int SIGNAL    = -1; // 指示后续线程需要被唤醒static final int CONDITION = -2; // 指示当前线程需要等待条件static final int PROPAGATE = -3; // 指示当前线程需要传播（共享锁中）// 此外，还有 0 是初始化的状态\n\n如果Node是非负数表示均不需要被激活\n注意：特别注意\n\nSIGNAL：意思表示，后续节点被park了，在当前节点在释放或是取消时，一定要唤醒后续节点\nCANCEL：由于超时或是中断，此节点被取消执行了！\nCONDITION：表示处于条件队列中，在条件没有满足的时候，不会进入同步等待队列\nPROPAGATE：共享模式的特有状态，用于传播唤醒状态\n\nAQS为什么得用一个双向链表？为什么不用单向链表？因为AQS中多次使用到了前继节点：\n使用前继节点的状态，来判断当前节点的行为，比如前继节点为SIGNAL，就表示前继节点在释放或是取消的时候，千万要唤醒后继节点\nSIGNAL状态也就意味着，只有前继节点才能唤醒后继节点\ntryAcquire与acquire方法加锁实际是由底层的acquire方法实现的：\npublic final void acquire(int arg) &#123;    if (!tryAcquire(arg) &amp;&amp; // 调用一次我们的实现类        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))        selfInterrupt();&#125;\n\n\n\n首先调用tryAcquire获取，如果能获取成功，直接结束，如果没能获取成功就执行2\n执行addWaiter方法，将当前的Thread包装为一个Node节点，放在链表的尾部，执行3\n调用acquireQueued，下面列出代码：\n不断轮训\n首先：获取当前Node的前继节点，如果前继节点为head并且获取到了资源，那么表示自己可以执行了\n然后：判断前继节点的运行状态，根据不同状态执行不同操作shouldParkAfterFailedAcquire\n如果前继节点的状态为CANCELLED（说明线程取消执行），则进行下一次循环\n如果前继节点状态为SIGNAL，就表示当前节点需要park（也就是进入等待状态），返回True\n\n\n如果需要park线程，那么就调用parkAndCheckInterrupt，也就是LockSupport.park()\n\n\n\nfinal boolean acquireQueued(final Node node, int arg) &#123;    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor(); // 获取前继节点            if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 如果前继节点为head，并且再次tryAcquire成功，就可以执行了                setHead(node); // 执行当前的Thread                p.next = null; // help GC                failed = false;                return interrupted;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // // 在获取锁失败后，是否要被park呢？                parkAndCheckInterrupt()) // 把当前Node park掉，调用LockSupport.park(this);                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;\n\n// 在获取锁失败后，是否要被park呢？private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;    int ws = pred.waitStatus;    if (ws == Node.SIGNAL) // 如果前继节点还是等待被激活，那么就返回true        return true;    if (ws &gt; 0) &#123; // 非负数表示都不需要被激活，通常会是1，cancel状态        do &#123;            node.prev = pred = pred.prev;        &#125; while (pred.waitStatus &gt; 0); // 让node前进，找到一个有效的前驱节点        pred.next = node;    &#125; else &#123;        // 进入这里一定是PROPAGATE或是0，此时表示我们可以被激活，但是无需park        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);    &#125;    return false;&#125;\n\n\n返回 true 的情况：如果前驱节点的状态为 SIGNAL，则表明当前线程应该阻塞（park），等待前驱节点唤醒它。\n\n返回 false 的情况：如果前驱节点的状态不是 SIGNAL，则当前线程暂时不会阻塞，还需要进一步处理。可能是因为前驱节点被取消，需要跳过，或者前驱节点还没有设置为 SIGNAL 状态，需要进行状态更新。\n\n\ntryRelease与release方法释放锁也是调用tryRelease，如果释放成功就唤醒后继节点\npublic final boolean release(int arg) &#123;    if (tryRelease(arg)) &#123; // 释放成功        // 保存头节点        Node h = head;         if (h != null &amp;&amp; h.waitStatus != 0) // 头节点不为空并且头节点状态不为0            unparkSuccessor(h); //释放头节点的后继结点        return true;    &#125;    return false;&#125;\n\nAQS实现简单的独占锁AQS内部类部分：\n\ntryAcquire：用cas判断当前状态，如果获取到了就设为独占setExclusiveOwnerThread\ntryRelease：首先判断状态是不是unlock，清除独占，设置state为unlock\n\nstatic class Sync extends AbstractQueuedSynchronizer &#123;    private  static final int UNLOCK = 0;    private static final int LOCK = 1;    @Override    protected boolean tryAcquire(int acquires) &#123;        if (compareAndSetState(UNLOCK, LOCK)) &#123;            setExclusiveOwnerThread(Thread.currentThread());            return true;        &#125;        return false;    &#125;    @Override    protected boolean tryRelease(int releases) &#123;        if (getState() == UNLOCK) &#123;            throw new IllegalMonitorStateException(&quot;Lock is not held by the current thread.&quot;);        &#125;        // 清除当前独占线程        setExclusiveOwnerThread(null);        setState(UNLOCK);        return true;    &#125;    public Condition newCondition() &#123;        return new ConditionObject();// ConditionObject与Node一样，都是AQS内部类，负责条件判断    &#125;&#125;\n\n外部实现Lock：\npublic class AqsLock implements Lock &#123;    private Sync sync;    public AqsLock() &#123;sync = new Sync();&#125;    @Override    public void lock() &#123;sync.acquire(1);&#125;    @Override    public void unlock() &#123;sync.release(1);&#125;    @Override    public void lockInterruptibly() throws InterruptedException &#123;        sync.acquireInterruptibly(1);    &#125;    @Override    public boolean tryLock() &#123;        return sync.tryAcquire(1);    &#125;    @Override    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123;        return sync.tryAcquireNanos(1, unit.toNanos(time));    &#125;    @Override    public Condition newCondition() &#123;        return sync.newCondition();    &#125;    static class Sync extends AbstractQueuedSynchronizer &#123;        // 省略    &#125;&#125;\n\ntryAcquireShared与acquireShared方法在共享锁中，state的数字就有了意义，他表示资源的个数：\ntryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。\n\n同独占锁的实现，共享锁也是这样：\npublic final void acquireShared(int arg) &#123;    if (tryAcquireShared(arg) &lt; 0) // 调用一次tryAcquireShared，如果失败        doAcquireShared(arg);&#125;\n\n如果获取失败，调用下面的方法，与独占锁的acquireQueued方法很像，他们的主要区别在于setHeadAndPropagate()方法\nprivate void doAcquireShared(int arg) &#123;    final Node node = addWaiter(Node.SHARED);     // 以共享的方式包装一个Node，在独占锁中，Node是在外部构造的    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();// 获取前继节点，判断是否为head            if (p == head) &#123;                int r = tryAcquireShared(arg);                if (r &gt;= 0) &#123; // 如果当前有剩余资源，那么就可以执行                    setHeadAndPropagate(node, r); // 与独占锁的区别，还会传播唤醒下一个节点                    p.next = null; // help GC                    if (interrupted)                        selfInterrupt();                    failed = false;                    return;                &#125;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;\n\n与独占锁的区别就在于下面这个方法，独占锁直接setHead(node)，而共享锁还会尝试唤醒后继节点\nprivate void setHeadAndPropagate(Node node, int propagate) &#123;    Node h = head; // Record old head for check below    setHead(node);\t    // 判断后继是否需要传播唤醒    if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 ||        (h = head) == null || h.waitStatus &lt; 0) &#123;        Node s = node.next; // s指向后继节点        if (s == null || s.isShared()) // 如果后继节点为空，或者后继节点是共享模式，就进行释放操作            doReleaseShared();    &#125;&#125;\n\n需要唤醒后面节点的条件有：\n\npropagate &gt; 0：如果 propagate 大于 0，表示需要继续传播唤醒后续线程。\nh == null：如果旧的头节点 h 为空，说明队列之前为空，需要唤醒新的节点。\nh.waitStatus &lt; 0：如果旧的头节点的状态是负数，表示头节点处于等待状态（通常为 SIGNAL），表明可能有后续节点需要被唤醒\nh = head：再次检查当前的头节点是否已经发生变化。\nh.waitStatus &lt; 0：再次检查新的头节点状态。\n\ntryReleaseShared与releaseShared方法public final boolean releaseShared(int arg) &#123;    if (tryReleaseShared(arg)) &#123;        doReleaseShared();        return true;    &#125;    return false;&#125;\n\nprivate void doReleaseShared() &#123;    for (;;) &#123;        Node h = head;        if (h != null &amp;&amp; h != tail) &#123;            int ws = h.waitStatus;            if (ws == Node.SIGNAL) &#123;                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))                    continue;                unparkSuccessor(h); // 在这里释放了wait的Node            &#125;            else if (ws == 0 &amp;&amp;                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))                continue;        &#125;        if (h == head)            break;    &#125;&#125;\n\nAQS要点总结1、AQS有两个内部类Node和ConditionObject2、AQS同步队列是一个双向链表，条件队列是一个单向链表3、AQS的Node包裹了一个Thread，只有head才有执行的权利，而且只有head才能唤醒后继节点4、Node的SIGNAL状态表示，后继节点处于park，当前节点释放时，一定要激活后继节点（unpark后继节点）5、Condition满足后，会调用transferForSignal从条件队列转移到同步队列6、acquire的流程为：tryAcquire（尝试获取一次）-&gt;addWaiter（包装为Node添加到队列）-&gt;acquireQueued（判断前继节点状态，决定当前节点行为）7、当前继节点为SIGNAL，表示当前节点会在前继节点释放时被唤醒；前继节点为CANCEL，表示会直接跳过前继节点；前继节点propagate，表示处于传播状态，可以无条件唤醒后继节点（用于共享模式）；8、AQS有两种同步方式：共享和独占。独占的实现类有ReentrantLock，共享的实现类有CountDownLatch。9、共享模式实现方式与独占差不多，区别在于是否可以传播唤醒后继节点\nCountDownLatch问题\n1、CountDownLatch适用于什么场景？\n\nCountDownLatch典型的用法是将一个程序分为n个互相独立的可解决任务，并创建值为n的CountDownLatch。\n\n2、CountDownLatch的实现原理是什么？\n\n当每一个任务完成时，都会在这个锁存器上调用countDown，等待问题被解决的任务调用这个锁存器的await，将他们自己拦住，直至锁存器计数结束\n这个计数器是用AQS的state实现的，使用了AQS的共享模式，每次获取资源都调用tryAquireShared模式，每次释放资源都调用tryReleaseShared。\nDemo：七颗龙珠召唤神龙当某一个线程需要等待N个线程执行完成时，就使用\npublic class DragenBall implements Runnable&#123;    CountDownLatch cdl;    @Override    public void run() &#123;        System.out.println(&quot;已收集第&quot;+no+&quot;颗龙珠&quot;);        cdl.countDown();    &#125;    int no;    public DragenBall(int no, CountDownLatch cdl) &#123;        this.no = no;        this.cdl = cdl;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        CountDownLatch cdl = new CountDownLatch(7);        for (int i = 0; i &lt; 7; i++) &#123;            DragenBall dragenBall = new DragenBall(i, cdl);            new Thread(dragenBall).start();        &#125;        cdl.await();        System.out.println(&quot;召唤神龙&quot;);    &#125;&#125;\n\n实现原理利用了AQS的共享模式，内部使用state作为count的数量，每次CountDown就释放一个资源\ntryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。\n\nCountDownLatch有一个内部类继承了AQS：\nprivate static final class Sync extends AbstractQueuedSynchronizer &#123;    Sync(int count) &#123;        setState(count);    &#125;    int getCount() &#123;        return getState();    &#125;    protected int tryAcquireShared(int acquires) &#123;        return (getState() == 0) ? 1 : -1;    &#125;    protected boolean tryReleaseShared(int releases) &#123;        // Decrement count; signal when transition to zero        for (;;) &#123;            int c = getState();            if (c == 0)                return false;            int nextc = c-1;            if (compareAndSetState(c, nextc))                return nextc == 0;        &#125;    &#125;&#125;\n\nCountDownLatch的其他部分很简单：关键看await()与countDown实现\npublic class CountDownLatch &#123;    private static final class Sync extends AbstractQueuedSynchronizer &#123;        // 省略    &#125;    private final Sync sync;        public CountDownLatch(int count) &#123;        if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;);        this.sync = new Sync(count);    &#125;    public void await() throws InterruptedException &#123;        sync.acquireSharedInterruptibly(1);    &#125;    public boolean await(long timeout, TimeUnit unit)        throws InterruptedException &#123;        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));    &#125;    public void countDown() &#123;        sync.releaseShared(1);    &#125;    public long getCount() &#123;        return sync.getCount();    &#125;    public String toString() &#123;        return super.toString() + &quot;[Count = &quot; + sync.getCount() + &quot;]&quot;;    &#125;&#125;\n\nReentrantLock问题\n1、ReentrantLock是什么锁？\n\n可重入的、可公平可不公平、悲观锁\n\n2、ReentrantLock是如何实现可重入的？\n\n通过state状态维护可重入次数，每次tryAcquire时：\n\n如果没有被占据，就获得锁\n如果被占据，判断是不是当前线程占据，如果是的话，就将state+acquire次数，就实现了重入\n\n\n3、ReentrantLock是如何实现公平与非公平的？\n\n\n非公平锁：tryAcquire时，直接cas判断（直接抢占）\n公平锁：tryAcquire时，会先判断head后是否有线程，如果有，就说明存在比自己等待时间长的线程。\n\n\n4、对比Synchronized的有什么区别？\n\n\nSynchronized：加锁syn(obj)、进入等待obj.wait()、obj.notify()、obj.notifyAll()\n实现方式：加锁解锁JVM自动实现，通过JVM内部的monitor对象，\n可重入：调用字节码monitor_enter和monitor_exit实现可重入\n公平锁与非公平锁：只支持非公平锁\n条件：条件只能使用obj进行判断，不支持多个条件\n锁粒度：1.5之前直接为重量级锁，之后引入了锁升级过程，但还是独占锁，读写不分离\n\n\nReentrantLock：加锁lock()、解锁unlock()、进入等待condition.await()、唤醒condition.signal()\n实现方式：加锁解锁使用AQS，同步队列+条件队列\n可重入：state状态存储重入次数，tryAcquire时判断是否是当前线程重入\n公平锁与非公平锁：支持公平锁，默认非公平锁\n条件：通过ConditionObject对象及条件队列实现，满足条件后，调用signal()将Node传送给同步队列\n锁粒度：独占锁，读写不分离\n\n\n\n内部结构内部集成关系，由一个静态内部类继承AQS（大部分都是这么实现的），然后又有两个静态内部类分别集成Sync，实现公平锁与非公平锁。\n\nSync类Sync类实现了非公平的获取方式，tryAcquire在子类中实现。\n下面是源码，可以看到可重入的实现方式：\n\n如果没有线程占据锁，那么就获得\n如果当前线程就是获取了锁的线程current == getExclusiveOwnerThread()，可以再次获得，将state+acquires次数\n\nabstract static class Sync extends AbstractQueuedSynchronizer &#123;    abstract void lock();    // Sync类实现了非公平的获取方式，tryAcquire在子类中实现    final boolean nonfairTryAcquire(int acquires) &#123;        final Thread current = Thread.currentThread();        int c = getState();        if (c == 0) &#123; // 如果当前没有线程占据            if (compareAndSetState(0, acquires)) &#123;                setExclusiveOwnerThread(current);                return true;            &#125;        &#125;        else if (current == getExclusiveOwnerThread()) &#123;            // 如果占据的线程就是当前线程（实现了可重入）            int nextc = c + acquires;            if (nextc &lt; 0) // overflow，可重入大小不能超过Integer.MAX_VALUE                throw new Error(&quot;Maximum lock count exceeded&quot;);            setState(nextc);            return true;        &#125;        return false;    &#125;    protected final boolean tryRelease(int releases) &#123;        int c = getState() - releases;        if (Thread.currentThread() != getExclusiveOwnerThread())             // 如果当前占锁的线程不是调用release的线程，就报错了            throw new IllegalMonitorStateException();        boolean free = false;        if (c == 0) &#123; // 重入次数为0时，才可以释放锁            free = true;            setExclusiveOwnerThread(null);        &#125;        setState(c);        return free;    &#125;\t    protected final boolean isHeldExclusively() &#123;return getExclusiveOwnerThread() == Thread.currentThread();&#125;    final ConditionObject newCondition() &#123;return new ConditionObject();&#125;    final Thread getOwner() &#123;return getState() == 0 ? null : getExclusiveOwnerThread();&#125;    final int getHoldCount() &#123;return isHeldExclusively() ? getState() : 0;&#125;    final boolean isLocked() &#123;return getState() != 0;&#125;&#125;\n\nNonFairSyncNonfairSync直接调用Sync的获取方式即可\nstatic final class NonfairSync extends Sync &#123;    private static final long serialVersionUID = 7316153563782823691L;    final void lock() &#123;        if (compareAndSetState(0, 1))            setExclusiveOwnerThread(Thread.currentThread());        else            acquire(1);    &#125;    protected final boolean tryAcquire(int acquires) &#123;        return nonfairTryAcquire(acquires);// 调用父类方法    &#125;&#125;\n\nFairSync公平锁如何实现？\n在tryAcquire方法中，并不像非公平锁一样，直接调用cas，而是先判断当前同步队列是否有节点\n（如果有节点，就说明该线程等待的时间比当前线程时间要长）\nstatic final class FairSync extends Sync &#123;    final void lock() &#123;        acquire(1);    &#125;    protected final boolean tryAcquire(int acquires) &#123;        final Thread current = Thread.currentThread();        int c = getState();        if (c == 0) &#123;            if (!hasQueuedPredecessors() &amp;&amp; // 这里判断                compareAndSetState(0, acquires)) &#123;                setExclusiveOwnerThread(current);                return true;            &#125;        &#125;        else if (current == getExclusiveOwnerThread()) &#123;            int nextc = c + acquires;            if (nextc &lt; 0)                throw new Error(&quot;Maximum lock count exceeded&quot;);            setState(nextc);            return true;        &#125;        return false;    &#125;&#125;\n\n这里看下hasQueuedPredecessors方法：\n如果当前head后有节点（说明有线程在等待，且不是当前线程在等待），那么返回true\npublic final boolean hasQueuedPredecessors() &#123;    Node t = tail; // Read fields in reverse initialization order    Node h = head;    Node s;    return h != t &amp;&amp;        ((s = h.next) == null || s.thread != Thread.currentThread());&#125;\n\nReentrantReadWriteLock问题\n1、为什么有ReentrantLock还要引入ReentrantReadWriteLock\n\n对于大部分操作来说，读写的要求是不一致的，读锁可以一起读，写锁只能一个线程写，而ReentrantLock是悲观锁，不论读写都会锁住，不利于提高读操作的并发性。\n\n2、如何实现的读写分离？\n\nReentrantReadWriteLock在内部实现了读锁与写锁，读锁使用共享模式的AQS，写锁使用独占模式的AQS。\n\n写锁：状态存放在AQS的state的低16位，如果低16位不为0，表示写锁已被获取\n读锁：读锁状态存放的位置有state的高16位以及ThreadLocalHoldCounter的HoldCounter，他存放了所有线程的读锁数量。\n\n获取写锁时，是如何判断有没有读锁的？通过判断state和写锁（低16位），如果state==0但是写锁数不为0，那么就存在读锁。\n\n3、本地线程计数器ThreadLocalHoldCounter是做什么的？\n\n存放不同的线程的读锁的计数状态（没有存放写锁的状态）\n\n4、缓存计数器cachedHoldCounter是做什么的？\n\n避免每次都去读取ThreadLocal，存放当前线程的读锁计数，是一个优化机制\n\n6、支持锁升级吗？为什么？\n\n不支持，为了避免：\n\n防止死锁：如果有多个线程获取了读锁，然后想获取写锁，都会等待对方释放读锁，就会形成死锁问题\n为了避免数据不一致：多个线程获取了读锁，一个线程还获取了写锁，那么这个线程的写入操作对其他线程不可见\n\n\n7、支持锁降级吗？为什么？\n\n支持锁降级，可以保证数据一致性，获取写锁后获取读锁，再释放写锁，可以保证前后读取到的数据一致，不会有其他线程进行更改。\n内部结构\n内部有五个类：Sync、Fair、NonfairSync；Lock、ReadLock、WriteLock\nReadLock与WriteLock先从读写锁开始介绍，因为ReentrantReadWriteLock本质是一个锁\n\nReadLock：调用Sync的acquireShared与releaseShared\nWriteLock：调用Sync的acquire与release\n\n均调用了Sync，重点去看Sync的获取方法\npublic static class WriteLock implements Lock, java.io.Serializable &#123;    private final Sync sync;    public void lock() &#123;        sync.acquire(1);    &#125;    public boolean tryLock( ) &#123;        return sync.tryWriteLock();    &#125;    public void unlock() &#123;        sync.release(1);    &#125;    public void unlock() &#123;            sync.releaseShared(1);        &#125;&#125;\n\npublic static class ReadLock implements Lock, java.io.Serializable &#123;    private static final long serialVersionUID = -5992448646407690164L;    private final Sync sync;    public void lock() &#123;        sync.acquireShared(1);    &#125;    public boolean tryLock() &#123;        return sync.tryReadLock();    &#125;\n\nSyncSync同样是一个继承了AQS的静态内部类，其内部还有两个类：\n\nHoldCount：一个计数器，专门用于计算读锁的个数\nThreadLocalHoldCounter：继承了ThreadLocal，而且存储HoldCount\n\nabstract static class Sync extends AbstractQueuedSynchronizer &#123;    // 省略成员和方法    static final class HoldCounter &#123;        int count = 0;        // 存储线程id而不是引用，为了避免留下垃圾        final long tid = getThreadId(Thread.currentThread());    &#125;    static final class ThreadLocalHoldCounter        extends ThreadLocal&lt;HoldCounter&gt; &#123;        // 重写了initialValue，表示即使没有set，get时返回的也是HolderCount数量        public HoldCounter initialValue() &#123;            return new HoldCounter();        &#125;    &#125;&#125;\n\nSync如何进行计数？AQS的state中的高16读低16写\nstatic final int SHARED_SHIFT   = 16;static final int SHARED_UNIT    = (1 &lt;&lt; SHARED_SHIFT);static final int MAX_COUNT      = (1 &lt;&lt; SHARED_SHIFT) - 1; // 最大次数为2^16-1static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;// 高16位表示读锁计数static int sharedCount(int c)    &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;// 低16为表示写锁计数static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125;\n\nSync构造时，就会创建本地线程计数器ThreadLocalHoldCounter\nprivate transient ThreadLocalHoldCounter readHolds;private transient HoldCounter cachedHoldCounter;private transient Thread firstReader = null;private transient int firstReaderHoldCount;Sync() &#123;    readHolds = new ThreadLocalHoldCounter();    setState(getState()); // ensures visibility of readHolds&#125;\n\n这里中断介绍一下四个成员：\n\nreadHolds：ThreadLocal对象，保存了每一个线程的HoldCounter，也就是保存了每个线程的读锁的个数\ncachedHoldCounter：缓存当前线程的读锁个数（因为查找ThreadLocal会有开销）\nfirstReader：跟踪第一个获取读锁的线程，是一个优化手段\nfirstReaderHoldCount：第一个读取锁线程的读锁个数，配合firstReader使用\n\nSync的写实现写锁调用Sync的acquire与release：\n写锁的实现与普通的独占锁实现基本一致，有几个比较关键的点：\n\n如果当前state不为0，但是写锁为0，表示有读锁，那么直接返回false\n多了一个判断当前是否存在独占锁的逻辑，是否存在独占锁是通过判断state的低16位判断的。而且不允许数量超过2^16\n\nprotected final boolean tryAcquire(int acquires) &#123;    Thread current = Thread.currentThread();    int c = getState();    int w = exclusiveCount(c); // state低16表示写锁数量    if (c != 0) &#123; // 存在读锁或是写锁        // 写锁为0（写锁为0，c不为0，表示读锁不为0） 或 当前线程没有独占资源        if (w == 0 || current != getExclusiveOwnerThread())            return false;        // 写锁+要求的资源数&gt;2^16-1，报错        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)            throw new Error(&quot;Maximum lock count exceeded&quot;);        // 获取到写锁        setState(c + acquires);        return true;    &#125;    if (writerShouldBlock() ||  // writerShouldBlock对公平和非公平锁操作不同        !compareAndSetState(c, c + acquires))        return false;    setExclusiveOwnerThread(current);    return true;&#125;\n\n writerShouldBlock：\n\n对于公平锁操作，会判断同步队列头部是否有线程等待hasQueuedPredecessors\n对于非公平锁，直接返回false，写锁应该一直允许抢占\n\n写锁的释放\nprotected final boolean tryRelease(int releases) &#123;    if (!isHeldExclusively())        throw new IllegalMonitorStateException();    int nextc = getState() - releases;    boolean free = exclusiveCount(nextc) == 0;    // 如果释放完全，那么清空独占    if (free)        setExclusiveOwnerThread(null);    setState(nextc);    return free;&#125;\n\nSync的读实现读锁（共享锁）调用Sync的acquireShared与releaseShared：\nprotected final int tryAcquireShared(int unused) &#123;    Thread current = Thread.currentThread();    int c = getState();    if (exclusiveCount(c) != 0 &amp;&amp; // 如果存在写锁        getExclusiveOwnerThread() != current) // 并且不是自己的写锁        return -1; // 返回-1 表示失败    int r = sharedCount(c); // 获取高16位，当前读锁的个数    if (!readerShouldBlock() &amp;&amp;        r &lt; MAX_COUNT &amp;&amp; // 读锁也得小于MAX_COUNT        compareAndSetState(c, c + SHARED_UNIT)) &#123; // 加读锁        if (r == 0) &#123; // 如果当前没有读锁            firstReader = current; // firstReader指向第一个获取读锁的Thread            firstReaderHoldCount = 1; // 读锁计数        &#125; else if (firstReader == current) &#123; // 如果第一个获取锁的线程又来获取读锁            firstReaderHoldCount++;        &#125; else &#123;            HoldCounter rh = cachedHoldCounter; // 获取            if (rh == null || rh.tid != getThreadId(current))                // 如果缓存为空或是不匹配，就要去ThreadLocal里面找                cachedHoldCounter = rh = readHolds.get();            else if (rh.count == 0)                // 如果为0，说明当前线程之前没有获取过读锁。                // 此时，需要重新设置，确保ThreadLocal中保存的计数器是最新的                readHolds.set(rh);            rh.count++; // 成功获取到读锁        &#125;        return 1; // 获取成功    &#125;    // 执行下面代码的情况有：CAS失败或是当前head后有线程，会进行额外的逻辑进行CAS操作，不再赘述    return fullTryAcquireShared(current);&#125;\n\n readerShouldBlock：\n\n对于公平锁操作，会判断同步队列头部是否有线程等待hasQueuedPredecessors（与写锁一样）\n对于非公平锁，会判断同步队列第一个线程是否是独占锁，如果是返回true\n\nfirstReader：\n\nfirstReader是一个Thread的指针，指向第一个获取读锁的线程\n\nfirstReaderHoldCount是获取读锁的锁数量的计数\n\n\n使用firstReader与firstReaderHoldCount是为了在一般情况下，避免遍历ThreadLocal的开销\ncachedHoldCounter：\n\ncachedHoldCounter 保存当前线程的读锁个数\n\n值得注意的是，如果线程已经获取了写锁，那么依然可以获取读锁，这意味着ReentrantReadWriteLock支持锁降级\n锁升级与锁降级锁升级与锁降级指的是：\n\n锁升级：在已有读锁的情况下，获取写锁，然后释放读锁\n锁降级：在已有写锁的情况下，获取读锁，然后释放写锁\n\n\n锁降级的好处：\n\n对于锁降级来说，如果我们先释放写锁，在获取读锁，那么这个过程可能数据就会变动，造成前后数据读取不一致，因此锁降级可以支持前后数据读取一致性\nReentrantReadWriteLock支持锁降级，但不支持锁升级，原因是：如果当前有很多线程持有读锁，其中一个线程进行了锁升级，那么他的写入改动，对其他已经获取读锁的线程是不可见的。\nExcutor的四种线程池实现\nSingleThreadExecutor：1个核心线程和最大线程，阻塞队列无限\n\npublic static ExecutorService newSingleThreadExecutor() &#123;    return new FinalizableDelegatedExecutorService        (new ThreadPoolExecutor(1, 1,                                0L, TimeUnit.MILLISECONDS,                                new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;\n\n\nnewFixedThreadPool：固定大小，核心与最大线程相同，阻塞队列也是无限\n\npublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123;    return new ThreadPoolExecutor(nThreads, nThreads,                                  0L, TimeUnit.MILLISECONDS,                                  new LinkedBlockingQueue&lt;Runnable&gt;(),                                  threadFactory);&#125;\n\n\nCachedThreadPool：0核心数量，但是最大线程无限，适合于短期的大量短任务，60秒后会自动释放线程\n\npublic static ExecutorService newCachedThreadPool() &#123;    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                  60L, TimeUnit.SECONDS,                                  new SynchronousQueue&lt;Runnable&gt;());&#125;\n\n如果任务数量过多且执行速度较慢，可能会创建大量的线程，从而导致 OOM\nSynchronousQueue是一个继承了AQS的同步队列，没有容量，不存储元素。\n\nScheduledThreadPool：最大线程数也是无限，阻塞队列是DelayedWorkQueue也无界\n\npublic static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123;    return new ScheduledThreadPoolExecutor(corePoolSize);&#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123;    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,          new DelayedWorkQueue());&#125;\n\n线程池总结：\n\nSingleThreadExecutor、newFixedThreadPool、ScheduledThreadPool的阻塞队列都是无界的，如果请求堆积，容易引起OOM\nCachedThreadPool的阻塞队列虽然不存储元素，但是他的最大线程数无限，如果短期来了大量任务且执行时间长，也会出现OOM\n\n线程池用的阻塞队列总结：\n\nLinkedBlockingQueue，无界队列，如果任务堆积有可能OOM\nSynchronousQueue：同步队列，是AQS的实现，不存储元素\nDelayedWorkQueue：延迟阻塞队列，内部是一个堆，按照执行时间排序，会自动扩容，也是无界的\n\nThreadPoolExecutor核心数据结构核心数据结构是一个阻塞队列+Worker的hashset\nprivate final BlockingQueue&lt;Runnable&gt; workQueue; // 阻塞队列private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();// 线程池是一个hashSet// Worker就是一个线程\n\n\nworker就是一个继承了AQS、实现了Runnable接口的包裹了Thread的内部类：\nprivate final class Worker    extends AbstractQueuedSynchronizer // AQS    implements Runnable // Runnable&#123;    final Thread thread; // 线程final复用    Runnable firstTask; // 使用第一个任务来初始化Worker    volatile long completedTasks;    Worker(Runnable firstTask) &#123;        setState(-1); // 创建线程后的state状态是-1，不允许在初始化未完成前被中断        this.firstTask = firstTask;        // 使用线程工程        this.thread = getThreadFactory().newThread(this);    &#125;\t    public void run() &#123;        runWorker(this); // 调用ThreaPoolExecutor的runWorker执行    &#125;    // 下面都是通过AQS来加锁的方法，实现方式与AQS简单独占锁相同，此处省略    protected boolean isHeldExclusively() &#123;&#125;    protected boolean tryAcquire(int unused) &#123;&#125;    protected boolean tryRelease(int unused) &#123;&#125;    public void lock()        &#123; acquire(1); &#125;    public boolean tryLock()  &#123; return tryAcquire(1); &#125;    public void unlock()      &#123; release(1); &#125;    public boolean isLocked() &#123; return isHeldExclusively(); &#125;    void interruptIfStarted() &#123;        Thread t;        if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123;            try &#123;                t.interrupt();            &#125; catch (SecurityException ignore) &#123;            &#125;        &#125;    &#125;&#125;\n\nctl状态线程池使用一个AtomicInteger来控制状态，它包括两个概念workercount和runState\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\n\nworkercount：线程池最大数量是2^29-1（高三位表示状态）\nrunState：高三位表示状态\n\nprivate static final int COUNT_BITS = Integer.SIZE - 3; // 32 - 3 = 29private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;// Packing and unpacking ctlprivate static int runStateOf(int c)     &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c)  &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;\n\n线程池的状态有：\nprivate static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;// 不会接受新任务，但还会处理队列任务private static final int STOP       =  1 &lt;&lt; COUNT_BITS;// 不接受新任务，忽略队列任务private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;// 所有任务都已终止private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;// terminated()方法已经执行完成\n\n\nexecute方法public void execute(Runnable command) &#123;    if (command == null)        throw new NullPointerException();    int c = ctl.get();    // 当前数量小于核心线程    if (workerCountOf(c) &lt; corePoolSize) &#123;        if (addWorker(command, true)) // 参数为true，表示创建核心线程去执行任务            return;        c = ctl.get();    &#125;    // 如果线程池仍在运行，并且任务队列可以添加任务    if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;        int recheck = ctl.get();        // 如果线程池没有运行，就会移除刚增加的任务，并且拒绝        if (! isRunning(recheck) &amp;&amp; remove(command))            reject(command);        // 如果线程池没有线程，就启动一个新的非核心线程来处理        else if (workerCountOf(recheck) == 0)            addWorker(null, false);    &#125;    // 如果任务不能加入队列（可能是队列满了）那么使用非核心线程执行    else if (!addWorker(command, false))        reject(command);&#125;\n\naddWorker方法addWorker(command, true)：传入两个参数，分别是Runnable任务与bool，为true表示创建核心线程执行，为false表示创建非核心线程执行。\n\n创建新线程需要全局锁ReentrantLock\n\n详细代码如下：\nprivate boolean addWorker(Runnable firstTask, boolean core) &#123;    retry: // 这里还用了带标签的break方法    // 外层无限循环，用于在某些条件下重试添加工作线程    for (;;) &#123;        int c = ctl.get();  // 获取线程池的状态和当前工作线程数        int rs = runStateOf(c);  // 获取线程池的运行状态（如RUNNING, SHUTDOWN等）        // 只有在必要时才检查队列是否为空。        // 如果线程池已SHUTDOWN且队列非空，且没有传入任务，则返回false        if (rs &gt;= SHUTDOWN &amp;&amp;            ! (rs == SHUTDOWN &amp;&amp;               firstTask == null &amp;&amp;               ! workQueue.isEmpty()))            return false;        // 内层循环用于尝试增加工作线程计数，可能因竞争失败需要重试        for (;;) &#123;            int wc = workerCountOf(c);  // 获取当前的工作线程数            // 如果工作线程数超过限制（CAPACITY或核心线程数/最大线程数），则返回false            if (wc &gt;= CAPACITY ||                wc &gt;= (core ? corePoolSize : maximumPoolSize))                return false;            // 使用CAS操作尝试增加工作线程计数            if (compareAndIncrementWorkerCount(c))                break retry;  // 成功增加工作线程计数，退出外层循环            c = ctl.get();  // 如果CAS失败，重新获取ctl            // 如果在尝试期间线程池的运行状态发生了变化，重新尝试            if (runStateOf(c) != rs)                continue retry;  // 重新开始外层循环            // 否则，CAS因工作线程计数变化而失败，重新尝试内层循环        &#125;    &#125;    // 以下代码用于真正创建并启动工作线程    boolean workerStarted = false;  // 标记工作线程是否成功启动    boolean workerAdded = false;  // 标记工作线程是否成功添加    Worker w = null;  // Worker对象表示一个工作线程及其任务    try &#123;        w = new Worker(firstTask);  // 创建一个新的Worker对象，并绑定初始任务        final Thread t = w.thread;  // 获取Worker对应的线程对象        if (t != null) &#123;            final ReentrantLock mainLock = this.mainLock;            mainLock.lock();  // 获取主锁，确保线程池的一致性操作            try &#123;                // 在持有锁的情况下重新检查状态                // 如果线程池仍然在运行或是SHUTDOWN且没有初始任务，继续                int rs = runStateOf(ctl.get());                if (rs &lt; SHUTDOWN ||                    (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123;                    // 如果线程已经启动（不应该发生），抛出异常                    if (t.isAlive())                        throw new IllegalThreadStateException();                    workers.add(w);  // 将新Worker添加到工作线程集合中                    int s = workers.size();  // 获取当前工作线程集合的大小                    if (s &gt; largestPoolSize)  // 更新最大线程池大小                        largestPoolSize = s;                    workerAdded = true;  // 标记工作线程已成功添加                &#125;            &#125; finally &#123;                mainLock.unlock();            &#125;            if (workerAdded) &#123;                t.start();  // 启动工作线程！！！！                workerStarted = true;            &#125;        &#125;    &#125; finally &#123;        if (!workerStarted)            addWorkerFailed(w);  // 如果线程未启动成功，执行失败处理    &#125;    return workerStarted;  // 返回是否成功启动工作线程&#125;\n\n在addWorker里调用了t.start()方法，也就是调用worker的run方法！\nrunWorker方法worker是实现了Runnable接口的，在run方法中调用了runworker方法：\nfinal void runWorker(Worker w) &#123;    Thread wt = Thread.currentThread();    Runnable task = w.firstTask;    w.firstTask = null;    w.unlock(); // 将state从-1变为0，就可以支持中断了    boolean completedAbruptly = true;    try &#123;        while (task != null || (task = getTask()) != null) &#123;// 这里的getTask见下文            w.lock(); // aqs上锁            if ((runStateAtLeast(ctl.get(), STOP) ||                 (Thread.interrupted() &amp;&amp;                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;                !wt.isInterrupted())                wt.interrupt();            try &#123;                beforeExecute(wt, task); // 可以进行执行任务前的操作                Throwable thrown = null; // 执行额外操作可能会抛出异常                try &#123;                    task.run(); // 真正执行                &#125; catch (RuntimeException x) &#123;                    thrown = x; throw x;                &#125; catch (Error x) &#123;                    thrown = x; throw x;                &#125; catch (Throwable x) &#123;                    thrown = x; throw new Error(x);                &#125; finally &#123;                    afterExecute(task, thrown);                &#125;            &#125; finally &#123;                task = null;                w.completedTasks++;                w.unlock(); // aqs解锁            &#125;        &#125;        completedAbruptly = false;    &#125; finally &#123;        processWorkerExit(w, completedAbruptly);    &#125;&#125;\n\n\n w.unlock()：在创建完worker的时候，设置了state为-1（看构造函数），是为了防止在初始化未完成前被中断，这里unlock，解锁，将aqs的state变为0。此时就支持了被中断的能力\n\n getTask()：会获取当前阻塞队列的任务，也有判断线程是否销毁的逻辑\n\n  task.run();：真正执行run方法的位置\n\n\ngetTask方法下面看一下getTask，是如何获取队列任务，并且抛出异常的：\n\nallowCoreThreadTimeOut：是否允许核心线程过期？可以设置这个值，让核心线程也去销毁\nworkQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)：在keepAliveTime时间内阻塞，除非获取到元素\nworkQueue.take()：一直阻塞，直到可以获取出数据\n\n\n线程是如何超时被销毁的？\n\n在getTask方法中通过workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)获取任务，如果任务为空，就标记超时为true，在下一次循环中就会销毁线程\nprivate Runnable getTask() &#123;    boolean timedOut = false; // 标记上一次poll()是否超时    for (;;) &#123; // 无限循环，直到获取到任务或决定终止线程        int c = ctl.get();        int rs = runStateOf(c);        // 如果线程池处于SHUTDOWN或更高状态，并且队列为空或池状态至少为STOP        if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123;            decrementWorkerCount(); // 减少工作线程计数            return null; // 返回null，表示没有任务，线程将退出        &#125;        int wc = workerCountOf(c);        // 判断工作线程是否需要根据超时策略进行回收        boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;        // （如果工作线程数大于最大线程数 或（线程允许超时且上次操作超时））且 （当前有多于1个工作线程或队列为空）        if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))            &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123;            // 尝试减少工作线程计数            if (compareAndDecrementWorkerCount(c))                return null; // 返回null，表示线程将退出            continue; // 如果未能成功减少工作线程计数，重新尝试        &#125;                try &#123;            // 根据是否允许超时，决定从队列中获取任务的方式            Runnable r = timed ?                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : // 带超时的poll                workQueue.take(); // 阻塞式获取任务            if (r != null)                return r; // 如果获取到任务，返回任务            timedOut = true; // 如果poll超时且未获取到任务，标记为超时        &#125; catch (InterruptedException retry) &#123;            timedOut = false; // 如果线程被中断，重置超时标记，并重新尝试获取任务        &#125;    &#125;&#125;\n\n线程池的关闭问题线程池有shutdown()和shutdownNow()方法，原理是遍历线程池中规定工作线程，然后逐个调用线程的interrupt方法来中断。\n\nshutdown：不会立即停止，会停止接受外部任务，等待队列的任务执行完成后，才停止\nshutdownNow：停止接受任务，忽略队列等待的任务，尝试中断正在执行的任务（不一定会立马停止）\n\n线程池总结\nThreadPoolExecutor的结构：\n一个AtomicInteger的状态，高3bit表示线程池状态，低29位表示当前线程池数量\n一个HashSet&lt;Worker&gt;，线程池存储线程使用了一个set\nBlockingQueue&lt;Runnable&gt;，任务的阻塞队列\nWorker：其内部有一个线程，还是一个继承了AQS，实现了Runnable接口的类，既可以保证自己给自己加锁，又能执行任务，他的run方法的实现调用了runWorker方法，\n\n\n调用链路：ThreaPoolExecutor中的executor方法-&gt;addWorker方法-&gt;getTask获取任务\nexecutor(Runnable command)方法：根据不同逻辑（核心线程数量与当前线程数量的关系），调用addWorker方法\naddWorker方法：addWorker负责Worker的线程的创建逻辑，创建时会以ReentrantLock加锁的逻辑，线程由线程工厂创建，创建完成后，将worker添加到set内，最后会执行t.start()方法，也就是执行了run方法，也就是执行了runWorker方法。\nrunWorker方法：runWorker方法真正调用了任务的run方法，并且可以添加一些前后的处理逻辑，执行时后不断调用getTask方法获取任务，执行任务时，使用worker的AQS lock与unlock方法进行加锁。\ngetTask方法：获取阻塞队列的任务，主要通过两个方法poll与take，poll中有保活时间，如果获取到的任务为null，说明当前线程空闲，下一次循环就会被销毁。而且还可以设置allowCoreThreadTimeOut为true，核心线程也会在空闲时被销毁。\n\n\n\n简而言之：线程池的工作流程是，在任务传入后，调用executor方法，executor方法会判断线程数与核心线程数的关系，考虑是否创建Worker，创建Worker调用addWorker方法，创建后会将Worker放入线程池set内，然后执行线程的start方法，由于Worker实现了Runnable接口，重写了run方法，也就是调用了runWorker方法，runWorker方法会不断的调用getTask获取任务，getTask方法通过阻塞队列的poll与take方法获取任务，其中poll方法有保活时间，如果保活时间内都没有获取到任务，说明当前线程空闲，就会被销毁。\n相关链接\n狂神说JUC编程\n大佬猿人谷blog\n敖丙ThreadLocal\n我自己的博客\n敖丙锁升级\nRedSpider社区\n\n","categories":["JUC"],"tags":["JUC","锁"]}]